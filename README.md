# ML_news_private

this is just a placeholder, the organized and correct repository is [here](https://github.com/SalvatoreRa/ML-news-of-the-week)

# scheme

# ML news: 

## Research
|Link|description|
|---|---|
|[.]() | |
|[.]() | |
|[.]() | |

## News
|Link|description|
|---|---|
|[.]() | |
|[.]() | |
|[.]() | |


## Resources
|Link|description|
|---|---|
|[.]() | |
|[.]() | |
|[.]() | |

## Perspectives
|Link|description|
|---|---|
|[.]() | |
|[.]() | |
|[.]() | |

# ON WORKING

# ML news: 

## Research
|Link|description|
|---|---|
|[Introducing Chai-1: Decoding the molecular interactions of life.](https://www.chaidiscovery.com/blog/introducing-chai-1) |A novel multi-modal foundation model for predicting molecular structures, capable of handling proteins, small molecules, DNA, RNA, and more. It delivers state-of-the-art performance across various tasks in drug discovery, achieving a 77% success rate on the PoseBusters benchmark (compared to 76% by AlphaFold 3) and a Cα LDDT score of 0.849 on the CASP15 protein monomer structure prediction set (outperforming ESM3-98B’s 0.801). |
|[Knowing When to Ask - Bridging Large Language Models and Data.](https://docs.datacommons.org/papers/DataGemma-FullPaper.pdf) |It incorporates a series of fine-tuned Gemma 2 models to enable LLMs to access and utilize numerical and statistical data effectively. A new method called Retrieval Interleaved Generation (RIG) is introduced, allowing LLMs to reliably integrate public statistical data from Data Commons into their responses. RIG, a tool-based approach, interleaves statistical tokens with natural language queries for optimal retrieval from Data Commons. To achieve this, the LLM is fine-tuned on an instruction-response dataset created with the assistance of Gemini 1.5. This RIG technique enhances factual accuracy from 5-7% to approximately 58%. |
|[Agent Workflow Memory.](https://arxiv.org/abs/2409.07429) |It introduces Agent Workflow Memory to capture and provide commonly reused workflows to the agent as needed, guiding the agent's future generations. This mechanism operates both offline and online, drawing inspiration from how humans learn and reuse workflows from past experiences to inform future actions. It reportedly boosts performance, improving baseline results by 24.6% and achieving a 51.1% relative success rate on Mind2Web and WebArena, all while being more efficient. |
|[LLaMA-Omni: Seamless Speech Interaction with Large Language Models.](https://arxiv.org/abs/2409.06666) |A model architecture designed for low-latency speech interaction with LLMs, built on Llama-3.1-8B-Instruct, which can simultaneously generate both text and speech responses from speech instructions. It achieves response latency as low as 226ms. The architecture includes a speech encoder (Whisper-large-v3), a speech adaptor, an LLM, and a speech decoder. Additionally, they developed a dataset of 200,000 speech interactions and responses to support the model's training. |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |

## News
|Link|description|
|---|---|
|[Data center emissions probably 662% higher than big tech claims. Can it keep up the ruse?](https://www.theguardian.com/technology/2024/sep/15/data-center-gas-emissions-tech) |Emissions from in-house data centers of Google, Microsoft, Meta and Apple may be 7.62 times higher than official tally |
|[North Korean hackers target Python devs with malware disguised as coding tests — hack has been underway for a year.](https://www.tomshardware.com/tech-industry/cyber-security/python-developers-targeted-by-north-korean-lazarus-group-with-fake-jobs-and-malware-disguised-as-coding-tests) | Fake Python job opportunities used to attack programmers|
|[Sam Altman told OpenAI staff the company’s non-profit corporate structure will change next year.](https://fortune.com/2024/09/13/sam-altman-openai-non-profit-structure-change-next-year/) |OpenAI asserts that it has surpassed its current organizational structure and is now striving to simplify it, making it more appealing to potential investors. |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |

## Resources
|Link|description|
|---|---|
|[What is the Role of Small Models in the LLM Era: A Survey.](https://arxiv.org/abs/2409.06857) |It closely explores the connection between LLMs and SLMs, highlighting common applications of SLMs such as data curation, enhancing model training, improving inference efficiency, serving as evaluators, retrievers, and more. The study provides valuable insights for practitioners, helping them better grasp the importance and utility of SLMs. |
|[Theory, Analysis, and Best Practices for Sigmoid Self-Attention.](https://arxiv.org/abs/2409.04431) |It introduces Flash-Sigmoid, a hardware-optimized, memory-efficient implementation of sigmoid attention, offering up to a 17% speed-up in inference kernels compared to FlashAttention-2 on H100 GPUs. The results demonstrate that SigmoidAttn performs on par with SoftmaxAttn across various tasks and domains. |
|[Achieving Peak Performance for Large Language Models: A Systematic Review.](https://arxiv.org/abs/2409.04833) |A comprehensive review of techniques for enhancing and accelerating LLMs from three perspectives: training, inference, and system serving. It provides an overview of the latest optimization and acceleration strategies, covering advancements in training methods, hardware utilization, scalability, and system reliability. |
|[Grounding AI in reality with a little help from Data Commons.](https://research.google/blog/grounding-ai-in-reality-with-a-little-help-from-data-commons/) |Google has introduced Retrieval-Augmented and Retrieval-Interleaved Generation through Gemma 2, enhancing these techniques with access to numerous external data sources. This guide focuses on the fine-tuning process. |
|[AudioBERT: Audio Knowledge Augmented Language Model.](https://arxiv.org/abs/2409.08199v1) |AuditoryBench is a newly developed dataset designed to evaluate auditory knowledge and understanding in language models. |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |

## Perspectives
|Link|description|
|---|---|
|[What’s so funny about getting an AI app to give you a roasting?](https://www.theguardian.com/technology/article/2024/sep/15/whats-so-funny-about-getting-an-ai-app-to-give-you-a-roasting) |Roasting can be really brutal, but at least if we inflict it on ourselves, we can get ahead of the joke |
|[Artificial intelligence will affect 60 million US and Mexican jobs within the year.](https://english.elpais.com/economy-and-business/2024-09-15/artificial-intelligence-will-affect-60-million-us-and-mexican-jobs-within-the-year.html) |IDB study shows the impact that AI will have on the labor market. Women and low-skilled workers are more vulnerable to being replaced |
|[Generative AI is reportedly tripling carbon dioxide emissions from data centers.](https://www.techradar.com/pro/generative-ai-triples-the-carbon-dioxide-emissions-from-data-centers) | Research suggest data centers will emit 2.5 billion tons of greenhouse gas by 2030|
|[A review of OpenAI o1 and how we evaluate coding agents.](https://www.cognition.ai/blog/evaluating-coding-agents) |Devin, an AI coding agent, was tested using OpenAI's new o1 models, demonstrating enhanced reasoning and error diagnosis capabilities compared to GPT-4o. The o1-preview model enables Devin to better analyze, backtrack, and minimize hallucinations. Although it has yet to be integrated into production systems, early results show notable improvements in autonomous coding tasks. |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |

# ML news: Week 9 - 15 September

## Research
|Link|description|
|---|---|
|[De novo design of high-affinity protein binderswith AlphaProteo.](https://storage.googleapis.com/deepmind-media/DeepMind.com/Blog/alphaproteo-generates-novel-proteins-for-biology-and-health-research/AlphaProteo2024.pdf) |demonstrates a family of machine learning models that have been trained for protein design; reports 3-to 300-fold improvements in binding affinities and higher experimental success rates when compared to other methods on seven target proteins; demonstrates that AlphaProteo's performance is similar to the seven targets when tested on hundreds of target proteins from the PDB.  |
|[In Defense of RAG in the Era of Long-Context Language Models.](https://arxiv.org/abs/2409.01666) |reports that one of the main problems that a RAG system addresses (i.e., uses more relevant information) is that longer-context LLMs suffer from a diminished focus on relevant information. They suggest an order-preserving RAG mechanism that enhances performance on long-context question answering, but it's not perfect—in fact, the quality of responses increases and then declines as retrieved chunks increase. They also mention a sweet spot where it can achieve better quality with a lot fewer tokens than long-context LLMs. |
|[Strategic Chain-of-Thought: Guiding Accurate Reasoning in LLMs through Strategy Elicitation.](https://arxiv.org/abs/2409.03271v1) | a technique to improve LLM performance by adding strategic information prior to the intermediate CoT reasoning phases; the strategy for addressing problems aids in directing the creation of the CoT paths and solutions; promises to use the Llama3-8b model to get a 21.05% gain on the GSM8K datasets.|
|[The Effects of Generative AI on High Skilled Work: Evidence from Three Field Experiments with Software Developers.](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4945566) |Examines the effects of generative AI on software developers, highlighting a 26.08% rise in completed tasks among developers utilizing AI tools such as GitHub Copilot. Additionally, it indicates that less experienced developers are more inclined to adopt AI tools and experience significant productivity improvements. |
|[LongCite: Enabling LLMs to Generate Fine-grained Citations in Long-context QA.](https://arxiv.org/abs/2409.02897) |Creates a large-scale supervised fine-tuning (SFT) dataset using off-the-shelf large language models (LLMs) to enhance long-context question answering with citations. The training focuses on 8B and 9B parameter models, improving their ability to generate citations from extended contexts while enhancing response accuracy. It claims to outperform GPT-4o on their proposed LongBench-Cite benchmark. |
|[MemLong: Memory-Augmented Retrieval for Long Text Modeling.](https://arxiv.org/abs/2408.16967) |Employs an external retriever to gather historical information, enhancing the performance of long-context large language models (LLMs). It consistently surpasses other state-of-the-art LLMs on long-context benchmarks and can extend context length from 4k to 80k on a single 3090 GPU. |
|[Pandora's Box or Aladdin's Lamp: A Comprehensive Analysis Revealing the Role of RAG Noise in Large Language Models.](https://arxiv.org/abs/2408.13533) | Introduces a benchmark, NoiserBench, to assess how various types of noisy information impact the performance of retrieval-augmented generation (RAG) models. The study reveals that, among different beneficial noise types (e.g., semantic, datatype, and illegal sentence), illegal sentence noise leads to the greatest performance improvement across models and datasets.|
|[Beyond Preferences in AI Alignment.](https://arxiv.org/abs/2408.16984) | Critiques the prevailing AI alignment method of human preference tuning, highlighting how it fails to grasp the rich, nuanced content of human values. The argument is made that AI alignment requires a reframing, suggesting that instead of aligning with individual human preferences, AI systems should align with normative standards relevant to their societal roles.|
|[Planning In Natural Language Improves LLM Search For Code Generation.](https://arxiv.org/abs/2409.03733) |Obtaining a variety of candidate solutions is one of the difficulties in code creation. Even repeated sampling frequently falls short of producing enough originality to address an issue. But if you start with a natural language plan and generate ideas for potential solution paths, the resulting generation is much more varied and diverse, which leads to better solutions for code creation. |
|[Imitating Language via Scalable Inverse Reinforcement Learning.](https://arxiv.org/abs/2409.01369) |Modern language modeling can largely be viewed as a specialized form of imitation learning, which benefits from extensive research in the broader field. This paper investigates the application of inverse reinforcement learning to mimic entire sequences rather than individual tokens. The findings are encouraging and suggest that reinforcement learning could play an increasingly important role in the training pipelines of language models moving forward. |
|[Can LLMs Generate Novel Research Ideas? A Large-Scale Human Study with 100+ NLP Researchers.](https://arxiv.org/abs/2409.04109) | This longitudinal study evaluated the abilities of 100 NLP researchers to generate and review novel ideas. The findings revealed that while LLMs were able to produce more innovative ideas, these ideas were slightly less practical compared to those created by human researchers.|
|[Superhuman Automated Forecasting.](https://www.safe.ai/blog/forecasting) |The Safe AI Institute has published research on a system capable of surpassing human experts in forecasting accuracy. |
|[The AdEMAMix Optimizer: Better, Faster, Older.](https://arxiv.org/abs/2409.03137) | This paper from Apple introduces an alternative to the traditional exponential moving average optimization method, incorporating contributions from older gradients to significantly enhance learning convergence.|
|[DiverGen: Improving Instance Segmentation by Learning Wider Data Distribution with More Diverse Generative Data.](https://arxiv.org/abs/2405.10185v1) | DiverGen is an innovative approach for generating datasets to improve instance segmentation models. Instead of relying on expensive manual annotations, it leverages generative models to create diverse data, helping to mitigate overfitting and boost model performance.|
|[Policy Filtration in RLHF to Fine-Tune LLM for Code Generation.](https://arxiv.org/abs/2409.06957v1) |Policy Filtration for Proximal Policy Optimization (PF-PPO) is a technique aimed at enhancing the precision of reinforcement learning from human feedback (RLHF), specifically in the context of code generation tasks. |
|[Data Augmentation via Latent Diffusion for Saliency Prediction.](https://arxiv.org/abs/2409.07307v1) | Researchers have introduced a novel data augmentation technique to enhance saliency prediction models, which have historically struggled due to the scarcity of labeled data.|


## News
|Link|description|
|---|---|
|[Google using anti-competitive tactics in UK ad market, claims watchdog.](https://www.theguardian.com/technology/article/2024/sep/06/google-competition-uk-ad-market-cma) | CMA says tech company has ‘abused its dominant position’ to the detriment of publishers and advertisers|
|[Apple to unveil iPhone 16 and ‘Apple Intelligence’ AI features.](https://www.theguardian.com/technology/article/2024/sep/09/apple-ai-iphone-16) |Apple watchers also expect new colors for the iPhone at the annual launch event, this year titled ‘It’s Glowtime’ |
|[TSMC's $65 billion Arizona facility can now match Taiwan production yields according to early trials.](https://www.techspot.com/news/104622-tsmc-arizona-facility-matches-taiwan-production-yields-early.html) |he US is committed to establishing semiconductor manufacturing within its borders, and perhaps no effort is more crucial to this goal than TSMC's three-fab facility in Arizona. The government is pouring billions into the development, alongside TSMC's $65 billion investment. |
|[AI Firm’s Misconfigured Server Exposed 5.3 TB of Mental Health Records.](https://hackread.com/ai-firm-misconfigured-server-exposed-mental-health-data/) |A misconfigured server from a US-based AI healthcare firm Confidant Health exposed 5.3 TB of sensitive mental health records, including personal details, assessments, and medical information, posing serious privacy risks for patients. |
|[California’s big AI regulation bill is headed to Gavin Newsom.](https://calmatters.org/economy/technology/2024/08/ai-safety-bill-california-legislature/) |A California bill requiring makers of large AI systems to test them for potential harm cleared the Legislature today. It could still face a veto by Gov. Gavin Newsom. |
|[Google search monopoly US case remedies to come by December.](https://www.reuters.com/legal/google-search-monopoly-case-remedies-come-by-december-2024-09-06/) |The U.S. Department of Justice plans to issue an outline by December on what Alphabet's, must do to restore competition after a judge earlier found the company illegally monopolized the market for online search, prosecutors said at a court hearing in Washington on Friday. |
|[Intel reveals first Lunar Lake laptop CPUs: everything you need to know.](https://www.theverge.com/2024/9/3/24233957/intel-lunar-lake-core-ultra-200v-launch) |Previously known as Lunar Lake, Intel has introduced its Core Ultra 200V portfolio, which features competitive integrated GPUs for tiny notebooks, fast CPUs, and enhanced AI capabilities. The CPUs have 32GB RAM capacity, eight CPU cores, integrated memory, and improved efficiency. Prominent producers such as Acer, Asus, Dell, and HP will introduce laptops equipped with these novel CPUs. Reviews to support Intel's assertions are still pending. |
|[OpenAI, Still Haunted by Its Chaotic Past, Is Trying to Grow Up.](https://www.nytimes.com/2024/09/03/technology/openai-chatgpt-revenue.html?unlocked_article_code=1.H04.oIwg.zLvnRVHOKpNH&smid=url-share) |In order to draw in significant investors such as Microsoft, Apple, and Nvidia, OpenAI is reorganizing its management and organization with the goal of reaching a $100 billion valuation. Internal disagreements within the organization regarding its safety procedures and objectives have resulted in a high employee turnover rate, with important researchers leaving to work for competitors such as Anthropic. OpenAI struggles to strike a balance between business goals and moral considerations while developing AI technology, despite increasing income and user base growth. |
|[BP extends use of AI in five-year deal with spy tech firm Palantir.](https://www.theguardian.com/business/article/2024/sep/09/bp-ai-deal-palantir-oil-gas-artificial-intelligence) |Oil and gas company to use artificial intelligence to speed up decision-making by engineers |
|[Google’s second antitrust suit brought by US begins, over online ads.](https://www.theguardian.com/technology/article/2024/sep/09/google-antitrust-lawsuit-online-ads) |DoJ accused tech giant of more monopolistic behavior a month after judge found it illegally cornered online search |
|[What is Apple Intelligence, when is it coming and who will get it?](https://techcrunch.com/2024/09/09/what-is-apple-intelligence-when-is-coming-and-who-will-get-it/) | At WWDC 2024, Apple unveiled Apple Intelligence, a platform designed to integrate AI capabilities into existing applications like Mail, Messages, and Siri. Utilizing large language models, it supports functions such as text summarization and image generation, all aimed at enhancing the user experience. A beta version will be available in the U.S. starting this October, with plans to expand globally in 2025.|
|[New open source AI leader Reflection 70B’s performance questioned, accused of ‘fraud’.](https://venturebeat.com/ai/new-open-source-ai-leader-reflection-70bs-performance-questioned-accused-of-fraud/) |HyperWrite's Reflection 70B, a variant of Meta's Llama 3.1 LLM, is under scrutiny after independent evaluators were unable to reproduce its advertised performance. The problems were traced back to corrupted model weights during the upload to Hugging Face, causing inconsistencies. The AI community is now awaiting further clarifications and updates to better understand the model's true capabilities. |
|[The new Shortwave AI Assistant.](https://www.shortwave.com/blog/new-shortwave-ai-email-assistant/) | Shortwave has substantially enhanced its AI Assistant, equipping it to handle complex, multi-step tasks like advanced searches, calendar lookups, and in-depth email analysis, making it more versatile and powerful in managing user tasks.|
|[OpenAI might use Apple’s TSMC for chips.](https://www.computerworld.com/article/3502761/openai-might-use-apples-tsmc-for-chips.html) | OpenAI could greatly lower operational costs by adopting more efficient chips, which would be particularly beneficial as its user base continues to expand, allowing for better scalability and resource management.|
|[Apple takes direct aim at Microsoft’s Copilot+ PCs in new AI-focused Mac promos.](https://9to5mac.com/2024/09/06/microsoft-copilot-pcs-apple-mac/) |Apple is actively marketing the Mac as the "best AI PC," positioning it as a direct competitor to Microsoft's Copilot+ PCs. This strategic push highlights Apple's focus on integrating AI capabilities into its devices, aiming to challenge Microsoft's AI-driven offerings in the PC market. |
|[GPT-fabricated scientific papers on Google Scholar: Key features, spread, and implications for preempting evidence manipulation.](https://misinforeview.hks.harvard.edu/article/gpt-fabricated-scientific-papers-on-google-scholar-key-features-spread-and-implications-for-preempting-evidence-manipulation/) |Generative AI tools, such as ChatGPT, are increasingly generating fraudulent research papers that are finding their way into databases like Google Scholar, mixing with legitimate studies. These papers, frequently addressing sensitive topics like health and the environment, threaten the integrity of science and public trust. Strengthened oversight and improved filtering mechanisms in academic search engines are crucial to addressing this rising concern. |
|[Apple announces its new A18 and A18 Pro iPhone chips.](https://techcrunch.com/2024/09/09/apple-announces-its-new-a18-iphone-chip/) |At its "Glowtime" event, Apple introduced the A18 and A18 Pro chips, highlighting substantial CPU and GPU upgrades compared to the A16 Bionic. The A18 Pro offers increased memory bandwidth and improved image processing. Both chips come equipped with advanced AI capabilities, with the A18 Pro specifically enhancing on-device model performance and thermal design for a superior gaming experience. |
|[AMD announces unified UDNA GPU architecture — bringing RDNA and CDNA together to take on Nvidia's CUDA ecosystem.](https://www.tomshardware.com/pc-components/cpus/amd-announces-unified-udna-gpu-architecture-bringing-rdna-and-cdna-together-to-take-on-nvidias-cuda-ecosystem) |At IFA 2024, AMD revealed plans to merge its RDNA and CDNA architectures into a unified UDNA microarchitecture, positioning itself to compete more effectively with Nvidia's CUDA ecosystem. This strategic shift is aimed at simplifying development and strengthening AMD's foothold in the AI and high-performance computing (HPC) markets. The move to UDNA marks a significant transition, with full-scale adoption anticipated after the release of the RDNA 4 generation. |
|[Waymo Giving 100,000 Robotaxi Rides Per Week But Not Making Any Money.](https://futurism.com/the-byte/waymo-not-profitable) | Waymo is now delivering over 100,000 paid autonomous rides per week in San Francisco, Phoenix, and Los Angeles, a figure that has doubled since May. Despite this growth, the company remains unprofitable, with Google’s experimental division facing a $2 billion operating loss. The high costs of vehicles and city mapping, along with ongoing public hesitation, continue to hinder Waymo's journey to profitability.|
|[iOS 18.1 with Apple Intelligence launches in October, more languages rolling out over time.](https://9to5mac.com/2024/09/09/ios-18-1-apple-intelligence-languages-october/) |Apple announced that Apple Intelligence will launch in beta with iOS 18.1 in October, initially available exclusively for US English users. |
|[Bringing generative AI to video with Adobe Firefly Video Model.](https://blog.adobe.com/en/publish/2024/09/11/bringing-gen-ai-to-video-adobe-firefly-video-model-coming-soon) |Adobe's Firefly Video Model introduces AI-driven tools to video editing programs such as Premiere Pro. Set to launch in beta later this year, the model provides editors with improved workflows, enabling them to experiment with creative concepts, fill gaps in timelines, and incorporate new elements into their videos. |
|[Mistral releases Pixtral 12B, its first multimodal model.](https://techcrunch.com/2024/09/11/mistral-releases-pixtral-its-first-multimodal-model/) |French AI startup Mistral has introduced Pixtral 12B, a multimodal model with 12 billion parameters designed to handle both images and text. The model, accessible through GitHub and Hugging Face, can be fine-tuned and is available under the Apache 2.0 license. This release comes after Mistral secured $645 million in funding, strengthening its role as a key player in Europe's AI industry. |
|[Elon Musk says Tesla has ‘no need’ to license xAI models.](https://techcrunch.com/2024/09/08/elon-musk-says-tesla-has-no-need-to-license-xai-models/) |Elon Musk has refuted claims that Tesla will share revenue with his AI startup xAI in exchange for using its AI models. He explained that while Tesla has gained from xAI engineers' expertise, it doesn't need to license xAI's models. Musk also noted that xAI's large models are incompatible with Tesla's vehicle computers. |
|[Apple is thinking about a rival to Meta Ray-Ban glasses.](https://www.androidauthority.com/apple-non-ar-smart-glasses-meta-glasses-3479479/) | |
|[OpenAI in talks to raise funds at $150B valuation, Bloomberg says.](https://www.tipranks.com/news/the-fly/openai-in-talks-to-raise-funds-at-150b-valuation-bloomberg-says) |Apple might be developing non-AR smart glasses, positioning them as potential competitors to Meta's $299 Ray-Ban glasses, which also lack AR functionality. Meta's glasses come equipped with features like a camera and an AI chatbot. By excluding AR capabilities, Apple's glasses could be more affordable, lighter, and have improved battery life due to reduced complexity. |
|[Meta fed its AI on almost everything you’ve posted publicly since 2007.](https://www.theverge.com/2024/9/12/24242789/meta-training-ai-models-facebook-instagram-photo-post-data) |Unless you’re in the EU, there’s no ability to opt out of AI training settings that keep Facebook or Instagram posts public. |
|[Google is using AI to make fake podcasts from your notes.](https://www.theverge.com/2024/9/11/24242138/google-notebook-llm-ai-fake-podcasts-research) |Google’s NotebookLM app can now generate ‘lively’ audio discussions with two AI hosts about the documents you’ve given it. |
|[Introducing OpenAI o1-preview.](https://openai.com/index/introducing-openai-o1-preview) |OpenAI has launched its latest model, designed to think carefully before responding. It was trained using reasoning processes, allowing it to take time to deliberate before providing an answer. This approach has resulted in superhuman performance in certain areas. Initially, users will be limited to around 30 queries per week, though OpenAI plans to remove this restriction in the near future. |
|[Google is now rolling out Gemini Live to free users on Android.](https://9to5google.com/2024/09/12/gemini-live-android-free-users/) | Google is launching Gemini Live, its conversational AI tool, to all free Android users following a month of early access for advanced users. With this feature, users can interrupt responses to provide new information and receive text transcripts of their conversations. While extensions like Gmail are not yet supported, Gemini Live introduces ten new voice options, with additional features expected to be added soon.|
|[Sergey Brin says he’s working on AI at Google ‘pretty much every day’.](https://techcrunch.com/2024/09/10/sergey-brin-says-hes-working-at-google-pretty-much-every-day-on-ai/) |Google co-founder and ex-Alphabet president Sergey Brin said he’s back working at Google “pretty much every day” because he hasn’t seen anything as exciting as the recent progress in AI — and doesn’t want to miss out. |
|[Amazon starts testing ads in its Rufus chatbot.](https://techcrunch.com/2024/09/11/amazon-starts-testing-ads-in-its-rufus-chatbot/) |Amazon's shopping chatbot, Rufus, will soon incorporate sponsored ads, displaying them based on the user's search queries and the context of their conversations. |


## Resources
|Link|description|
|---|---|
|[OLMoE: Open Mixture-of-Experts Language Models.](https://arxiv.org/abs/2409.02060) |Presents a fully open large language model (LLM) that utilizes a sparse Mixture-of-Experts approach. OLMoE is a 7B parameter model with 1B active parameters per input token. An instruction-tuned version is also available, which reportedly surpasses the performance of Llama-2-13B-Chat and DeepSeekMoE 16B. |
|[Large Language Model-Based Agents for Software Engineering: A Survey.](https://arxiv.org/abs/2409.02977) |A survey paper on large language model (LLM)-based agents in software engineering, offering insights across various areas such as requirements engineering, test generation, and software maintenance. |
|[DepthCrafter: Generating Consistent Long Depth Sequences for Open-world Videos.](https://arxiv.org/abs/2409.02095) |Researchers were able to produce very accurate depth information without requiring any camera posture or optical flow information by using Stable Diffusion video as a prior model. |
|[SmileyLlama: Modifying Large Language Models for Directed Chemical Space Exploration.](https://arxiv.org/abs/2409.02231) |Using DPO style data and supervised fine-tuning on open-source language models, LLMs can be trained to produce compounds with intriguing features for potential medicinal development. |
|[Running a LLM on the ESP32.](https://github.com/DaveBben/esp32-llm) |This code demonstrates how to execute a small language model on an Arduino board, showcasing the process of deploying and running AI models on resource-constrained hardware. |
|[DocAI.](https://github.com/madisonmay/docai) |This is another example of effectively leveraging existing models to extract structured information from documents, demonstrating the innovative use of pre-trained AI models to automate data extraction tasks efficiently. |
|[FluxMusic.](https://github.com/feizc/FluxMusic) |Text-to-music generation using a rectified flow transformer involves converting text inputs into musical compositions by utilizing a model that combines transformer architectures with rectified flow techniques. This approach enhances the model's ability to generate coherent and diverse music sequences based on textual descriptions. |
|[iText2KG: Incremental Knowledge Graphs Construction Using Large Language Models.](https://github.com/AuvaLab/itext2kg) | iText2KG is a Python package that leverages large language models to extract entities and relationships from text, progressively constructing consistent knowledge graphs. This tool automates the process of transforming unstructured text into structured knowledge, allowing for the incremental growth of comprehensive knowledge graphs.|
|[Multimodal RAG using ColPali (with Byaldi) and Qwen2-VL.](https://github.com/merveenoyan/smol-vision/blob/main/ColPali_%2B_Qwen2_VL.ipynb) | Merve has created a great resource for using language and vision models to improve retrieval.|
|[Awesome-Text2X-Resources.](https://github.com/ALEEEHU/Awesome-Text2X-Resources) | This is an open collection of state-of-the-art (SOTA) and novel Text-to-X methods (where X can represent any output, such as images, audio, or 3D models). The collection includes papers, code, and datasets, aimed at staying up-to-date with the expected surge in research developments in this area over the coming months.|
|[Qihoo-T2X: An Efficiency-Focused Diffusion Transformer via Proxy Tokens for Text-to-Any-Task.](https://arxiv.org/abs/2409.04005v1) | The Proxy Token Diffusion Transformer optimizes diffusion transformers by minimizing redundant computations, employing a reduced set of representative tokens for attention processing. This approach enhances efficiency while maintaining model performance.|
|[UniDet3D: Multi-dataset Indoor 3D Object Detection.](https://arxiv.org/abs/2409.04234v1) |UniDet3D is a robust 3D object detection model designed to operate across multiple indoor datasets, delivering strong performance in identifying and detecting objects in three-dimensional spaces. |
|[Starst3r.](https://github.com/phuang1024/Starst3r) |This innovative tool leverages Mast3r along with smart optimizations to efficiently reconstruct 3D scenes from just a few 2D images, offering impressive results with minimal input. |
|[simple_tma.](https://github.com/kuterd/opal_ptx/blob/master/notebooks/simple_tma.ipynb) | Image processing and cropping that can be run on the GPU.|
|[Lexicon3D.](https://yunzeman.github.io/lexicon3d/) |In a recent study comparing seven visual encoding models for 3D scene understanding, researchers found that the most effective model varied based on the specific task. DINOv2 emerged as the top performer overall, while video models excelled in object-level tasks, and diffusion models outperformed others in geometric tasks. Surprisingly, models pretrained on language showed notable limitations in this context. |
|[One-DM:One-Shot Diffusion Mimicker for Handwritten Text Generation.](https://github.com/dailenson/one-dm) |The One-DM model generates handwritten text that can imitate any style using only a single sample as reference. This approach allows for highly personalized handwriting generation with minimal input data. |
|[optillm.](https://github.com/codelion/optillm) | Optillm assists in optimizing prompts by utilizing various well-established research algorithms, including Monte Carlo Tree Search, Z3 solvers, and Self Consistency, to improve performance.|
|[Train Till You Drop: Towards Stable and Robust Source-free Unsupervised 3D Domain Adaptation.](https://github.com/valeoai/ttyd) | Researchers tackled the challenge of source-free unsupervised domain adaptation for 3D semantic segmentation by implementing regularization techniques and proposing a new criterion to improve adaptation performance.|
|[Memory-Efficient Optical Flow.](https://arxiv.org/abs/2409.04243v1) | HCVFlow is a newly developed memory-efficient optical flow method designed to address the high computational demands of all-pairs cost volumes in high-resolution images.|
|[Concept Sliders: LoRA Adaptors for Precise Control in Diffusion Models.](https://sliders.baulab.info/) | Concept Sliders offer a powerful mechanism for controlling the output of diffusion models. Recent efforts have been made to integrate them with the new Flux suite of models, enhancing their functionality and adaptability.|
|[Minifying HTML for GPT-4o: Remove all the HTML Tags.](https://blancas.io/blog/html-minify-for-llm/) |Converting HTML to plain text can significantly reduce costs with minimal performance loss in GPT-4o for data extraction tasks. Tests on the Mercury Prize dataset demonstrated that GPT-4o performs effectively even without the HTML structure, and GPT-4o mini offers a cost-efficient solution for handling unstructured questions. For structured extraction tasks, it's advisable to test both versions to find the right balance between cost and accuracy. |
|[Prompt2Fashion: An automatically generated fashion dataset.](https://arxiv.org/abs/2409.06442v1) |This dataset, created with large language models, curates outfit recommendations for various occasions, styles, and body types, providing high-quality and relevant suggestions. |
|[Sources of Uncertainty in 3D Scene Reconstruction.](https://arxiv.org/abs/2409.06407v1) |Researchers are improving 3D scene reconstruction techniques such as Neural Radiance Fields (NeRFs) and 3D Gaussian Splatting (GS) by incorporating uncertainty estimation methods. Although these approaches produce high-quality renders, they face challenges in addressing uncertainties caused by noise, occlusions, and camera inaccuracies. |
|[🦙🎧 LLaMA-Omni: Seamless Speech Interaction with Large Language Models.](https://github.com/ictnlp/LLaMA-Omni) | Llama Omni is a speech input-output model built on Llama 3.1 8B, designed to operate with extremely low latency while maintaining high-quality responses.|
|[AWS AI Stack.](https://github.com/serverless/aws-ai-stack) | This ready-to-use, full-stack boilerplate project is designed for building serverless AI applications on AWS. It is ideal for developers looking for a reliable AWS foundation for AI apps and seamless access to powerful LLM models through Bedrock, while ensuring your app's data remains separate from model providers.|
|[Internet of Agents.](https://github.com/openbmb/ioa) | The Internet of Agents (IoA) is a novel framework aimed at enhancing multi-agent collaboration by enabling more efficient integration of diverse third-party agents.|
|[ell: The Language Model Programming Library.](https://docs.ell.so/) |Ell is a newly released package developed by a former OpenAI scientist, designed to manage prompts as code, streamlining the process of working with prompts in AI applications. |
|[EMO-Disentanger.](https://github.com/yuer867/emo-disentanger) |This research employs a two-stage model to separate and analyze emotive elements in piano music generation, enabling more expressive and nuanced performances. |
|[Reader-LM: Small Language Models for Cleaning and Converting HTML to Markdown.](https://jina.ai/news/reader-lm-small-language-models-for-cleaning-and-converting-html-to-markdown/) |Jina has unveiled two cutting-edge models capable of transforming noisy HTML into clean, structured Markdown, optimized for training and reasoning tasks. |
|[Agent Workflow Memory.](https://github.com/zorazrw/agent-workflow-memory) | Agent Workflow Memory (AWM) is a technique that enables language model-based agents to learn and retain reusable task workflows from previous experiences, allowing them to effectively manage complex, long-horizon tasks.|
|[Hi3D-Official.](https://github.com/yanghb22-fdu/hi3d-official) | Hi3D is a novel model designed to improve the generation of multi-view consistent, high-resolution 3D images from a single input. By using a video diffusion technique, it addresses the limitations of traditional 2D methods that lack 3D awareness, leveraging temporal consistency from video models to enhance geometric coherence across different views.|
|[Fine Tuning Llama 3.1 405B with Axolotl on a Lambda 1-Click Cluster.](https://axolotlai.substack.com/p/fine-tuning-llama-31b-waxolotl-on) |Axolotal AI has collaborated with Lambda Labs to demonstrate how their one-click cluster can be used to fine-tune the Llama 3.1 405B model. Although the process requires 64 GPUs, the new tools make it possible with minimal infrastructure setup, streamlining the process significantly. |
|[super-benchmark.](https://github.com/allenai/super-benchmark) |SUPER is a newly introduced benchmark aimed at evaluating how effectively large language models (LLMs) can replicate tasks sourced from research repositories. |
|[Using GPT-4o for web scraping.](https://blancas.io/blog/ai-web-scraper/) |An AI-powered web scraper, utilizing OpenAI's GPT-4o, is designed to extract structured data from HTML tables. While it performs well on simple tables, its results are mixed when dealing with more complex tables, such as those with merged rows or intricate structures. |



## Perspectives
|Link|description|
|---|---|
|[‘If journalism is going up in smoke, I might as well get high off the fumes’: confessions of a chatbot helper.](https://www.theguardian.com/technology/article/2024/sep/07/if-journalism-is-going-up-in-smoke-i-might-as-well-get-high-off-the-fumes-confessions-of-a-chatbot-helper) | Journalists and other writers are employed to improve the quality of chatbot replies. The irony of working for an industry that may well make their craft redundant is not lost on them|
|[Will AI make us overconfident?](https://tedunderwood.com/2024/08/31/will-ai-make-us-overconfident/) | Students are increasingly turning to AI tools like ChatGPT to tackle complex research challenges, surprising educators with their swift advancements. AI-powered development tools, particularly in coding, greatly enhance both ambition and productivity, though they also introduce risks of overconfidence and mistakes. Despite occasional inaccuracies, AI offers valuable interactive starting points for difficult tasks, potentially fostering more active learning and encouraging exploration across disciplines.|
|[LLMs struggle to explain themselves.](https://www.jonathanychan.com/blog/llms-struggle-to-explain-themselves/) | An interactive demo was employed to evaluate large language models' (LLMs) ability to recognize and explain number sequences produced by random programs. The findings revealed that although LLMs often correctly identified the sequences, their explanations of the underlying patterns were frequently inaccurate. This underscores the limitations of LLMs' reasoning capabilities, despite their strong performance on standardized tests.|
|[No more free pass: Regulation starts to crack down on social media platforms.](https://english.elpais.com/technology/2024-09-09/no-more-free-pass-regulation-starts-to-crack-down-on-social-media-platforms.html) | The arrest of Telegram’s CEO in France and the closure of X in Brazil are two of the latest signs that times are changing, with networks beginning to be held more accountable|
|[Here’s how 7 news audience directors are thinking about Google’s AI Overviews.](https://www.niemanlab.org/2024/08/how-7-news-audience-directors-are-thinking-about-responding-to-googles-ai-overviews/) |Google's AI Overviews, which use the Gemini language model, received significant criticism for inaccuracies and potentially harmful recommendations following their launch in the U.S. Despite the negative feedback, Google extended the feature to six additional countries, sparking concerns among publishers about decreased web traffic and distorted content. AI experts and SEO specialists stress the importance of transparency and improved citation methods to preserve trust and ensure consistent traffic. |
|[Diffusion is spectral autoregression.](https://sander.ai/2024/09/02/spectral-autoregression.html) |Diffusion models and autoregressive models share a fundamental similarity, as both rely on iterative refinement processes. The author demonstrates, using Fourier transform techniques, that diffusion models function similarly to approximate autoregression in the frequency domain, especially for visual data. This insight suggests promising pathways for unifying generative modeling approaches across various data types. |
|[Why We Fear Diverse Intelligence Like AI.](https://www.noemamag.com/why-we-fear-diverse-intelligence-like-ai/) |The emergence of AI and various forms of intelligence is blurring traditional distinctions between "real beings" and machines. Rather than centering discussions only on AI, it's important to recognize and ethically interact with a broad range of cognitive systems, including bioengineered, robotic, and hybrid entities. By broadening our understanding of intelligence and fostering compassion, we can better navigate the ethical challenges posed by these rapidly evolving technologies. |
|[SGSeg: Enabling Text-free Inference in Language-guided Segmentation of Chest X-rays via Self-guidance.](https://shuchangye-bib.github.io/websites/SGSeg/sgseg.html) |SGSeg is a segmentation framework for chest X-rays that incorporates language guidance during training but allows for text-free inference during the prediction phase. |
|[Are novelists who worry about the rise of AI really ‘classist and ableist’?](https://www.theguardian.com/commentisfree/article/2024/sep/11/are-novelists-who-worry-about-the-rise-of-ai-really-classist-and-ableist) |An international writing organisation appeared to greenlight the use of AI, prompting anger, the resignation of four board members and an entire creative community to ask: ‘What?!’ |
|[AI Chatbots Have a Political Bias That Could Unknowingly Influence Society.](https://www.sciencealert.com/ai-chatbots-have-a-political-bias-that-could-unknowingly-influence-society?utm_source=reddit_post) | A new study has uncovered strong evidence that we can now add political bias to that list, further demonstrating the potential of the emerging technology to unwittingly and perhaps even nefariously influence society's values and attitudes.|
|[How influencers and algorithms mobilize propaganda — and distort reality.](https://www.nature.com/articles/d41586-024-02917-1) |The engagement-fuelled logic of social media has bequeathed us a world in which what’s trending is a yardstick for what’s true. |
|[Artificial intelligence can help to make animal research redundant.](https://www.nature.com/articles/d41586-024-02894-5) |One alternative in its early stages is artificial intelligence (AI), whereby generative adversarial networks produce animal data. But there remains a disconnect between AI-generated animal data and human safety data. Computer models that simulate complex human physiological processes could close this gap, with AI used to analyse the resulting data sets. |
|[Wikipedia is facing an existential crisis. Can gen Z save it?](https://www.theguardian.com/commentisfree/2024/sep/12/wikipedia-generation-z-young-editors-chatbots) |The world’s most important knowledge platform needs young editors to rescue it from chatbots – and its own tired practices |
|[AI-Generated Junk Science Is Flooding Google Scholar, Study Claims.](https://www.newsweek.com/ai-generated-junks-science-floods-google-scholar-study-claims-1950703) |Anew study claims to have uncovered a disturbing trend in the world of academic research: AI tools like ChatGPT being used to produce fake scientific papers that are infiltrating Google Scholar, one of the most widely used academic search engines. |
|[Will the "AI Scientist" Bring Anything to Science?](https://spectrum.ieee.org/ai-for-science-2) |Researchers have created an AI tool capable of automating scientific workflows, from generating hypotheses to executing experiments and drafting research papers. While its accuracy and coherence require further development, critics warn that AI's role in simulations, such as in quantum computing and materials science, may lead to narrower research questions and less impactful findings. Supporters, however, see potential in using this AI to streamline early stages of research, helping scientists conceptualize and define their projects more efficiently. |
|[Is AI Quietly Sabotaging Itself—And The Internet?](https://www.forbes.com/sites/torconstantino/2024/08/26/is-ai-quietly-killing-itself-and-the-internet/?ss=ai) |Amid the growth of AI content online, a group of researchers at Cambridge and Oxford universities set out to see what happens when generative AI tools query content produced by AI. What they found was alarming. |


# ML news: Week 2 - 8 September

## Research
|Link|description|
|---|---|
|[Diffusion Models Are Real-Time Game Engines.](https://arxiv.org/abs/2408.14837) | a two-phase training process involving an RL agent to learn and a diffusion model to generate frames; it can interactively simulate DOOM over at 20 frames per second on a single TPU. A game engine driven by a diffusion model allows real-time interaction with complex environments over long trajectories.|
|[Agentic Retrieval-Augmented Generation for Time Series Analysis.](https://arxiv.org/abs/2408.14484) | suggests an agentic RAG framework for time series analysis. It makes use of a multi-agent architecture in which an agent directs specialized sub-agents to carry out time-series tasks. These sub-agents can retrieve pertinent prompts that contain information about past patterns and trends, which helps to improve predictions on new data. The sub-agents use tuned small language models to accomplish these tasks.|
|[Persuasion Games using Large Language Models.](https://arxiv.org/abs/2408.15879) |asserts that the persuasive efficacy of LLMs can be increased by using a multi-agent framework, in which the main agent conducts persuasive dialogue while supporting agents handle crucial functions like information retrieval and response analysis. The study finds that LLMs are capable of influencing users' perspectives and convincing them to make a purchase decision; for example, sales agents can influence user perspectives in a 71% positive way. |
|[Smaller, Weaker, Yet Better: Training LLM Reasoners via Compute-Optimal Sampling.](https://arxiv.org/abs/2408.16737) | discovers that synthetic data produced by weaker + less costly (WC) models is superior to data produced by stronger but more expensive models for the purpose of fine-tuning models; generally, the results imply that WC models might be a compute-optimal method for training sophisticated LLM reasoners.|
|[Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model.](https://www.arxiv.org/abs/2408.11039) |demonstrates that it is possible to scale from 7B parameter models to 2T multi-modal tokens that can compete in performance with similar scale diffusion and language models. It also presents a training recipe to train multi-modal models over discrete and continuous data; it combines next token prediction with diffusion to train transformer models over mixed-modality sequences. |
|[ReMamba: Equip Mamba with Effective Long-Sequence Modeling.](https://arxiv.org/abs/2408.15496) |examines the long-context capacities and efficiency of Mamba models; the RNN-like nature of Mamba is the cause of the long-context deficiencies; it does this by compressing data using the following method: achieves a 3.2 improvement over the baseline on LongBench and 1.6 improvement on L-Eval; the strategy appears to also apply to Mamba 2. the top-k hidden states during the first forward pass and uses Mamba's selective mechanism to incorporate them into the state space during the second forward pass. |
|[Text2SQL is Not Enough: Unifying AI and Databases with TAG.](https://arxiv.org/abs/2408.14717v1) | develops a benchmark and discovers that standard methods only answer 20 percent of natural language queries correctly. It suggests Table-Augmented Generation (TAG), a unified framework for responding to natural language queries over databases. It represents a wider range of unexplored interactions between LLMs and databases. |
|[Auxiliary-Loss-Free Load Balancing Strategy for Mixture-of-Experts.](https://arxiv.org/abs/2408.15664) | Sparsifying the computation is aided by routing tokens to MoE experts. But it can be hard to learn that routing. Usually, there is a complex loss structure. This research presents an innovative solution to this issue, leading to a significant increase in training stability and expert balancing.|
|[Toward Robust Early Detection of Alzheimer's Disease via an Integrated Multimodal Learning Approach.](https://arxiv.org/abs/2408.16343v1) |A multimodal classification approach intended to enhance the early detection of Alzheimer's disease is presented in this work. |
|[Targeted Cause Discovery with Data-Driven Learning.](https://arxiv.org/abs/2408.16218v1) |A sophisticated machine learning technique has been created by researchers to determine a target's direct and indirect causal variables within a system. |
|[Stochastic Layer-Wise Shuffle: A Good Practice to Improve Vision Mamba Training.](https://arxiv.org/abs/2408.17081v1) |In order to prevent overfitting in Vision Mamba models and enable them to scale up to 300M parameters while still performing competitively with Vision Transformers (ViTs), this research presents a stochastic layer-wise shuffle regularization strategy. |
|[Pre-trained Text-to-Image Diffusion Models Are Versatile Representation Learners for Control.](https://arxiv.org/abs/2405.05852v1) |Stable Control Representations are a tool that researchers are using to help embodied AI machines interpret scenes more precisely. These representations capture detailed visuospatial information required for challenging tasks by utilizing pre-trained text-to-image diffusion models. |
|[AI generates covertly racist decisions about people based on their dialect.](https://www.nature.com/articles/s41586-024-07856-5) |language models perpetuate covert racism through dialect prejudice, specifically against African American English (AAE), leading to negative stereotypes and harmful consequences, while overt stereotypes about African Americans are more positive, and current bias mitigation practices may worsen this issue. |
|[Latent Distillation for Continual Object Detection at the Edge.](https://arxiv.org/abs/2409.01872v1) |A unique Continual Learning technique for object detection that overcomes memory and computational limitations on edge devices is called latent distillation. |
|[Masked Mixers for Language Generation and Retrieval.](https://arxiv.org/abs/2409.01482v1) |Masked mixers are a unique architecture designed to enhance input representation in language models by substituting masked convolutions for self-attention. |
|[Masked Autoencoders for Microscopy are Scalable Learners of Cellular Biology.](https://arxiv.org/abs/2404.10242v1) | Using masked autoencoders and self-supervised learning, researchers have created a novel technique that greatly enhances the processing of large-scale microscope pictures.|
|[Pooling And Attention: What Are Effective Designs For LLM-Based Embedding Models?](https://github.com/yixuantt/poolingandattn) |This work compares alternative pooling and attention strategies while examining multiple designs for LLM-based embedding models. |
|[AlphaProteo generates novel proteins for biology and health research.](https://deepmind.google/discover/blog/alphaproteo-generates-novel-proteins-for-biology-and-health-research/) |New AI system designs proteins that successfully bind to target molecules, with potential for advancing drug design, disease understanding and more. |

## News
|Link|description|
|---|---|
|[X goes offline in Brazil after Elon Musk’s refusal to comply with local laws.](https://www.theguardian.com/technology/article/2024/aug/31/x-offline-brazil-elon-musk) |Millions of users shut out and 500,000 switch to rival platform Bluesky as providers enact supreme court ban |
|['A tech firm stole our voices - then cloned and sold them'.](https://www.bbc.com/news/articles/c3d9zv50955o) | Paul Skye Lehrman and Linnea Sage, voice-over performers, discovered that an AI-powered text-to-speech platform had cloned their voices without permission after they were tricked into providing audio recordings through Fiverr. The couple has filed a lawsuit against the platform, Lovo, for allegedly using their voices illegally. |
|[Did your car witness a crime? Bay Area police may be coming for your Tesla — and they might tow it.](https://www.sfchronicle.com/crime/article/tesla-sentry-mode-police-evidence-19731000.php) |Tesla's Sentry Mode, a feature that uses the car's cameras to monitor its surroundings, is increasingly being used by law enforcement as evidence in criminal investigations. The footage captured by the system has been instrumental in solving various crimes, such as car break-ins and hit-and-run incidents.  |
|[Updates to the Command R Series.](https://cohere.com/blog/command-series-0824) | Updates were made to Command R and Command R+ for almost every task. Their recall, speed, arithmetic, and reasoning have all improved.|
|[Workers at Google DeepMind Push Company to Drop Military Contracts.](https://time.com/7013685/google-ai-deepmind-military-contracts-israel/) |In a letter, almost 200 workers at Google DeepMind demanded that the firm revoke its military contracts, citing a breach of its own AI ethics policy. Armed forces have purchased DeepMind technology from Google Cloud, which has caused internal strife among AI personnel who respect moral principles. Although Google's response showed that company was following the AI Principles, employees are still not pleased and want further regulation to prevent the military from using their AI. |
|[TRL release.](https://github.com/huggingface/trl/releases/tag/v0.10.1) |This could be among the Transformer Reinforcement Learning library's more significant updates. WinRate Callbacks, Liger Kernels, onlineDPO, and other features are included. |
|[xAI Starts Colossus Training Cluster.](https://threadreaderapp.com/thread/1830650370336473253.html) |With intentions to double its size in a few months, xAI has initiated the 100,000 Colossus H100 training cluster, which is now the largest in the world. |
|[First MLPerf benchmarks for Nvidia Blackwell, AMD, Google, Untether AI.](https://spectrum.ieee.org/new-inference-chips) |In MLPerf's LLM Q&A benchmark, Nvidia's new Blackwell chip showed the best per GPU performance, demonstrating notable improvements with its 4-bit floating-point accuracy. Rivals like AMD and Untether AI, however, have displayed encouraging outcomes, especially in terms of energy efficiency. For example, Untether AI's speedAI240 chip performed exceptionally well in the edge-closed category, demonstrating a range of strengths in emerging AI inference technology. |
|[Two Oxford PhDs are building an app to let you remix photos into memes.](https://techcrunch.com/2024/08/29/two-oxford-phds-are-building-an-app-to-let-you-remix-photos-into-memes/) |A new social network by a duo of Oxford PhDs is working on an app to let you add friends to a photo in a more memeable and fun way. |
|[Apple and Nvidia may invest in OpenAI.](https://www.theverge.com/2024/8/29/24231626/apple-nvidia-openai-invest-microsoft) | The two tech giants might join OpenAI’s potentially huge funding round.|
|[Boston Dynamics’ new electric Atlas can do push-ups.](https://techcrunch.com/2024/08/22/boston-dynamics-new-electric-atlas-can-do-push-ups/) | In a recent video, Boston Dynamics demonstrated Atlas, its electric biped robot, completing push-ups to highlight the strength of its actuators during its early commercialization phase for factory floor applications.|
|[Meet Boardwalk Robotics’ Addition to the Humanoid Workforce.](https://spectrum.ieee.org/boardwalk-robotics-alex-humanoid) |The humanoid upper torso robot Alex, by Boardwalk Robotics, is intended for use in manufacturing, logistics, and maintenance. Alex is a legless robot that was developed separately while utilizing the heritage of IHMC's bipedal robot experience. Its designers prioritized manipulation over mobility in order to guarantee efficiency and safety. Pilots are now choosing commercial partners, but researchers can buy Alex right now. |
|[Americans Are Uncomfortable with Automated Decision-Making.](https://www.eff.org/deeplinks/2024/08/americans-are-uncomfortable-automated-decision-making) | Consumer Reports recently released a national survey finding that Americans are uncomfortable with use of artificial intelligence (AI) and algorithmic decision-making in their day to day lives. Nearly three-quarters of respondents (72%) said they would be “uncomfortable”|
|[Canva says its AI features are worth the 300 percent price increase.](https://www.theverge.com/2024/9/3/24234698/canva-price-increase-300-percent-ai-features) | The design software company is massively jacking up subscription prices for some users.|
|[AI worse than humans in every way at summarising information, government trial finds.](https://www.crikey.com.au/2024/09/03/ai-worse-summarising-information-humans-government-trial/) | A test of AI for Australia's corporate regulator found that the technology might actually make more work for people, not less.|
|[Reliant’s paper-scouring AI takes on science’s data drudgery.](https://techcrunch.com/2024/08/20/reliant-ai/) | Karl Moritz Hermann co-founded Reliant AI, which has raised $11.3 million in a seed round to automate academic literature reviews. Tabular, the company's AI solution, promises zero-error data extraction from scientific papers. Reliant offers researchers an intuitive user interface (UI) while utilizing LLMs and patented methodologies to increase efficiency compared to conventional methods. Its usage of in-house hardware highlights its dedication to provide the research sector with premium, domain-specific AI solutions.|
|[Leveraging AI for efficient incident response.](https://engineering.fb.com/2024/06/24/data-infrastructure/leveraging-ai-for-efficient-incident-response/) |With the help of heuristic retrieval and LLM-based ranking, Meta has developed an AI-assisted root cause analysis system that has successfully identified 42% of the causes in its web monorepo investigations. Improving system accuracy has mostly been achieved by fine-tuning the Llama 2 model using previous data. The organization intends to increase the integration of AI tools with the goal of achieving autonomous processes and proactive risk mitigation. |
|[Artificial Intelligence Predicts Earthquakes With Unprecedented Accuracy.](https://scitechdaily.com/artificial-intelligence-predicts-earthquakes-with-unprecedented-accuracy/) |After testing their AI in China, researchers at the University of Texas were able to predict 70% of earthquakes. |
|[Recall 2.0? Microsoft plans another AI feature that scans everything.](https://www.pcworld.com/article/2447369/recall-2-microsoft-plans-another-ai-feature-that-reads-everything.html) |Another AI-driven feature that searches PC content surfaces in Windows 11, raising questions about data privacy. |
|[You.com raises $50M Series B.](https://you.com/articles/50m-series-b) |The search engine, agent platform, and knowledge base startup You.com has raised more money as it expands. |
|[Sakana raises $100m Series A.](https://sakana.ai/series-a/) |With the increase, Sakana will be able to hire more researchers, expand its computational capacity, and generally establish itself as one of Japan's top AI labs. |
|[Google AI Overviews rollout hits news publisher search visibility.](https://pressgazette.co.uk/platforms/google-ai-overviews-rollout-hits-news-publisher-search-visibility/) |Some news items now have AI-written summaries available in Google's US and UK search results. According to research, publisher visibility is being impacted by these AI Overviews, which is causing original articles to fall in the search results. To sustain traffic, this move may require major adjustments to SEO tactics. |
|[US, UK, EU and others sign landmark AI safety treaty.](https://siliconangle.com/2024/09/05/us-uk-eu-others-sign-landmark-ai-safety-treaty/) | More than a dozen countries have signed a treaty designed to ensure that artificial intelligence models are used in a safe manner.|
|[OpenAI's Next-Generation Models Could Reportedly Cost $2,000.](https://www.inc.com/ben-sherry/openais-next-generation-models-could-reportedly-cost-2000.html) | The Sam Altman-led company's new artificial intelligence models, such as Strawberry and Orion, likely won't be cheap ([prices as high as $2,000 per month](https://www.pymnts.com/artificial-intelligence-2/2024/report-openai-considers-2000-monthly-subscription-prices-for-new-llms/)).|
|[Alleged fraudster got $10 million in royalties using robots to stream AI-made music.](https://www.engadget.com/entertainment/streaming/alleged-fraudster-got-10-million-in-royalties-using-robots-to-stream-ai-made-music-162944343.html) |A North Carolina man is facing fraud charges after allegedly uploading hundreds of thousands of AI-generated songs to streaming services and using bots to play them billions of times. Michael Smith is said to have received over $10 million in royalties since 2017 via the scheme. |
|[Advertisers plan to withdraw from X in record numbers.](https://edition.cnn.com/2024/09/05/business/advertisers-x-withdrawal/index.html) | A record number of firms plan to cut advertising spending on X next year because of concerns that extreme content on the platform could damage their brands, dealing another blow to the financial fortunes of Elon Musk’s social media company.|
|[Dutch Regulator Slams Clearview AI with €30.5 Million Penalty for “Massive” Rights Breach.](https://thedeepdive.ca/dutch-regulator-slams-clearview-ai-with-e30-5-million-penalty-for-massive-rights-breach/) |The Dutch Data Protection Authority (DPA) announced on Tuesday that it has imposed a €30.5 million ($33.7 million) fine on US facial recognition company Clearview AI for illegally creating a database of billions of facial images. |
|[M&S using AI as personal style guru in effort to boost online sales.](https://www.theguardian.com/business/article/2024/sep/05/m-and-s-using-ai-to-advise-shoppers-body-shape-style-preferences) | Shoppers can use technology to advise them on outfit choices based on their body shape and style preferences|
|[Google’s AI-powered Ask Photos feature begins US rollout.](https://techcrunch.com/2024/09/05/googles-ai-powered-ask-photos-feature-begins-u-s-rollout/) | More sophisticated natural language queries may now be used to search through photographs with Google photographs' new AI-powered search function, "Ask Photos," which is now available to a limited number of American users.|
|[Alibaba releases new AI model Qwen2-VL that can analyze videos more than 20 minutes long.](https://venturebeat.com/ai/alibaba-releases-new-ai-model-qwen2-vl-that-can-analyze-videos-more-than-20-minutes-long/) | Qwen2-VL, a new vision-language model with improved visual understanding, multilingual text-image processing, and video comprehension, has been published by Alibaba Cloud. In comparison to models such as Meta's Llama 3.1 and OpenAI's GPT-4o, Qwen2-VL performs better and is compatible with a wider range of applications, such as real-time video analysis and technical help. The models are open-source under Apache 2.0 for the smaller versions, and are available in three sizes (7B, 2B, and shortly 72B).|
|[Broadcom is working to integrate optical connectivity directly into GPUs.](https://www.techspot.com/news/104495-broadcom-working-integrate-optical-connectivity-directly-gpus.html) |Currently, one of the main obstacles to training large models is the bandwidth of GPU interface. The problem would be much reduced if Broadcom could include optical transfer directly into GPUs, as they are now working on doing. |
|[YouTube is making tools to detect face and voice deepfakes.](https://www.engadget.com/ai/youtube-is-making-tools-to-detect-face-and-voice-deepfakes-191536027.html) |It plans to launch a pilot program for the voice detection tool by early next year. |
|[Google is working on AI that can hear signs of sickness.](https://techcrunch.com/2024/08/29/google-is-working-on-ai-that-can-hear-signs-of-sickness/) |Given everything you’ve already heard about AI, you may not be surprised to learn that Google is among other outfits beginning to use sound signals to predict early signs of disease.  |

## Resources
|Link|description|
|---|---|
|[AutoGen Studio: A No-Code Developer Tool for Building and Debugging Multi-Agent Systems.](https://arxiv.org/abs/2408.15247) |An interface written in minimal code to quickly prototype AI agents. It may be used for multi-agent workflow evaluation and debugging, and it is constructed on top of the AutoGen framework. |
|[Foundation Models for Music: A Survey.](https://arxiv.org/abs/2408.14340) | gives a thorough rundown of the most recent pre-trained models and foundation models in the music industry.|
|[A Practitioner's Guide to Continual Multimodal Pretraining.](https://arxiv.org/abs/2408.14471) | a thorough manual on ongoing multimodal related; presents FoMo-In-Flux, a large-scale continuous pretraining benchmark with fine-grained and extended horizons.|
|[AI feedback loop will spell death for future generative models.](https://www.techspot.com/news/99064-ai-feedback-loop-spell-death-future-generative-models.html) |When you train LLMs with LLM-generated content, the results tend to be digital poop |
|[Apple's robotics work aims to solve user's first-world problems.](https://appleinsider.com/articles/24/08/25/first-world-problems-drives-apples-robotics-development) |Apple might be getting more involved in robotics and releasing moving gadgets, like an iPad supported by a robotic arm. Under the direction of Vice President of Technology Kevin Lynch, Apple is making headway in robotics with the assistance of specialists from companies such as Israel's Technion, and plans to expand its AI interfaces beyond Siri. Apple is thinking of releasing these new robotic devices around 2026 or 2027, while they are still conceptual. |
|[Towards Real-world Event-guided Low-light Video Enhancement and Deblurring.](https://arxiv.org/abs/2408.14916v1) |Using event cameras, this end-to-end system concurrently solves motion deblurring and low-light enhancement in videos. |
|[Enhancing Sound Source Localization via False Negative Elimination.](https://arxiv.org/abs/2408.16448v1) |To overcome false negatives in conventional methods of sound source localization, researchers have put forth a novel audio-visual learning framework. Two schemes are included in the framework: Semantic-Aware Contrastive Learning (SACL) and Self-Supervised Predictive Learning (SSPL). While SACL improves the contrastive learning process to better align auditory and visual elements, SSPL removes false negatives by emphasizing positive-only learning. |
|[FastSD CPU.](https://github.com/rupeshs/fastsdcpu) | Flux Schnell on the CPU is now supported by a widely used inference library.|
|[Spiking Diffusion Models.](https://github.com/andycao1125/sdm) |A new class of Spiking Neural Networks (SNNs) called Spiking Diffusion Models (SDMs) is intended for image production and offers significant energy savings along with great biological plausibility. |
|[Laion 5B safety Release.](https://laion.ai/blog/relaion-5b/) | The biggest publicly available image dataset on the internet was Laion 5B. Because of worries about offensive and hazardous imagery, it was taken down. After a major effort to address these problems, the group is now rereleasing the dataset.|
|[ml_dtypes.](https://github.com/jax-ml/ml_dtypes) |Bfloat16 and fp8 support for native numpy arrays. |
|[VisionTS.](https://github.com/keytoyze/visionts) |By redefining time series forecasting as an image reconstruction challenge, VisionTS is a novel method that takes advantage of the similarities between time series data and natural images to improve forecasting. To achieve remarkable zero-shot performance, it makes use of a visual masked autoencoder (MAE) that has been pre-trained on ImageNet. |
|[Codec Does Matter: Exploring the Semantic Shortcoming of Codec for Audio Language Model.](https://arxiv.org/abs/2408.17175v1) | A novel method for improving LLMs' audio generating performance is called X-Codec.|
|[The timm (PyTorch Image Models) Leaderboard.](https://huggingface.co/spaces/timm/leaderboard) |This leaderboard is based on the results of the models from timm. Timm comprises various vision models.|
|[CogVideoX-5B.](https://github.com/huggingface/diffusers/releases/tag/v0.30.1?utm_source=tldrai) |CogVideo 5B model will launch next week in Hugging Face Diffusers. |
|[Anthropic Quickstarts.](https://github.com/anthropics/anthropic-quickstarts/) | Anthropic has made available a helpful selection of initial projects. It collaborated with former chief AI officers from Brex, Uber, Facebook, and other companies to draft the first Quickstart, a Claude-powered scalable customer support assistant.|
|[The Missing Guide to the H100 GPU Market.](https://blog.lepton.ai/the-missing-guide-to-the-h100-gpu-market-91ebfed34516) | This guide covers all the important factors of buying a GPU, such as availability considerations, pricing for various alternatives, and guaranteeing reliability in addition to highlighting the significance of other hardware features. It answers the most important queries consumers have about GPUs, including pricing, performance, and shipping.|
|[Efficient Camera Exposure Control for Visual Odometry via Deep Reinforcement Learning.](https://github.com/shuyanguni/drl_exposure_ctrl) | A deep reinforcement learning framework is being developed in this research to enhance the stability of visual odometry (VO) systems in difficult-to-light settings.|
|[Multi-scale Cross-restoration Framework for Electrocardiogram Anomaly Detection.](https://github.com/mediabrain-sjtu/ecgad) | a sophisticated ECG diagnosis system that enhances the identification of uncommon but serious cardiac anomalies by self-supervised anomaly detection pretraining.|
|[RWKV.cpp.](https://threadreaderapp.com/thread/1831000938120917336.html) | The great RWKV models have included a local inference model with its cpp project.|
|[MAPF-GPT.](https://github.com/Cognitive-AI-Systems/MAPF-GPT) |A novel learning-based method called MAPF-GPT has been developed to tackle the difficult multi-agent pathfinding (MAPF) problem. The model navigates agents by imitation learning; it does not require extra heuristics, reward functions, or communication. |
|[EnsLoss.](https://github.com/statmlben/ensLoss) |An ensemble approach called EnsLoss integrates loss functions into the Empirical Risk Minimization (ERM) paradigm. |
|[Disentangled Motion Modeling for Video Frame Interpolation.](https://github.com/jhlew/momo) | MoMo is a novel diffusion-based approach for video frame interpolation (VFI). It enhances visual quality by focusing on intermediate motion modeling through a disentangled two-stage training process.|
|[repo2vec.](https://github.com/Storia-AI/repo2vec) |Repo2vec is a new package that functions similarly to GitHub Copilot but with up-to-date repo information, making it simple to communicate with any public or private codebase. |
|[Building LLMs from the Ground Up: A 3-hour Coding Workshop.](https://magazine.sebastianraschka.com/p/building-llms-from-the-ground-up) | Great resource about LLM building from scratch |
|[SGLang v0.3 Release.](https://lmsys.org/blog/2024-09-04-sglang-v0-3/) | The most recent release brings enhancements to SGLang inference, including Multi-Image/Video LLaVA-OneVision, 1.5x Faster torch.compile, and 7x Faster DeepSeek MLA.|
|[OLMoE: Open Mixture-of-Experts Language Models.](https://arxiv.org/abs/2409.02060) |Best in class performance for 1B activated parameters in an excellent open MoE. |
|[StyleTokenizer: Defining Image Style by a Single Instance for Controlling Diffusion Models.](https://arxiv.org/abs/2409.02543v1) |This work presents StyleTokenizer, an approach that aligns style representation with text prompts to improve style control in text-to-image generation. |
|[Applied Machine Learning (Cornell CS5785, Fall 2024).](https://github.com/kuleshov/cornell-cs5785-2024-applied-ml) | Open resources for the Fall 2024 Applied ML class at Cornell.|
|[Laminar - Open-Source observability, analytics, evals and prompt chains for complex LLM apps.](https://github.com/lmnr-ai/lmnr) |  Laminar hosts background job queues of LLM pipelines. Outputs of those pipelines are turned into metrics. |
|[LongLLaVA.](https://github.com/freedomintelligence/longllava) | A multimodal model called LongLLaVA was created to handle long-context tasks like comprehending high-resolution images and videos.|


## Perspectives
|Link|description|
|---|---|
|[I learned the language of computer programming in my 50s – here’s what I discovered.](https://www.theguardian.com/technology/article/2024/aug/31/learning-computer-programming-language-coding-devil-stack-andrew-smith) | A writer with no technical background recounts his incredible journey into the realm of coding and the invaluable lesson it taught him about the modern world|
|[Why A.I. Isn’t Going to Make Art.](https://www.newyorker.com/culture/the-weekend-essay/why-ai-isnt-going-to-make-art) |To create a novel or a painting, an artist makes choices that are fundamentally alien to artificial intelligence. |
|[Autonomous car bombs, online recruitment: Experts worry how AI can transform terrorism.](https://www.foxnews.com/world/autonomous-car-bombs-online-recruitment-experts-worry-how-ai-can-transform-terrorism) | Law enforcement has to anticipate novel AI uses and develop countermeasures|
|[Researchers built an ‘AI Scientist’ — what can it do?](https://www.nature.com/articles/d41586-024-02842-3) |The large language model does everything from reading the literature to writing and reviewing its own papers, but it has a limited range of applicability so far. |
|[The Next Generation Pixar: How AI will Merge Film & Games.](https://a16z.com/the-next-generation-pixar/) |With its ability to combine dynamic gaming engagement with narrative depth, generative AI has the potential to completely transform storytelling. This change is being accelerated by recent developments in generative models, such as Luma AI's Dream Machine and OpenAI's Sora, which allow for the creation of interactive videos in real time. This development, which combines AI, gaming, and film, could result in the next "Pixar" in interactive media. |
|[China's robot makers chase Tesla to deliver humanoid workers.](https://www.reuters.com/technology/chinas-robot-makers-chase-tesla-deliver-humanoid-workers-2024-08-23/) | At the World Robot Conference in Beijing, more than 25 Chinese businesses featured humanoid robots designed for factory automation. These companies were supported by significant government funding and took advantage of China's extensive supply network. By 2035, the market for humanoid robots is expected to reach $38 billion globally. By 2025, China hopes to have these robots in large quantities, stepping up the battle with Tesla's planned Optimus robot. Tesla expects to roll out 1,000 Optimus robots in its factories over the course of the next year, while Chinese companies are predicting substantial cost savings on their models.|
|[Why AI can’t spell ‘strawberry’.](https://techcrunch.com/2024/08/27/why-ai-cant-spell-strawberry/) |Because of their tokenization techniques, large language models occasionally perform poorly on tasks like letter counting. This demonstrates how the LLM architecture has shortcomings that impact how well they comprehend text. Nevertheless, developments are still being made. For example, Google DeepMind's AlphaGeometry 2 for formal math and OpenAI's Strawberry for enhanced reasoning |
|[Diffusion is spectral autoregression.](https://sander.ai/2024/09/02/spectral-autoregression.html) |It's common knowledge that auto regressive models and diffusion models are essentially distinct types of methodologies. When it comes to diffusion models that genuinely take auto-regressive steps in the frequency domain, they might, in fact, be more comparable than we previously realized. |
|[Can AI Scaling Continue Through 2030?](https://epochai.org/blog/can-ai-scaling-continue-through-2030) | AI training is expanding at a rate that has never been seen before—four times faster than previous technology advances in genome sequencing and mobile use. According to research, the main limitations in scaling AI training could last until 2030 and are related to power availability and chip production capacity. If hundreds of billions are committed, training runs up to 2e29 FLOP would become feasible, representing significant advancement comparable to the transition from GPT-2 to GPT-4. Advanced network topologies and multimodal and synthetic data production methodologies might help overcome difficulties like data shortages and latency.|
|[GPU Utilization is a Misleading Metric.](https://trainy.ai/blog/gpu-utilization-misleading) |Although frequently tracked, GPU utilization may not fully capture GPU performance in machine learning workloads since it does not take into consideration whether the GPU's computational power is being utilized to its fullest. Trainy found this out when, during LLM training, 100% GPU usage was achieved, but only ~20% model FLOPS utilization (MFU) was achieved. It suggests using fused kernel optimization and the appropriate model parallelism level to obtain a 4x speedup in training time and tracking SM efficiency for a better performance indication. |
|[AI-Implanted False Memories.](https://www.media.mit.edu/projects/ai-false-memories/overview/) | In simulated criminal witness interviews, generative chatbots driven by massive language models greatly increased the generation of false memories, inducing roughly three times more instantaneous false recollections than a control group, according to a study by MIT Media Lab.|
|[The biology of smell is a mystery — AI is helping to solve it.](https://www.nature.com/articles/d41586-024-02833-4) |Scientists are beginning to crack the fiendishly complex code that helps us to sense odours. |
|[How much is AI hurting the planet? Big tech won't tell us.](https://mashable.com/article/ai-environment-energy) | big tech companies, like Google, are not disclosing the full environmental impact of AI, while emissions from their operations have significantly increased, with Google's greenhouse gas emissions rising by 48% between 2019 and 2023|
|[AI Has Created a Battle Over Web Crawling.](https://spectrum.ieee.org/web-crawling) |A research by the Data Provenance Initiative cautions that when websites restrict crawler bots more and more, high-quality data may become inaccessible to generative AI models. This trend, which is motivated by worries about data exploitation, may cause AI training to rely more on low-quality data rather than well-maintained sources. Businesses may use direct licensing or synthetic data to preserve the effectiveness of AI models in the face of increasing data scarcity. |
|[What Succeeding at AI Safety Will Involve.](https://sleepinyourhat.github.io/checklist/) |Sam from Anthropic hazard a guess as to what will have to be done in order for AI safety to be successful while creating superhuman AI systems. |
|[the art of programming and why i won't use llm.](https://kennethnym.com/blog/why-i-still-wont-use-llm/) |Although LLMs are praised for increasing productivity and are being incorporated into coding workflows more and more, some contend that their programming effectiveness is overstated. |
|[‘He was in mystic delirium’: was this hermit mathematician a forgotten genius whose ideas could transform AI – or a lonely madman?.](https://www.theguardian.com/science/article/2024/aug/31/alexander-grothendieck-huawei-ai-artificial-intelligence) |In isolation, Alexander Grothendieck seemed to have lost touch with reality, but some say his metaphysical theories could contain wonders |
|[AI Checkers Forcing Kids To Write Like A Robot To Avoid Being Called A Robot.](https://www.techdirt.com/2024/09/04/ai-checkers-forcing-kids-to-write-like-a-robot-to-avoid-being-called-a-robot/) |Can the fear of students using generative AI and the rise of questionable AI “checker” tools create a culture devoid of creativity? |
|[The AI Arms Race Isn’t Inevitable.](https://www.palladiummag.com/2024/08/23/the-ai-arms-race-isnt-inevitable/) |Prominent AI labs are pushing Western governments to support swift AI developments in order to prevent rivals like China from gaining a decisive technological advantage. They are increasingly portraying AI research as a geopolitical zero-sum game crucial for national security. This story supports drastic steps to ensure AI domination, even at the expense of escalating geopolitical tensions and possibly jeopardizing safety and ethical standards. |
|[Is AI eating all the energy?](https://blog.giovanh.com/blog/2024/08/18/is-ai-eating-all-the-energy-part-1-of-2/) |AI's total energy footprint is influenced by both rising demand and rising energy efficiency. Power, heat, carbon, and water use are all positively connected with AI's energy consumption. The general trend of AI processing becoming more power-hungry is being countered by hardware efficiency improvements. Although its influence is lessened by broad use, AI still accounts for a small but growing portion of data center power consumption, with training activities using a lot more energy than inference. |
|[Debate over “open source AI” term brings new push to formalize definition.](https://arstechnica.com/information-technology/2024/08/debate-over-open-source-ai-term-brings-new-push-to-formalize-definition/) | In an effort to clarify the meaning and address the term's overuse, the Open Source Initiative (OSI) published a proposed definition of "open source AI" that includes usage rights, study, modification, and sharing freedoms. With this step, researchers and engineers will be able to assess AI systems in a more transparent manner. In October, a stable version of the definition is anticipated, which may have an impact on upcoming releases of AI models and regulations.|
|[Predicting AI.](https://www.strangeloopcanon.com/p/predicting-ai) |This author considers their forecasts for AI and notes that they were correct to predict the growth of open source, multimodal models, and improved tool usability. |
|[Bill Gates has a good feeling about AI.](https://www.theverge.com/24235730/bill-gates-ai-climate-change-energy-tech-microsoft-netflix) |The Verge spoke with Bill Gates about AI, misinformation, and climate change. |
|[Enterprise AI Infrastructure: Privacy, Maturity, Resources.](https://www.heavybit.com/library/article/enterprise-ai-infrastructure-privacy-maturity-resources) |An interesting interview with BentoML's CEO discusses how to enhance business tooling, make sure you can expand, and avoid over-engineering it from the start. |


# ML news: ML news: Week 26 August - 1 September

## Research
|Link|description|
|---|---|
|[Automated Design of Agentic Systems.](https://arxiv.org/abs/2408.08435) | declares that it is possible to learn any possible agentic system, including prompts, tool use, control flows, and more, using their approach. They accomplish this by concentrating on three main components, known as search space (define agents), search algorithm (explore search space), and the evaluation function (evaluate candidate agents). presents Meta Agent Search, a meta agent that iteratively programs and tests new agents based on a growing archive of previous discoveries. |
|[LLM Pruning and Distillation in Practice: The Minitron Approach.](https://arxiv.org/abs/2408.11796) | presents pruning and distillation techniques applied to the original models to produce 4B and 8B parameter models, respectively. Prior to pruning, they also fine-tune the teacher model on their datasets leading to better distillation; their compression strategy yields a state-of-the-art 8B model (MN-Minitron-8B) which outperforms all similarly-sized models on common language modeling benchmarks. offers a thorough report on effective methods for compressing Llama 3.1 and Mistral NeMo models.|
|[The Vizier Gaussian Process Bandit Algorithm.](https://arxiv.org/abs/2408.11527) |introduces Vizier, an open-source Python implementation of the Gaussian process bandit optimization technique, which is utilized by Google for millions of optimizations and research. It includes benchmarking data that show the algorithm's wider applicability. |
|[Enhancing Robustness in Large Language Models: Prompting for Mitigating the Impact of Irrelevant Information.](https://arxiv.org/abs/2408.10615) |  proposes a two-stage prompting technique to remove irrelevant information from context; it serves as a self-mitigation process that first identifies the irrelevant information and then filters it out; this leads to enhancement in robustness of the model and overall better performance on reasoning tasks.|
|[MagicDec: Breaking the Latency-Throughput Tradeoff for Long Context Generation with Speculative Decoding.](https://arxiv.org/abs/2408.11049) |demonstrates how speculative decoding can improve throughput, lower latency, and preserve accuracy in long context generation scenarios; it discovers that bottlenecks change from compute-bound to memory-bound as sequence length and batch size increase; with these realizations, they demonstrate that speculative decoding can be used more successfully for longer sequences, even when using large batch sizes.  |
|[PEDAL: Enhancing Greedy Decoding with Large Language Models using Diverse Exemplars.](https://arxiv.org/abs/2408.08869) | employs a hybrid self-ensembling approach (based on diverse exemplars) to enhance LLM performance overall. Specifically, it generates multiple candidate responses using diverse exemplars and aggregates them using an LLM to produce a final response; this approach achieves lower cost compared to self-consistency approaches and better accuracy compared to greedy decoding.|
|[Autonomous Driving with Spiking Neural Networks.](https://arxiv.org/abs/2405.19687v1) |The first unified Spiking Neural Network (SNN) designed to tackle the energy issues associated with autonomous driving is called Spiking Autonomous Driving (SAD). |
|[Pre-training Small Base LMs with Fewer Tokens.](https://arxiv.org/abs/2404.08634v1) |By inheriting a few transformer blocks and training on a very small percentage (0.1%) of the initial data, Inheritune is a simplified technique for creating smaller base language models from larger ones. With just one A6000 GPU and this method, a 1.5B parameter model could be created in less than 30 minutes, with performance comparable to larger models trained on much greater amounts of data. |
|[Teaching chat models to solve chess puzzles.](https://raw.sh/posts/chess_puzzles) |At 1800 elo on average, traditional base language models are rather competent chess players. Nevertheless, chat models frequently see a sharp decline in performance. This article explains how to use prompting and fine-tuning to teach conversation models, such as GPT-4o, to play chess. |
|[xGen-VideoSyn-1: High-fidelity Text-to-Video Synthesis with Compressed Representations.](https://www.arxiv.org/abs/2408.12590) | The text-to-video (T2V) model xGen-VideoSyn-1 from Salesforce creates lifelike scenes based on written descriptions. The model makes use of a diffusion transformer (DiT) for enhanced temporal consistency and generalization and a video variational autoencoder (VidVAE) for video data compression, which lowers processing requirements.|
|[Memory-Efficient LLM Training with Online Subspace Descent.](https://arxiv.org/abs/2408.12857v1) |Online Subspace Descent is a novel optimizer that increases memory efficiency to improve LLM training.|
|[Generative Verifiers: Reward Modeling as Next-Token Prediction.](https://arxiv.org/abs/2408.15240) |Typically, reward models are taught to be discriminative classifiers. The reward signal in this DeepMind experiment is the yes/no logits of a language model. It was discovered that enabling a model to incorporate ensembling and CoT increased performance by sixteen percent. |
|[Multilingual Arbitrage: Optimizing Data Pools to Accelerate Multilingual Progress.](https://arxiv.org/abs/2408.14960) |By using the discrepancy between routing synthetic data creation and oracle model performance, Cohere's Aya model was able to significantly increase its win rate in comparison to baseline models. |
|[Text2SQL is Not Enough: Unifying AI and Databases with TAG.](https://arxiv.org/abs/2408.14717v1) | A novel paradigm called Table-Augmented Generation answers complex natural language queries by fusing databases and language models.|
|[The Mamba in the Llama: Distilling and Accelerating Hybrid Models.](https://arxiv.org/abs//2408.15237) |Because mamma models do not include a KV cache for backtracking, they are difficult to accelerate with speculative decoding. This document presents several new distillation techniques and acceleration algorithms from some of the original authors. |
|[Efficient LLM Scheduling by Learning to Rank.](https://arxiv.org/abs/2408.15792) | Head of line bottlenecks occur when delivering multiple concurrent requests to a large language model since we don't know how long output generation will take. The shortest requests can be served first if you can learn to rank the relative lengths between them, which will increase throughput for multi-batch generation by 6.5 times.|
|[MTMamba++: Enhancing Multi-Task Dense Scene Understanding via Mamba-Based Decoders.](https://arxiv.org/abs/2408.15101v1) |A new model architecture called MTMamba++ aims to improve multi-task scene understanding. This method captures long-range dependencies and enhances cross-task interactions using a Mamba-based decoder with two core blocks: STM and CTM. |

## News
|Link|description|
|---|---|
|[Scientists to use AI to analyse 1.6m brain scans to develop tool predicting dementia risk.](https://www.theguardian.com/society/article/2024/aug/26/scientists-to-use-ai-to-analyse-brain-scans-to-develop-tool-predicting-dementia-risk) |Researchers will use artificial intelligence to match image data of patients from Scotland with linked health records |
|[Microsoft releases powerful new Phi-3.5 models, beating Google, OpenAI and more.](https://venturebeat.com/ai/microsoft-releases-powerful-new-phi-3-5-models-beating-google-openai-and-more/) |Microsoft unveiled the Phi-3.5-mini-instruct, Phi-3.5-MoE-instruct, and Phi-3.5-vision-instruct, three new models in its Phi series that each achieve remarkable benchmark achievements while tackling distinct AI tasks. Developers can access these models on Hugging Face and they are offered as open source under the MIT License. The Phi models have outperformed rivals like GPT-4o and Llama in certain benchmarks, demonstrating near-state-of-the-art performance despite their smaller size than some of its contemporaries. |
|[Data Exfiltration from Slack AI via indirect prompt injection.](https://promptarmor.substack.com/p/data-exfiltration-from-slack-ai-via) |It was found that there is a vulnerability in Slack AI that allows attackers to use indirect prompt injection to steal data from private channels they do not have access to. Through the use of public channel messages, attackers can coerce the LLM into disclosing sensitive data, like API keys, in response to queries. This problem continues, along with a phishing attack vector, even after Slack AI's update on August 14th, which added channel and DM files and greatly increased the surface area at risk for exploits of this kind. |
|[Bringing Llama 3 to life.](https://engineering.fb.com/2024/08/21/production-engineering/bringing-llama-3-to-life/) | Llama 3.1, an enhanced open-source LLM from Meta, adds new features like model distillation and the ability to generate synthetic data.|
|[Anthropic reveals system prompts for Claude.](https://docs.anthropic.com/en/release-notes/system-prompts) |Anthropic has updated all models' dates and included system prompts. |
|[D-ID launches an AI video translation tool that includes voice cloning and lip sync.](https://techcrunch.com/2024/08/21/d-id-launches-an-ai-video-translation-tool-that-includes-voice-cloning-and-lip-sync/) |AI video creation platform D-ID is the latest company to ship a tool for translating videos into other languages using AI technologies. However, in this case, D-ID also clones the speaker’s voice and changes their lip movements to match the translated words as part of the AI editing process. |
|[Vyond Pushes AI Video's Enterprise Era.](https://www.vyond.com/blog/vyond-new-all-in-one-2024-release/) | Vyond is an AI platform for creating videos with an emphasis on enterprise use cases.|
|[Mark Zuckerberg says White House ‘pressured’ Facebook to censor Covid-19 content.](https://www.theguardian.com/technology/article/2024/aug/27/mark-zuckerberg-says-white-house-pressured-facebook-to-censor-covid-19-content) | Meta boss regrets bowing to government power and says he would not make the same choices today|
|[What the Telegram founder’s arrest means for the regulation of social media firms.](https://www.theguardian.com/technology/article/2024/aug/27/what-does-the-telegram-founders-arrest-mean-for-the-regulation-of-social-media-companies-pavel-durov) |Pavel Durov’s detention by French authorities is a major break from the norm – but his low-moderation, non-encrypted app is an anomaly |
|[Tesla Is Erasing Its Own History.](https://insideevs.com/news/731502/tesla-is-erasing-its-own-history/) | CEO Elon Musk’s original Tesla Motors Master Plan no longer exists on Tesla’s website.|
|[After a decade of free Alexa, Amazon now wants you to pay.](https://www.washingtonpost.com/technology/2024/08/27/amazon-ai-alexa-new-subscription/) | AI is a chance for companies to charge for products we’re in the habit of using for free.|
|[AI for creating comics? Europe’s industry completely rejects it, Tintin executive says.](https://www.scmp.com/lifestyle/arts-culture/article/3268398/ai-creating-comics-europes-industry-completely-rejects-it-tintin-executive-says) |Tools such as Midjourney and Dall-E have triggered a fightback in comic land as publishers gear up for litigation ahead of new EU rules |
|[Police officers are starting to use AI chatbots to write crime reports. Will they hold up in court?](https://apnews.com/article/ai-writes-police-reports-axon-body-cameras-chatgpt-a24d1502b53faae4be0dac069243f418#) | AI technology is being integrated into police work to automate the writing of reports from body camera footage.|
|[Questions about the safety of Tesla’s ‘Full Self-Driving’ system are growing.](https://apnews.com/article/tesla-musk-self-driving-analyst-automated-traffic-a4cc507d36bd28b6428143fea80278ce) |Tesla has been accused of deceptive marketing over its self-driving technology, as a prominent analyst questions the safety and readiness of the system, potentially leading to increased scrutiny of automated driving claims. |
|[Japan: AI-powered drones to monitor disaster zones and identify criminals.](https://interestingengineering.com/innovation/japan-ai-powered-drones-monitor-disaster-zones-criminals) |Drones move faster than police cars or guards, reaching incident site quickly and allowing for prompt action and response. |
|[Artifacts are now generally available.](https://www.anthropic.com/news/artifacts) |Artifacts are now widely accessible, including on mobile devices, thanks to Anthropic. |
|[Introducing Cerebras Inference.](https://cerebras.ai/blog/introducing-cerebras-inference-ai-at-instant-speed) | Large unified memory is present in the chipset of Cerebras. It can therefore avoid problems with bandwidth and serve models at thousands of tokens per second.|
|[OpenAI Aims to Release New AI Model, ‘Strawberry,’ in Fall.](https://www.pymnts.com/news/artificial-intelligence/2024/openai-aims-release-new-ai-model-strawberry-fall/) |"Strawberry" is a new AI product that OpenAI intends to launch in the fall. It will be able to carry out complex jobs like creating marketing plans and will have advanced thinking abilities, such as the capacity to answer math problems that have never been seen before. |
|[This 1mm 'fan on a chip' could put active cooling inside ultra-thin gadgets.](https://www.engadget.com/mobile/this-1mm-fan-on-a-chip-could-put-active-cooling-inside-ultra-thin-gadgets-130014002.html) |The XMC-2400 µCooling chip, a 1mm-tall solid-state fan intended to cool down thin electronics such as smartphones, has been introduced by xMEMS. |
|[Nvidia rides big tech’s AI investment to beat Wall Street’s sky-high expectations.](https://www.theguardian.com/technology/article/2024/aug/28/nvidia-nvda-q2-earnings-report) |Chipmaker, third most valuable company in world, records $30.04bn in revenue, showing AI demand continues to rise |
|[AI makes racist decisions based on dialect.](https://www.science.org/content/article/ai-makes-racist-decisions-based-dialect) | Large language models strongly associated negative stereotypes with African American English|
|[Lawmakers call for crackdown on AI deepfakes after Grok backlash.](https://thehill.com/policy/technology/4850752-lawmakers-crackdown-ai-deepfakes-grok-backlash/) | A group of Democratic lawmakers are pushing the Federal Election Commission (FEC) to increase regulation on artificial intelligence (AI) deepfakes following the release of the social platform X’s chatbot Grok.|
|[Midjourney says it’s ‘getting into hardware’.](https://techcrunch.com/2024/08/28/midjourney-says-its-getting-into-hardware/) |Midjourney, the AI image-generating platform that’s reportedly raking in more than $200 million in revenue without any VC investment, is getting into hardware. |
|[Google rolling out Gems and Imagen 3, with people generation, to Gemini Advanced.](https://9to5google.com/2024/08/28/gemini-advanced-gems-imagen-3/) | Gems are “custom versions of Gemini” that you can create to “act as an expert on topics or refine them toward your specific goals.” They can “remember a detailed set of instructions to help you save time on tedious, repetitive or difficult tasks.”|
|[OpenAI in Talks for Funding Round Valuing It Above $100 Billion.](https://www.msn.com/en-us/money/technology/openai-in-talks-for-funding-round-valuing-it-above-100-billion/ar-AA1pBesH) | With Microsoft anticipated to take part, OpenAI is in talks to raise several billion dollars in a fresh investment round headed by Thrive Capital, which would value the business over $100 billion.|
|[How to harness AI’s potential in research — responsibly and ethically.](https://www.nature.com/articles/d41586-024-02762-2) |Artificial intelligence is propelling advances in all areas of science. But vigilance is needed, warn four researchers at the leading edge. |
|[The On‑Device Intelligence Update.](https://cartesia.ai/blog/2024-08-27-on-device) |Cartesian has released several updates to their models and systems. Additionally, an open hybrid State space model has been released. |
|[Stephen Wolfram thinks we need philosophers working on big questions around AI.](https://techcrunch.com/2024/08/25/stephen-wolfram-thinks-we-need-philosophers-working-on-big-questions-around-ai/) | |
|[The top AI deals in Europe this year.](https://techcrunch.com/2024/08/24/the-top-ai-deals-in-europe-this-year/) | Despite general headwinds for startups, AI ventures continue to secure substantial funding. U.S. AI startups have achieved nearly 30 deals over $100M in 2024, with Europe not far behind. Major investments include WAYVE ($1B), Mistral AI (~$1B), Helsing ($484M), Poolside ($400M), DeepL ($320M), H ($220M), and Flo Health ($200M).|
|[California advances landmark legislation to regulate large AI models.](https://www.theguardian.com/technology/article/2024/aug/29/california-ai-regulation-bill) |Groundbreaking bill aims to reduce potential AI risks – requiring model testing and disclosure of safety protocol |
|[Nvidia shares fall on slowing growth and production concerns.](https://www.theguardian.com/technology/article/2024/aug/29/nvidia-shares-fall-after-investors-spooked-by-slowing-growth-delays-next-generation-ai-chips) | Doubling of quarterly revenues to £23bn fails to allay worry about delays to next generation of AI chips|
|[X’s AI tool Grok lacks effective guardrails preventing election disinformation, new study finds.](https://www.independent.co.uk/tech/grok-ai-elon-musk-x-election-harris-trump-b2603457.html) |The Center for Countering Digital Hate (CCDH) found that Grok was able to churn out ‘convincing’ AI fake images including one of Vice President Kamala Harris doing drugs and another of former president Donald Trump looking sick in bed |
|[100M Token Context Windows.](https://magic.dev/blog/100m-token-context-windows) | It isn't a typo, yes. 100 million tokens for agent programming and reasoning in context. Additionally, Magic Dev disclosed a collaboration to construct two new supercomputers on Google Cloud. This is a result of a recent $320 million fundraising effort to quicken the company's product development.|
|[OpenAI and Anthropic will share their models with the US government.](https://www.theverge.com/2024/8/29/24231395/openai-anthropic-share-models-us-ai-safety-institute) |The companies will grant the AI Safety Institute access to major new models for safety testing. |
|[California legislature passes controversial “kill switch” AI safety bill.](https://arstechnica.com/ai/2024/08/as-contentious-california-ai-safety-bill-passes-critics-push-governor-for-veto/) | After passing the State Assembly, California's contentious AI safety bill, SB-1047, is now one step closer to being signed into law by Governor Gavin Newsom. By September 30, Newsom must determine whether or not to sign it into law.|
|[OpenAI says ChatGPT usage has doubled since last year.](https://www.axios.com/2024/08/29/openai-chatgpt-200-million-weekly-active-users) |OpenAI reported that 92% of Fortune 500 firms utilize ChatGPT, and that the platform has over 200 million weekly active users—a tripling of its user base from a year ago. |
|[TikTok owner ByteDance launches new video search tool, eyeing Baidu’s dominance.](https://www.scmp.com/tech/big-tech/article/3275514/tiktok-owner-bytedance-launches-new-video-search-tool-eyeing-baidus-dominance) | In a direct challenge to Baidu's search dominance, ByteDance has released Douyin Search, an app for searching short video content on TikTok's Chinese counterpart.|

## Resources
|Link|description|
|---|---|
|[Language Modeling on Tabular Data: A Survey of Foundations, Techniques and Evolution.](https://arxiv.org/abs/2408.10548) |includes topics like classification of tabular data structures and data types, datasets used for model training and evaluation, modeling techniques and training objectives, data processing methods, popular architectures, challenges and future research directions. It also provides a thorough survey of language modeling techniques for tabular data. |
|[Graph Retrieval-Augmented Generation: A Survey.](https://arxiv.org/abs/2408.08921) |focuses on methods used in the GraphRAG workflow (graph-guided retrieval, graph-based indexing, and graph-enhanced creation); explores GraphRAG's tasks, applications, assessment, and industrial use cases. |
|[Controllable Text Generation for Large Language Models: A Survey.](https://arxiv.org/abs/2408.12599) | gives a thorough overview of controllable text generating techniques in LLMs; covers topics like as helpfulness, safety, consistency, and style.|
|[Challenges and Responses in the Practice of Large Language Models.](https://arxiv.org/abs/2408.09416) | selects a number of significant questions and provides thoughtful answers; the questions are divided into groups according to themes including data, applications, infrastructure, software architecture, and brain science.|
|[Self-Supervised Learning of Time Series Representation via Diffusion Process and Imputation-Interpolation-Forecasting Mask.](https://arxiv.org/abs/2405.05959v1) | The first diffusion-based method for learning time series representations is called Time Series Diffusion Embedding, or TSDE. Time series data is divided into segments by TSDE, which then creates informative embeddings by using dual-orthogonal Transformer encoders with a crossover mechanism.|
|[Liger Kernel: Efficient Triton Kernels for LLM Training.](https://github.com/linkedin/Liger-Kernel) | Surprisingly, LinkedIn released the Liger Kernel, a productive set of kernels for training language models. For the widely used Llama models, it reduces memory utilization by about 60% and boosts throughput by 20%. It interacts with several common modeling frameworks and just takes three lines of code change, which is important for practitioners.|
|[pgvectorscale.](https://github.com/timescale/pgvectorscale) | With better performance for embedding search and more affordable storage for AI applications, pgvectorscale expands upon pgvector. Compared to other popular and competitive vector retailers, it is about 28 times faster.|
|[GenderCARE.](https://github.com/kstanghere/gendercare-ccs24) |A thorough framework called GenderCARE is designed to identify and lessen gender prejudices. It presents novel standards for assessing gender prejudice, with a focus on diversity, inclusivity, and impartiality. |
|[Generalized SAM: Efficient Fine-Tuning of SAM for Variable Input Image Sizes.](https://arxiv.org/abs/2408.12406v1) |A novel technique for more effectively fine-tuning the Segment Anything Model (SAM) with variable-size images is called Generalized SAM (GSAM). |
|[google/siglip-so400m-patch14-224.](https://huggingface.co/google/siglip-so400m-patch14-224) | A new SigLIP model from Google leverages a vision transformer model architecture that is tuned for shape.|
|[GaussianOcc: Fully Self-supervised and Efficient 3D Occupancy Estimation with Gaussian Splatting.](https://ganwanshui.github.io/GaussianOcc/) |Using surround views, GaussianOcc is an effective and entirely self-supervised approach for 3D occupancy estimate. |
|[Infinite Dataset Hub.](https://huggingface.co/spaces/infinite-dataset-hub/infinite-dataset-hub) |This space, which is powered by phi-3-mini, generates data on any topic using a rarity prompt. It is intriguing and potent even though it isn't the most accurate. |
|[Neural Assets: 3D-Aware Multi-Object Scene Synthesis with Image Diffusion Models.](https://neural-assets-paper.github.io/) |By conditioning on individual object representations, neural networks are able to represent and manage 3D objects in 2D contexts. This work could be the key to untangling 3D objects. |
|[T3M: Text Guided 3D Human Motion Synthesis from Speech.](https://arxiv.org/abs/2408.12885v1) |T3M is a brand-new technique that researchers have developed for producing 3D animations that are controlled by text inputs. T3M is a useful technology for virtual reality, gaming, and film creation because it enables more precise and customized animations than earlier methods that solely used voice. |
|[BiRefNet.](https://github.com/ZhengPeng7/BiRefNet) | Bireference segmentation with background removal at the cutting edge of technology.|
|[RB-Modulation.](https://github.com/google/RB-Modulation/) | Google has developed a really innovative method for customizing diffusion models that works better than several widely used techniques. It may be used with PyTorch and, with some adjustments, Flux as well.|
|[FlexEdit: Marrying Free-Shape Masks to VLLM for Flexible Image Editing.](https://github.com/a-new-b/flex_edit) |With FlexEdit, you may precisely modify images based on language commands by combining free-shape masks with Vision Large Language Models (VLLMs). |
|[Quick Fine-tuning of Phi 3.5.](https://colab.research.google.com/drive/1lN6hPQveB_mHSnTOYifygFcrO8C1bxq4) | Quick fine-tuning script with Unsloth of the new Microsoft models.|
|[Fire-Flyer AI-HPC: A Cost-Effective Software-Hardware Co-Design for Deep Learning.](https://arxiv.org/abs/2408.14158) |A paper detailing DeepSeek's hardware-software co-design approach for deep learning has been published. |
|[Announcing Higgs Llama V2.](https://boson.ai/higgs-v2/) |Higgs-Llama-3-70B-v2, a new model from Boson AI, performs exceptionally well on conversation and comprehension benchmarks such as Arena-Hard and AlpacaEval 2.0. Compared to Claude 3.5 Sonnet, the model increases day 1 retention by 5.3% and decreases response regeneration rates by 21.6%. Improved using an internal reward model called Higgs Judger, its performance is tied to that of Google's Gemini 1.5 Pro. |
|[The Zyphra Training Cookbook.](https://www.zyphra.com/post/the-zyphra-training-cookbook) | Pre-training normal Transformers is not the same as pre-training hybrid (Mamba type) models. In order to get the desired performance, this post examines scaling various hyperparameters, data gathering, and other factors.|
|[LlamaDuo.](https://github.com/deep-diver/llamaduo) | This is a system that optimizes small models to act as a backup in the event that closed API models become unavailable. It demonstrates a smooth transition from a large to a small model.|
|[LitServe.](https://github.com/Lightning-AI/LitServe) |A flexible and user-friendly serving engine for AI models based on FastAPI is called LitServe. The need to rebuild a FastAPI server for each model is eliminated by features like batching, streaming, and GPU autoscaling. |
|[IntelLabs/LlavaOLMoBitnet1B.](https://huggingface.co/IntelLabs/LlavaOLMoBitnet1B) | Llava BitNet is the first ternary (-1, 0, 1) weight model trained on VLM tasks. The model, weights, and scripts are in the process of being fully open sourced. The technical report will be released soon and suggests the model has promising performance.|
|[Qwen2-Audio.](https://huggingface.co/collections/Qwen/qwen2-audio-66b628d694096020e0c52ff6) |Qwen has released audio input style models that can reason about music, audio, and sound. |
|[Sketch2Scene: Automatic Generation of Interactive 3D Game Scenes from User's Casual Sketches.](https://xrvisionlabs.github.io/Sketch2Scene/) |This team developed an incredible model that generates fully playable 3D game scenarios from a single input sketch by sequentially using many models. |
|[OctFusion: Octree-based Diffusion Models for 3D Shape Generation.](https://github.com/octree-nn/octfusion) |OctFusion is an efficient and high-quality method for using diffusion models to generate 3D objects. In about 2.5 seconds, it can generate 3D shapes at any resolution using a single Nvidia 4090 GPU. |
|[MambaInLlama.](https://github.com/jxiw/mambainllama) |By reusing weights from attention layers, researchers have shown that massive Transformer models can be reduced to more deployable linear RNNs. |
|[Cross-Modal Temporal Alignment for Event-guided Video Deblurring.](https://arxiv.org/abs/2408.14930v1) |By incorporating an event camera—which records motion with microsecond temporal resolution—researchers have created a novel method for video deblurring that improves the quality of motion-blurred footage. |
|[JoyCaption Pre-Alpha.](https://huggingface.co/spaces/fancyfeast/joy-caption-pre-alpha) | An open-source VLM created especially for upcaptioning images.|
|[Introducing RPBench-Auto.](https://boson.ai/rpbench-blog/) |An automated evaluation pipeline called RPBench-Auto, which draws inspiration from ArenaHard and Alpaca Eval, has been introduced by Boson AI to measure the role-playing talents of LLMs. |
|[Lightweight Champ: NVIDIA Releases Small Language Model With State-of-the-Art Accuracy.](https://blogs.nvidia.com/blog/mistral-nemo-minitron-8b-small-language-model/) |Mistral-NeMo-Minitron 8B is a miniaturized version of the recently released Mistral NeMo 12B model, delivering high accuracy combined with the compute efficiency to run the model across GPU-accelerated data centers, clouds and workstations. |
|[NousResearch/hermes-function-calling-v1.](https://huggingface.co/datasets/NousResearch/hermes-function-calling-v1) |Excellent publicly available dataset from Nous Research to train call function models. |
|[Qwen2-VL: To See the World More Clearly.](https://qwenlm.github.io/blog/qwen2-vl/) |Qwen2-VL is the latest version of the vision language models based on Qwen2 in the Qwen model familities |
|[RAW-Adapter: Adapting Pre-trained Visual Model to Camera RAW Images.](https://cuiziteng.github.io/RAW_Adapter_web/) |A novel method called RAW-Adapter modifies pre-trained sRGB models so they can efficiently handle RAW data from cameras. |
|[Llama usage double May through July.](https://ai.meta.com/blog/llama-usage-doubled-may-through-july-2024/) | Meta has published some usage statistics for the Llama model. It discovered that there was a high demand for its models being used in business environments.|
|[SAM & SAM 2 in 3D Slicer: SegmentWithSAM Extension for Annotating Medical Images.](https://arxiv.org/abs/2408.15224v1) |In order to expedite the annotation of 3D medical pictures, this study modified the Segment Anything Model 2 (SAM 2), which was initially created for video annotation. |

## Perspectives
|Link|description|
|---|---|
|[AI analysed 1,500 policies to cut emissions. These ones worked.](https://www.nature.com/articles/d41586-024-02717-7) |Only 63 climate change interventions led to significant reductions in carbon emissions. |
|[AI cheating is overwhelming the education system – but teachers shouldn’t despair.](https://www.theguardian.com/commentisfree/article/2024/aug/24/ai-cheating-chat-gpt-openai-writing-essays-school-university) | With adjustments to the way we teach students to think about writing, we can shift the emphasis from product to process|
|[What’s Really Going On in Machine Learning? Some Minimal Models.](https://writings.stephenwolfram.com/2024/08/whats-really-going-on-in-machine-learning-some-minimal-models/) |The inventor of Wolfram|Alpha, Stephen Wolfram, published a fantastic analysis of the various events occurring in machine learning models. He found a collection of dynamics pertaining to the non-linearities in basic neural networks. |
|[AI companies are pivoting from creating gods to building products. Good.](https://www.aisnakeoil.com/p/ai-companies-are-pivoting-from-creating) |AI firms are finding it difficult to match their products to the markets for LLMs, which has resulted in large investments but little profit. The five primary obstacles impeding the commercialization of AI products are price, dependability, security and safety concerns, privacy, and user interface constraints. It is imperative that these sociotechnical obstacles are resolved in order for AI to be widely integrated and used in consumer goods. |
|[My friend, Claude.](https://trevorklee.substack.com/p/my-friend-claude) |Due to increased job obligations, this author relies on Anthropic's LLM Claude for technical writing, highlighting the expanding value of LLMs in professional settings. Claude's help has been cost-effective even though it required expert verification, and it highlights how quickly the landscape for specialty experts confronting AI-driven automation is changing. The author considers how knowledge work may change when AI technologies like Claude are more frequently used for everyday tasks. |
|[AI firms must play fair when they use academic data in training.](https://www.nature.com/articles/d41586-024-02757-z) |Researchers are among those who feel uneasy about the unrestrained use of their intellectual property in training commercial large language models. Firms and regulators need to agree the rules of engagement. |
|[Stakes high for European Union after arrest of Telegram co-founder.](https://www.theguardian.com/world/article/2024/aug/28/european-union-arrest-telegram-pavel-durov-law-analysis) |The charges against Pavel Durov increases pressure on Brussels to enforce new European law on the platform |
|[MIT neuroscientists discover neurons with distinct language processing timescales.](https://interestingengineering.com/health/mit-brain-clusters-temporal-window) |In language-processing areas of the brain, some cell populations respond to one word, while others respond to strings of words. |
|[How to Tell If What You're Reading Was Written By AI.](https://lifehacker.com/tech/how-to-tell-if-what-youre-reading-was-written-by-ai) | From the moment ChatGPT introduced the world to generative AI in late 2022, it was apparent that, going forward, you can no longer trust that something you're reading was written by a human.|
|[California AI bill sparks debate in Silicon Valley as some tech giants call it a threat to innovation.](https://finance.yahoo.com/news/california-ai-bill-sparks-debate-in-silicon-valley-as-some-tech-giants-call-it-a-threat-to-innovation-214246503.html) | A first-of-its-kind AI bill is winding its way through California, causing infighting between groups of AI pioneers.|
|[Exodus at OpenAI: Nearly half of AGI safety staffers have left, says former researcher.](https://fortune.com/2024/08/26/openai-agi-safety-researchers-exodus/) |Nearly half the OpenAI staff that once focused on the long-term risks of superpowerful AI have left the company in the past several months, according to Daniel Kokotajlo, a former OpenAI governance researcher. |
|[Technology may be advancing - but it’s making us more stupid.](https://www.telegraph.co.uk/business/2024/08/26/technology-may-be-advancing-but-its-making-us-more-stupid/) | ‘Deskilling’ in the face of cognitive automation is a problem that is too easily ignored|
|[Inference is FREE and INSTANT.](https://fume.substack.com/p/inference-is-free-and-instant) |Large language models (LLMs) may not be much better at reasoning, but they will be more helpful for repeated jobs due to their rising speeds and falling prices. These models may not have genuine understanding, yet they are nonetheless capable of handling simple tasks effectively. |
|[UK’s new science minister on budget battles, Brexit and AI leadership.](https://www.nature.com/articles/d41586-024-02628-7) | Former clinical scientist Patrick Vallance speaks to Nature about his priorities as the minister overseeing the nation’s research.|
|[Urgently clarify how AI can be used in medicine under new EU law.](https://www.nature.com/articles/d41586-024-02753-3) |The European Union’s Artificial Intelligence Act entered into force on 1 August. Phased implementation begins in February 2025, banning artificial intelligence (AI) systems deemed to pose unacceptable risks. Before that happens, policymakers must do more to ensure that patients’ safety and interests are protected. |



# ML news: 19 - 25  August

## Research
|Link|description|
|---|---|
|[The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery.](https://arxiv.org/abs/2408.06292) |a novel artificial intelligence (AI) agent that, for less than $15, can develop and write a full conference-level scientific paper; it automates scientific discovery by empowering frontier LLMs to conduct independent research and summarize findings; it also uses an automated reviewer to assess the papers it generates; it claims to achieve near-human performance in assessing paper scores; and it claims to generate papers that, according to their automated reviewer, surpass the acceptance threshold at a premier machine learning conference.  |
|[LongWriter: Unleashing 10,000+ Word Generation from Long Context LLMs.](https://arxiv.org/abs/2408.07055) | suggests AgentWrite as a way to allow off-the-shelf LLMs to produce coherent outputs longer than 20K words. AgentWrite divides the long generation task into smaller tasks and uses a divide-and-conquer strategy to produce the outputs; the agent then splits the task into smaller writing subtasks and concatenates the outputs to produce a final output (i.e., plan + write). This method is then used to create SFT datasets, which are used to tune LLMs to produce coherent longer outputs automatically; a 9B parameter model, further enhanced through DPO, achieves state-of-the-art performance on their benchmark and outperforms proprietary models.|
|[EfficientRAG: Efficient Retriever for Multi-Hop Question Answering.](https://arxiv.org/abs/2408.04259) | trains a filter model to formulate the next-hop query based on the original question and previous annotations; this is done iteratively until all chunks are tagged as <Terminate> or the maximum # of iterations is reached; after the above process has gathered enough information to answer the initial question, the final generator (an LLM) generates the final answer. trains an auto-encoder LM to label and tag chunks; it retrieves relevant chunks, tags them as either <Terminate> or <Continue>, and annotates <Continue> chunks for continuous processing.|
|[RAGChecker: A Fine-grained Framework for Diagnosing Retrieval-Augmented Generation.](https://arxiv.org/abs/2408.08067) |a detailed assessment methodology for RAG retrieval and generating module diagnosis; demonstrates that RAGChecker exhibits superior correlations with human judgment; presents multiple illuminating patterns and trade-offs in RAG architecture design decisions.  |
|[HybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction.](https://arxiv.org/abs/2408.04948) |integrates VectorRAG and GraphRAG to create a HybridRAG system that performs better than either one separately; it was tested on a set of transcripts from financial earning calls. When the benefits of both methods are combined, questions can be answered with more accuracy. |
|[Mutual Reasoning Makes Smaller LLMs Stronger Problem-Solvers.](https://arxiv.org/abs/2408.06195) |introduces self-play mutual reasoning to enhance small language models' reasoning powers without the need for better models or fine-tuning; To create richer reasoning trajectories, MCTS is enhanced with human-like reasoning actions derived from SLMs; The target SLM chooses the last reasoning trajectory as the solution, while another SLM offers unsupervised input on the trajectories; For LLaMA2-7B, rStar increases GSM8K accuracy from 12.51% to 63.91% while steadily raising other SLM accuracy. |
|[Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters.](https://arxiv.org/abs/2408.03314.) |explores how inference-time computation in LLMs scales. Specifically, it examines how much an LLM can be improved given a fixed amount of inference-time compute; it discovers that the efficacy of various scaling strategies varies by prompt difficulty; it then suggests an adaptive compute-optimal strategy that can increase efficiency by more than 4x when compared to a best-of-N baseline; it reports that optimally scaling test-time compute can outperform a 14x larger model in a FLOPs-matched evaluation. |
|[Medical Graph RAG: Towards Safe Medical Large Language Model via Graph Retrieval-Augmented Generation.](https://arxiv.org/abs/2408.04187) |a graph-based framework for the medical domain that improves LLMs and produces evidence-based results; makes use of chunk documents and a hybrid static-semantic approach to enhance context capture; uses graphs to represent entities and medical knowledge, creating an interconnected global graph; This method outperforms cutting-edge models and increases precision across a number of medical Q&A metrics. |
|[BAM dense to MoE Upcycling.](https://arxiv.org/abs/2408.08274) | By using this technique, the FFN and Attention layers of dense models can be recycled into a Mixture of Experts (MoE) model for additional training. This preserves downstream performance while saving a significant amount of computing expense.|
|[BAPLe: Backdoor Attacks on Medical Foundational Models using Prompt Learning.](https://asif-hanif.github.io/baple/) | Backdoor attacks can be incorporated into medical foundation models using the BAPLe technique during the prompt learning stage.|
|[ShortCircuit: AlphaZero-Driven Circuit Design.](https://arxiv.org/abs/2408.09858) |AI-powered automation and optimization of chip design can lower costs while satisfying the need for more powerful chips. Using an Alpha Zero based approach, this method was tested on numerous circuits and produced small and effective designs with an 84.6% success rate. |
|[Automated Design of Agentic Systems.](https://arxiv.org/abs/2408.08435) | This study examines the fragility of current agent systems and explores potential future directions for the design of learning systems. Programming languages are used by their creators as a testbed where unsupervised agent creation and execution are possible.|
|[Loss of plasticity in deep continual learning.](https://www.nature.com/articles/s41586-024-07711-7) |The pervasive problem of artificial neural networks losing plasticity in continual-learning settings is demonstrated and a simple solution called the continual backpropagation algorithm is described to prevent this issue. |
|[Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model.](https://arxiv.org/abs/2408.11039) |Incredible new model from Meta that performs diffusion and next token prediction on text and image interleaving. It performs comparably to earlier generation devices like Dalle 2 and Llama 2 in benchmark tests for text and graphics. |
|[To Code, or Not To Code? Exploring Impact of Code in Pre-training.](https://arxiv.org/abs/2408.10914) |The industry keeps this to itself, although pretraining models on code aids in their generalization to other reasoning-intensive activities. This Cohere study investigates that issue in detail and demonstrates that code may be used as a foundational element of thinking in a variety of contexts. |

## News
|Link|description|
|---|---|
|[AI-generated parody song about immigrants storms into German Top 50.](https://www.theguardian.com/technology/article/2024/aug/18/artificial-intelligence-song-immigrants-germany-top-50) |Artist Butterbro accused of walking fine line between parody and discrimination and helping make racial slur mainstream |
|[Tesla faces lowest duty on Chinese-made cars exported to EU.](https://www.theguardian.com/technology/article/2024/aug/20/tesla-faces-lowest-duty-on-chinese-made-cars-exported-to-eu) |The 9% tariff is much less than others face after investigation into Beijing’s ‘unfair’ subsidies of EVs |
|[Google’s upgraded AI image generator is now available.](https://www.theverge.com/2024/8/15/24221218/google-ai-image-generator-imagen-3-available) | Google says Imagen 3 is its highest-quality image generator so far — and now more users in the US can try it.|
|[Runway’s Gen-3 Alpha Turbo is here and can make AI videos faster than you can type.](https://venturebeat.com/ai/runways-gen-3-alpha-turbo-is-here-and-can-make-ai-videos-faster-than-you-can-type/) |The new Gen-3 Alpha Turbo from Runway ML is currently available with a variety of subscription plans, including free trials, and offers 7x quicker AI video creation at half the cost of its predecessor. Time lag is greatly decreased by this speed increase, which promotes more productive workflows, especially in industries where time is of the essence. Runway is negotiating the ethical waters of AI training data practices while pushing for more advancements, such as improved control systems.|
|[Eric Schmidt Walks Back Claim Google Is Behind on AI Because of Remote Work.](https://www.msn.com/en-us/money/companies/eric-schmidt-says-google-is-falling-behind-on-ai-and-remote-work-is-why/ar-AA1oO2my) | Eric Schmidt, ex-CEO and executive chairman at Google, walked back remarks in which he said his former company was losing the artificial intelligence race because of its remote-work policies.|
|[Gemini Advanced updated with latest 1.5 Pro model for improved reasoning.](https://9to5google.com/2024/08/15/gemini-advanced-1-5-pro-update/) | Google has enhanced Gemini 1.5 Pro in Gemini Advanced, delivering improved responses for prompts requiring advanced reasoning and coding.|
|[Waymo is developing a roomier robotaxi with less-expensive tech](https://www.cnbc.com/2024/08/19/waymo-generation-6-robotaxi-geely-zeekr.html) |Waymo has revealed its Generation 6 self-driving technology that is built into Geely Zeekr EVs and requires less cameras and sensors. With the help of machine intelligence and semiconductor developments, the Alphabet division intends to quickly implement this technology to survive a variety of weather conditions. With this update, Waymo is able to continue scaling its Waymo One service, which is presently offering 50,000 trips each week. |
|[Gemini Live could use some more rehearsals.](https://techcrunch.com/2024/08/19/gemini-live-could-use-some-more-rehearsals/) |Google's AI-powered voice interaction technology, Gemini Live, attempts to replicate genuine speech but has trouble with errors and hallucinations. It isn't as customizable or expressive as rivals like OpenAI's Advanced Voice Mode, even though it uses professional actors for more expressive voices. Overall, the bot's usefulness and purpose are unclear due to its limited capability and dependability concerns, especially considering that it is a component of Google's expensive AI Premium Plan. |
|[Hamming Launches 100x faster testing of voice agents.](https://www.producthunt.com/posts/hamming-ai-yc-s24) | With the use of a technology called hamming, you may test hundreds of situations for your voice AI systems and create personalities that resemble Character AI.|
|[Fine-tuning now available for GPT-4o.](https://openai.com/index/gpt-4o-fine-tuning/) | With the announcement of fine-tuning for GPT-4o, OpenAI enables developers to tailor the model using their own datasets for certain use cases. Through September 23, it will be giving away one million free training tokens per day.|
|[OpenAI strikes search deal with Condé Nast.](https://www.axios.com/2024/08/20/openai-conde-nast-deal-chatgpt-search) | With the signing of a multi-year licensing deal, OpenAI and Condé Nast are able to integrate content from the publisher's brands, like Vogue and The New Yorker, into their ChatGPT and SearchGPT platforms.|
|[Meta’s Self-Taught Evaluator enables LLMs to create their own training data.](https://venturebeat.com/ai/metas-self-taught-evaluator-enables-llms-to-create-their-own-training-data/?utm_source=tldrai) | Meta FAIR researchers have introduced the Self-Taught Evaluator, a method to train evaluative LLMs without human annotations, potentially enhancing the efficiency and scalability of LLM assessment. Using the LLM-as-a-Judge concept, it iteratively generates and refines responses to create a training dataset, demonstrating improved performance on benchmarks like RewardBench. This technique could enable enterprises to leverage unlabeled data for LLM tuning while acknowledging the importance of a well-aligned seed model and the limitations of benchmarks.|
|[Video: $16,000 humanoid robot ready to leap into mass production.](https://newatlas.com/robotics/unitree-g1-humanoid-robot-mass-production/) |China's Unitree Robotics is a relatively recent entry in the general-purpose humanoid robot space, but its $16,000 G1 model is already proving itself to be quite the performer. So much so that the company has now revealed a version that's ready for mass production. |
|[US mayoral candidate who pledged to govern by customized AI bot loses race.](https://www.theguardian.com/us-news/article/2024/aug/21/wyoming-cheyenne-ai-bot-mayor) |Victor Miller proposed customized ChatGPT bot to govern Cheyenne, Wyoming – but fared badly at the ballot box |
|[Authors sue Anthropic for copyright infringement over AI training.](https://www.theguardian.com/technology/article/2024/aug/20/anthropic-ai-lawsuit-author) |Andrea Bartz, Charles Graeber and Kirk Wallace Johnson allege company misused work to teach chatbot Claude |
|[Ideogram 2.0.](https://about.ideogram.ai/2.0) |A new model from Ideogram has better text rendering and image generating capabilities. |
|[Introducing Zed AI.](https://zed.dev/blog/zed-ai) |With the help of a hosted service called Zed AI, developers may employ LLMs and yet have complete control over their code by integrating AI-powered coding into the Zed text editor. Zed and Anthropic have teamed to enable quick editing with Claude. |
|[Nvidia’s AI NPCs will debut in a multiplayer mech battle game next year.](https://www.theverge.com/2024/8/20/24224391/mecha-break-nvidia-ai-npcs-announced) |Nvidia ACE, the company’s AI-powered system for giving voices and conversation skills to in-game characters, is set to debut in Mecha Break, a new multiplayer mech battle game coming to PC, Xbox X / S, and PlayStation 5 in 2025. |
|[These 'living computers' are made from human neurons — and you can rent one for $500 a month.](https://www.livescience.com/technology/artificial-intelligence/these-living-computers-are-made-from-human-neurons) | Using human-brain organoids into computing, FinalSpark's "Neuroplatform" provides a biocomputing platform that may be rented with the goal of lowering AI's energy consumption. Standardizing production and increasing the life of organoids beyond 100 days are challenges. Alternatives such as fungal networks and cellular computing are also investigated for jobs that are beyond the capabilities of silicon-based computers.|
|[AI made of jelly ‘learns’ to play Pong — and improves with practice.](https://www.nature.com/articles/d41586-024-02704-y) |Inspired by neurons in a dish playing the classic video game, researchers show that synthetic hydrogels have a basic ‘memory’. |
|[Cursor raises $60m.](https://www.cursor.com/blog/series-a) | Cursor raised a Series A to continue building its AI-powered coding IDE.|
|[Perplexity AI plans to start running ads in fourth quarter as AI-assisted search gains popularity.](https://www.cnbc.com/2024/08/22/perplexity-ai-plans-to-start-running-search-ads-in-fourth-quarter.html) |The AI-assisted search startup Perplexity AI, which just raised $1 billion in funding, intends to launch adverts on its search app in Q4. |
|[Pixel 9 phones: The Gemini AI stuff, reviewed.](https://arstechnica.com/gadgets/2024/08/pixel-9-phones-the-gemini-ai-stuff-reviewed/) |One of the main features of the Pixel 9 phones is Google's Gemini AI, which provides customers with a number of AI-powered features like task assistance, picture editing, and screenshot management. Its effectiveness as a full-fledged assistant is uneven, though, with sporadic hiccups and several Google Assistant functions that aren't completely incorporated. Notwithstanding these problems, Pixel users can benefit from intriguing features like document summarizing and creative photo "reimagining" tools. |
|[AMD explains its AI PC strategy.](https://www.engadget.com/computing/amd-explains-its-ai-pc-strategy-123004804.html) | With its Ryzen AI 300 CPUs, AMD is pushing the AI PC industry forward by incorporating NPUs to improve AI-powered applications such as Microsoft's Recall.|
|[Gemini in Gmail can now help polish up your drafts.](https://www.theverge.com/2024/8/20/24159832/google-gmail-gemini-help-me-write-polish) | ‘Help me write’ can now polish your emails, in addition to being able to formalize them or shorten them.|
|[Royal Society facing calls to expel Elon Musk amid concerns about conduct.](https://www.theguardian.com/technology/article/2024/aug/23/royal-society-facing-calls-to-expel-elon-musk-amid-concerns-about-conduct) |Some fellows fear tech billionaire could bring institution into disrepute with incendiary comments |
|[Apple Intelligence is coming. Here’s what it means for your iPhone.](https://www.theguardian.com/technology/article/2024/aug/24/apple-intelligence-iphone-ios-18-siri-chat-gpt-launch) |Apple is about to launch a ChatGPT-powered version of Siri as part of a suite of AI features in iOS 18. Will this change the way you use your phone – and how does it affect your privacy? |

## Resources
|Link|description|
|---|---|
|[A Survey of NL2SQL with Large Language Models: Where are we, and where are we going?](https://arxiv.org/abs/2408.05109) |a thorough rundown of NL2SQL approaches driven by LLMs, including models, data gathering, assessment strategies, and error analysis |
|[DeepSeek-Prover-V1.5.](https://arxiv.org/abs/2408.08152) |Process supervision was used to train DeepSeek's extremely potent math model, which performs noticeably better than larger models on a number of MATH benchmarks. |
|[DifuzCam: Replacing Camera Lens with a Mask and a Diffusion Model.](https://arxiv.org/abs/2408.07541) | This is a fun project that reconstructs very low quality images from a cheap camera using a diffusion model.|
|[Knowledge Fusion of Large Language Models.](https://github.com/fanqiwan/FuseAI) | Several models can be combined with Fuse Chat, allowing each to contribute their unique capabilities. This is the code base containing the model weights for several robust 7B models that achieve good results on the MT bench.|
|[SigmaRL.](https://github.com/cas-lab-munich/sigmarl) | The goal of the decentralized, open-source SigmaRL framework is to enhance the generalization and sample efficiency of multi-agent Reinforcement Learning (RL) in the context of motion planning for automated and networked vehicles.|
|[Comparative Evaluation of 3D Reconstruction Methods for Object Pose Estimation.](https://arxiv.org/abs/2408.08234) | In order to evaluate how the quality of 3D reconstructions affects object position estimate accuracy in industrial applications, this work presents a thorough benchmark.|
|[MVInpainter: Learning Multi-View Consistent Inpainting to Bridge 2D and 3D Editing.](https://ewrfcas.github.io/MVInpainter/) |The process of producing many views from a single image is known as multi view image synthesis. |
|[BLIP-3.](https://arxiv.org/abs/2408.08872) | For a while, BLIP was the most used multimodal model. The most recent iteration employs a pure autoregressive loss and is noticeably simpler. It attains cutting-edge results on certain captioning benchmarks.|
|[SAM2-UNet: Segment Anything 2 Makes Strong Encoder for Natural and Medical Image Segmentation.](https://arxiv.org/abs/2408.08870v1) | A new image segmentation framework called SAM2-UNet uses the potent Segment Anything Model 2 (SAM2) as its encoder.|
|[A Survey on Benchmarks of Multimodal Large Language Models.](https://arxiv.org/abs/2408.08632v1) | A thorough analysis of 180 benchmarks for Multimodal Large Language Model evaluation is presented in this work.|
|[SuGaR: Surface-Aligned Gaussian Splatting for Efficient 3D Mesh Reconstruction and High-Quality Mesh Rendering.](https://github.com/Anttwo/SuGaR) |You can create an editable and animatable mesh output from a video or image series using mesh reconstruction from gaussian splatting. It just takes a few steps on a single GPU to accomplish this, and it does so very rapidly and efficiently. |
|[Llama-3.1 Storm Models.](https://huggingface.co/collections/akjindal53244/llama-31-storm-models-66ba6c96b7e24ecb592787a9) |These are the first tuned models that significantly outperform Meta's Llama-3.1 base models. |
|[EasyRec: Simple yet Effective Language Model for Recommendation.](https://github.com/hkuds/easyrec) | EasyRec is a language paradigm created especially for jobs involving recommendations. To produce high-quality semantic embeddings, it makes use of cooperative data from several datasets and creative contrastive learning objectives.|
|[Classifying all of the pdfs on the internet.](https://snats.xyz/pages/articles/classifying_a_bunch_of_pdfs.html) |A wonderful post about classifying every PDF available on the internet according to its semantic content using clever prompting and embeddings. |
|[How to get from high school math to cutting-edge ML/AI: a detailed 4-stage roadmap with links to the best learning resources that I’m aware of.](https://www.justinmath.com/how-to-get-from-high-school-math-to-cutting-edge-ml-ai/?utm_source=tldrai) |Software experts can use the following four-step learning plan to comprehend advanced ML/AI papers: Basic math (calculus, algebra, linear algebra, probability, statistics), deep learning (multi-layer neural networks), classical machine learning (basic regression, classification models), and cutting-edge machine learning (transformers, LLMs, diffusion models) are the first four areas of study in machine learning. For stages 1-2, author-created content is essential, while for stages 3–4, suggested outside items are necessary. Once each level is mastered, students are better prepared to take on challenging ML papers and keep up with the rapidly advancing field of AI research. |
|[llamafile v0.8.13](https://github.com/Mozilla-Ocho/llamafile/releases/tag/0.8.13?utm_source=tldrai) | Whisper models are now supported by Llama files, which also offer a number of speed and quality-of-life enhancements.|
|[MeshFormer: High-Quality Mesh Generation with 3D-Guided Reconstruction Model.](https://meshformer3d.github.io/) |A quick, affordable, and cutting-edge approach for creating 3D meshes that can be trained on text or images. In particular, it employs a cascade of steps, such as a normal map generator, that transfers distinct duties to different submodels and signed distance function supervision. |
|[NeuFlow_v2.](https://github.com/neufieldrobotics/NeuFlow_v2) | Optical flow code that is incredibly quick and effective and suitable for low-power devices like phones and certain security camera systems.|
|[X-ray Report Generation.](https://github.com/event-ahu/medical_image_analysis) |To produce X-ray medical reports more efficiently and with less computer complexity, a new framework was created. |
|[TraDiffusion：Trajectory-Based Training-Free Image Generation.](https://github.com/och-mac/tradiffusion) |A novel technique called TraDiffusion uses mouse trajectories rather than box or mask controls to guide text-to-image generation. |
|[Loss Rider.](https://github.com/jndean/LossRider) | A fun utility that illustrates when loss functions converge and get too spiky by animating a curve rider sled as it descends them.|
|[kyScript-100M: 1,000,000,000 Pairs of Scripts and Shooting Scripts for Short Drama.](https://github.com/vaew/skyscript-100m) |The goal of the large dataset SkyScript-100M is to improve the production of excellent shooting scripts for short dramas. |
|[NeuFlow v2: High-Efficiency Optical Flow Estimation on Edge Devices.](https://arxiv.org/abs/2408.10161v1) |This work presents a novel approach to optical flow estimation that delivers excellent accuracy at a large computational cost savings. |
|[Torch-Pruning.](https://github.com/VainF/Torch-Pruning) |repository of cutting-edge techniques with numerous supported algorithms for language model pruning that is kept up to date. |
|[Image, Tell me your story!.](https://github.com/ukplab/5pils) | A novel strategy for identifying visual misrepresentation has been presented by researchers, which emphasizes the importance of the original meta-context of images—a factor that automated approaches frequently ignore. |
|[Pathology-LLaVA.](https://github.com/ddw2aigroup2cqupt/pa-llava) |Pathology image analysis is the target application for PA-LLaVA, a domain-specific language-vision assistant. |
|[Microsoft's Phi-3 family.](https://github.com/microsoft/Phi-3CookBook/blob/c53fa9fda5df6a42476dd8ba5f1ccb446dd1608c/md/01.Introduce/Phi3Family.md) | A detailed analysis of the MoE and vision model from Microsoft's recently released Phi 3.5 models. |
|[The Top 100 Gen AI Consumer Apps - 3rd Edition.](https://a16z.com/100-gen-ai-apps-3) |Based on customer interaction patterns, Andreessen Horowitz's most recent consumer AI research ranks the top 100 generative AI apps and divides them into the top 50 AI online products and the top 50 AI mobile apps. The research offers in-depth analyses of trends, new competitors in the sector, and developing categories. |
|[Eight basic rules for causal inference.](https://pedermisager.org/blog/seven_basic_rules_for_causal_inference/) | This comprehensive blog article explains the relationship between causal mechanisms and observable correlations using R code simulations, causal graphs, and logic concepts to illustrate the seven basic laws of causal inference.|
|[Jamba-1.5.](https://huggingface.co/collections/ai21labs/jamba-15-66c44befa474a917fcf55251) | AI21 has released new versions of its hybrid Transformer and State space model architecture.|
|[biorecap: an R package for summarizing bioRxiv preprints with a local LLM.](https://arxiv.org/abs/2408.11707v1) | The recently released biorecap R package uses locally run big language models to fetch and summarize recent publications, assisting academics in managing the massive amount of bioRxiv preprints.|
|[aurora.](https://github.com/microsoft/aurora) | Microsoft's high quality atmospheric prediction model, code, and checkpoints are available as open source.|
|[NuSegDG.](https://github.com/xq141839/nusegdg) | A novel framework named NuSegDG has been created by researchers to improve the generalizability of nuclei segmentation in various medical pictures.|
|[Pano2Room: Novel View Synthesis from a Single Indoor Panorama.](https://arxiv.org/abs/2408.11413v1) | Pano2Room is a novel technique that overcomes limitations in single-view 3D scene synthesis by reconstructing high-quality 3D indoor scenes from a single panoramic image.|
|[Awesome Object-Centric Robotic Manipulation.](https://github.com/rayyoh/ocrm_survey) | This repository offers a thorough introduction to embodied learning, a promising robotic manipulation methodology that prioritizes perceptual feedback and physical interaction.|









































