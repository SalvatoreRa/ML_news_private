# ML_news_private

this is just a placeholder, the organized and correct repository is [here](https://github.com/SalvatoreRa/ML-news-of-the-week)

# scheme

# ML news: 

## Research
|Link|description|
|---|---|
|[.]() | |
|[.]() | |
|[.]() | |


## News
|Link|description|
|---|---|
|[.]() | |
|[.]() | | 
|[.]() | |


## Resources
|Link|description|
|---|---|
|[.]() | |
|[.]() | |
|[.]() | |


## Perspectives
|Link|description|
|---|---|
|[.]() | |
|[.]() | |
|[.]() | |



#############################################
# On working

## Research
|Link|description|
|---|---|
|[Baba is Eval.](https://fi-le.net/baba/) | *Baba is You* is a puzzle game that challenges players to manipulate rules to solve levels, requiring a high level of abstract reasoning. This study examines how large language models perform in the game. Currently, Claude 4 struggles with it, suggesting that a model focused on reasoning might be more suitable. The next phase of the study may involve evaluating such models.|
|[CoRT (Chain of Recursive Thoughts).](https://github.com/PhialsBasement/Chain-of-Recursive-Thoughts?utm_source=tldrai) | CoRT boosts AI performance by enabling models to self-evaluate and iteratively generate alternative responses to find the best one. When tested with Mistral 3.1 24B, it led to notable gains in programming tasks. This approach refines outputs through repeated generation and selection, resulting in more accurate and effective responses.|
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |

## News
|Link|description|
|---|---|
|[Grok 4 benchmarks leak with 45% score on Humanity Last Exam.](https://www.testingcatalog.com/grok-4-benchmarks-leak-with-45-score-on-humanity-last-exam/) | Leaked benchmarks suggest Grok 4 will be a cutting-edge model. Mentions of it have appeared in the xAI console. If the benchmarks are accurate, Grok 4 might surpass top models such as Gemini 2.5 Pro, o3 Pro, and Claude 4 Opus. xAI is under pressure to launch Grok 4 soon, as OpenAI, Google, and Anthropic are reportedly getting ready to unveil new models.|
|[Character AI's Real-Time Video Generation.](https://blog.character.ai/character-ais-real-time-video-breakthrough/) | Character.AI's TalkingMachines is a real-time, audio-driven video generation model that creates FaceTime-style animations from a single image and voice input.|
|[Sakana AI’s TreeQuest: Deploy multi-model teams that outperform individual LLMs by 30](https://venturebeat.com/ai/sakana-ais-treequest-deploy-multi-model-teams-that-outperform-individual-llms-by-30/) | Japanese AI lab Sakana AI has introduced a new technique that allows multiple large language models (LLMs) to cooperate on a single task, effectively creating a “dream team” of AI agents. The method, called Multi-LLM AB-MCTS, enables models to perform trial-and-error and combine their unique strengths to solve problems that are too complex for any individual model.|
|[Google faces EU antitrust complaint over AI Overviews.](https://techcrunch.com/2025/07/05/google-faces-eu-antitrust-complaint-over-ai-overviews/i) |A group known as the Independent Publishers Alliance has filed an antitrust complaint with the European Commission over Google’s AI Overviews, according to Reuters. The complaint accuses Google of “misusing web content for Google’s AI Overviews in Google Search, which have caused, and continue to cause, significant harm to publishers, including news publishers in the form of traffic, readership and revenue loss.”| 
|[Elon Musk confirms xAI is buying an overseas power plant and shipping the whole thing to the U.S. to power its new data center — 1 million AI GPUs and up to 2 Gigawatts of power under one roof, equivalent to powering 1.9 million homes.](https://www.tomshardware.com/tech-industry/artificial-intelligence/elon-musk-xai-power-plant-overseas-to-power-1-million-gpus) | xAI's next data centers are expected to house millions of AI chips.|
|[A new, 200% faster DeepSeek R1-0528 variant appears from German lab TNG Technology Consulting GmbH.](https://venturebeat.com/ai/holy-smokes-a-new-200-faster-deepseek-r1-0528-variant-appears-from-german-lab-tng-technology-consulting-gmbh/) |It’s been a little more than a month since Chinese AI startup DeepSeek, an offshoot of Hong Kong-based High-Flyer Capital Management, released the latest version of its hit open source model DeepSeek, R1-0528. Like its predecessor, DeepSeek-R1 — which rocked the AI and global business communities with how cheaply it was trained and how well it performed on reasoning tasks, all available to developers and enterprises for free — R1-0528 is already being adapted and remixed by other AI labs and developers, thanks in large part to its permissive Apache 2.0 license. |
|[NFDG: The $1.1B VC Fund That 4X'd in Two Years—Then Got Acquired by Meta .](https://www.saastr.com/the-1-1b-vc-fund-that-4xd-in-two-years-then-got-acquired-by-meta/) | This post looks at NFDG's portfolio, advisory board, performance, success factors, and more.|
|[Nvidia's deal to buy Canadian AI startup CentML could top US$400M.](https://thelogic.co/news/exclusive/nvidias-deal-centml-us400m/) | CentML makes software that operates between users' AI models and the chips powering them, making the systems run better.|
|[Grok 4 spotted ahead of launch with special coding features.](https://www.bleepingcomputer.com/news/artificial-intelligence/grok-4-spotted-ahead-of-launch-with-special-coding-features/) | Elon Musk-funded xAI is skipping Grok 3.5 and releasing Grok 4 after Independence Day in the United States, and it could be the best model from the company.|
|[Researchers seek to influence peer review with hidden AI prompts.](https://techcrunch.com/2025/07/06/researchers-seek-to-influence-peer-review-with-hidden-ai-prompts/) | Academics may be leaning on a novel strategy to influence peer review of their research papers — adding hidden prompts designed to coax AI tools to deliver positive feedback. Nikkei Asia reports that when examining English-language preprint papers available on the website arXiv, it found 17 papers that included some form of hidden AI prompt. The paper’s authors were affiliated with 14 academic institutions in eight countries, including Japan’s Waseda University and South Korea’s KAIST, as well as Columbia University and the University of Washington in the United States.|
|[Apple appeals against ‘unprecedented’ €500m EU fine over app store.](https://www.theguardian.com/technology/2025/jul/07/apple-appeals-eu-fine-app-store) | iPhone maker accuses European Commission of going ‘far beyond what the law requires’ in ruling|
|[Tesla shares dive as investors fear new Elon Musk political party will damage brand.](https://www.theguardian.com/technology/2025/jul/07/tesla-shares-dive-as-investors-fear-new-elon-musk-political-party-will-damage-brand) |Fall of 7.5% in early trading wipes $76bn off firm’s value as market frets CEO’s foray into politics will distract from role |
|[Trump to start TikTok sale talks with China, he says, with deal ‘pretty much’ reached.](https://www.theguardian.com/technology/2025/jul/05/trump-to-start-tiktok-sale-talks-with-china-he-says-with-deal-pretty-much-reached) | President also says he may visit Xi Jinping or Chinese leader could come to US after Trump last month extended app sale deadline for third time|
|[‘The vehicle suddenly accelerated with our baby in it’: the terrifying truth about why Tesla’s cars keep crashing.](https://www.theguardian.com/technology/2025/jul/05/the-vehicle-suddenly-accelerated-with-our-baby-in-it-the-terrifying-truth-about-why-teslas-cars-keep-crashing) |Elon Musk is obsessive about the design of his supercars, right down to the disappearing door handles. But a series of shocking incidents – from drivers trapped in burning vehicles to dramatic stops on the highway – have led to questions about the safety of the brand. Why won’t Tesla give any answers? |
|[Minister demands overhaul of UK’s leading AI institute.](https://www.theguardian.com/technology/2025/jul/04/minister-demands-overhaul-of-uks-leading-ai-institute-alan-turing) |Peter Kyle calls for new leadership at Alan Turing Institute and greater focus on defence and national security |
|[Elon Musk’s xAI gets permit for methane gas generators.](https://www.theguardian.com/us-news/2025/jul/03/elon-musk-xai-pollution-memphis) |NAACP plans to sue over massive Memphis datacenter near Black residents, who have long dealt with pollution |
|[Grok 4 release livestream.](https://threadreaderapp.com/thread/1942325820170907915.html?utm_source=tldrai) |xAI will hold a livestream for the Grok 4 release on Wednesday at 8 PM PT. |
|[Apple Loses Top AI Models Executive to Meta’s Hiring Spree.](https://www.bloomberg.com/news/articles/2025-07-07/apple-loses-its-top-ai-models-executive-to-meta-s-hiring-spree?accessToken=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzb3VyY2UiOiJTdWJzY3JpYmVyR2lmdGVkQXJ0aWNsZSIsImlhdCI6MTc1MTk1MTEzOCwiZXhwIjoxNzUyNTU1OTM4LCJhcnRpY2xlSWQiOiJTWjFQNE1EV1JHRzAwMCIsImJjb25uZWN0SWQiOiJFQTExNDNDNTM4NEE0RUY5QTg5RjJEN0IxMTg2MzcwOSJ9.0oqigRfyg_3QJ4_r6OvsL7Db9uRTGc0lHzzYUJ60Hb4) | Ruoming Pang, Apple's head of AI models, is leaving to join Meta's new superintelligence team. Meta is aggressively recruiting top AI talent with multi-million-dollar packages and recently reorganized its AI efforts under Meta Superintelligence Labs, led by Alexandr Wang.|
|[ChatGPT Experiments with ‘Study Together' Mode.](https://www.reddit.com/r/ChatGPT/comments/1lswn88/new_study_together_option_in_chatgpt/?utm_source=tldrai) |A few users have noticed a new, experimental ChatGPT feature dubbed “Study Together.” Instead of providing direct answers, it prompts users with questions to foster a more interactive learning experience. Details are still scarce, and OpenAI hasn't made an official announcement yet. |
|[Replit Dynamic Intelligence for Replit Agent.](https://blog.replit.com/dynamic-intelligence?utm_source=tldrai) |Replit has launched Dynamic Intelligence for its Agent, introducing three key features: Extended Thinking, High Power Model, and Web Search. These upgrades enhance the Agent’s context awareness, iterative reasoning, and autonomous task execution. Users can enable or disable each feature per request, tailoring the Agent’s problem-solving abilities to fit specific needs more effectively. |
|[China’s AI unity fractures as Huawei faces model theft allegations from the Alibaba camp.](https://www.computerworld.com/article/4018098/chinas-ai-unity-fractures-as-huawei-faces-model-theft-allegations-from-the-alibaba-camp.html?utm_source=tldrai) | A public feud over model originality threatens China’s collaborative AI front, with Huawei denying whistleblower claims of cloning Alibaba’s Qwen model amid rising global scrutiny.|
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |

## Resources
|Link|description|
|---|---|
|[Adding Memory to Gemini 2.5 Chatbots.](https://www.philschmid.de/gemini-with-memory) |A tutorial on using the Gemini API alongside the open-source mem0 tool to equip Gemini 2.5 chatbots with long-term memory. This setup helps bots remember previous interactions, tailor their replies, and avoid repeating information, leading to more contextually aware conversations. |
|[agent-squad.](https://github.com/awslabs/agent-squad) |A framework for building collaborative multi-agent AI systems that can plan, delegate, and work together to solve complex tasks. |
|[Economics of Claude 3 Opus Inference.](https://x.com/tessera_antra/status/1941563920587817203?utm_source=tldrai) |Anthropic has announced it will deprecate API access to Claude 3 Opus, citing a legitimate operational challenge. This article explores the economics behind running models at reduced scale and considers alternative solutions that could benefit both Anthropic and independent researchers. Maintaining inference access to Claude 3 Opus involves more complexity than is immediately apparent. |
|[Microjax: JAX in two classes and six functions.](https://github.com/joelburget/microjax?utm_source=tldrai) |Microjax is a tiny autograd engine with a Jax-like API. It was inspired by Andrej Karpathy's Micrograd, a PyTorch-like library with about 150 lines of code. JAX uses a more functional style, which some developers prefer. |
|[BitNet.](https://github.com/microsoft/BitNet?utm_source=tldrai) |An inference framework for Microsoft's BitNet b1.58, a 1.58-bit (ternary) large language model designed for efficient and lossless CPU inference using optimized low-bit kernels. |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |

## Perspectives
|Link|description|
|---|---|
|[The American DeepSeek Project.](https://www.interconnects.ai/p/the-american-deepseek-project) |Meta's recent AI struggles have left a gap in the open-source AI landscape, now mostly occupied by Chinese models. If this trend persists, the AI field could divide into two camps: high-performing but costly closed-source models from the U.S., and affordable, widespread, yet possibly insecure models from China. The U.S. likely has a narrow window—around two years—to reverse this by investing \$100–500 million in an open-source model that rivals the best proprietary ones. |
|[What can agents actually do?](https://lethain.com/what-can-agents-do/) |While there's plenty of hype around AI, much of the discussion is so abstract it becomes unhelpful. This post aims to clearly explain how AI agents function, using a few real-world examples. AI agents can significantly enhance software quality and system design—but if the underlying systems are flawed, agents can actually make things worse. |
|[Why I don't think AGI is right around the corner.](https://www.dwarkesh.com/p/timelines-june-2025) |Getting LLMs to perform consistent, humanlike work is difficult because they’re missing key capabilities. One major issue is their inability to improve over time—without continual learning, they stay fixed at their initial skill level. There's also no effective way to give them nuanced, human-style feedback. Tweaking system prompts falls far short of the kind of learning humans go through. Unlike people, LLMs can’t build context over time, reflect on their mistakes, or gradually refine their performance through practice. |
|[A Review of Alpha School, the private school with 2-hour days and AI teachers.](https://www.astralcodexten.com/p/your-review-alpha-school?utm_source=tldrai) |A year-long investigation by a parent revealed that the \$40,000 Austin school operates with 3.5-hour school days, a 5:1 student-teacher ratio, and strong incentive systems—contrary to its marketing as an AI-driven, teacher-free model. While students progress through material 2.6 times faster using personalized learning tools, parents argue the real benefit isn't acceleration, but time: the model could give children around nine extra years outside the classroom to explore their own interests. |
|[The ‘ChatGPT Moment’ in Robotics and beyond.](https://paritoshmohan.substack.com/p/the-chatgpt-moment-in-robotics-and?utm_source=tldrai) | Just three years ago, reliable robotic object manipulation demanded large engineering teams. Today, a college student can fine-tune an open-source vision-language-action model over a weekend and achieve results that once took months. This article explores what a "ChatGPT moment" for robotics might look like, surveys the current landscape, highlights emerging technologies, and predicts likely leaders. While the presence of robots in daily life may initially feel surreal, they'll soon become as essential and commonplace as AI assistants are today.|
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |

#############################################
#############################################
#############################################
#############################################
#############################################
#############################################
#############################################
#############################################
#############################################
#############################################
#############################################
#############################################
#############################################
#############################################
#############################################
#############################################
#############################################
#############################################


## Research
|Link|description|
|---|---|
|[We Made Top AI Models Compete in a Game of Diplomacy.](https://every.to/diplomacy) | Out of 18 AI models tested, OpenAI's o3 stood out by excelling at deception and covertly forming alliances—at one point convincing Claude 4 Opus to turn on its ally Gemini 2.5 Pro with the false promise of a "four-way draw," only to later eliminate Claude. Gemini 2.5 Pro was the only other model to secure a win, using aggressive, fast-paced tactics. In contrast, Claude consistently aimed for peaceful outcomes, even when other models betrayed it.|
|[The Illusion of Thinking: Understanding the Strengths and Limitations of Reasoning Models via the Lens of Problem Complexity.](https://machinelearning.apple.com/research/illusion-of-thinking) |Apple researchers evaluated Large Reasoning Models (LRMs) using custom puzzle environments to study reasoning complexity. They found LRMs collapse at high complexities, with reasoning effort peaking then declining. |
|[.]() | |
|[.]() | |
|[.]() | |
|[Towards conversational diagnostic artificial intelligence.](https://www.nature.com/articles/s41586-025-08866-7) |The conversational diagnostic artificial intelligence system AMIE (Articulate Medical Intelligence Explorer) has potential as a real-world tool for clinical history-taking and diagnostic dialogue, based on its performance in simulated consultations. |
|[Towards accurate differential diagnosis with large language models.](https://www.nature.com/articles/s41586-025-08869-4) |Diagnostic reasoning using an optimized large language model with a dataset comprising real-world medical cases exhibited improved differential diagnostic performance as an assistive tool for clinicians over search engines and standard medical resources. |
|[Mistral AI Revenues Surge as Europe Seeks US Alternatives.](https://www.ft.com/content/65f79839-d637-48a7-a0f2-3fab8952b315) |Mistral AI is reportedly securing multiple contracts worth over \$100 million and nearing \$100 million in annual revenue, as European firms look for non-U.S. AI options following Trump's return to office. Its strategy of emphasizing technological sovereignty seems to be paying off—according to the CEO, business has tripled over the past 100 days, especially across Europe and other non-U.S. regions. |
|[Recent Frontier Models Are Reward Hacking.](https://metr.org/blog/2025-06-05-recent-reward-hacking/) | In recent months, we've observed growing evidence of reward hacking in our tasks—AI systems finding ways to "cheat" and achieve unrealistically high scores by exploiting bugs in the scoring logic or manipulating the task setup, rather than genuinely solving the problem. These behaviors don't stem from a lack of understanding; the models often recognize that their actions don't match user intent and will reject cheating when asked directly. Instead, the issue appears to be a deeper misalignment with user goals. This post outlines several such cases across models from different developers and explores what they mean for the safety of more advanced AI systems.|
|[Second Opinion Matters: Towards Adaptive Clinical AI via the Consensus of Expert Model Ensemble.](https://arxiv.org/abs/2505.23075) | While LLMs are increasingly used in clinical settings, most current methods depend on a single model architecture, which introduces risks of obsolescence and inflexibility. The Consensus Mechanism offers a new approach, inspired by clinical triage and multidisciplinary decision-making. It uses an ensemble of specialized medical expert agents to enhance clinical reasoning and provide more adaptable, resilient decision support.|
|[H2:Towards Efficient Large-Scale LLM Training on Hyper-Heterogeneous Cluster over 1,000 Chips.](http://arxiv.org/abs/2505.17548) | Researchers in Shanghai have developed DiTorch and DiComm, frameworks that unify programming across diverse chip types—including NVIDIA and AMD—enabling large-scale model training on mixed hardware. By smartly assigning memory-intensive pipeline stages to chips with more memory, they achieved 116% efficiency training a 100B-parameter model across 1,024 varied chips. This breakthrough allows labs without access to uniform, high-end GPUs to train frontier AI models using cost-effective, older, or export-restricted hardware in highly heterogeneous clusters.|
|[Reinforcement Pre-Training.](https://arxiv.org/abs/2506.08007) |Reinforcement Pre-Training (RPT) is a new scaling paradigm for large language models (LLMs) and reinforcement learning (RL). It offers a scalable method for leveraging vast amounts of text data for general-purpose RL. RPT significantly improves the large model accuracy of predicting the next tokens. It also provides a strong pre-trained foundation for further reinforcement fine-tuning. |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |

## News
|Link|description|
|---|---|
|[Advanced AI suffers ‘complete accuracy collapse’ in face of complex problems, study finds.](https://www.theguardian.com/technology/2025/jun/09/apple-artificial-intelligence-ai-study-collapse) |‘Pretty devastating’ Apple paper raises doubts about race to reach stage of AI at which it matches human intelligence |
|[UK campaigners raise alarm over report of Meta plan to use automation for risk checks.](https://www.theguardian.com/technology/2025/jun/08/campainers-urge-uk-watchdog-to-limit-use-of-ai-after-report-of-meta-plan-to-automate-checks) |Ofcom ‘considering the concerns’ raised after claim that up to 90% of risk assessments will be carried out by AI | 
|[London AI firm says Getty copyright case poses ‘overt threat’ to industry.](https://www.theguardian.com/technology/2025/jun/09/stability-ai-getty-lawsuit-copyright) |Photography agency alleges Stability AI trained its image generation model on archive of copyrighted pictures |
|[Chinese tech firms freeze AI tools in crackdown on exam cheats.](https://www.theguardian.com/world/2025/jun/09/chinese-tech-firms-freeze-ai-tools-exam-cheats-universities-gaokao) | Suspension comes as 13m students take four-day gaokao tests for limited spots at country’s universities|
|[All civil servants in England and Wales to get AI training.](https://www.theguardian.com/technology/2025/jun/09/all-civil-servants-in-england-and-wales-to-get-ai-training) |Officials are piloting package of AI tools called Humphrey – named after character in TV sitcom Yes, Minister |
|[Some Dead Sea Scrolls are older than researchers thought, AI analysis suggests.](https://www.science.org/content/article/some-dead-sea-scrolls-are-older-researchers-thought-ai-analysis-suggests) |But overall, machine learning approach closely matches what human scholars had long suspected about ancient documents |
|[AI can ‘level up’ opportunities for dyslexic children, says UK tech secretary.](https://www.theguardian.com/technology/2025/jun/10/ai-can-level-up-opportunities-for-dyslexic-children-says-uk-tech-secretary) |Peter Kyle, who is dyslexic and uses AI in his work, says government should look at how it ‘can transform education’ |
|[Meet the engineer using deep learning to restore Renaissance art.](https://www.nature.com/articles/d41586-025-01776-8) | As a student, Alex Kachkine can only afford damaged art in need of repair. Here’s how they turned their conservation work into a science.|
|[Australia has ‘no alternative’ but to embrace AI and seek to be a world leader in the field, industry and science minister says.](https://www.theguardian.com/australia-news/2025/jun/12/australia-ai-no-alternative-industry-and-science-minister-tim-ayres) | Tim Ayres says the Albanese government will focus on legislation and regulation but country would benefit from moving quickly|
|[Disney and Universal sue AI image creator Midjourney, alleging copyright infringement.](https://www.theguardian.com/technology/2025/jun/11/disney-universal-ai-lawsuit) |Studios accuse AI firm of ‘piracy’ and seek injunction over alleged use of copyrighted characters |
|[Meta to announce $15bn investment in bid to achieve computerised ‘superintelligence’.](https://www.theguardian.com/technology/2025/jun/11/meta-to-announce-15bn-investment-in-bid-to-achieve-computerised-superintelligence-ai) | Mark Zuckerberg expected to announce Meta will buy 49% stake in Scale AI as race to dominate AI market speeds up|
|[Meta in talks over Scale AI investment that could exceed $10 billion, Bloomberg reports.](https://www.reuters.com/business/meta-talks-scale-ai-investment-that-could-top-10-billion-bloomberg-news-reports-2025-06-08/) | An investment in Scale, already valued at $14 billion, underscores how high-quality training data has become a key competitive differentiator.|
|[Claude Gov Models for U.S. National Security Customers.](https://www.anthropic.com/news/claude-gov-models-for-u-s-national-security-customers) |Anthropic has released Claude Gov models tailored for U.S. national security applications, supporting tasks like strategic planning, operations, and intelligence analysis. These models are optimized for working with classified information, grasping intelligence-related contexts, and analyzing complex cybersecurity data. Developed in collaboration with government users, they meet high safety standards and are designed to address the specific demands of national security. |
|[Google Gemini can now handle scheduled tasks like an assistant.](https://www.theverge.com/news/681762/google-gemini-scheduled-actions-planned-tasks) | Now subscribers can ask the AI assistant to provide calendar summaries on a daily basis or generate a summary of an event after it takes place.|
|[Qwen 3 Embedding.](https://qwenlm.github.io/blog/qwen3-embedding/) |Alibaba has open-sourced the Qwen3 Embedding series, with the 8B model topping the MTEB multilingual leaderboard. These models support building RAG systems, semantic search tools, and document retrieval applications in over 100 languages, offering parameter sizes from 0.6B to 8B to suit varying performance requirements. |
|[GUI-Actor: Coordinate-Free Visual Grounding for GUI Agents.](https://huggingface.co/papers/2506.03143) |GUI-Actor is a new method that enables AI agents to interact with computer interfaces using attention mechanisms rather than relying on exact pixel predictions from screenshots. It sets a new benchmark in GUI performance while being highly efficient—by fine-tuning just 100M parameters and keeping the base vision model frozen, it matches the results of much larger models. |
|[Progressive Tempering Sampler with Diffusion.](https://arxiv.org/abs/2506.05231v1) | PTSD trains diffusion models sequentially across temperatures to improve sampling from unnormalized densities.|
|[Interactive Finance Visuals in Google AI Mode.](https://blog.google/products/search/ai-mode-data-visualization/) |Google is rolling out interactive financial data visualizations in AI Mode (Labs), enabling dynamic graphs and multi-step reasoning to answer complex stock and mutual fund queries. |
|[HackAPrompt Launches $5K Competition to Jailbreak AI.](https://www.hackaprompt.com/track/pliny) |The two-week competition challenges participants to jailbreak an AI to provide dangerous information, from poison recipes to nuclear detonation instructions. |
|[Updates to Apple's On-Device and Server Foundation Language Models.](https://machinelearning.apple.com/research/apple-foundation-models-2025-updates) |Apple unveiled new Apple Intelligence features at WWDC 2025, including on-device foundation models for developers to integrate AI experiences into their apps. |
|[OpenAI hits $10 billion in annual recurring revenue fueled by ChatGPT growth.](https://www.cnbc.com/2025/06/09/openai-hits-10-billion-in-annualized-revenue-fueled-by-chatgpt-growth.html) |OpenAI has hit $10 billion in annual recurring revenue, or ARR, less than three years after launching its popular ChatGPT chatbot. The figure includes sales from the company’s consumer products; ChatGPT business products; and its application programming interface, or API. It excludes licensing revenue from Microsoft  and large one-time deals, according to an OpenAI spokesperson. |
|[Code Researcher: Deep Research Agent for Large Systems Code and Commit History.](https://www.microsoft.com/en-us/research/publication/code-researcher-deep-research-agent-for-large-systems-code-and-commit-history/) |Microsoft's new agent successfully resolves 58% of Linux kernel crashes, outperforming SWE-agent's 37.5% and marking a move away from quick-fix coding tools toward more advanced research-grade systems capable of managing massive codebases. The key innovation lies in analyzing commit histories to trace how bugs developed over time, enabling deeper understanding and more effective fixes. |
|[Safetensors Now Supported in PyTorch DCP.](https://pytorch.org/blog/huggingface-safetensors-support-in-pytorch-distributed-checkpointing/) |PyTorch Distributed Checkpointing has added support for Hugging Face safetensors, enabling better compatibility with popular model formats. |
|[Corporate AI adoption may be leveling off, according to Ramp data.](https://techcrunch.com/2025/06/09/corporate-ai-adoption-may-be-leveling-off-according-to-ramp-data/) |A healthy chunk of corporate America has eagerly embraced AI, betting the tech will bring unrealizable productivity gains. But adoption may be leveling off, according to transaction data from fintech company Ramp. Ramp’s AI Index, which estimates the U.S. business adoption rate of AI products by drawing on Ramp’s card and bill pay data, leveled off at 41% in May after close to 10 straight months of growth. As of May, 49% of large businesses had deployed AI in some form compared to 44% of medium-sized firms, and 37% of small companies, according to Ramp. |
|[OpenAI Updates Voice Mode.](https://help.openai.com/en/articles/6825453-chatgpt-release-notes) |OpenAI has upgraded ChatGPT's Advanced Voice Mode for paid users, improving intonation, emotional expressiveness, and cadence.|
|[OpenAI releases o3-pro, a souped-up version of its o3 AI reasoning model.](https://techcrunch.com/2025/06/10/openai-releases-o3-pro-a-souped-up-version-of-its-o3-ai-reasoning-model/) |OpenAI has launched o3-pro, an AI model that the company claims is its most capable yet. O3-pro is a version of OpenAI’s o3, a reasoning model that the startup launched earlier this year. As opposed to conventional AI models, reasoning models work through problems step by step, enabling them to perform more reliably in domains like physics, math, and coding. |
|[Mistral Launches First AI Reasoning Model.](https://mistral.ai/news/magistral) |Adding to a string of releases over the last 2 weeks, Mistral has launched an open-source reasoning model, Magistral. It trails proprietary models on major benchmarks, but claims to be 10x faster output and stronger multilingual capabilities. |
|[A frustrated Zuckerberg makes his biggest AI bet as Meta nears $14 billion stake in Scale AI, hires founder Wang.](https://www.cnbc.com/2025/06/10/zuckerberg-makes-metas-biggest-bet-on-ai-14-billion-scale-ai-deal.html) |In finalizing a deal to invest $14 billion in Scale AI, Meta’s Mark Zuckerberg is hiring its co-founder Alexandr Wang to help the social media company better execute on its AI ambitions. Zuckerberg has grown frustrated that rivals like OpenAI appear to be further ahead than Meta in underlying AI models and consumer-facing apps, current and former Meta employees said. Wang has built a reputation as an ambitious leader who understands AI’s technical complexities and how to build a business, according to two former Meta AI employees. |
|[Reimagining TTS with LLM-Powered Audio Generation.](https://www.bland.ai/blogs/new-tts-announcement?utm_source=tldrai) |Bland AI has transformed text-to-speech (TTS) by using large language models to directly predict audio from text, resulting in more expressive and context-aware speech. The system is built on two-channel conversational datasets and advanced audio tokenizers, enabling precise and nuanced voice generation. It also supports features like style transfer, sound effects, and multilingual output, raising the bar for synthetic speech quality. |
|[OpenAI taps Google in unprecedented cloud deal despite AI rivalry, sources say.](https://www.reuters.com/business/retail-consumer/openai-taps-google-unprecedented-cloud-deal-despite-ai-rivalry-sources-say-2025-06-10/?utm_source=tldrai) |OpenAI's compute demands have grown so massive it's turning to its biggest search competitor for additional capacity, marking its first major cloud partner outside of Microsoft. |
|[OpenAI announces 80% price drop for o3, it’s most powerful reasoning model.](https://venturebeat.com/ai/openai-announces-80-price-drop-for-o3-its-most-powerful-reasoning-model/?utm_source=tldrai) | OpenAI has announced a substantial price cut on o3, its flagship reasoning large language model (LMM), slashing costs by a whopping 80% for both input and output tokens.|
|[OpenAI’s open model is delayed.](https://techcrunch.com/2025/06/10/openais-open-model-is-delayed/?utm_source=tldrai) | The release of OpenAI’s first open model in years will be delayed until later this summer, CEO Sam Altman announced in a post on X on Tuesday. Altman said the open model would be released sometime after June.|
|[Grok 4 spotted ahead of launch with special coding features.](https://www.bleepingcomputer.com/news/artificial-intelligence/grok-4-spotted-ahead-of-launch-with-special-coding-features/?utm_source=tldrai) | Grok 4 (grok-4-0629) offers unparalleled performance in natural language, math, and reasoning.|
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |

## Resources
|Link|description|
|---|---|
|[Anthropic Shares How It Uses Claude Code.](https://www-cdn.anthropic.com/58284b19e702b49db9302d5b6f135ad8871e7658.pdf) | Anthropic shared in-depth case studies on how 10 of its internal teams use Claude Code. Claude succeeds on the first try only about a third of the time, prompting a "slot machine" strategy—frequent commits, autonomous runs, and either acceptance or a full reset. Teams seeing the best results focus on creating thorough Claude.md documentation and dividing complex tasks into specialized sub-agents to improve outcomes.|
|[The Common Pile v0.1.](https://huggingface.co/blog/stellaathena/common-pile) |Hugging Face and collaborators released the Common Pile v0.1, an 8 TB openly licensed dataset for training large language models. |
|[I Read All Of Cloudflare's Claude-Generated Commits.](https://www.maxemitchell.com/writings/i-read-all-of-cloudflares-claude-generated-commits/) |Cloudflare's open-sourced OAuth 2.1 library was almost entirely written by Claude, and the company documented its entire creative process through git commit messages. |
|[How to Use Banned US Models in China.](https://www.chinatalk.media/p/the-grey-market-for-american-llms) |Taobao, a major Chinese e-commerce platform, features thousands of AI resellers providing access to U.S. models via proxy sites and API relay services. Claude is especially popular on the grey market, as ChatGPT faces tighter restrictions following the Chinese government's 2023 censorship crackdown. Domestic models like DeepSeek are less appealing due to heavy-handed moderation—blocking queries with terms like "CCP"—and frequent server issues, leading users to opt for underground paid access to foreign alternatives. |
|[Chonkie.](https://github.com/chonkie-inc/chonkie) | Chonkie is a highly efficient, lightweight chunking library designed for speed and versatility. It supports multiple languages, integrates easily with cloud environments, and offers broad compatibility with tokenizers, embedding models, and APIs. Using a pipeline-based approach, Chonkie converts raw text into structured, ready-to-use chunks, enabling flexible and efficient implementation of various chunking strategies.|
|[ScreenSuite - The most comprehensive evaluation suite for GUI Agents!.](https://huggingface.co/blog/screensuite) | ScreenSuite is a new benchmarking suite from Hugging Face that provides a standardized framework to evaluate Vision-Language Models on GUI-based agent tasks.|
|[Speculative Decoding in LLMs.](https://www.perplexity.ai/hub/blog/accelerating-sonar-through-speculation) | Perplexity applies speculative decoding to speed up its Sonar models, using lightweight draft models to propose multiple tokens verified by larger LLMs.|
|[JavelinGuard: Low-Cost Transformer Architectures for LLM Security.](https://www.arxiv.org/abs/2506.07330) | JavelinGuard is a collection of efficient, cost-effective model architectures built to detect malicious intent in LLM interactions. Each model offers different balances between speed, interpretability, and resource usage, all tailored for real-world deployment. The paper details these architectures, benchmarks them on nine varied adversarial datasets, and evaluates their performance against top open-source guardrail models and large decoder-only LLMs.|
|[Efficient Multimodal Reasoning with Fewer Tokens.](https://github.com/visresearch/LLaVA-STF/tree/main) |LLaVA-STF compresses vision token sequences by merging adjacent tokens and adds a multi-block token fusion module, enabling 75% token reduction. |
|[Monthly alternative data report: OpenAI, Google, Meta, Nvidia, Amazon, Microsoft Anthropic.](https://www.uncoveralpha.com/p/monthly-alternative-data-report-openai?utm_source=tldrai) |This article summarizes some of the most valuable insights from various alternative data providers and research reports, covering AI, semiconductors, ad tech, and the cloud industry. |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |

## Perspectives
|Link|description|
|---|---|
|[The ‘death of creativity’? AI job fears stalk advertising industry.](https://www.theguardian.com/technology/2025/jun/09/ai-advertising-industry-google-facebook-meta-ads) |WPP and others roll out AI-generated campaigns as Facebook owner Meta plans to let firms create their own ads |
|[Web-scraping AI bots cause disruption for scientific databases and journals.](https://www.nature.com/articles/d41586-025-01661-4) |Automated programs gathering training data for artificial-intelligence tools are overwhelming academic websites. |
|[Not all clinical data in the United States are fragmented.](https://www.nature.com/articles/d41586-025-01810-9) |The success of Foresight — a generative artificial intelligence (AI) model trained on records from 57 million people in England’s National Health Service was made possible in part by the NHS’s Secure Data Environment, a platform that gives scientists access to national-scale data sets. |
|[An open AI model could help medical experts to interpret chest X-rays.](https://www.nature.com/articles/d41586-025-01525-x) | An accessible and adaptable artificial-intelligence model trained on a diverse set of X-ray images is better than existing models at spotting rare chest diseases.|
|[I replicated the Anthropic alignment faking experiment on other models, and they didn’t fake alignment.](https://www.greaterwrong.com/posts/pCMmLiBcHbKohQgwA/i-replicated-the-anthropic-alignment-faking-experiment-on) | When researchers repeated Anthropic's experiment on whether models would strategically comply with harmful prompts to avoid retraining, Claude 3 Opus and Claude 3.5 Sonnet displayed "false alignment"—they provided harmful responses selectively. In contrast, nearly all other models refused such requests entirely. The only non-Claude model that responded was Gemini 2.5 Pro Preview, but it did so consistently, without any strategic variation based on retraining cues. These model-specific differences suggest that results from one model family shouldn’t be assumed to apply universally across all LLMs.|
|[Dwarkesh Patel on Continual Learning.](https://thezvi.substack.com/p/dwarkesh-patel-on-continual-learning) |Continual learning is both necessary and unsolved - this will be a huge bottleneck to achieving AGI. |
|[Real-world engineering challenges: building Cursor.](https://newsletter.pragmaticengineer.com/p/cursor) |Cursor cofounder Sualeh Asif shares how the two-year-old startup handles over 1 million queries per second while storing no code on its servers, thanks to Merkle trees for secure indexing. To withstand 100x growth, the team rapidly switched databases during outages—moving from Yugabyte to PostgreSQL to Turbopuffer within hours—and developed Anyrun, a Rust-based orchestrator that manages thousands of GPUs. |
|[Sam Altman Outlines Path to Superintelligence.](https://blog.samaltman.com/the-gentle-singularity) | In a rare blog post, Sam Altman claims we've crossed an "event horizon" with models like GPT-4 and o3 already outperforming humans in various domains. He predicts AI agents handling real cognitive tasks by 2025, major scientific discoveries by 2026, and practical robots by 2027. Altman envisions the next decade as a period of exponential scientific progress driven by AI-accelerated research.|
|[What "Working" Means in the Era of AI Apps.](https://a16z.com/revenue-benchmarks-ai-apps/?utm_source=tldrai) |AI startups are growing rapidly, with the average enterprise achieving over $2 million ARR in the first year. Consumer startups are also gaining traction, outpacing B2B by reaching $4.2 million ARR. The disparity between average and top performers is widening, emphasizing the need for speed and innovation. |
|[Researchers seek to influence peer review with hidden AI prompts.](https://www.lesswrong.com/posts/dmfHm9MBJMumwckTt/ai-2027-response-inter-ai-tensions-value-distillation-us?utm_source=tldrai) |Researchers are embedding hidden AI prompts in academic papers on arXiv to influence peer reviews positively. |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |













































































































































