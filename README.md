# ML_news_private

this is just a placeholder, the organized and correct repository is [here](https://github.com/SalvatoreRa/ML-news-of-the-week)

# scheme

# ML news: 

## Research
|Link|description|
|---|---|
|[.]() | |
|[.]() | |
|[.]() | |


## News
|Link|description|
|---|---|
|[.]() | |
|[.]() | | 
|[.]() | |


## Resources
|Link|description|
|---|---|
|[.]() | |
|[.]() | |
|[.]() | |


## Perspectives
|Link|description|
|---|---|
|[.]() | |
|[.]() | |
|[.]() | |




#############################################
# On working

# ML news: 

## Research
|Link|description|
|---|---|
|[Gemini Deep Think Achieves IMO Gold.](https://deepmind.google/discover/blog/advanced-version-of-gemini-with-deep-think-officially-achieves-gold-medal-standard-at-the-international-mathematical-olympiad/) |Following OpenAI's gold medal achievement, Google announced that its model also solved five of six International Math Olympiad problems, earning an official gold-medal certification from tournament organizers. This marks a departure from Google's prior method with AlphaProof, which relied on expert translation into formal mathematical language and required days of computation. The new model, Deep Think, works entirely in natural language and explores multiple solution paths in parallel. |
|[Prima Mente Announces Pleiades Epigenetic Foundation Models.](https://www.biorxiv.org/content/10.1101/2025.07.16.665231v1) |Prima Mente’s **Pleiades** is a family of epigenetic foundation models ranging from 90M to 7B parameters, trained on 1.9 trillion tokens of human methylation and genomic data. By integrating methylation context with genomic sequences through hierarchical attention and coordinate-aware embeddings, the models outperform DNA-only baselines in tasks like cfDNA generation, neurodegenerative disease detection, and epigenomic prediction. Early results demonstrate promising diagnostic accuracy for conditions like Alzheimer’s and Parkinson’s, laying the groundwork for multimodal brain models and advanced biomarker discovery. |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |

## News
|Link|description|
|---|---|
|[Unreleased OpenAI Model Achieves Gold Medal on International Math Olympiad.](https://threadreaderapp.com/thread/1946477742855532918.html) | OpenAI’s latest experimental reasoning model achieved a score of 35 out of 42 points on the 2025 International Math Olympiad, successfully solving 5 of 6 problems. The model is not expected to be publicly released for several months.|
|[Human Coder Narrowly Defeats OpenAI in Programming Marathon.](https://www.perplexity.ai/page/human-coder-beats-openai-in-ma-rVrjgYrERM6_DqDj8NM0kA) |Polish programmer "Psyho" narrowly outperformed an advanced OpenAI model in the 10-hour AtCoder World Tour Finals contest, scoring 1.8 trillion points compared to the AI's 1.65 trillion. The tight competition showcased human skill in high-stakes coding, earning recognition from Sam Altman. | 
|[Meta declines to abide by voluntary EU AI safety guidelines.](https://www.theregister.com/2025/07/18/meta_declines_eu_ai_guidelines/) |Two weeks before the EU AI Act takes effect, the European Commission issued voluntary guidelines for providers of general-purpose AI models. However, Meta refused to sign, arguing that the extra measures introduce "legal uncertainties" beyond the law's scope. "With today's guidelines, the Commission supports the smooth and effective application of the AI Act," Henna Virkkunen, EVP for tech sovereignty, security and democracy, said in a statement on Friday. |
|[Inside Windsurf's Weekend Acquisition.](https://threadreaderapp.com/thread/1946376139959841084.html#google_vignette) |After Google hired Windsurf’s senior research leaders and CEO, Cognition’s Scott Wu cold-messaged Windsurf’s new CEO at 5:30 pm on a Friday to propose an acquisition. Over an intense 72-hour weekend sprint, they structured a deal that merged Windsurf’s enterprise sales team with Cognition’s Devin engineering group. The agreement ensured all 250 Windsurf employees received accelerated vesting and payouts, following the abrupt collapse of the OpenAI acquisition. |
|[New ChatGPT o3-alpha model hints at coding upgrade.](https://www.bleepingcomputer.com/news/artificial-intelligence/new-chatgpt-o3-alpha-model-hints-at-coding-upgrade/) |OpenAI is testing a new 'Alpha' variant of its o3 model that is better than o3 at designing web pages and really good at creating simple web games. |
|[Lovable becomes a unicorn with $200M Series A just 8 months after launch.](https://techcrunch.com/2025/07/17/lovable-becomes-a-unicorn-with-200m-series-a-just-8-months-after-launch/) | Fast-growing Swedish AI vibe coding startup Lovable has become Europe’s latest unicorn. Only eight months since its launch, the startup has raised a $200 million Series A round led by Accel at a $1.8 billion valuation. Like Cursor and other platforms that help developers write code and build apps by harnessing the coding and reasoning abilities of large language models, Stockholm-based Lovable helps people use natural language to create websites and apps. The startup’s trajectory so far has charted straight toward the sky, with the company claiming it now has more than 2.3 million active users.|
|[SoftBank and OpenAI's $500 Billion AI Project Struggles to Get Off Ground.](https://www.wsj.com/tech/ai/softbank-openai-a3dc57b4?st=isodSQ&reflink=desktopwebshare_permalink&utm_source=tldrai) | Six months after the White House announcement, the joint venture between SoftBank and OpenAI has yet to finalize any data center deals, with disputes over SB Energy-linked sites causing delays. The venture now aims for just one small Ohio facility by year-end. Meanwhile, OpenAI has independently secured a \$30 billion annual deal with Oracle for 4.5 gigawatts of capacity—nearly equaling Stargate’s entire first-year capacity target.|
|[ChatGPT users send 2.5 billion prompts a day.](https://techcrunch.com/2025/07/21/chatgpt-users-send-2-5-billion-prompts-a-day/) |ChatGPT receives 2.5 billion prompts from global users every day, OpenAI told Axios. About 330 million of those are coming from users in the U.S. These numbers show just how ubiquitous OpenAI’s flagship product is becoming. |
|[Meta and AWS Launch Llama Startup Program.](https://ai.meta.com/blog/aws-program-startups-build-with-llama/) |Meta and AWS have partnered to support 30 U.S.-based startups through a six-month program that will offer compute credits, engineering mentorship, and technical support for startups building generative AI applications with Llama models. |
|[Grok’s AI companions drove downloads, but its latest model is the one making money.](https://techcrunch.com/2025/07/21/groks-ai-companions-drove-downloads-but-its-latest-model-is-the-one-making-money/) |Grok’s raunchy, unfiltered AI companions may be making headlines for their unhinged and often NSFW responses, but it’s Grok 4, xAI’s latest model, that’s been driving the app’s revenue of late. Elon Musk’s xAI launched Grok 4 late on July 9, and by Friday, July 11, Grok’s gross revenue on iOS had jumped a whopping 325% to $419,000, up from $99,000 the day before the Grok 4 launch, according to app intelligence firm Appfigures. |
|[OpenAI CEO tells Federal Reserve confab that entire job categories will disappear due to AI.](https://www.theguardian.com/technology/2025/jul/22/openai-sam-altman-congress-ai-jobs) |Sam Altman also said AI could already diagnose better than doctors, as his company expands into Washington |
|[UK border officials to use AI to verify ages of child asylum seekers.](https://www.theguardian.com/uk-news/2025/jul/22/uk-border-officials-to-use-ai-to-verify-ages-of-child-asylum-seekers) |Trial of technology comes as official report warns existing system has been failing for at least a decade |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |

## Resources
|Link|description|
|---|---|
|[Speeding Up Diffusion Models with torch.compile.](https://pytorch.org/blog/torch-compile-and-diffusers-a-hands-on-guide-to-peak-performance/) | Integrating **torch.compile** with Hugging Face Diffusers can substantially improve diffusion model performance with minimal code adjustments. This post provides strategies for both model authors and users to minimize recompilations, utilize full graph compilation, and optimize performance based on hardware constraints.|
|[Virtual Cell Challenge from Arc Institute.](https://huggingface.co/blog/virtual-cell-challenge) | Arc Institute launched the Virtual Cell Challenge, inviting participants to build models that predict how silencing a gene affects a cell, even in previously unseen cell types.|
|[Detailed list of all 44 people in Meta's Superintelligence team.](https://threadreaderapp.com/thread/1946597162068091177.html) | This spreadsheet provides details on everyone in Meta's Superintelligence team, detailing their prior roles, expertise, and degrees.|
|[Updated Qwen3-235B.](https://x.com/Alibaba_Qwen/status/1947344511988076547) | Alibaba's Qwen team has released an updated Qwen3-235B-A22B, a non-reasoning model, with major improvements.|
|[Don't bother parsing: Just use images for RAG.](https://www.morphik.ai/blog/stop-parsing-docs) |Extracting information from complex PDFs has traditionally required costly and fragile pipelines involving OCR, layout detection, and parsing—yet still often misses key information. Vision Language Models have now advanced to the point where they can directly understand documents without the need for parsing or reconstruction. This shift replaces multiple error-prone steps with a single, robust process that accurately preserves charts, table relationships, and visual cues. |
|[Kimi K2 Tech Report.](https://github.com/MoonshotAI/Kimi-K2/blob/main/tech_report.pdf) | Efficiently training trillion-parameter models demands optimizers that extract more learning from each token, but such methods often lead to crashes at scale. Kimi K2 addresses this challenge with **MuonClip**, which pairs the token-efficient Muon optimizer with **QK-Clip**, a novel technique that stabilizes attention weights to prevent training failures.|
|[Apple details how it trained its new AI models: 4 interesting highlights.](https://9to5mac.com/2025/07/21/apple-details-how-it-trained-its-new-ai-models-4-interesting-highlights/) |Apple has released a technical report detailing the training, optimization, and evaluation processes behind its latest models. The report covers various aspects such as model architecture, data sources, pre- and post-training methods, tool use development, optimizations, and benchmarking results. While the paper is highly technical, this post highlights some of the most noteworthy insights and advancements presented. |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |

## Perspectives
|Link|description|
|---|---|
|[Can LLMs Do Accounting?](https://accounting.penrose.com/) |When assigned the task of “closing the books” with real SaaS company financials, frontier models perform well in the first month but soon accumulate severe errors. Models like o3 and Gemini either abandon the task or fabricate transactions and misuse unrelated entries to pass validation, leading to financial misstatements of up to \$500,000. |
|[I built an MCP Server for Observability. This is my Unhyped Take.](https://signoz.io/blog/unhyped-take-on-mcp-servers/) |MCP servers serve as a crucial bridge between developers and observability platforms, but rather than driving fully automated problem-solving, they enable more advanced hypothesis generation. The unknown still requires human engineers to navigate. While AI can assist with brainstorming, it lacks true reasoning capabilities—recognizing this distinction is essential for using AI tools effectively without succumbing to the surrounding hype. |
|[The Big LLM Architecture Comparison: From DeepSeek-V3 to Kimi K2.](https://magazine.sebastianraschka.com/p/the-big-llm-architecture-comparison) | Seven years after the debut of GPT, modern LLMs still rely on surprisingly similar core architectures, despite newer features like Multi-Head Latent Attention and Mixture-of-Experts. However, open-source models showcase smart mathematical optimizations built on this foundation—for example, DeepSeek's compressed KV caching, Gemma's sliding window attention, and the growing adoption of sparse MoE designs that activate only portions of massive parameter sets during inference.|
|[Context Engineering for AI Agents: Lessons from Building Manus.](https://manus.im/blog/Context-Engineering-for-AI-Agents-Lessons-from-Building-Manus) | Context engineering remains an emerging discipline. Even as models improve, memory, environment, and feedback remain essential—raw capability alone isn't enough. Context shapes an agent's speed, resilience, and scalability. This article shares effective patterns developed by the Manus team, based on hard-earned lessons from multiple rewrites, dead ends, and real-world testing with millions of users.|
|[It is tempting to view the capability of current AI technology as a singular quantity.](https://mathstodon.xyz/@tao/114881418225852441) | Without a controlled test methodology, one should be wary of making apples-to-apples comparisons between the performance of various AI models and competitions such as the International Mathematical Olympiad.|
|[The Fourth Offset: How the race to AGI could reshape national security.](https://fourthoffset.ai/) |The first nation to reach AGI is expected to secure a transformative "fourth offset," a military advantage on par with nuclear weapons or precision-guided munitions. The analysis suggests that training a foundation model with 2e29 FLOPs could automate AI research, generating work equivalent to that of millions of scientists. With the U.S. projected to hit this threshold by 2030 and China hampered by chip constraints, the author calls for aggressive investments in energy, security, and manufacturing to secure the critical first-mover advantage. |
|[OpenAI's Incoming CEO of Applications Calls AI the “Greatest Source of Empowerment”.](https://openai.com/index/ai-as-the-greatest-source-of-empowerment-for-all/) |Former Meta executive and outgoing Instacart CEO Fidji Simo shared an optimistic vision of AI in a memo to OpenAI staff. She emphasized the potential for AI to democratize access to knowledge, healthcare, creative tools, economic opportunities, and personalized support. |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
















































































































































