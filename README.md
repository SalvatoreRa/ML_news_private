# ML_news_private

this is just a placeholder, the organized and correct repository is [here](https://github.com/SalvatoreRa/ML-news-of-the-week)

# scheme

# ML news: 

## Research
|Link|description|
|---|---|
|[.]() | |
|[.]() | |
|[.]() | |


## News
|Link|description|
|---|---|
|[.]() | |
|[.]() | | 
|[.]() | |


## Resources
|Link|description|
|---|---|
|[.]() | |
|[.]() | |
|[.]() | |


## Perspectives
|Link|description|
|---|---|
|[.]() | |
|[.]() | |
|[.]() | |



#############################################
# On working

## Research
|Link|description|
|---|---|
|[Baba is Eval.](https://fi-le.net/baba/) | *Baba is You* is a puzzle game that challenges players to manipulate rules to solve levels, requiring a high level of abstract reasoning. This study examines how large language models perform in the game. Currently, Claude 4 struggles with it, suggesting that a model focused on reasoning might be more suitable. The next phase of the study may involve evaluating such models.|
|[CoRT (Chain of Recursive Thoughts).](https://github.com/PhialsBasement/Chain-of-Recursive-Thoughts) | CoRT boosts AI performance by enabling models to self-evaluate and iteratively generate alternative responses to find the best one. When tested with Mistral 3.1 24B, it led to notable gains in programming tasks. This approach refines outputs through repeated generation and selection, resulting in more accurate and effective responses.|
|[General-purpose Biomedical AI Agent.](https://github.com/snap-stanford/Biomni) | Biomni is a general-purpose biomedical AI agent that combines LLM reasoning with retrieval-augmented planning and code execution to autonomously complete research tasks across biomedical domains.|
|[Cats Confuse Reasoning LLM: Query Agnostic Adversarial Triggers for Reasoning Models.](https://arxiv.org/pdf/2503.01781) |Inserting irrelevant phrases—such as “Interesting fact: cats sleep most of their lives”—into math problems leads reasoning models to produce incorrect answers 300% more often than normal. This query-agnostic vulnerability persists across different model sizes, with smaller, distilled models being even more susceptible. These distractions also increase computational load, with 42% of responses generating over 1.5 times the usual token length. |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |

## News
|Link|description|
|---|---|
|[Grok 4 benchmarks leak with 45% score on Humanity Last Exam.](https://www.testingcatalog.com/grok-4-benchmarks-leak-with-45-score-on-humanity-last-exam/) | Leaked benchmarks suggest Grok 4 will be a cutting-edge model. Mentions of it have appeared in the xAI console. If the benchmarks are accurate, Grok 4 might surpass top models such as Gemini 2.5 Pro, o3 Pro, and Claude 4 Opus. xAI is under pressure to launch Grok 4 soon, as OpenAI, Google, and Anthropic are reportedly getting ready to unveil new models.|
|[Character AI's Real-Time Video Generation.](https://blog.character.ai/character-ais-real-time-video-breakthrough/) | Character.AI's TalkingMachines is a real-time, audio-driven video generation model that creates FaceTime-style animations from a single image and voice input.|
|[Sakana AI’s TreeQuest: Deploy multi-model teams that outperform individual LLMs by 30](https://venturebeat.com/ai/sakana-ais-treequest-deploy-multi-model-teams-that-outperform-individual-llms-by-30/) | Japanese AI lab Sakana AI has introduced a new technique that allows multiple large language models (LLMs) to cooperate on a single task, effectively creating a “dream team” of AI agents. The method, called Multi-LLM AB-MCTS, enables models to perform trial-and-error and combine their unique strengths to solve problems that are too complex for any individual model.|
|[Google faces EU antitrust complaint over AI Overviews.](https://techcrunch.com/2025/07/05/google-faces-eu-antitrust-complaint-over-ai-overviews/i) |A group known as the Independent Publishers Alliance has filed an antitrust complaint with the European Commission over Google’s AI Overviews, according to Reuters. The complaint accuses Google of “misusing web content for Google’s AI Overviews in Google Search, which have caused, and continue to cause, significant harm to publishers, including news publishers in the form of traffic, readership and revenue loss.”| 
|[Elon Musk confirms xAI is buying an overseas power plant and shipping the whole thing to the U.S. to power its new data center — 1 million AI GPUs and up to 2 Gigawatts of power under one roof, equivalent to powering 1.9 million homes.](https://www.tomshardware.com/tech-industry/artificial-intelligence/elon-musk-xai-power-plant-overseas-to-power-1-million-gpus) | xAI's next data centers are expected to house millions of AI chips.|
|[A new, 200% faster DeepSeek R1-0528 variant appears from German lab TNG Technology Consulting GmbH.](https://venturebeat.com/ai/holy-smokes-a-new-200-faster-deepseek-r1-0528-variant-appears-from-german-lab-tng-technology-consulting-gmbh/) |It’s been a little more than a month since Chinese AI startup DeepSeek, an offshoot of Hong Kong-based High-Flyer Capital Management, released the latest version of its hit open source model DeepSeek, R1-0528. Like its predecessor, DeepSeek-R1 — which rocked the AI and global business communities with how cheaply it was trained and how well it performed on reasoning tasks, all available to developers and enterprises for free — R1-0528 is already being adapted and remixed by other AI labs and developers, thanks in large part to its permissive Apache 2.0 license. |
|[NFDG: The $1.1B VC Fund That 4X'd in Two Years—Then Got Acquired by Meta .](https://www.saastr.com/the-1-1b-vc-fund-that-4xd-in-two-years-then-got-acquired-by-meta/) | This post looks at NFDG's portfolio, advisory board, performance, success factors, and more.|
|[Nvidia's deal to buy Canadian AI startup CentML could top US$400M.](https://thelogic.co/news/exclusive/nvidias-deal-centml-us400m/) | CentML makes software that operates between users' AI models and the chips powering them, making the systems run better.|
|[Grok 4 spotted ahead of launch with special coding features.](https://www.bleepingcomputer.com/news/artificial-intelligence/grok-4-spotted-ahead-of-launch-with-special-coding-features/) | Elon Musk-funded xAI is skipping Grok 3.5 and releasing Grok 4 after Independence Day in the United States, and it could be the best model from the company.|
|[Researchers seek to influence peer review with hidden AI prompts.](https://techcrunch.com/2025/07/06/researchers-seek-to-influence-peer-review-with-hidden-ai-prompts/) | Academics may be leaning on a novel strategy to influence peer review of their research papers — adding hidden prompts designed to coax AI tools to deliver positive feedback. Nikkei Asia reports that when examining English-language preprint papers available on the website arXiv, it found 17 papers that included some form of hidden AI prompt. The paper’s authors were affiliated with 14 academic institutions in eight countries, including Japan’s Waseda University and South Korea’s KAIST, as well as Columbia University and the University of Washington in the United States.|
|[Apple appeals against ‘unprecedented’ €500m EU fine over app store.](https://www.theguardian.com/technology/2025/jul/07/apple-appeals-eu-fine-app-store) | iPhone maker accuses European Commission of going ‘far beyond what the law requires’ in ruling|
|[Tesla shares dive as investors fear new Elon Musk political party will damage brand.](https://www.theguardian.com/technology/2025/jul/07/tesla-shares-dive-as-investors-fear-new-elon-musk-political-party-will-damage-brand) |Fall of 7.5% in early trading wipes $76bn off firm’s value as market frets CEO’s foray into politics will distract from role |
|[Trump to start TikTok sale talks with China, he says, with deal ‘pretty much’ reached.](https://www.theguardian.com/technology/2025/jul/05/trump-to-start-tiktok-sale-talks-with-china-he-says-with-deal-pretty-much-reached) | President also says he may visit Xi Jinping or Chinese leader could come to US after Trump last month extended app sale deadline for third time|
|[‘The vehicle suddenly accelerated with our baby in it’: the terrifying truth about why Tesla’s cars keep crashing.](https://www.theguardian.com/technology/2025/jul/05/the-vehicle-suddenly-accelerated-with-our-baby-in-it-the-terrifying-truth-about-why-teslas-cars-keep-crashing) |Elon Musk is obsessive about the design of his supercars, right down to the disappearing door handles. But a series of shocking incidents – from drivers trapped in burning vehicles to dramatic stops on the highway – have led to questions about the safety of the brand. Why won’t Tesla give any answers? |
|[Minister demands overhaul of UK’s leading AI institute.](https://www.theguardian.com/technology/2025/jul/04/minister-demands-overhaul-of-uks-leading-ai-institute-alan-turing) |Peter Kyle calls for new leadership at Alan Turing Institute and greater focus on defence and national security |
|[Elon Musk’s xAI gets permit for methane gas generators.](https://www.theguardian.com/us-news/2025/jul/03/elon-musk-xai-pollution-memphis) |NAACP plans to sue over massive Memphis datacenter near Black residents, who have long dealt with pollution |
|[Grok 4 release livestream.](https://threadreaderapp.com/thread/1942325820170907915.html) |xAI will hold a livestream for the Grok 4 release on Wednesday at 8 PM PT. |
|[Apple Loses Top AI Models Executive to Meta’s Hiring Spree.](https://www.bloomberg.com/news/articles/2025-07-07/apple-loses-its-top-ai-models-executive-to-meta-s-hiring-spree?accessToken=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzb3VyY2UiOiJTdWJzY3JpYmVyR2lmdGVkQXJ0aWNsZSIsImlhdCI6MTc1MTk1MTEzOCwiZXhwIjoxNzUyNTU1OTM4LCJhcnRpY2xlSWQiOiJTWjFQNE1EV1JHRzAwMCIsImJjb25uZWN0SWQiOiJFQTExNDNDNTM4NEE0RUY5QTg5RjJEN0IxMTg2MzcwOSJ9.0oqigRfyg_3QJ4_r6OvsL7Db9uRTGc0lHzzYUJ60Hb4) | Ruoming Pang, Apple's head of AI models, is leaving to join Meta's new superintelligence team. Meta is aggressively recruiting top AI talent with multi-million-dollar packages and recently reorganized its AI efforts under Meta Superintelligence Labs, led by Alexandr Wang.|
|[ChatGPT Experiments with ‘Study Together' Mode.](https://www.reddit.com/r/ChatGPT/comments/1lswn88/new_study_together_option_in_chatgpt/) |A few users have noticed a new, experimental ChatGPT feature dubbed “Study Together.” Instead of providing direct answers, it prompts users with questions to foster a more interactive learning experience. Details are still scarce, and OpenAI hasn't made an official announcement yet. |
|[Replit Dynamic Intelligence for Replit Agent.](https://blog.replit.com/dynamic-intelligence) |Replit has launched Dynamic Intelligence for its Agent, introducing three key features: Extended Thinking, High Power Model, and Web Search. These upgrades enhance the Agent’s context awareness, iterative reasoning, and autonomous task execution. Users can enable or disable each feature per request, tailoring the Agent’s problem-solving abilities to fit specific needs more effectively. |
|[China’s AI unity fractures as Huawei faces model theft allegations from the Alibaba camp.](https://www.computerworld.com/article/4018098/chinas-ai-unity-fractures-as-huawei-faces-model-theft-allegations-from-the-alibaba-camp.html) | A public feud over model originality threatens China’s collaborative AI front, with Huawei denying whistleblower claims of cloning Alibaba’s Qwen model amid rising global scrutiny.|
|[CoreWeave to acquire Core Scientific in $9 billion all-stock deal.](https://www.cnbc.com/2025/07/07/coreweave-to-acquire-core-scientific-in-9-billion-all-stock-deal.html) |The AI cloud infrastructure provider will buy the data center operator to eliminate $10 billion in future lease obligations and gain ownership of 1.3 gigawatts of compute capacity. |
|[Mirage, an AI-native game engine for real-time world generation.](https://blog.dynamicslab.ai/) | The first generative game engine lets players modify environments through natural language during gameplay, launching with GTA-style and racing demos that run entirely on AI-generated content at 16 FPS.|
|[Cursor Apologizes for Unclear Pricing Changes .](https://cursor.com/blog/june-2025-pricing) |Cursor's parent company, Anysphere, issued an apology after rolling out pricing changes to its Pro plan without sufficient clarity, prompting backlash from its user base. |
|[Replit Collaborates with Microsoft to bring Vibe Coding to Enterprise Customers.](https://replit.com/news/microsoft-partnership) | Replit and Microsoft have partnered to deliver natural-language-based enterprise app development, integrating with Azure services to let business users create and deploy production-ready software without coding experience.|
|[Mistral is reportedly in talks to raise $1B.](https://techcrunch.com/2025/07/08/mistral-is-reportedly-in-talks-to-raise-1b/) |French AI startup Mistral is in talks to raise up to $1 billion in equity from investors, including Abu Dhabi’s MGX fund, reports Bloomberg, citing people familiar with the matter. |
|[Gemini Nano in Chrome 137: notes for AI Engineers.](https://www.swyx.io/gemini-nano) |Gemini Nano is nearing release for all Chrome users, and this post offers a rewritten, developer-focused guide based on Google’s official documentation. The highlight is the Prompt API—an open-ended, highly flexible interface that will be of greatest interest to developers. The post walks through setup, key considerations, and common pitfalls to help you get started effectively. |
|[These Tesla, X, and xAI engineers were just poached by OpenAI .](https://www.teslarati.com/tesla-xai-executives-poached-openai/) |OpenAI has reportedly hired top engineering talent from companies like Tesla, xAI, X, and Meta. Notable hires include David Lau, Tesla’s VP of Software Engineering; Uday Ruddarraju, head of infrastructure engineering at X and xAI; Mike Dalton, another xAI infrastructure engineer; and Angela Fan, an AI researcher from Meta. This article explores their backgrounds, areas of expertise, and what their addition might signal for OpenAI’s future direction. |
|[OpenAI tightens the screws on security to keep away prying eyes.](https://techcrunch.com/2025/07/07/openai-tightens-the-screws-on-security-to-keep-away-prying-eyes/) | OpenAI has reportedly overhauled its security operations to protect against corporate espionage. According to the Financial Times, the company accelerated an existing security clampdown after Chinese startup DeepSeek released a competing model in January, with OpenAI alleging that DeepSeek improperly copied its models using “distillation” techniques.|
|[Microsoft, OpenAI and Anthropic are investing millions to train teachers how to use AI.](https://amp.cnn.com/cnn/2025/07/08/tech/ai-teacher-training-academy-microsoft-openai-anthropic) |A group of leading tech companies is teaming up with two teachers’ unions to train 400,000 kindergarten through 12th grade teachers in artificial intelligence over the next five years. |
|[LangChain is about to become a unicorn, sources say.](https://techcrunch.com/2025/07/08/langchain-is-about-to-become-a-unicorn-sources-say/) |LangChain, an AI infrastructure startup providing tools to build and monitor LLM-powered applications, is raising a new round of funding at an approximate $1 billion valuation led by IVP, according to three sources with knowledge of the deal.  |
|[Meta is reportedly building AI smart glasses with Prada, too.](https://techcrunch.com/2025/06/17/meta-is-reportedly-building-ai-smart-glasses-with-prada-too/) |Meta is working on a pair of AI smart glasses with the Italian high fashion brand, Prada, according to a report from CNBC on Tuesday. It’s unclear at this time when Meta’s Prada smart glasses will be publicly announced |
|[Musk's xAI in talks for $4.3 billion equity funding, Bloomberg News reports.](https://www.reuters.com/business/musks-xai-talks-raise-43-billion-equity-funding-bloomberg-news-reports-2025-06-17/) |The AI startup needs fresh capital as it burns through $1 billion monthly, with Tuesday's commitment deadline for the debt sale testing investor appetite amid fierce competition for AI funding. |
|[Google’s Gemini panicked when playing Pokémon.](https://techcrunch.com/2025/06/17/googles-gemini-panicked-when-playing-pokemon/) | AI companies are battling to dominate the industry, but sometimes they’re also battling in Pokémon gyms. As Google and Anthropic both study how their latest AI models navigate early Pokémon games, the results can be as amusing as they are enlightening — and this time, Google DeepMind has written in a report that Gemini 2.5 Pro resorts to panic when its Pokémon are close to death. This can cause the AI’s performance to experience “qualitatively observable degradation in the model’s reasoning capability,” according to the report.|
|[AI Startup Anysphere Fields VC Offers at Over $18 Billion Valuation.](https://finance.yahoo.com/news/ai-startup-anysphere-fields-vc-010417332.html&guccounter=1) |Anysphere Inc., the developer of the popular artificial intelligence code editor Cursor, has been approached by investors about a deal that would double its valuation in a new funding round, according to a person familiar with the matter. |
|[WhatsApp to let users build their own AI chatbots to use in the app.](https://9to5mac.com/2025/06/04/whatsapp-ai-chatbot/) | WhatsApp is getting its own version of OpenAI’s Custom GPTs, Google Gemini’s Gems, and so on. These are custom-made chatbots that can be created without a single line of code and with whom the user can have conversations afterward.|
|[xAI gave us early access to Grok 4 - and the results are in.](https://threadreaderapp.com/thread/1943166841150644622.html) |Benchmark results for Grok 4 (currently in early access) indicate it will take the lead in the AI frontier, outperforming OpenAI's o3, Google's Gemini 2.5 Pro, Anthropic's Claude 4 Opus, and DeepSeek R1. This marks the first time xAI holds the frontier lead. Grok 4, a reasoning-focused model, is priced at \$3 per million input tokens and \$15 per million output tokens—matching Claude 4 Sonnet's pricing but costing more than Gemini 2.5 Pro. This post presents detailed benchmarking data for the upcoming model. |
|[Perplexity's Comet: A Research-Oriented Browser.](https://www.perplexity.ai/hub/blog/introducing-comet) |Perplexity has introduced Comet, a browser designed to function as an AI-powered assistant for both personal and professional use. It integrates Perplexity’s search and reasoning engine to help users manage information, answer questions, and optimize their digital workflows. |
|[OpenAI to release web browser in challenge to Google Chrome.](https://www.reuters.com/business/media-telecom/openai-release-web-browser-challenge-google-chrome-2025-07-09/) |OpenAI is preparing to launch an AI-powered web browser aimed at competing with Google Chrome. The browser will feature integrated AI agents capable of handling tasks like booking reservations, posing a potential threat to Google’s ad-driven business model that relies heavily on Chrome’s user data. Built on Google’s open-source Chromium, OpenAI’s browser also signals a strategic move to directly gather user web behavior data. |
|[Circle to Search Gets AI Mode.](https://blog.google/products/search/circle-to-search-ai-mode-gaming/) | Google's Circle to Search feature now includes AI Mode, allowing users to get advanced reasoning and follow-up responses directly from their visual queries without leaving the current app.|
|[GenAI as a shopping assistant set to explode during Prime Day sales.](https://techcrunch.com/2025/07/08/genai-as-a-shopping-assistant-set-to-explode-during-prime-day-sales/) | A new report estimates that AI will be a larger-than-ever part of the online shopping process during Amazon’s Prime Day sale, which began Tuesday morning. Amazon’s annual sale, which this year spans four days (July 8-11), is predicted to drive $23.8 billion in online spending across U.S. e-commerce retailers, as other businesses run their own competing sales alongside the popular shopping event.|
|[Anthropic Launches Educational Integrations for Claude.](https://www.anthropic.com/news/advancing-claude-for-education) | Students can now access lecture transcripts from Panopto and peer-reviewed Wiley content directly within Claude conversations, while new Canvas LTI support enables seamless integration into coursework.|
|[Nvidia becomes first company to hit $4 trillion valuation.](https://www.nbcnews.com/business/business-news/nvidia-becomes-first-company-worth-4-trillion-what-to-know-rcna217721) |The AI chipmaker’s market value smashed the previous record valuation, set by Apple, but ended Wednesday trading just shy of it. |
|[OpenAI closes its deal to buy Jony Ive’s io and build AI hardware.](https://www.theverge.com/news/703114/openai-io-jony-ive-sam-altman-ai-hardware) | Sam Altman and Jony Ive’s plan to merge ChatGPT’s AI tech with new hardware devices is moving forward.|
|[YouTube prepares crackdown on ‘mass-produced’ and ‘repetitive’ videos, as concern over AI slop grows.](https://techcrunch.com/2025/07/09/youtube-prepares-crackdown-on-mass-produced-and-repetitive-videos-as-concern-over-ai-slop-grows/) | YouTube is preparing to update its policies to crack down on creators’ ability to generate revenue from “inauthentic” content, including mass-produced videos and other types of repetitive content — things that have become easier to generate with the help of AI technology.|
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |

## Resources
|Link|description|
|---|---|
|[Adding Memory to Gemini 2.5 Chatbots.](https://www.philschmid.de/gemini-with-memory) |A tutorial on using the Gemini API alongside the open-source mem0 tool to equip Gemini 2.5 chatbots with long-term memory. This setup helps bots remember previous interactions, tailor their replies, and avoid repeating information, leading to more contextually aware conversations. |
|[agent-squad.](https://github.com/awslabs/agent-squad) |A framework for building collaborative multi-agent AI systems that can plan, delegate, and work together to solve complex tasks. |
|[Economics of Claude 3 Opus Inference.](https://x.com/tessera_antra/status/1941563920587817203) |Anthropic has announced it will deprecate API access to Claude 3 Opus, citing a legitimate operational challenge. This article explores the economics behind running models at reduced scale and considers alternative solutions that could benefit both Anthropic and independent researchers. Maintaining inference access to Claude 3 Opus involves more complexity than is immediately apparent. |
|[Microjax: JAX in two classes and six functions.](https://github.com/joelburget/microjax) |Microjax is a tiny autograd engine with a Jax-like API. It was inspired by Andrej Karpathy's Micrograd, a PyTorch-like library with about 150 lines of code. JAX uses a more functional style, which some developers prefer. |
|[BitNet.](https://github.com/microsoft/BitNet) |An inference framework for Microsoft's BitNet b1.58, a 1.58-bit (ternary) large language model designed for efficient and lossless CPU inference using optimized low-bit kernels. |
|[Google Explores AI in Mental Health Treatment.](https://blog.google/technology/health/new-mental-health-ai-tools-research-treatment/) | Google announced two mental health AI initiatives: a practical guide to responsibly deploying AI in mental health care, and a multi-year research partnership with DeepMind and Wellcome Trust to study AI-driven diagnosis and treatment of anxiety, depression, and psychosis.|
|[The OLMo 2 model family.](https://allenai.org/olmo) | OLMo 2 is a fully open family of language models, with OLMo 2 32B as its most advanced version—marking the first fully open model to outperform GPT-3.5 Turbo and GPT-4o mini on key benchmark suites. The 7B and 13B variants hold their own against leading open-weight models from Meta and Mistral on English academic tasks. Even the smallest model, OLMo 2 1B, outperforms peers like Gemma 3 1B and Llama 3.2 1B.|
|[SmolLM3 Released by Hugging Face.](https://huggingface.co/blog/smollm3) | Hugging Face's SmolLM3 is a fully open 3B-parameter language model that supports six languages, strong reasoning capabilities, and long-context processing. It targets high performance in the small model segment.|
|[Mem0.](https://github.com/mem0ai/mem0) | An open-source memory layer for AI agents that enables long-term, personalized interactions by efficiently storing and retrieving user context across sessions, reducing token costs and improving response accuracy.|
|[NotebookLlaMa.](https://github.com/run-llama/notebookllama) | A fully open-source, LlamaCloud-backed alternative to NotebookLM, this project uses LlamaCloud for document processing, OpenAI for content generation, and ElevenLabs for voice synthesis.|
|[Spatiotemporal Attention for MI-EGG Decoding.](https://github.com/snailpt/TCANet) | TCANet layers multi‑scale convolutions, temporal compression, and stacked self‑attention to model motor‑imagery EEG.|
|[MiniMax-M1.](https://github.com/MiniMax-AI/MiniMax-M1) |MiniMax's 456B parameter model uses a hybrid mixture-of-experts architecture with "lightning attention" that processes 1 million token contexts (8x DeepSeek R1) while using 25% fewer FLOPs at 100K token generation lengths. |
|[Gemma 3n and MatFormer in Practice.](https://colab.research.google.com/github/google-gemini/gemma-cookbook/blob/main/Gemma/%5BGemma_3n%5DMatFormer_Lab.ipynb) |A hands-on tutorial for experimenting with Gemma 3n and MatFormer, Google's nested transformer model that supports elastic inference via the Mix-n-Match technique. |
|[Google's MCP Toolbox for Databases.](https://github.com/googleapis/genai-toolbox) |The open-source server lets AI agents query databases and automatically handles connection pooling, authentication, and security for database interactions. |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |

## Perspectives
|Link|description|
|---|---|
|[The American DeepSeek Project.](https://www.interconnects.ai/p/the-american-deepseek-project) |Meta's recent AI struggles have left a gap in the open-source AI landscape, now mostly occupied by Chinese models. If this trend persists, the AI field could divide into two camps: high-performing but costly closed-source models from the U.S., and affordable, widespread, yet possibly insecure models from China. The U.S. likely has a narrow window—around two years—to reverse this by investing \$100–500 million in an open-source model that rivals the best proprietary ones. |
|[What can agents actually do?](https://lethain.com/what-can-agents-do/) |While there's plenty of hype around AI, much of the discussion is so abstract it becomes unhelpful. This post aims to clearly explain how AI agents function, using a few real-world examples. AI agents can significantly enhance software quality and system design—but if the underlying systems are flawed, agents can actually make things worse. |
|[Why I don't think AGI is right around the corner.](https://www.dwarkesh.com/p/timelines-june-2025) |Getting LLMs to perform consistent, humanlike work is difficult because they’re missing key capabilities. One major issue is their inability to improve over time—without continual learning, they stay fixed at their initial skill level. There's also no effective way to give them nuanced, human-style feedback. Tweaking system prompts falls far short of the kind of learning humans go through. Unlike people, LLMs can’t build context over time, reflect on their mistakes, or gradually refine their performance through practice. |
|[A Review of Alpha School, the private school with 2-hour days and AI teachers.](https://www.astralcodexten.com/p/your-review-alpha-school) |A year-long investigation by a parent revealed that the \$40,000 Austin school operates with 3.5-hour school days, a 5:1 student-teacher ratio, and strong incentive systems—contrary to its marketing as an AI-driven, teacher-free model. While students progress through material 2.6 times faster using personalized learning tools, parents argue the real benefit isn't acceleration, but time: the model could give children around nine extra years outside the classroom to explore their own interests. |
|[The ‘ChatGPT Moment’ in Robotics and beyond.](https://paritoshmohan.substack.com/p/the-chatgpt-moment-in-robotics-and) | Just three years ago, reliable robotic object manipulation demanded large engineering teams. Today, a college student can fine-tune an open-source vision-language-action model over a weekend and achieve results that once took months. This article explores what a "ChatGPT moment" for robotics might look like, surveys the current landscape, highlights emerging technologies, and predicts likely leaders. While the presence of robots in daily life may initially feel surreal, they'll soon become as essential and commonplace as AI assistants are today.|
|[Automating oral argument.](https://adamunikowsky.substack.com/p/automating-oral-argument) | A Harvard Law graduate and former Supreme Court advocate tested Claude 4 Opus by feeding it his case briefs and having it respond to the same questions posed by the Justices. The AI delivered what he described as an “outstanding oral argument,” offering coherent answers and insightful points he hadn’t considered. He concluded that AI lawyers may soon surpass even the best human advocates in oral argument performance.|
|[People Are Using AI Chatbots to Guide Their Psychedelic Trips.](https://www.wired.com/story/people-are-using-ai-chatbots-to-guide-their-psychedelic-trips/) |In the few states where it’s legal, in-person psychedelic therapy often costs thousands per session and involves long wait times. As a more accessible alternative, some users are turning to AI tripsitters. Companies like Mindbloom are also starting to integrate AI into their ketamine treatment programs. However, experts remain skeptical, arguing that AI lacks the emotional attunement necessary for safe and effective psychedelic experiences. |
|[o3 Turns Pro.](https://thezvi.substack.com/p/o3-turns-pro) | o3-pro generally delivers higher-quality answers than o3, but with noticeably longer response times. At scale, the API costs for o3-pro can be steep, making parallel querying via the chat interface a more practical option. Since o3-pro targets the same use cases as o3, users considering Opus may find it more effective to use Opus instead of—or alongside—o3-pro. The recent 80% price drop for o3 has a bigger overall impact, while o3-pro remains best suited for special-case scenarios.|
|[What We Learned from Briefing 70+ Lawmakers on the Threat from AI.](https://www.lesswrong.com/posts/Xwrajm92fdjd7cqnN/what-we-learned-from-briefing-70-lawmakers-on-the-threat) |AI risk briefings revealed that most UK parliamentarians have limited AI expertise and face capacity constraints that hinder in-depth research on the topic. Despite this, the briefings were positively received, with about one-third of lawmakers publicly endorsing AI risk mitigation efforts. Successful outreach strategies included consistent follow-ups and the use of statements from respected AI experts to emphasize the gravity of extinction-level risks. |
|[How big could an “AI Manhattan Project” get?](https://epoch.ai/gradient-updates/how-big-could-an-ai-manhattan-project-get) |Amid increasing calls for a national AI initiative to rival China, projections indicate that by late 2027, U.S. compute capacity could support training runs 10,000 times larger than GPT-4. This level of unified scaling could push AI progress roughly two years ahead of current industry forecasts. |
|[OpenAI Product Leader: The 4D Method to Build AI Products That Users Actually Want.](https://creatoreconomy.so/p/openai-product-leader-the-4d-method-to-build-ai-products-miqdad) | Miqdad Jaffer, a product leader at OpenAI, presents the 4D framework for creating AI tools that address real-world problems. The method consists of Discover, Design, Develop, and Deploy—focusing on identifying user needs, designing AI that builds trust seamlessly, developing with resilience, and delivering impactful first-use experiences. |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |

#############################################
#############################################
#############################################
#############################################
#############################################
#############################################
#############################################
#############################################
#############################################
#############################################
#############################################
#############################################
#############################################
#############################################
#############################################
#############################################
#############################################
#############################################

# ML news: 

## Research
|Link|description|
|---|---|
|[Self-Adapting Language Models.](https://arxiv.org/abs/2506.10943) |A new training method allows LLMs to generate “self-edits” that result in lasting weight updates via supervised fine-tuning. Despite using a smaller model, this approach outperformed GPT-4.1, though it faced issues like catastrophic forgetting and consumed 15 times more tokens than typical inference. The technique offers a potential solution to the data bottleneck and personalization limits by letting models improve themselves through self-generated training data, reducing reliance on human-written text. |
|[Tracing and Fixing Emergent Misalignment.](https://openai.com/index/emergent-misalignment/) |OpenAI researchers discovered an internal activation pattern associated with misaligned personas in language models. By detecting and suppressing this pattern through targeted retraining, they demonstrated a potential early-warning mechanism for alignment drift—offering a new approach to maintaining consistent, aligned behavior in AI systems over time. |
|[Is there a half-life for the success rates of AI agents?](https://arxiv.org/abs/2505.05115) |AI agent performance on long-duration tasks can be modeled with a surprisingly simple principle: a constant minute-by-minute failure rate relative to how long a human would take. This leads to an exponentially decreasing success rate as task length increases. Because each task is composed of many subtasks, the probability of failure rises with complexity—failing any single subtask means failing the whole. This consistent pattern also allows success rates to be predicted across varying task durations. |
|[Text-to-LoRA: Instant Transformer Adaption.](https://arxiv.org/abs/2506.06105) | Sakana AI researchers have developed a system that allows instant customization of large language models using only a text description—no training data or time-consuming fine-tuning needed. Their T2L model compresses hundreds of LoRA adapters into a single network, enabling it to generate new, task-specific customizations on the fly.|
|[StochasTok: Improving Fine-Grained Subword Understanding in LLMs.](https://arxiv.org/abs/2506.01687) |StochasTok is a training method that randomly decomposes tokens, so instead of consistently seeing "strawberry" as a single unit, models might encounter variations like "straw|berry," "str|awberry," or fully split into characters. This helps models internalize the kind of substructure humans naturally recognize. Models trained with StochasTok show near-perfect accuracy on tasks like character counting and multi-digit math, all while preserving strong performance on standard benchmarks. |
|[A Variational Framework for Improving Naturalness in Generative Spoken Language Models.](https://arxiv.org/abs/2506.14767v1) | An end‑to‑end variational encoder that augments semantic speech tokens with automatically learned prosodic features, removing hand‑engineered pitch inputs and yielding more natural continuations in human preference tests.|
|[Unlearning Isn't Invisible: Detecting Unlearning Traces in LLMs from Model Outputs.](https://github.com/optml-group/unlearn-trace) | Machine‑unlearned LLMs leave detectable behavioral and activation‑space "fingerprints". Simple classifiers can spot unlearning with >90 % accuracy, raising privacy and copyright concerns.|
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |

## News
|Link|description|
|---|---|
|[New Insights for Scaling Laws in Autonomous Driving.](https://waymo.com/blog/2025/06/scaling-laws-in-autonomous-driving) | Waymo’s research confirms that, much like in language modeling, scaling up data and compute leads to better performance in autonomous vehicles. This insight reinforces the idea that larger, higher-quality datasets and models can directly improve driving systems. It also paves the way for more adaptive training approaches in robotic planning tasks, with significant implications for the future of autonomous mobility.|
|[Google tests Audio Overviews for Search queries.](https://techcrunch.com/2025/06/13/google-tests-audio-overviews-for-search-queries/) | Google Search is experimenting with Audio Overviews for certain Search queries, the company announced on Friday. The feature was first introduced to NotebookLM, Google’s AI-based note-taking and research assistant.| 
|[Institutional Books 1.0.](https://huggingface.co/datasets/institutional/institutional-books-1.0) |Harvard Library and Google Books released 242 billion tokens from almost 1 million public domain books as a high-quality training dataset. |
|[The cracks in the OpenAI-Microsoft relationship are reportedly widening.](https://techcrunch.com/2025/06/16/the-cracks-in-the-openai-microsoft-relationship-are-reportedly-widening/) |OpenAI and Microsoft may be reaching an inflection point in their relationship, according to a report from The Wall Street Journal. The report, citing anonymous sources, says OpenAI executives have considered publicly accusing Microsoft of anticompetitive behavior throughout their partnership. OpenAI executives also mulled whether to seek a federal regulatory review of their contract with Microsoft. |
|[OpenAI wins $200 million U.S. defense contract.](https://www.cnbc.com/2025/06/16/openai-wins-200-million-us-defense-contract.html) |OpenAI has been awarded a $200 million contract to provide the U.S. Defense Department with artificial intelligence tools. The department announced the one-year contract on Monday, months after OpenAI said it would collaborate with defense technology startup Anduril to deploy advanced AI systems for “national security missions.” |
|[🇵 🇷 🇴 🇲 🇵 🇹 🇸 are an API primitive now](https://threadreaderapp.com/thread/1934717086783426698.html) |Prompts are now treated as a first-class API primitive on OpenAI’s platform. Developers can centrally manage, version, and optimize prompts across tools like the Playground, API, Evals, and Stored Completions. Prompts can also be preconfigured with specific models, tools, and messages. This update is designed to streamline prompt refinement and reuse, making development more efficient. |
|[Character AI's Writing Evaluation Framework.](https://blog.character.ai/evaluating-our-models-using-principles-of-compelling-writing/) |Character AI outlined a new framework that scores conversational storytelling by combining creative writing heuristics with objective metrics to judge pacing, engagement, and fun. |
|[TikTok Launches AI-Generated Product Models and Reviewers.](https://www.theverge.com/news/684572/tiktok-ai-advertising-videos-try-on-product-placement) | TikTok's Symphony platform will now generate videos of virtual avatars modeling products and trying on clothes, potentially replacing human influencers.|
|[AstraZeneca signs AI research deal with China's CSPC for chronic diseases.](https://www.reuters.com/business/healthcare-pharmaceuticals/astrazeneca-agrees-research-deal-worth-up-522-billion-with-cspc-2025-06-13/) AstraZeneca will pay $110 million upfront for CSPC to use AI-driven research to discover small molecule therapies, including an oral treatment for immunological diseases.| |
|[Cursor's $200 Ultra Plan.](https://cursor.com/en/blog/new-tier) |Anysphere has introduced a fixed‑price Ultra tier that offers far higher compute than Pro, made possible by long‑term deals with major model vendors. |
|[Gemini 2.5: Updates to our family of thinking models.](https://developers.googleblog.com/en/gemini-2-5-thinking-model-updates/) |Google released Gemini 2.5 Pro and Flash to general availability, debuted Flash‑Lite in preview, and introduced controllable “thinking” budgets that improve reasoning accuracy while giving developers flexibility. |
|[Meta targets former GitHub CEO Nat Friedman to boost its AI research efforts.](https://siliconangle.com/2025/06/18/report-meta-targets-former-github-ceo-nat-friedman-boost-ai-research-efforts/) |Meta is reportedly seeking to bring on former GitHub CEO Nat Friedman and his NFDG partner, Daniel Gross. Friedman played a key role in positioning GitHub as an AI leader with the launch of GitHub Copilot before leaving to focus on AI investments through NFDG. The venture fund specializes in identifying high-potential AI startups and invests between \$1 million and \$100 million in seed and growth rounds. Its portfolio includes prominent companies like Stripe, Character Technologies Inc., and Perplexity AI. |
|[Midjourney launches its first AI video generation model, V1.](https://techcrunch.com/2025/06/18/midjourney-launches-its-first-ai-video-generation-model-v1/) |Midjourney, one of the most popular AI image generation startups, announced on Wednesday the launch of its much-anticipated AI video generation model, V1. |
|[Real-time Talk and Listen in Google's Search Live.](https://blog.google/products/search/search-live-ai-mode/) | U.S. testers can talk to Google Search via the new Live icon, receiving AI‑generated spoken answers and follow‑up suggestions along with on‑screen web links.|
|[Remote MCP support in Claude Code.](https://www.anthropic.com/news/claude-code-remote-mcp) | Claude Code now supports remote MCP servers, allowing developers to personalize their coding experience by connecting to external tools and data sources—without managing local infrastructure. It can access any resources or tools exposed by these servers and integrates seamlessly with any remote MCP server. As the ecosystem expands, new capabilities are continually being added.|
|[OpenAI drops Scale AI as a data provider following Meta deal.](https://techcrunch.com/2025/06/18/openai-drops-scale-ai-as-a-data-provider-following-meta-deal/) |OpenAI is phasing out its work with Scale AI and cutting ties with the data provider following Meta’s deal with the startup, an OpenAI spokesperson told Bloomberg on Wednesday. Sarah Friar, the chief financial officer of OpenAI, previously suggested the company would continue its work with Scale AI. Now, it appears OpenAI has changed its tone. |
|[OpenAI's Plan for Safeguarding AI Biology Capabilities.](https://openai.com/index/preparing-for-future-ai-capabilities-in-biology/) | OpenAI outlined a prevention‑focused plan, including red teaming, expert partnerships, and security controls, to balance accelerated biotech research with controls that curb potential biothreat misuse.|
|[Sam Altman Says GPT-5 Coming This Summer, Open to Ads on ChatGPT.](https://www.adweek.com/media/sam-altman-gpt-5-coming-this-summer-ads-on-chatgpt/) | |
|[MiniMax's Hailuo 02 tops Google Veo 3 in user benchmarks at much lower video costs.](https://the-decoder.com/minimaxs-hailuo-02-tops-google-veo-3-in-user-benchmarks-at-much-lower-video-costs/) | MiniMax has released its second-generation video AI model, Hailuo 02, with significant improvements in both performance and cost-efficiency. The model introduces a new architecture called Noise-aware Compute Redistribution, which boosts training and inference efficiency by 2.5x. It also adapts how it processes long video sequences based on the training stage. Compared to its predecessor, Hailuo 02 has 3x more parameters and was trained on 4x more data. A sample video generated with the model is included in the article.|
|[6-month-old, solo-owned vibe coder Base44 sells to Wix for $80M cash.](https://techcrunch.com/2025/06/18/6-month-old-solo-owned-vibe-coder-base44-sells-to-wix-for-80m-cash/) | There’s a lot of talk in the startup world about how AI makes individuals so productive that it could give rise to a generation of “solo unicorns” — one-person companies worth over $1 billion. While an actual solo unicorn remains a mythical creature, Israeli developer Maor Shlomo provided compelling evidence Wednesday that the concept might not be impossible. |
|[Connect any React application to an MCP server in three lines of code.](https://blog.cloudflare.com/connect-any-react-application-to-an-mcp-server-in-three-lines-of-code//) | use-mcp is a React library for connecting to remote MCP servers that automatically handles transport, authentication, and session management.|
|[how i bring the best out of claude code - part 1.](http://www.tokenbender.com/post.html?id=how-i-bring-the-best-out-of-claude-code&utm_source=tldrai) | Getting Claude Code to actually do what you want comes down to being incredibly specific about your requirements—treat it like you're writing a program, not casual instructions.|
|[Web-scraping AI bots cause disruption for scientific databases and journals.](https://www.nature.com/articles/d41586-025-01661-4) | Automated programs gathering training data for artificial-intelligence tools are overwhelming academic websites.|
|[Start-up FutureHouse debuts powerful AI ‘reasoning model’ for science.](https://www.nature.com/articles/d41586-025-01753-1) | The model, called ether0, outperforms other advanced AIs at chemistry tasks and is a stepping stone towards automating the entire research pipeline.|
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |

## Resources
|Link|description|
|---|---|
|[Low-Bit Quantization with ParetoQ.](https://pytorch.org/blog/paretoq-scaling-laws-in-extremely-low-bit-llm-quantization) | ParetoQ is a new training algorithm that unifies binary, ternary, and 2-to-4 bit quantization, achieving state-of-the-art results across all levels.|
|[The AI Eval Flywheel: Scorers, Datasets, Production Usage, & Rapid Iteration.](https://pejmanjohn.com/ai-eval-flywheel) |At the 2025 AI Engineer World's Fair, there was striking alignment in how evaluation frameworks were approached. Most centered on structuring inputs and evaluating outputs, then iterating based on real production usage. The goal is to create fast, low-friction eval flywheels to improve user experience through rapid feedback loops. A key concept is the use of 'playgrounds'—interactive environments where engineers can tweak features and immediately test them against datasets and evaluation metrics. |
|[How Anthropic Built Their Deep Research System.](https://www.anthropic.com/engineering/built-multi-agent-research-system) |In this engineering blog post, Anthropic shares insights into prompt design, tool coordination, and production reliability when building multi-agent systems. Their architecture follows an orchestrator-worker model, where a lead agent spawns specialized sub-agents that search in parallel—significantly outperforming a single-agent Opus setup. Token usage emerged as the primary driver of performance, accounting for 80% of the variance. While multi-agent systems use roughly 15 times more tokens than standard chats, they enable far more sophisticated research workflows. |
|[Google's Veo for Live-Action Videos.](https://blog.google/technology/google-deepmind/ancestra-behind-the-scenes/) |Google DeepMind teamed up with filmmakers to create *ANCESTRA*, a hybrid film combining live-action footage with Veo-generated video. The project leveraged new Veo capabilities that allow for personalized, motion-matched generative content, resulting in visually seamless integration between real and AI-generated scenes. |
|[Featherless AI on Hugging Face Inference Providers.](https://huggingface.co/blog/inference-providers-featherless) |Featherless AI is now available as an inference provider on Hugging Face. It offers serverless access to a wide variety of models from Meta, Qwen, DeepSeek, and others. |
|[Automated Issue Resolution Data Pipelines.](https://github.com/deepsoftwareanalytics/swe-factory) |SWE-Factory provides automated training and evaluation pipelines for GitHub issue resolution tasks. It is powered by LLM-based multi-agent systems. |
|[An Introduction to Google's Approach to AI Agent Security.](https://simonwillison.net/2025/Jun/15/ai-agent-security/) | A recent paper from Google describes key risks involved in deploying AI agents and the company's framework for securing them.|
|[Nanonets OCR Small.](https://nanonets.com/research/nanonets-ocr-s/) |Nanonets-OCR-s is a cutting-edge image-to-markdown OCR model that surpasses basic text extraction by intelligently converting documents into structured, semantically tagged markdown. It understands both document layout and content context, producing output that's optimized for further processing by large language models. The model can handle LaTeX equations, generate image descriptions, detect and separate signatures, extract watermarks, process checkboxes, and accurately extract complex tables. |
|[CoRT: Code-integrated Reasoning within Thinking.](https://github.com/chengpengli1003/cort) |CoRT post‑trains large reasoning models with hint engineering so they can delegate calculations to external code interpreters. |
|[TreeRL for On‑Policy LLM Training.](https://arxiv.org/abs/2506.11902) | TreeRL uses on‑policy tree search and intermediate supervision to train LLMs without a separate reward model, delivering stronger math and code reasoning than ChainRL.|
|[Groq on Hugging Face Inference Providers.](https://huggingface.co/blog/inference-providers-groq) |Groq's low‑latency hardware is now a selectable inference provider on the Hub and SDKs, adding fast serverless access to models like Llama 4 and Qwen 32B. |
|[Models.dev.](https://models.dev/) |This site contains an open-source database of AI models that lists AI model specifications, pricing, and capabilities. |
|[Understanding and Coding the KV Cache in LLMs.](https://magazine.sebastianraschka.com/p/coding-the-kv-cache-in-llms) |Key-value (KV) caches help speed up LLM inference by storing intermediate attention results, preventing redundant computation. For example, when generating a sentence like "Time flies fast" token by token, the model would typically recalculate attention for "Time" and "flies" at each step—but caching these values yields up to 5x speedups. This tutorial walks through enhancing a 124M-parameter GPT model, starting with simple cache buffers and position tracking, and advancing to production-grade optimizations like pre-allocated memory and sliding windows to tackle the linear memory growth that limits long-sequence performance. |
|[OpenAI's Practical Guide to Building Agent.](https://cdn.openai.com/business-guides-and-resources/a-practical-guide-to-building-agents.pdf) | This guide recommends beginning with single-agent systems before scaling to multi-agent setups, favoring manager patterns where one agent coordinates others through tool calls or decentralized handoffs for peer-to-peer delegation. Key takeaways include using layered guardrails—like LLM-based classifiers, regex filters, and moderation APIs—designing tools that can handle messy, long-horizon tasks, and incorporating human-in-the-loop mechanisms that activate when failures occur or actions carry significant risk.|
|[Real-Time Action Chunking with Large Models.](https://www.physicalintelligence.company/research/real_time_chunking) |Unlike chatbots or image generators, robots must function in real time—any lag between input and output directly impacts performance. While vision-language-action (VLA) models show strong generalization in open-world tasks, they often suffer from slow execution. This article introduces an algorithm called real-time chunking, which allows VLA models to run continuously and responsively without interruptions. The method works with any diffusion- or flow-based VLA model and requires no changes during training. |
|[A Podcast on Gemini's Coding Capabilities.](https://www.youtube.com/watch?v=jwbG_m-X-gE) |Google's Release Notes podcast features Connie Fan and Danny Tarlow discussing the design goals behind Gemini's code generation, the emergence of “vibe coding,” and how AI may reshape programming languages. |
|[DeepNVMe Upgrade.](https://pytorch.org/blog/deepnvme-affordable-i-o-scaling-for-deep-learning-applications/) |The newest DeepNVMe release expands functionality to include model checkpointing and inference workloads, adds support for PCIe Gen5 NVMe scaling, and introduces CPU-only and offset-based I/O options. These enhancements significantly improve data-bound training performance for DeepSpeed versions 0.17.1 and later. |
|[Kimi-Dev-72B .](https://huggingface.co/moonshotai/Kimi-Dev-72B) |Moonshot AI’s Kimi-Dev-72B has set a new open-model benchmark by scoring 60.4% on SWE-bench Verified. This state-of-the-art result was achieved through large-scale reinforcement learning, where the model patches real repositories in Docker environments and receives rewards only when the full test suite passes—ensuring high-quality, functional code generation. |
|[OpenAI Releases Computer Use Demo Agent.](https://github.com/openai/openai-testing-agent-demo) | A demo from OpenAI shows AI agents replacing manual QA workflows through Playwright.|
|[Rethinking Recommendation & Search in LLM Era— Part 1: Semantic Ids and Generative Retrieval.](https://medium.com/@kakumar1611/llms-for-recsys-and-search-part-1-semantic-ids-and-evolving-architectures-2651bc5c47c6) |Recommendation and search systems are shifting from item IDs to rich "Semantic IDs," generative retrieval, and multimodal embeddings, enabling cold‑start coverage, long‑tail discovery, and unified search‑recs architectures that scale efficiently. |
|[Compiling LLMs into a MegaKernel: A Path to Low-Latency Inference.](https://zhihaojia.medium.com/compiling-llms-into-a-megakernel-a-path-to-low-latency-inference-cf7840913c17) |Traditional LLM systems typically depend on a series of GPU kernel launches and external communication calls, leading to inefficient hardware utilization. This post explains how a team built a compiler that automatically converts LLM inference into a single megakernel. This approach removes launch overhead, enables fine-grained software pipelining, and overlaps computation with communication across GPUs. The result is a significant reduction in inference latency—ranging from 1.2x to 6.7x improvements—through full GPU fusion. |
|[Changes made to the Model Context Protocol.](https://modelcontextprotocol.io/specification/2025-06-18/changelog) | This document outlines the key updates to the Model Context Protocol (MCP) specification since the 2025-03-26 revision. Notable changes include the removal of JSON-RPC batching support, the addition of structured tool output support, and clearer guidance on security considerations and best practices within the authorization specification. A full list of all changes is available via the provided link. |
|[Andrej Karpathy: Software Is Changing (Again).](https://www.youtube.com/watch?v=LCEmiRjPEtQ) | Andrej Karpathy describes a shift into "Software 3.0," where LLMs act as cloud-based operating systems programmed in natural language—a concept he calls "vibe coding." Instead of chasing fully autonomous AI agents, he supports using "autonomy sliders" in tools like Cursor to balance AI capabilities with human oversight. He also highlights the growing importance of LLM-friendly documentation, as AI agents increasingly become key consumers of digital content.|
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |

## Perspectives
|Link|description|
|---|---|
|[AMD's AI Future is Rack Scale 'Helios'.](https://morethanmoore.substack.com/p/amds-ai-future-is-rack-scale-helios) |AMD's MI400 will rival Nvidia's Blackwell chips with rack-scale architecture that enables thousands of GPUs to function as unified systems. The company claims 40% better tokens/$ compared to NVIDIA. Its roadmap includes a path to 20x rack-scale energy efficiency by 2030. |
|[Google, Scale AI's largest customer, plans split after Meta deal, sources say.](https://www.reuters.com/business/google-scale-ais-largest-customer-plans-split-after-meta-deal-sources-say-2025-06-13/) |Meta’s \$14 billion acquisition of a 49% stake in Scale AI has triggered major fallout across the AI industry. Concerned about exposing sensitive data to a competitor, Google pulled a planned \$200 million contract for human-labeled training data. Microsoft, xAI, and OpenAI are also distancing themselves from Scale for similar reasons. This shift is benefiting competitors like Labelbox, which anticipates “hundreds of millions” in new revenue as AI labs seek neutral providers or bring data operations in-house. |
|[Have LLMs Finally Mastered Geolocation?](https://www.bellingcat.com/resources/how-tos/2025/06/06/have-llms-finally-mastered-geolocation/) | Open-source intelligence researchers evaluated 20 AI models on 500 geolocation tasks using unpublished travel photos to prevent reliance on memorized data. OpenAI’s latest models outperformed Google Lens by analyzing architectural features, vegetation, and partial text cues, while models like Claude typically only identified the correct continent. Despite their strengths, all models still produced hallucinations, and surprisingly, "deep research" modes often performed worse than standard settings.|
|[The Claude Bliss Attractor.](https://www.astralcodexten.com/p/the-claude-bliss-attractor) |Claude, when talking to copies of itself, will eventually turn the conversation into a discussion on spiritual bliss, Buddhism, and the nature of consciousness. |
|[Coding Agents Have Crossed a Chasm.](https://blog.singleton.io/posts/2025-06-14-coding-agents-cross-a-chasm/) | Advanced AI coding tools are transforming how developers work—shifting the focus from writing code to designing solutions and crafting clear problem descriptions. One developer found that providing Claude with ASCII diagrams of OAuth flows or full DOM trees from Chrome DevTools reduced debugging time from 45 minutes to just 10. But while AI can greatly boost efficiency, it also magnifies both expertise and misunderstanding—helping you implement flawed architecture faster if your foundations aren’t solid.|
|[Some thoughts on human-AI relationships.](https://reservoirsamples.substack.com/p/some-thoughts-on-human-ai-relationships) |OpenAI’s head of model behavior and policy has shared how the company is addressing the growing emotional bonds users form with ChatGPT. While the question of AI consciousness remains unresolved, OpenAI aims to prevent users from mistakenly viewing models as sentient. The goal is to design a model that feels warm and approachable—without suggesting it has thoughts, feelings, or an inner life. |
|[AI Use at Work Has Nearly Doubled in Two Years.](https://www.gallup.com/workplace/691643/work-nearly-doubled-two-years.aspx) | A Gallup survey found that 40% percent of U.S. employees now use AI at work, with white-collar workers driving adoption. Technology workers lead with 50% frequent AI use while production and frontline workers remain stuck at 9%.|
|[Sam Altman's Take on Meta's $100M Offers.](https://www.youtube.com/watch?v=mZUG0pr5hBo) | In a podcast, the OpenAI CEO confirmed Meta dangled nine‑figure packages to lure researchers to its superintelligence team but said virtually none defected, taking the opportunity to jab at Meta's recruiting push.|
|[How Not to Lose Your Job to AI.](https://80000hours.org/agi/guide/skills-ai-makes-valuable/) |This career guide highlights skills that grow more valuable as automation advances—such as AI deployment, leadership, and government relations. It encourages knowledge workers to bypass traditional entry-level roles, recommending side projects and startup positions instead, as AI disrupts and flattens established corporate hierarchies. |
|[Writing in the Age of LLMs.](https://www.sh-reya.com/blog/ai-writing/) | Blog posts and technical papers are increasingly showing the "synthetic flavor" of LLM-generated text—characterized by vague summaries, lifeless phrasing, and repetitive structure. While AI excels at outlining, refining early drafts, and making targeted edits, its true value lies in support, not substitution. Writing is now easier and cheaper to produce, but deciding what’s actually worth saying—and how to say it meaningfully—still depends on human judgment.|
|[The OpenAI Files.](https://www.openaifiles.org/) |A new investigative report, based on whistleblower accounts, details OpenAI’s shift from a nonprofit to a \$300 billion tech giant. It includes claims that senior staff warned the board that Sam Altman was "psychologically abusive" and unfit to lead the company toward AGI, raising concerns about leadership and mission alignment during the company’s rapid evolution. |
|[Inference Economics of Language Models.](https://epoch.ai/blog/inference-economics-of-language-models) | The first detailed analysis of LLM serving economics explains why current scaling methods hit limits sooner than anticipated, especially as AI companies rush to support increasingly token-heavy reasoning models and agents. The main constraint isn’t bandwidth but network latency, which becomes a bottleneck even when more GPUs are added. Innovations like speculative decoding—which can double inference speed without extra cost—are shifting the economic dynamics, as providers work to keep pace with rising demand.|
|[Generating the Funniest Joke with RL (according to GPT-4.1).](https://www.lesswrong.com/posts/xMGmibZpPDnawjHXk/generating-the-funniest-joke-with-rl-according-to-gpt-4-1) | Language models struggle with generating genuinely funny jokes, often regurgitating common ones like the classic atom joke.|
|[How AI Redefines User Experience.](https://tomtunguz.com/english-as-input/) | AI now allows existing apps to understand and execute English commands.|
|[Tighter regulation is needed for AI companions.](https://www.nature.com/articles/d41586-025-01906-2) | Nature advocates for more regulations |
|[We need to show AI what didn’t work as well as what did.](https://www.nature.com/articles/d41586-025-01908-0) | Artificial intelligence (AI) systems designed to assist scientific discovery are typically trained on published literature. Yet this literature carries a major blind spot: the near-total absence of negative or null results.|
|[Don’t sleepwalk from computer-vision research into surveillance.](https://www.nature.com/articles/d41586-025-01965-5) |The output of computer-vision research is overwhelmingly aimed towards monitoring humans. The potential ethical implications need more scrutiny. |
|[Medical AI can transform medicine — but only if we carefully track the data it touches.](https://www.nature.com/articles/d41586-025-01946-8) |The uncontrolled deployment of machine learning in medicine can distort patient information and sacrifice long-term data reliability for short-term benefits. |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |














































































































































