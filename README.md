# ML_news_private

this is just a placeholder, the organized and correct repository is [here](https://github.com/SalvatoreRa/ML-news-of-the-week)

# scheme

# ML news: 

## Research
|Link|description|
|---|---|
|[.]() | |
|[.]() | |
|[.]() | |

## News
|Link|description|
|---|---|
|[.]() | |
|[.]() | |
|[.]() | |


## Resources
|Link|description|
|---|---|
|[.]() | |
|[.]() | |
|[.]() | |

## Perspectives
|Link|description|
|---|---|
|[.]() | |
|[.]() | |
|[.]() | |

# ON WORKING

# ML news: 

## Research
|Link|description|
|---|---|
|[Discovering Preference Optimization Algorithms with and for Large Language Models.](https://arxiv.org/abs/2406.08414) |suggests an algorithm that adaptively combined logistic and exponential losses; this approach eliminates the need for human intervention by prompting an LLM to suggest and implement preference optimization loss functions based on previously assessed performance metrics. It also suggests an LLM-driven objective discovery of state-of-the-art preference optimization.  |
|[SelfGoal: Your Language Agents Already Know How to Achieve High-level Goals.](https://arxiv.org/abs/2406.04784) |a framework to increase the high-level goal-achieving capabilities of an LLM-based agent; during interaction with the environment, the framework adaptively decomposes a high-level goal into a tree structure of useful subgoals; enhances performance on a variety of tasks, including cooperative, competitive, and deferred feedback environments. |
|[Mixture-of-Agents Enhances Large Language Model Capabilities.](https://arxiv.org/abs/2406.04692) | a strategy that beats GPT-4o on AlpacaEval 2.0, MT-Bench, and FLASK by utilizing the combined strengths of several LLMs through a Mixture-of-Agents methodology; layers are constructed with numerous LLM agents, and each agent builds on the outputs of other agents in the previous levels.|
|[Transformers meet Neural Algorithmic Reasoners.](https://arxiv.org/abs/2406.09308) | Tokens in the LLM can now cross-attend to node embeddings from a GNN-based neural algorithmic reasoner (NAR) thanks to a new hybrid design; the resulting model, named TransNAR, shows gains in OOD reasoning across algorithmic challenges.|
|[Self-Tuning: Instructing LLMs to Effectively Acquire New Knowledge through Self-Teaching.](https://arxiv.org/abs/2406.06326) | increases an LLM's capacity to learn new information from raw documents through self-teaching; the process consists of three steps: 1) a self-teaching component that enhances documents with a series of knowledge-intensive tasks emphasizing comprehension, memorization, and self-reflection; 2) the model is configured to continuously learn using only the new documents, aiding in the thorough acquisition of new knowledge; and 3) the deployed model is used to learn new information from new documents while evaluating its QA skills.|
|[Visual Sketchpad: Sketching as a Visual Chain of Thought for Multimodal Language Models.](https://arxiv.org/abs/2406.09403) |a framework that gives a multimodal LLM access to a visual sketchpad and drawing tools; it can give a model, such as GPT-4, the ability to create intermediate sketches in order to reason over complex tasks; over strong base models without sketching, it performs better on many tasks; on all the tasks tested, GPT-4 equipped with SketchPad sets a new state of the art. |
|[Mixture of Memory Experts.](https://github.com/lamini-ai/Lamini-Memory-Tuning/blob/main/research-paper.pdf) |claims to enable scaling to a high number of parameters while keeping the inference cost fixed. It suggests a method to significantly reduce hallucination (10x) by tuning millions of expert adapters (e.g., LoRAs) to learn exact facts and retrieve them from an index at inference time. The memory experts are specialized to ensure faithful and factual accuracy on the data it was tuned on. |
|[Multimodal Table Understanding.](https://arxiv.org/abs/2406.08100) | presents Table-LLaVa 7B, a multimodal LLM for multimodal table understanding; it produces a large-scale dataset MMTab, comprising table images, instructions, and tasks; it is comparable with GPT-4V and greatly outperforms existing MLLMs on numerous benchmarks. |
|[Never Miss A Beat: An Efficient Recipe for Context Window Extension of Large Language Models with Consistent "Middle" Enhancement.](https://arxiv.org/abs/2406.07138) |suggests a training-efficient way to extend LLMs to longer context lengths (e.g., 4K -> 256K); it uses a truncated Gaussian to encourage sampling from the middle part of the context during fine-tuning; the approach helps to alleviate the so-called "Lost-in-the-Middle" problem in long-context LLMs. suggests a method to tune an LLM to effectively utilize information from the middle part of the context. |
|[Simple and Effective Masked Diffusion Language Models.](https://s-sahoo.com/mdlm/) | Easy diffusion model to model language. It functions fairly well and generates out of order.|
|[MLKV: Multi-Layer Key-Value Heads for Memory Efficient Transformer Decoding.](https://arxiv.org/abs/2406.09297v1) |A novel technique that dramatically lowers memory consumption during auto-regressive inference in transformers is called Multi-Layer Key-Value (MLKV) sharing. |
|[Understanding Hallucinations in Diffusion Models through Mode Interpolation.](https://arxiv.org/abs/2406.09358v1) | This study looks into the reasons behind "hallucinations"‚Äîimages that never were in the training set‚Äîthat are produced by diffusion-based picture generation models.|
|[Chain of Preference Optimization: Improving Chain-of-Thought Reasoning in LLMs.](https://arxiv.org/abs/2406.09136v1) |A technique called Chain of Preference Optimization (CPO) helps large language models (LLMs) become more adept at logical reasoning. CPO matches the reasoning steps of Chain-of-Thought (CoT) decoding with the optimal routes of ToT by fine-tuning LLMs using search trees from the Tree-of-Thought (ToT) technique. |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |

## News
|Link|description|
|---|---|
|[Apple to ‚ÄòPay‚Äô OpenAI for ChatGPT Through Distribution, Not Cash.](https://www.bloomberg.com/news/articles/2024-06-12/apple-to-pay-openai-for-chatgpt-through-distribution-not-cash) | The collaboration between Apple and OpenAI isn't anticipated to bring in a significant amount of money for either company, at least not right away. Apple is not paying OpenAI as part of the agreement because it feels that integrating OpenAI's technology and brand into its products is as valuable as or more valuable than financial compensation. The agreement isn't exclusive; Apple is already talking about providing additional chatbot choices. In the long run, Apple intends to profit from AI by entering into revenue-sharing contracts with AI partners.|
|[AI will make money sooner than you‚Äôd think, says Cohere CEO Aidan Gomez.](https://www.theverge.com/24173858/ai-cohere-aidan-gomez-money-revenue-llm-transformers-enterprise-stochastic-parrot) |Enterprise is the pathway to profit, Gomez says, but maybe don‚Äôt ask it to do medicine quite yet. |
|[Fake beauty queens charm judges at the Miss AI pageant.](https://www.npr.org/2024/06/09/nx-s1-4993998/the-miss-ai-beauty-pageant-ushers-in-a-new-type-of-influencer) |An AI model from Romania named Aiyana Rainbow is a finalist in the first Miss AI pageant, which showcases AI-generated models on social media. The event is a part of "The FanVue World AI Creator Awards," which is organized by FanVue and highlights the talent of AI creators who can create captivating content without having to be the face of the work. The $5,000 prize package for Miss AI will include mentorship and support from the public relations community. At the end of June, the outcomes will be made public. |
|[Elon Musk reconsiders phone project after Apple Intelligence OpenAI integration.](https://www.teslarati.com/elon-musk-reconsiders-phone-apple-intelligence-openai-chatgpt-integration/) | Elon Musk threatened to forbid any Apple devices from being used on the properties of his firms in response to Apple integrating OpenAI ChatGPT on a few of its devices.|
|[Microsoft‚Äôs star AI chief peers into OpenAI‚Äôs code, highlighting an unusual rivalry.](https://www.semafor.com/article/06/14/2024/microsoft-ai-ceo-mustafa-suleyman-audits-openais-code) |Primarily, OpenAI was established as a safety net against DeepMind, the AI startup that Google purchased in 2014. However, Mustafa Suleyman, a co-founder of DeepMind, has recently been taking on an unimaginable task: delving into OpenAI's crown jewels, the proprietary algorithms that power foundation models like GPT-4, according to people familiar with the situation. This is due to the fact that Suleyman is currently Microsoft's head of AI initiatives. As part of Microsoft's multibillion-dollar investment in OpenAI, the corporation possesses the intellectual property rights to its software. |
|[Amazon says it‚Äôll spend $230 million on generative AI startups.](https://techcrunch.com/2024/06/13/amazon-says-itll-spend-230-million-on-generative-ai-startups/) |Amazon says that it will commit up to $230 million to startups building generative AI-powered applications. |
|[McDonald‚Äôs ends AI drive-thru trial as fast-food industry tests automation.](https://www.theguardian.com/business/article/2024/jun/17/mcdonalds-ends-ai-drive-thru) |Companies have touted AI as future of the industry, but technology has also resulted in viral videos of wrong orders |
|[Balance effects of AI with profits tax and green levy, says IMF.](https://www.theguardian.com/business/article/2024/jun/17/ai-profits-tax-green-levy-imf-carbon-emissions) | Governments faced with economic upheaval caused by artificial intelligence should consider fiscal policies including taxes on excess profits and a green levy to atone for AI-related carbon emissions, according to the International Monetary Fund.|
|[Introducing Gen-3 Alpha.](https://runwayml.com/blog/introducing-gen-3-alpha/) | Runway has developed a brand-new, incredibly potent video generation model. Many of the current functions on its platform will be powered by it. You can find examples at the given URL.|
|[DeepMind‚Äôs new AI generates soundtracks and dialogue for videos.](https://techcrunch.com/2024/06/17/deepminds-new-ai-generates-soundtracks-and-dialog-for-videos) | V2A is an AI system that DeepMind is developing to create synchronized soundtracks for videos. It generates music, sound effects, and dialogue using diffusion models trained on audio, dialogue transcripts, and video clips.|
|[Giant Chips Give Supercomputers a Run for Their Money .](https://spectrum.ieee.org/cerebras-wafer-scale-engine) |The California-based business Cerebras has proven in molecular dynamics calculations that their second-generation wafer-scale engine outperforms the fastest supercomputer in the world by a large margin. Additionally, it can infer sparse huge language models with no loss of accuracy at one-third of the energy cost of a complete model. The hardware of Cerebras allows for quick memory access and interconnects, which make both accomplishments possible. Cerebras aims to expand the scope of its wafer-scale engine applications to encompass a broader range of issues, such as airflow models surrounding cars and molecular dynamics simulations of biological processes. |
|[Nvidia becomes world‚Äôs most valuable company amid AI boom.](https://www.theguardian.com/technology/article/2024/jun/18/nvidia-valuation-most-valuable) | Chipmaker dethrones Microsoft and Apple as stock market surge boosts valuation above $3.34tn|
|[The ‚ÄòGodfather of AI‚Äô quit Google a year ago. Now he‚Äôs emerged out of stealth to back a startup promising to use AI for carbon capture.](https://fortune.com/europe/2024/06/18/godfather-ai-geoffrey-hinton-quit-google-year-ago-emerged-stealth-back-startup-cuspai-ai-carbon-capture/) |Renowned AI researchers Geoff Hinton and Max Welling have gathered a talented team to develop AI systems aimed at advancing material science for carbon capture. |
|[Nvidia Conquers Latest AI Tests‚Äã.](https://spectrum.ieee.org/mlperf-nvidia-conquers) |Nvidia's Hopper architecture-based systems excelled in two recent MLPerf AI benchmark tests, which assess the fine-tuning of large language models and the training of graph neural networks. |
|[Perplexity AI searches for users in Japan, via SoftBank deal.](https://techcrunch.com/2024/06/17/softbank-ties-up-with-perplexity/) |Perplexity is capitalizing on its strategic partnership with SoftBank to broaden its presence in Japan. As part of this initiative, it is providing a free year of its premium AI-powered search engine, Perplexity Pro. SoftBank's goal is to draw users by offering AI services without creating internal solutions. With a valuation of $1 billion, Perplexity is expanding its funding and investor base, which features prominent tech leaders and venture firms. |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |

## Resources
|Link|description|
|---|---|
|[Nemotron-4 340B.](https://research.nvidia.com/publication/2024-06_nemotron-4-340b) |offers a reward model to filter data based on many qualities and an instruct model to generate high-quality data; exhibits impressive results on widely-used benchmarks such as MMLU and GSM8K; It competes with GPT-4 in a number of activities, such as scoring highly in multi-turn chat; Together with the base model, a preference data is also made available. |
|[Bag of Tricks: Benchmarking of Jailbreak Attacks on LLMs.](https://arxiv.org/abs/2406.09324v1) |Determining ways to incorporate search into language model creation is now the Holy Grail of study. This work is quite encouraging as it demonstrates that on math performance, tiny models with search can match considerably more powerful models. |
|[MCTSr: Mathematic as a Blackbox for LLM.](https://github.com/trotsky1997/MathBlackBox) | |
|[VideoGPT.](https://github.com/mbzuai-oryx/videogpt-plus) | To improve video understanding, a model called VideoGPT+ combines image and video encoders. While video encoders offer temporal context, image encoders capture finely detailed spatial information.|
|[Scene Graph Generation in Large-Size VHR Satellite Imagery: A Large-Scale Dataset and A Context-Aware Approach.](https://linlin-dev.github.io/project/RSG.html) | In order to enhance Scene Graph Generation (SGG) for very-high-resolution satellite imaging (VHR SAI), this research introduces a new dataset and methodology.|
|[LLM.Mojo.](https://github.com/dorjeduck/llm.mojo) |This project is a port of Andrej Karpathy's llm.c to Mojo, currently in beta and subject to changes. |
|[Depth Anything V2.](https://arxiv.org/abs/2406.09414) | With the use of artificial data, the new Depth Anything model was trained, and its performance on intricate scenes has significantly increased.|
|[DeepSeek-Coder-V2.](https://github.com/deepseek-ai/DeepSeek-Coder-V2) |Robust DeepSeek Coder achieves scores of 90+ on HumanEval and matches GPT-4 Turbo on numerous other difficult benchmarks. It is free for business usage and accessible via an API. |
|[HelpSteer2: Open-source dataset for training top-performing reward models.](https://arxiv.org/abs/2406.08673) |Along with an excellent paper about training reward models to match model output to human preferences, Nvidia has made available a dataset and procedure. |
|[Differentiable rasterization.](https://srush.github.io/DiffRast) | Given a program that produces a vector representation of an image (think SVG), rasterization turns it into a pixel representation (think PNG). Everything ought to be adjustable. This article explains how to write SVG light that is differentiable.|
|[LARS - The LLM & Advanced Referencing Solution.](https://github.com/abgulati/LARS) |LARS is an application that enables you to run LLM's (Large Language Models) locally on your device, upload your own documents and engage in conversations wherein the LLM grounds its responses with your uploaded content. |
|[Beyond the Basics of Retrieval for Augmenting Generation.](https://parlance-labs.com/education/rag/ben.html) |The RAGatouille creator delivered a great discussion about COLBERT, some of the open issues, and how to significantly increase RAG performance. |
|[TokenCost.](https://github.com/AgentOps-AI/tokencost) |Tokencost helps calculate the USD cost of using major Large Language Model (LLMs) APIs by calculating the estimated cost of prompts and completions. |
|[GaiaNet node.](https://github.com/GaiaNet-AI/gaianet-node) | Install and run your own AI agent service.|
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |

## Perspectives
|Link|description|
|---|---|
|[Computer says yes: how AI is changing our romantic lives.](https://www.theguardian.com/technology/article/2024/jun/16/computer-says-yes-how-ai-is-changing-our-romantic-lives) | Artificial intelligence is creating companions who can be our confidants, friends, therapists and even lovers. But are they an answer to loneliness or merely another way for big tech to make money?|
|[Nvidia‚Äôs New Sales Booster: The Global Push for National AI Champions.](https://www.wsj.com/tech/ai/nvidias-new-sales-booster-the-global-push-for-domestic-ai-champions-6d005ab7) |Governments everywhere are increasing their spending to entice corporations and multinationals to construct new data centers and renovate existing ones so that AI can be developed locally and massive language models can be trained in the original languages using data from their own inhabitants. According to Nvidia, these independent AI initiatives should generate over $10 billion in revenue this year. The potential economic effects of generative AI are a source of concern for several governments. For their sensitive data and AI infrastructure, they want sovereign clouds, and US IT companies are happy to construct them for them. |
|[General Intelligence (2024).](https://nonint.com/2024/06/03/general-intelligence-2024/) | What is lacking and what would it take to create a generally intelligent agent? This essay suggests that we will be here in a few years and examines the three concepts required to create an agent. The writer is an OpenAI researcher.|
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |

# ML news: 10-16 June

## Research
|Link|description|
|---|---|
|[Scaling neural machine translation to 200 languages.](https://www.nature.com/articles/s41586-024-07335-x) |based on a sparsely Gated Mixture of Experts architecture and trained on data using a method designed for low-resource languages, presents a massive multilingual model that uses transfer learning across 200 languages. It evaluates on 40K translations and achieves an average 44% improvement in translation quality. |
|[MatMul-free LLMs.](https://arxiv.org/abs/2406.02528) | claims that memory consumption can be reduced by more than 10x by using an optimized kernel during inference; suggests an implementation that removes matrix multiplication operations from LLMs while maintaining performance at billion-parameter scales; the performance gap between full precision Transformers and the MatMul-free models narrows as the model size increases.|
|[Buffer of Thoughts .](https://arxiv.org/abs/2406.04271) |utilizes a meta-buffer containing high-level thoughts (thought templates) extracted from problem-solving processes to present a thought-augmented reasoning approach that improves the accuracy, efficiency, and robustness of LLM-based reasoning. The relevant thought template is then retrieved and instantiated with task-specific reasoning structures for the thought-augmented reasoning process. It shows SOTA performance on 10 difficult tasks at 12% of the cost of multi-query prompting methods such as Tree-of-Thoughts. |
|[SaySelf: Teaching LLMs to Express Confidence with Self-Reflective Rationales.](https://arxiv.org/abs/2405.20974) | supervised finetuning on a dataset containing summaries of the differences between multiple reasoning chains is performed by the training framework to teach LLMs to express more accurate fine-grained confidence estimates and self-reflective rationales. Reinforcement learning is then applied to calibrate confidence estimates, encouraging the LLM to produce accurate, high-confidence predictions and penalizing overconfidence in erroneous outputs.|
|[The Geometry of Categorical and Hierarchical Concepts in Large Language Models.](https://arxiv.org/abs/2406.01506) |investigates the geometry of categorical concepts and how the hierarchical relations between them are encoded in LLMs. It discovers that the hierarchical structure is reflected in the representation of complex concepts by polytopes made from direct sums of simplices, while simple categorical concepts are represented as simplices by the LLMs. |
|[Show, Don't Tell: Aligning Language Models with Demonstrated Feedback.](https://arxiv.org/abs/2406.00888) |suggests a technique that uses a very small number of demonstrations as feedback to align LLMs to a particular setting; it outperforms few-shot prompting, SFT, and self-play methods on the tested benchmarks and aligns LLM outputs to a user's demonstrated behaviors. Additionally, it can learn fine-grained style and task alignment across domains. |
|[Towards Scalable Automated Alignment of LLMs.](https://arxiv.org/abs/2406.01252) | gives a summary of the techniques used to align LLMs and examines the four orientations listed below: 1) Inductive bias alignment; 2) Behavior imitation alignment; 3) Model feedback alignment; and 4) Environment feedback alignment|
|[AgentGym: Evolving Large Language Model-based Agents across Diverse Environments.](https://arxiv.org/abs/2406.04151) | a novel framework with multiple tasks and contexts for wide-ranging, concurrent, and real-time agent exploration; constructs a generally competent LLM-based agent with the ability to self-evolve and investigates its potential beyond data that hasn't been seen before across tasks and environments.|
|[Everything to the Synthetic: Diffusion-driven Test-time Adaptation via Synthetic-Domain Alignment.](https://arxiv.org/abs/2406.04295) |A Synthetic-Domain Alignment (SDA) framework has been developed by researchers to improve test-time adaptation (TTA) techniques. By fine-tuning pretrained models with synthetic data produced by a conditional diffusion model, SDA efficiently aligns source and synthetic domains. |
|[ReNO: Enhancing One-step Text-to-Image Models through Reward-based Noise Optimization.](https://arxiv.org/abs/2406.04312v1) | Reward-based Noise Optimization (ReNO) is a novel technique to improve Text-to-Image (T2I) models during inference by employing signals from reward models with human preferences to optimize the baseline noise.|
|[YOLO-World: Real-Time Open-Vocabulary Object Detection.](https://arxiv.org/abs/2401.17270v1) | With YOLO-World, researchers have improved the widely used YOLO object detectors and included open-vocabulary detection. This method, which combines large-scale dataset training with vision-language modeling, enables it to swiftly and accurately detect a wide range of objects, even in situations for which it was not designed.|
|[Improved Scene Landmark Detection for Camera Localization.](https://arxiv.org/abs/2401.18083v1) | Using distinctive scene landmarks, researchers have developed a novel, privacy-friendly technique for camera localization. This method, which does not rely on real 3D point clouds for localization, is very accurate and storage-efficient since it makes use of 3D scene landmarks and a CNN-based heatmap.|
|[Proofread: Fixes All Errors with One Tap.](https://arxiv.org/abs/2406.04523) | The Gboard team has described how they correct sentence- and paragraph-level problems in written text on device using SFT on a PaLM2-XS model. They discovered that latency optimizations led to significant gains in utilization.|
|[BitsFusion: 1.99 bits Weight Quantization of Diffusion Model.](https://snap-research.github.io/BitsFusion/) | Using a new quantization approach, the Snap Research team was able to increase speed while reducing the size of the Stable Diffusion UNet model from 1.72 GB to 219 MB. Although the quantization technique is a little complicated, it shows great promise for generative model execution on consumer hardware.|
|[Introducing Apple‚Äôs On-Device and Server Foundation Models.](https://machinelearning.apple.com/research/introducing-apple-foundation-models) | During WWDC 2024, Apple debuted "Apple Intelligence". Apple Intelligence is an AI system that is built into macOS Sequoia, iOS 18, and iPadOS 18. It has sophisticated generative models for a variety of commonplace activities, like text refinement, picture generation, and notification summary. With an emphasis on user privacy and responsible AI development, this system integrates cloud and on-device capabilities to improve the user experience across all Apple products.|
|[OVMR: Open-Vocabulary Recognition with Multi-Modal References.](https://arxiv.org/abs/2406.04675v1) | OVMR is a novel approach that combines textual descriptions with sample photos to improve open-vocabulary recognition.|
|[Predictive Dynamic Fusion.](https://arxiv.org/abs/2406.04802v1) |The Predictive Dynamic Fusion (PDF) architecture solves stability and reliability problems to improve multimodal learning. |
|[Compute Better Spent: Replacing Dense Layers with Structured Matrices.](https://arxiv.org/abs/2406.06248) |The Linear layers are where Transformer computation is primarily done. This approach creates a structured representation with better scaling laws than naive dense layers, using less CPU than muP and Monarch matrices. |
|[CARES: A Comprehensive Benchmark of Trustworthiness in Medical Vision Language Models.](https://arxiv.org/abs/2406.06007v1) |A thorough methodology called CARES is used to assess the reliability of Medical Large Vision Language Models (Med-LVLMs). |
|[Learning to Route Among Specialized Experts for Zero-Shot Generalization.](https://arxiv.org/abs/2402.05859v1) | PHATGOOSE is an approach that dramatically increases an AI's capacity to generalize and learn new tasks without prior exposure by efficiently routing between different specialized language models for each portion of a task.|
|[Diabetic Retinopathy Detection.](https://arxiv.org/abs/2406.06384v1) |A unique framework that enhances the grading of diabetic retinopathy (DR), a condition that can result in visual impairment, has been developed by researchers. |
|[BERTs are Generative In-Context Learners.](https://arxiv.org/abs/2406.04823) |In a different universe, BERT models‚Äîrather than their decoder-only GPT counterparts‚Äîwould have been shown to be in-context learners. When that is the case, as this paper investigates, BERTs perform remarkably well in information retrieval but poorly in knowledge acquisition, most likely as a result of the bidirectional attention mechanism. |
|[TextGrad: Automatic "Differentiation" via Text.](https://arxiv.org/abs/2406.07496) | The concept of treating a language model that is capable of updating text as a backpropagation system is investigated in this study. The benchmark performance, not computationally matched against baseline models, shows significant increases, according to the researchers.|
|[Improve Mathematical Reasoning in Language Models by Automated Process Supervision.](https://arxiv.org/abs/2406.06592) |DeepMind found a great way to extend the labor-intensive process of process oversight that requires human intervention. With robust base models, it was able to automate a significant portion of the procedure, which resulted in significant mathematical reasoning performance on Gemini Pro tuned models. |
|[Autoregressive Model Beats Diffusion: ü¶ô Llama for Scalable Image Generation.](https://github.com/FoundationVision/LlamaGen) | For image generation, Llama Gen is an autoregressive model that scales better than diffusion alternatives. By using ImageNet to train a class-conditioned model, its researchers were able to raise the bar for FID.|
|[When Linear Attention Meets Autoregressive Decoding: Towards More Effective and Efficient Linearized Large Language Models.](https://arxiv.org/abs/2406.07368v1) |In order to address the efficiency concerns in autoregressive big language models, researchers have looked into combining speculative decoding with linear attention techniques. In order to improve training and performance, this work presents an augmentation strategy for linear attention that is consistent with speculative decoding. |
|[What If We Recaption Billions of Web Images with LLaMA-3?](https://arxiv.org/abs/2406.08478) |Using a vision model to caption online scraped photos significantly enhances downstream model performance. This is particularly valid for models like CLIP. |
|[Hearing Anything Anywhere.](https://masonlwang.com/hearinganythinganywhere/) |This research presents DiffRIR, a new framework that uses a planar scene reconstruction with a limited number of room impulse response (RIR) recordings to recreate the spatial acoustic properties of environments. |
|[Simple and Effective Masked Diffusion Language Models.](https://github.com/kuleshov-group/mdlm) | By using an efficient training recipe and incorporating a simpler Rao-Blackwellized objective, researchers have shown that masked discrete diffusion models can compete with autoregressive approaches in language modeling.|

## News
|Link|description|
|---|---|
|[First NHS physiotherapy clinic run by AI to start this year.](https://www.theguardian.com/society/article/2024/jun/09/first-nhs-physiotherapy-clinic-run-by-ai-to-start-this-year) |New platform to provide same-day appointments with digital physiotherapist in effort to cut waiting times|
|[Apple to launch iOS 18 AI features marketed as ‚ÄòApple Intelligence‚Äô.](https://9to5mac.com/2024/06/07/report-apple-to-launch-ios-18-ai-features-marketed-as-apple-intelligence/) |Bloomberg‚Äôs Mark Gurman today reports that Apple will launch its upcoming AI initiatives in iOS 18 and other operating systems under the brand name ‚ÄòApple Intelligence‚Äô, which is obviously a convenient twist on the ‚ÄòAI‚Äô acronym. |
|[Claude‚Äôs Character.](https://www.anthropic.com/research/claude-character) |Claude is not simply your average, sycophantic AI that nods in agreement with the user. A character version of Constitutional AI has been specifically used to create Claude's personality and character. This essay goes into great detail on how Claude uses post-training to control the kind of output that he typically produces in order to portray this desired character. |
|[Databricks + Tabular.](https://www.databricks.com/blog/databricks-tabular) |With the acquisition of Tabular, Databricks has brought together major players from Apache Iceberg and Delta Lake to concentrate on data format interoperability for its lakehouse architecture. With Delta Lake UniForm's compatibility solution at the forefront, the objective is to establish a single, open standard for data interoperability in order to prevent data silos. |
|[How the voices for ChatGPT were chosen.](https://openai.com/index/how-the-voices-for-chatgpt-were-chosen/) |We worked with industry-leading casting and directing professionals to narrow down over 400 submissions before selecting the 5 voices. |
|[OpenAI and Apple announce partnership to integrate ChatGPT into Apple experiences.](https://openai.com/index/openai-and-apple-announce-partnership/) |Apple is integrating ChatGPT into experiences within iOS, iPadOS, and macOS, allowing users to access ChatGPT‚Äôs capabilities‚Äîincluding image and document understanding‚Äîwithout needing to jump between tools.  |
|[Apple Intelligence: every new AI feature coming to the iPhone and Mac.](https://www.theverge.com/2024/6/10/24175405/wwdc-apple-ai-news-features-ios-18-macos-15-iphone-ipad-mac?utm_source=tldrai) |pple announced ‚ÄúApple Intelligence‚Äù at WWDC 2024, its name for a new suite of AI features for the iPhone, Mac, and more. Starting later this year, Apple is rolling out what it says is a more conversational Siri, custom, AI-generated ‚ÄúGenmoji,‚Äù and GPT-4o access that lets Siri turn to OpenAI‚Äôs chatbot when it can‚Äôt handle what you ask it for. |
|[Asana says its new AI teammates are ready to manage your projects.](https://www.fastcompany.com/91134681/asana-ai-teammates-dustin-moskovitz-interview) |With the goal of enhancing productivity and output quality, Asana has introduced "AI teammates" to take care of duties like proactive project detail organization and request triaging. This innovative feature is integrated into the workflow and functions like a human team member while yet being supervised by humans. It was showcased at Asana's Work Innovation Summit. |
|[Apple stock reaches record high after announcement of new AI features.](https://www.theguardian.com/technology/article/2024/jun/11/apple-stock-reaches-record-high) |Tech giant‚Äôs shares climb 7% a day after reveal of artificial intelligence features meant to increase appeal of the iPhone |
|[Elon Musk abruptly withdraws lawsuit against Sam Altman and OpenAI.](https://www.theguardian.com/technology/article/2024/jun/11/elon-musk-withdraws-lawsuit-against-sam-altman-openai) |Tesla CEO had accused the company of abandoning mission of creating artificial intelligence for greater good of humanity |
|[Mistral raises ‚Ç¨600m series B.](https://threadreaderapp.com/thread/1800558395872731379.html) | Mistral announced ‚Ç¨600M in Series B funding for thier first anniversary|
|[Mozilla Builders.](https://future.mozilla.org/builders/blog/announcing-mozilla-builders/) | Local AI, which enhances accessibility and privacy by bringing AI models and applications directly onto personal devices, is being embraced by the first Mozilla Builders Accelerator. Tools for developer productivity, locally based AI agents, dynamic user interfaces, fine-tuning adaption, retrieval-augmented creation, and enhanced function calling are some of the key areas of advancement. The initiative's goal is for participants to create an open-source, decentralized AI ecosystem with a focus on user empowerment.|
|[CaseMark Raises $1.7M to Empower Attorneys with AI.](https://www.casemark.ai/post/fueling-the-future-casemark-raises-1-7m-to-empower-attorneys-with-ai) |In order to increase the scope of its AI solutions for the legal sector, Gradient Ventures led pre-seed investment in CaseMark, an AI firm that is transforming legal operations. |
|[OpenAI ex-employees worry about company‚Äôs control over their millions of dollars in shares.](https://www.cnbc.com/2024/06/11/openai-insider-stock-sales-are-raising-concern-among-ex-employees-.html) | With OpenAI‚Äôs valuation soaring and an IPO nowhere in sight, the company is giving employees the chance to sell some equity in secondary transactions. Ex-employees sitting on millions of dollars worth of stock worry about OpenAI‚Äôs ability to force them to give up their shares, according to sources and internal messages. OpenAI recently circulated a document indicating that ex-employees who work at competitors are not included in the tender offers.|
|[Announcing the Open Release of Stable Diffusion 3 Medium.](https://stability.ai/news/stable-diffusion-3-medium) |Stable Diffusion 3 Medium is Stability AI‚Äôs most advanced text-to-image open model yet. The small size of this model makes it perfect for running on consumer PCs and laptops as well as enterprise-tier GPUs.|
|[Shutterstock ImageAI, Powered by Databricks.](https://www.databricks.com/company/newsroom/press-releases/introducing-shutterstock-imageai-powered-databricks-image) |  Databricks and Shutterstock announced a text-to-image Generative AI model optimized for enterprise use|
|[OpenAI Annualized Revenue Doubles.](https://seekingalpha.com/news/4115380-openai-annualized-revenue-doubles-to-hit-34b-report) | OpenAI has more than doubled its annualized revenue to hit $3.4B.|
|[Perplexity was planning revenue-sharing deals with publishers when it came under media fire.](https://www.semafor.com/article/06/12/2024/perplexity-was-planning-revenue-sharing-deals-with-publishers) | Perplexity, the AI search startup that recently came under fire from Forbes for allegedly misusing its content, was already working on revenue-sharing deals with high-quality publishers.|
|[Microsoft‚Äôs Nadella Is Building an AI Empire. OpenAI Was Just the First Step.](https://www.wsj.com/tech/ai/microsoft-nadella-openai-inflection-9727e77a?st=8kan7s8rxto660t) |After landing the deal that launched his company to the front of the artificial-intelligence race, the tech chief is spreading his bets. Will it be enough? |
|[OpenAI adds former NSA chief to its board.](https://www.axios.com/2024/06/13/open-ai-security-nakasone-nsa) |OpenAI said on Thursday that it is adding former NSA head and retired Gen. Paul Nakasone to its board of directors as well as its newly formed Safety and Security Committee. Why it matters: OpenAI is looking to convince skeptics that it is taking sufficient steps to ensure its models are safe as it works toward its goal of super intelligence. |
|[Apple Made Once-Unlikely Deal With Sam Altman to Catch Up in AI.](https://www.bloomberg.com/news/articles/2024-06-05/why-is-apple-aapl-teaming-up-with-openai-both-companies-need-each-other) |An OpenAI agreement is due to be announced at the Apple‚Äôs developer conference next week. |
|[LLM-Squared .](https://sakana.ai/llm-squared/) | Sakana AI has found a preference optimization scheme that works better than DPO by using an evolutionary approach. It trained models based on code that was suggested by a language model. It has a few suggested variations with very high performance after about 100 generations.|
|[Gemini 1.5 Pro and 1.5 Flash GA, 1.5 Flash tuning support, higher rate limits, and more API updates.](https://developers.googleblog.com/en/gemini-15-pro-and-15-flash-now-available/) |Updates to the Gemini API and Google AI Studio have been released by Google AI. These include support for model tuning, the stable release of Gemini 1.5, increased API rate limitations, additional JSON schema features, and mobile compatibility. The changes boost the alternatives available to developers more efficiently and more customized large-scale building. |
|[AI generated sound effects are here.](https://elevenlabs.io/blog/sound-effects-are-here/) | A new AI audio model from ElevenLabs can generate a variety of voices, tunes, and sound effects based on text cues. By utilizing Shutterstock's audio library, our partnership helps media professionals create better content by facilitating the quick and scalable production of high-quality audio. ElevenLabs' platform makes it simple for users to create sounds, which streamlines the audio design process.|
|[OpenAI welcomes Sarah Friar (CFO) and Kevin Weil (CPO).](https://openai.com/index/openai-welcomes-cfo-cpo/) |With the appointment of Kevin Weil as CPO and Sarah Friar as CFO, OpenAI has strengthened its leadership team to further its goal of developing AI products and doing research that are useful to developers, businesses, and consumers. |
|[Why the pope has the ears of G7 leaders on the ethics of AI.](https://www.theguardian.com/world/article/2024/jun/14/why-the-pope-has-the-ears-of-g7-leaders-on-the-ethics-of-ai) |Pope Francis is leaning on thinking of Paolo Benanti, a friar adept at explaining how technology can change world |
|[AI used to predict potential new antibiotics in groundbreaking study.](https://www.theguardian.com/society/article/2024/jun/05/ai-antibiotic-resistance) |Scientists used an algorithm to mine ‚Äòthe entirety of the microbial diversity‚Äô on Earth, speeding up antibiotic resistance research |


## Resources
|Link|description|
|---|---|
|[Spreadsheet Is All You Need.](https://github.com/dabochen/spreadsheet-is-all-you-need) |Complete GPT-2 style transformer model with all weights, parameters, and connections included in a spreadsheet. It is a tiny model that runs entirely within the rows and columns of a spreadsheet and is based on NanoGPT. |
|[Inspectus.](https://github.com/labmlai/inspectus) | Inspectus is a versatile visualization tool for large language models. It runs smoothly in Jupyter notebooks via an easy-to-use Python API. Inspectus provides multiple views, offering diverse insights into language model behaviors.|
|[SpatialRGPT: Grounded Spatial Reasoning in Vision Language Model.](https://www.anjiecheng.me/SpatialRGPT) | SpatialRGPT is a powerful vision-language model adept at understanding both 2D and 3D spatial arrangements. It can process any region proposal, such as boxes or masks, and provide answers to complex spatial reasoning questions.|
|[Thread.](https://github.com/squaredtechnologies/thread) | Thread is a Jupyter Notebook that combines the experience of OpenAI's code interpreter with the familiar development environment of a Python notebook. With Thread, you can use natural language to generate cells, edit code, ask questions or fix errors all while being able to edit or re-run code as you would in a regular Jupyter Notebook.|
|[How AI Image Models Work.](https://every.to/p/how-ai-image-models-work) | Since 2022, AI image production has advanced beyond producing images with text explanations. This article illustrates the quick progress and promise of AI in visual creation by explaining how these models hone chaotic inputs to create precise and detailed visuals using a kid's game comparison.|
|[Active Stereo Without Pattern Projector.](https://vppstereo.github.io/) | Without the need for a hardware pattern projector, researchers have presented a new framework that incorporates active stereo concepts into passive cameras that are commonly used.|
|[GLM-4-9B-Chat.](https://huggingface.co/THUDM/glm-4-9b-chat) |Excellent model with support for 26 languages, trained on 10T tokens by the Tsinghua KEM group. |
|[DIRECT-3D: Learning Direct Text-to-3D Generation on Massive Noisy 3D Data.](https://direct-3d.github.io/) | DIRECT-3D is a new text-to-3D generative model that directly generates 3D contents in a single forward pass without optimization.|
|[Together MoA.](https://www.together.ai/blog/together-moa) |Together has presented Mixture of Agents (MoA), a cutting-edge technique that mixes many LLMs for optimal performance, outperforming GPT-4o with an AlpacaEval 2.0 score of 65.1%. MoA employs a tiered architecture in which aggregators in later levels improve the initial answers from different models, improving output quality through cooperation. Even with improved precision, MoA still struggles with latency. Reducing latency and improving model design are two potential future possibilities. |
|[Mistral.rs.](https://github.com/EricLBuehler/mistral.rs) |Mistral.rs is a fast LLM inference (Rust-based inference framework) platform supporting inference on a variety of devices, quantization, and easy-to-use application with an Open-AI API compatible HTTP server and Python bindings. |
|[Generalizable Human Gaussians from Single-View Image.](https://jinnan-chen.github.io/projects/HGM/) |A diffusion-guided framework for building 3D human models from a single image is the Human Gaussian Model (HGM). |
|[Lighting Every Darkness with 3DGS: Fast Training and Real-Time Rendering for HDR View Synthesis.](https://srameo.github.io/projects/le3d/) |Real-time HDR view synthesis from RAW pictures can be achieved with the LE3D approach. It works especially well for situations set at night. |
|[TORAX.](https://github.com/google-deepmind/torax) | The Python-Jax differentiable fusion tokamak simulator developed by DeepMind at Google is now publicly available. The simulator supports several very powerful PDEs and has good auto-diff capabilities.|
|[AsyncDiff: Parallelizing Diffusion Models by Asynchronous Denoising.](https://czg1225.github.io/asyncdiff_page/) | A novel acceleration approach called AsyncDiff makes it possible to perform parallel processing in diffusion models. By splitting the noise prediction model into several parts and executing them on different devices, it drastically cuts latency without sacrificing quality.|
|[PowerInfer-2: Fast Large Language Model Inference on a Smartphone.](https://powerinfer.ai/v2/) |Fast inference on the phone for the special Mistral 47B MoE model. |
|[The AXLearn Library for Deep Learning.](https://github.com/apple/axlearn) |AXLearn is a library built on top of JAX and XLA to support the development of large-scale deep learning models. |
|[Samba: Simple Hybrid State Space Models for Efficient Unlimited Context Language Modeling.](https://github.com/microsoft/Samba) |Samba is a simple yet powerful hybrid model with an unlimited context length. Its architecture is frustratingly simple: Samba = Mamba + MLP + Sliding Window Attention + MLP stacking at the layer level. |
|[DiffusionKit.](https://github.com/argmaxinc/DiffusionKit) | Framework and tooling for running diffusion models on Apple's MLX framework.|
|[Splash Attention.](https://github.com/google/jax/blob/main/jax/experimental/pallas/ops/tpu/splash_attention/splash_attention_kernel.py) |new DeepMind kernel in Jax for Sparse Flash Attention |
|[Hugging Face acquires Agrilla.](https://huggingface.co/posts/dvilasuero/203008804842390) |Argilla a company specialized on data for preference optimization has been acquired. |


## Perspectives
|Link|description|
|---|---|
|[Building AI products.](https://www.ben-evans.com/benedictevans/2024/6/8/building-ai-products) |Though they can't give exact answers to questions, large language models (LLMs) like ChatGPT are excellent at producing responses that seem correct. In order to improve user experience and enhance functionality while reducing errors, AI in the future will integrate LLMs into specialized tools or embed them into already-existing applications. This will contextualize AI outputs within controllable, specified areas. |
|[Why passwords still matter in the age of AI.](https://www.theguardian.com/technology/article/2024/jun/11/apple-password-app-tech-age-of-ai) |As Apple‚Äôs new Passwords app tries to solve our identity crisis, why are we still proving who we are via strings of random characters? |
|[Examining LLM performance on public benchmarks.](https://threadreaderapp.com/thread/1785888203943161970.html) | Popular LLMs on public benchmarks: how overfit are they? Mistral and Phi are overfitting benchmarks, but GPT, Claude, Gemini, and Llama are not, according to new research from Scale AI SEAL. The scientists assessed public LLMs for overfitting on GSM8k and created a new eval GSM1k.|
|[How to track the economic impact of public investments in AI.](https://www.nature.com/articles/d41586-024-01721-1) | National statistics systems should recognize the researchers whose ideas drive artificial-intelligence applications, not just machines and factory outputs.|
|[Maintaining Large-Scale AI Capacity At Meta.](https://engineering.fb.com/2024/06/12/production-engineering/maintaining-large-scale-ai-capacity-meta/) |To meet AI demands, Meta is modernizing its data centers throughout the world. For AI training tasks, it intends to scale to 600,000 GPUs. In order to assure minimal disruptions and constant performance while enabling quick infrastructure scalability, this calls for creative maintenance tactics and tools like OpsPlanner. |

# ML news: Week 3 - 9 June

## Research
|Link|description|
|---|---|
|[Contextual Position Encoding: Learning to Count What's Important.](https://arxiv.org/abs/2405.18719) |The general position encoding method can attend to the i-th particular word, noun, or sentence; it improves perplexity on language modeling and coding tasks; it is context-dependent and can represent different levels of position abstraction; it suggests a new position encoding method, CoPE, to enable the position to be conditioned on context by incrementing position only on certain tokens. |
|[Faithful Logical Reasoning via Symbolic Chain-of-Thought.](https://arxiv.org/abs/2405.18357) |suggests a way to enhance LLMs' capacity for logical thinking by combining logical rules and symbolic expressions with chain-of-thought (CoT) prompting; this prompting method is known as Symbolic Chain-of-Thought and it is a fully LLM-based framework that consists of the following important steps: converts the context of natural language to symbolic format, 2) creates a step-by-step solution plan based on symbolic logical rules, and 3) employs a verifier to validate the translation and reasoning chain. |
|[Transformers Can Do Arithmetic with the Right Embeddings.](https://arxiv.org/abs/2405.17399) | The main problem this work addresses is the inability of transformers to track the exact position of digits; they do this by adding an embedding to each digit that encodes its position relative to the start of the number; these gains also transfer to multi-step reasoning tasks that include sorting and multiplication. achieves 99% accuracy on 100-digit addition problems by training on only 20-digit numbers with a single GPU.|
|[GNN-RAG: Graph Neural Retrieval for Large Language Model Reasoning.](https://arxiv.org/abs/2405.20139) | blends the reasoning powers of GNNs with the language understanding skills of LLMs in a RAG fashion; the GNN extracts relevant and useful graph information, and the LLM uses the information to answer questions over knowledge graphs (KGQA); GNN-RAG outperforms or matches GPT-4 performance with a 7B tuned LLM, and improves vanilla LLMs on KGQA.|
|[Attention as an RNN.](https://arxiv.org/abs/2405.13956) |is based on the parallel prefix scan algorithm, which enables efficient computation of attention's many-to-many RNN output. It achieves comparable performance to Transformers on 38 datasets while being more time and memory-efficient. presents a new attention mechanism that can be trained in parallel (like Transformers) and updated with new tokens requiring constant memory usage for inferences (like RNNs). |
|[Are Long-LLMs A Necessity For Long-Context Tasks? ](https://arxiv.org/abs/2405.15318) |suggests a reasoning framework to allow short-LLMs to handle long-context tasks by adaptively accessing and utilizing the context based on the tasks presented; it breaks down the long context into short contexts and processes them using a decision-making process. The argument makes the claim that long-LLMs are not necessary to solve long-context tasks. |
|[Sparse maximal update parameterization: A holistic approach to sparse training dynamics.](https://arxiv.org/abs/2405.15743) |All frontier model labs use muP, a potent tool, to transfer hyper parameters fine-tuned on tiny models to bigger, more costly training runs. This study investigates how to achieve that for sparse models, resulting in significantly better training results and lower computation expenses. |
|[Exploring Color Invariance through Image-Level Ensemble Learning.](https://arxiv.org/abs/2401.10512v1) | To address color bias in computer vision, researchers have created a novel learning technique called Random Color Erasing. By selectively excluding color information from training data, this technique strikes a balance between the significance of color and other parameters, producing models that perform better in challenging situations like industrial and wide-area surveillance.|
|[Conifer: Improving Complex Constrained Instruction-Following Ability of Large Language Models.](https://github.com/coniferlm/conifer) |Conifer enhances LLMs' comprehension of intricate instructions by utilizing a progressive learning methodology and a customized dataset. |
|[LLM Merging Competition: Building LLMs Efficiently through Merging.](https://llm-merging.github.io/) |Sakana AI is sponsoring the LLM Merging challenge at NeurIPS this year. |
|[Tribeca to Screen AI-Generated Short Films Created by OpenAI‚Äôs Sora.](https://www.indiewire.com/news/festivals/tribeca-ai-generated-short-films-sora-shorts-1235010911/) |Short films generated by artificial intelligence are popping up at more and more film festivals, and the largest event yet is dedicating an entire section to AI-generated movies. |
|[Adapting Large Multimodal Models to Distribution Shifts: The Role of In-Context Learning.](https://arxiv.org/abs/2405.12217v1) |A technique called InvariantSelectPR is intended to make Large Multimodal Models (LMMs) more adaptive in domain-specific fields such as healthcare. |
|[TAIA: Large Language Models are Out-of-Distribution Data Learners.](https://arxiv.org/abs/2405.20192v1) |A technique called TrainAllInfAttn improves the performance of big language models in niche markets with little data. |
|[MegActor: Harness the Power of Raw Video for Vivid Portrait Animation](https://megvii-research.github.io/MegFaceAnimate/) |A new model called MegActor uses unprocessed driving videos to create more lifelike portrait animation. It addresses identity leaking and background interference and produces remarkable results with unique data creation framework and background encoding approaches. |
|[MeshXL: Neural Coordinate Field for Generative 3D Foundation Models.](https://arxiv.org/abs/2405.20853) | MeshXL is a new model that generates high-quality 3D meshes.|
|[Position-Guided Prompt Learning for Anomaly Detection in Chest X-Rays.](https://github.com/sunzc-sunny/ppad) |Position-guided Prompt learning method for Anomaly Detection in chest X-rays (PPAD). PPAD leverages learnable text prompt and image prompt to minimize the gap between pre-training data and task-specific data. Through the position-guided prompts, the model can focus on various regions, simulating the diagnostic process of experts. |
|[Tree Diffusion: Diffusion Models For Code.](https://tree-diffusion.github.io/) |Wonderful diffusion paper that diffuses picture code. As part of the diffusion process, it has the ability to directly edit. Although it is sluggish, it can be simply used with search to significantly increase one's capacity for reasoning. |
|[Improved Techniques for Optimization-Based Jailbreaking on Large Language Models.](https://arxiv.org/abs/2405.21018v1) | Expanding upon the Greedy Coordinate Gradient (GCG) approach, researchers have enhanced methods for optimization-based jailbreaking of huge language models.|
|[ZeroSmooth: Training-free Diffuser Adaptation for High Frame Rate Video Generation.](https://ssyang2020.github.io/zerosmooth.github.io/) |A training-free video interpolation technique for generative video diffusion models has been developed by researchers. This novel method improves frame rates without requiring a lot of training or big datasets and works with different models. |
|[A whole-slide foundation model for digital pathology from real-world data.](https://www.nature.com/articles/s41586-024-07441-w) | Prov-GigaPath, a whole-slide pathology foundation model pretrained on 1.3 billion 256‚Äâ√ó‚Äâ256 pathology image tiles in 171,189 whole slides. To pretrain Prov-GigaPath, we propose GigaPath, a novel vision transformer architecture for pretraining gigapixel pathology slides. We further demonstrate the potential of Prov-GigaPath on vision‚Äìlanguage pretraining for pathology by incorporating the pathology reports. In sum, Prov-GigaPath is an open-weight foundation model that achieves state-of-the-art performance on various digital pathology tasks, demonstrating the importance of real-world data and whole-slide modelling.|
|[DreamMat: High-quality PBR Material Generation with Geometry- and Light-aware Diffusion Models.](https://zzzyuqing.github.io/dreammat.github.io/) |Using Dream Mat to enhance 3D object texture production is a brilliant idea. Given a 3D model, it employs several traditional graphic methods including Metallic, Roughness, and Albedo to generate a very appealing result. |
|[LlamaCare: A Large Medical Language Model for Enhancing Healthcare Knowledge Sharing.](https://arxiv.org/abs/2406.02350v1) | To solve classification problems in large language models (LLMs), researchers have developed LlamaCare, a refined LLM for medical information, in conjunction with Extended Classification Integration (ECI).|
|[XRec: Large Language Models for Explainable Recommendation.](https://github.com/hkuds/xrec) | XRec is a framework independent of models that improves explainable recommender systems by utilizing the language capabilities of huge language models.|
|[MetaMixer Is All You Need.](https://arxiv.org/abs/2406.02021v1) |Using simply convolutions, researchers have created a novel method called FFNification that preserves the query-key-value structure while converting self-attention processes into more effective token mixers. |
|[GrootVL: Tree Topology is All You Need in State Space Model.](https://github.com/easonxiao-888/grootvl) | By dynamically constructing a tree topology based on spatial correlations and input information, GrootVL is a network that enhances state space models.|
|[ProGEO: Generating Prompts through Image-Text Contrastive Learning for Visual Geo-localization.](https://arxiv.org/abs/2406.01906v1) | In order to increase Visual Geo-localization (VG) and boost its performance in applications such as SLAM, augmented reality, and autonomous driving, researchers have created a new two-stage training process.|
|[ReLUs Are Sufficient for Learning Implicit Neural Representations.](https://arxiv.org/abs/2406.02529v1) | A review of the application of ReLU activation functions to implicit neural representations (INRs) learning has been conducted. They countered spectrum bias by introducing basic limitations to ReLU neurons, which were inspired by second-order B-spline wavelets.|

## News
|Link|description|
|---|---|
|[OpenAI Is Restarting Its Robotics Research Group.](https://www.therobotreport.com/openai-is-restarting-its-robotics-research-group/) |The San Francisco-based company has been a pioneer in generative artificial intelligence and is returning to robotics after a three-year break. |
|[AI Overviews: About last week.](https://blog.google/products/search/ai-overviews-update-may-2024/) |In order to improve search results and give users more precise and pertinent information, particularly for complex inquiries, Google created AI Overviews. While there were certain problems, such incorrect results and misread content, Google has fixed these difficulties with over a dozen technical updates, like improving the identification of absurd questions and reducing the amount of user-generated content in AI Overviews. |
|[Nvidia said to be prepping AI PC chip with Arm and Blackwell cores.](https://www.theregister.com/2024/05/28/nvidia_ai_pc_arm_blackwell_core) | Competition could be heating up in the Windows on Arm space amid talk in the industry that Nvidia is readying a chip pairing next-gen Arm cores with its Blackwell GPU architecture.|
|[Ex-OpenAI board member reveals what led to Sam Altman's brief ousting.](https://www.msn.com/en-ae/money/companies/ex-openai-board-member-reveals-what-led-to-sam-altman-s-brief-ousting/ar-BB1ndnZE) |In a recent interview, former OpenAI board member Helen Toner provided fresh information into the circumstances surrounding CEO Sam Altman's November dismissal. It appears that the board was informed via Twitter about the release of ChatGPT. According to Toner, Altman had repeatedly lied to the board. It has been alleged that Altman had been lying about events within the organization for years and hiding facts. The board found it difficult to make decisions as a result of his lies, and they concluded that he wasn't the best person to take the firm to AGI. |
|[AI hardware firm Nvidia unveils next-gen products at Taiwan tech expo.](https://www.theguardian.com/technology/article/2024/jun/02/ai-hardware-firm-nvidia-unveils-next-gen-products-at-taiwan-tech-expo) |CEO Jensen Huang tells packed stadium in Taipei ‚Äònext Industrial Revolution has begun‚Äô |
|[AMD unveils new AI chips to compete with Nvidia.](https://www.fastcompany.com/91134766/amd-unveils-new-ai-chips-to-compete-with-nvidia) | AMD has been vying to compete against Nvidia, which currently dominates the lucrative market for AI semiconductors and commands about 80% of its share.|
|[Anthropic‚Äôs Claude 3 Opus and tool use are generally available on Vertex AI.](https://cloud.google.com/blog/products/ai-machine-learning/anthropics-claude-3-opus-and-tool-use-are-generally-available-on-vertex-ai) | Google Cloud now offers Claude 3 Opus with tool use along with the smaller models as part of its Vertex AI offering.|
|[State Space Duality (Mamba-2).](https://goombalab.github.io/blog/2024/mamba2-part1-model/) |Mambda is an effective model of state space. A lengthy and comprehensive explanation of the model and its enhancements is included in the second version that its team has issued. |
|[No physics? No problem. AI weather forecasting is already making huge strides.](https://arstechnica.com/ai/2024/06/as-a-potentially-historic-hurricane-season-looms-can-ai-forecast-models-help/) | With AI models like WindBorne's WeatherMesh, which leverages the extensive ERA5 dataset to outperform conventional models while using much less processing power, the weather forecasting industry is undergoing a transformation.|
|[Amazon‚Äôs Project PI AI looks for product defects before they ship.](https://www.theverge.com/2024/6/3/24170567/amazons-project-pi-product-defect-return-ai-computer-vision) |  Project PI combines computer vision and generative AI to catch damaged items and prevent returns.|
|[The Opaque Investment Empire Making OpenAI‚Äôs Sam Altman Rich.](https://wallstreetsights.com/business/openais-sam-altman-get-rich/4975/) |One of Silicon Valley's most active and successful individual investors is Sam Altman. At the beginning of this year, his stakes in his investment empire were valued at least $2.8 billion. A large portion of the portfolio is unknown. Readers are guided through Altman's investment knowledge in this article. |
|[Even the Raspberry Pi is getting in on AI.](https://www.theverge.com/2024/6/4/24170818/raspberry-pi-ai-chip-hailo-devices) |Raspberry Pi partnered with Hailo to provide an optional AI add-on to its microcomputers. |
|[Using AI to decode dog vocalizations.](https://news.umich.edu/using-ai-to-decode-dog-vocalizations) |Leveraging a human speech model to identify different types of barks.  University of Michigan researchers are exploring the possibilities of AI, developing tools that can identify whether a dog‚Äôs bark conveys playfulness or aggression. |
|[The future is ‚Ä¶ sending AI avatars to meetings for us, says Zoom boss.](https://www.theguardian.com/technology/article/2024/jun/05/the-future-is-sending-ai-avatars-to-meetings-for-us-says-zoom-boss) | Eric Yuan suggests technology is five or six years away and will free up time to spend with family|
|[AI researchers build ‚Äòfuture self‚Äô chatbot to inspire wise life choices.](https://www.theguardian.com/technology/article/2024/jun/05/ai-researchers-build-future-self-chatbot-to-inspire-wise-life-choices) |Scientists at MIT hope talking to 60-year-old self will shift thinking on health, money and work |
|[Cartwheel generates 3D animations from scratch to power up creators.](https://techcrunch.com/2024/06/05/cartwheel-generates-3d-animations-from-scratch-to-power-up-creators/) |Animating a 3D character from scratch is generally both laborious and expensive, requiring the use of complex software and motion capture tools. |
|[Mistral launches fine-tuning API.](https://mistral.ai/news/customization/) |Mistral has launched customization for its models via its platform and API. |
|[If you aren't seeing AI Overviews in your search results, it's probably thanks to Google.](https://www.androidpolice.com/google-ai-overviews-scaled-back-rocky-launch/) |After receiving heavy criticism since their mid-May public launch, AI Overviews in Google Search have dropped in visibility across search results. Since I/O, the average percentage of queries where AI Overviews appear has dropped from 27 percent to just 11 percent. Despite the reduction, healthcare-related queries a large percentage of AI results, raising concerns about both accuracy and reliability across Google.|
|[Google optimizes shipping routes.](https://research.google/blog/heuristics-on-the-high-seas-mathematical-optimization-for-cargo-ships/) |The mathematical optimization for cargo shipping routes was enhanced by Google's operations research group. They discovered a 13% drop in gasoline expenses and consumption. |
|[BrightEdge Releases Post Google I/O Data on The Impact of AI Overviews.](https://www.globenewswire.com/news-release/2024/06/04/2893289/0/en/BrightEdge-Releases-Post-Google-I-O-Data-on-The-Impact-of-AI-Overviews.html) | The main businesses affected by AI Overviews, what generates results, and where Google automatically anticipates and responds to search inquiries are all revealed by new research from BrightEdge Generative Parser.|
|[Nvidia emails: Elon Musk diverting Tesla GPUs to his other companies.](https://arstechnica.com/cars/2024/06/elon-musk-is-diverting-teslas-gpus-to-x-xai-nvidia-emails-say/) | The Tesla CEO is accused of diverting resources from the company again. Elon Musk is yet again being accused of diverting Tesla resources to his other companies. This time, it's high-end H100 GPU clusters from Nvidia. |
|[Securing Research Infrastructure for Advanced AI.](https://openai.com/index/securing-research-infrastructure-for-advanced-ai) |In its description of the security architecture of its AI training supercomputers, OpenAI highlights the use of Azure-based infrastructure and Kubernetes for orchestration to safeguard critical model weights and other assets. |
|[Extracting Concepts from GPT-4.](https://openai.com/index/extracting-concepts-from-gpt-4) |The team at OpenAI has discovered 16 million interpretable features in GPT-4 including price increases, algebraic rings, and who/what correspondence. This is a great step forward for SAE interpretability at scale. They shared the code in a companion GitHub repository. |
|[Mesop: Gradio Competition.](https://google.github.io/mesop/) |A rival to the well-liked AI prototyping framework Gradio has been made available by Google. Gradio is more mature than Mesop, which is pure Python and slightly more composable. |
|[Nvidia is now more valuable than Apple at $3.01 trillion.](https://www.theverge.com/2024/6/5/24172363/nvidia-apple-market-cap-valuation-trillion-ai) | The AI boom has pushed Nvidia‚Äôs market cap high enough to make it the second most valuable company in the world.|

## Resources
|Link|description|
|---|---|
|[An Introduction to Vision-Language Modeling.](https://arxiv.org/abs/2405.17247) |  we present this introduction to VLMs which we hope will help anyone who would like to enter the field. First, we introduce what VLMs are, how they work, and how to train them.|
|[Aya 23: Open Weight Releases to Further Multilingual Progress.](https://arxiv.org/abs/2405.15032) |a family of multilingual language models with up to 23 languages supported; it demonstrates that it can perform better on those particular languages than other large-scale multimodal models by purposefully concentrating on fewer languages and allocating greater capacity to them. |
|[Financial Statement Analysis with Large Language Models](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4835311) |claims that by analyzing trends and financial ratios, LLMs can produce insightful insights; demonstrates that GPT-4 outperforms more specialized models; and develops a profitable trading strategy based on GPT's predictions. |
|[SimPO: Simple Preference Optimization with a Reference-Free Reward.](https://arxiv.org/abs/2405.14734) | SimPO demonstrates how it outperforms other methods like DPO and claims to generate the strongest 8B open-source model. It is a more straightforward and efficient method for preference optimization with a reference-free reward; it uses the average log probability of a sequence as an implicit reward (i.e., no reference model required), which makes it more compute and memory efficient.|
|[Experimenting with local alt text generation.](https://hacks.mozilla.org/2024/05/experimenting-with-local-alt-text-generation-in-firefox-nightly/) |A model that runs in the browser and can provide alt text for web photos automatically has been trained by Mozilla. |
|[Mora: More like Sora for Generalist Video Generation.](https://github.com/lichao-sun/mora) |Mora is a multi-agent framework designed to facilitate generalist video generation tasks, leveraging a collaborative approach with multiple visual agents. It aims to replicate and extend the capabilities of OpenAI's Sora.|
|[FABRIC: Personalizing Diffusion Models with Iterative Feedback.](https://github.com/sd-fabric/fabric) |FABRIC (Feedback via Attention-Based Reference Image Conditioning) is a technique to incorporate iterative feedback into the generative process of diffusion models based on StableDiffusion. |
|[KL is All You Need.](https://blog.alexalemi.com/kl-is-all-you-need.html) |KL divergence is a quick, affordable, and effective method of measuring a certain type of distance between objects. In both conventional and contemporary AI, it is widely employed. This piece examines the potent idea both mathematically and graphically. |
|[7 Ways AI-Native Companies Can Improve User Retention.](https://a16z.com/7-ways-ai-native-companies-can-improve-retention/) |a manual with examples of how businesses like Perplexity, Civit, Lapse, Omnivore, and others are using them to increase retention for founders and product executives. |
|[FineWeb: decanting the web for the finest text data at scale.](https://huggingface.co/spaces/HuggingFaceFW/blogpost-fineweb-v1) | The performance of a large language model (LLM) depends heavily on the quality and size of its pretraining dataset. Recently, we released üç∑ FineWeb, a new, large-scale (15-trillion tokens, 44TB disk space) dataset for LLM pretraining. FineWeb is derived from 96 CommonCrawl snapshots and produces better-performing LLMs than other open pretraining datasets.|
|[An entirely open-source AI code assistant inside your editor.](https://ollama.com/blog/continue-code-assistant) | Continue enables you to easily create your own coding assistant directly inside Visual Studio Code and JetBrains with open-source LLMs. All this can run entirely on your own laptop or have Ollama deployed on a server to remotely power code completion and chat experiences based on your needs.|
|[MMLU-Pro: A More Robust and Challenging Multi-Task Language Understanding Benchmark.](https://arxiv.org/abs/2406.01574) | A popular benchmark for reasoning tasks is MMLU. It is frequently seen as the gold standard and as something that models overfit. A new, more rigorous, and refined benchmark called MMLU Pro is used to gauge language model reasoning.|
|[Omost.](https://github.com/lllyasviel/Omost) |Omost gives you control over how your images are generated. It comes from the same designer as ControlNet. First, it rewrites the prompts into a collection of illustrative code. After that, it renders the finished image using that. Crucially, you can modify the code either prior to or following generation in order to subtly alter the model's output. |
|[Control-GIC.](https://github.com/lianqi1008/Control-GIC) |A novel generative image compression framework called Control-GIC enables fine-grained bitrate modification while preserving high-quality output. |
|[LLM inference speed of light.](https://zeux.io/2024/03/15/llm-inference-sol/) |Using theoretical speed of light modeling as grounding is extremely significant for problems where the amount of computation and memory access is known a priori as it helps assess the quality of implementations and predict the impact of architectural modifications. |
|[Neural Surface Reconstruction.](https://github.com/prstrive/gens) | Without the need for 3D supervision, GenS is an end-to-end generalizable neural surface reconstruction model that performs exceptionally well at reconstructing surfaces from multi-view images.|
|[MatMul-Free LM.](https://github.com/ridgerchu/matmulfreellm) |Even at the billion-parameter scale, researchers have managed to remove matrix multiplication (MatMul) from huge language models without sacrificing speed. |
|[stable-audio-open-1.0 .](https://huggingface.co/stabilityai/stable-audio-open-1.0) | The weights for Stable Audio, which was trained to produce sound effects on audio samples with permissive licenses, have been released by Stability AI.|
|[CV-VAE: A Compatible Video VAE for Latent Generative Video Models.](https://ailab-cvc.github.io/cvvae/index.html) |With its spatio-temporally compressed latent spaces, CV-VAE is a video VAE that works with current image and video models to efficiently train new ones utilizing pre-trained ones. |
|[Qwen2.](https://qwenlm.github.io/blog/qwen2/) | Pretrained and instruction-tuned models of 5 sizes, including Qwen2-0.5B, Qwen2-1.5B, Qwen2-7B, Qwen2-57B-A14B, and Qwen2-72B.Having been trained on data in 27 additional languages besides English and Chinese. Having been trained on data in 27 additional languages besides English and Chinese. State-of-the-art performance in a large number of benchmark evaluations|
|[Dragonfly: A large vision-language model with multi-resolution zoom.](https://www.together.ai/blog/dragonfly-v1) | We are also launching two new open-source models  Llama-3-8b-Dragonfly-v1 a general-domain model trained on 5.5 million image-instruction pairs and Llama-3-8b-Dragonfly-Med-v1 finetuned on additional 1.4 biomedical image-instruction data. Dragonfly demonstrates promising performance on vision-language benchmarks like commonsense visual QA and image captioning. Dragonfly-Med outperforms prior models, including Med-Gemini on multiple medical imaging tasks, showcasing its capabilities for high-resolution medical data.|
|[MMLU Pro.](https://huggingface.co/datasets/TIGER-Lab/MMLU-Pro) |The industry standard for assessing knowledge and reasoning in language models is MMLU. |


## Perspectives
|Link|description|
|---|---|
|[Beyond the Cloud: Distributed AI and On-Device Intelligence.](https://sidstage.substack.com/p/beyond-the-cloud-distributed-ai-and) | Transition of AI workflows from cloud to the edge with specialized chip infrastructure & models, multi-modality and ambience across devices|
|[Sure, Google‚Äôs AI overviews could be useful ‚Äì if you like eating rocks.](https://www.theguardian.com/commentisfree/article/2024/jun/01/sure-googles-ai-overviews-could-be-useful-if-you-like-eating-rocks) |The company that shaped the development of search engines is banking on chatbot-style summaries. But so far, its suggestions are pretty wild |
|[AI's Communication Revolution: We're All Talking to Computers Now.](https://www.digitalnative.tech/p/ais-communication-revolution-were) | With its real-time integration of text, vision, and audio, OpenAI's GPT-4o is driving a revolution in communication through AI. As a result, human-to-AI communication becomes a fundamental form of digital connection and has the potential to bring about substantial societal changes as well as the emergence of new companies focused on AI-centric communication. This transition makes it possible for more natural interactions with AI.|
|[A Right to Warn about Advanced Artificial Intelligence.](https://righttowarn.ai/) | A group of AI workers, both present and past, is pleading with advanced AI companies to adopt values that guarantee openness and safeguard workers who voice concerns about risks. They emphasize how important it is for businesses to refrain from enforcing non-disparagement agreements, to make anonymous reporting procedures easier, to encourage candid criticism, and to shield whistleblowers from reprisals.|
|[Will Scaling Solve Robotics?](https://spectrum.ieee.org/solve-robotics) |The Conference on Robot Learning, which included 11 workshops and nearly 200 submitted papers, drew over 900 attendees last year. Whether it was possible to tackle robotics problems by training a huge neural network on a large data set was one of the main points of contention throughout the event. To help readers better comprehend the topic, this piece offers the opposing viewpoints. Scaling has been successful in several related domains. It is not feasible, though, because there is a lack of readily available robotics data and no obvious method for obtaining it. Scaling, even if it performs as well as it does in other domains, is probably not going to solve robotics. |
|[Plentiful, high-paying jobs in the age of AI.](https://www.noahpinion.blog/p/plentiful-high-paying-jobs-in-the) |Due to comparative advantage, it's feasible that a large number of professions that humans currently perform will be performed by humans eternally, regardless of how much better AIs become at those tasks. |
|[What I learned from looking at 900 most popular open source AI tools.](https://huyenchip.com/2024/03/14/ai-oss.html) |The goal of this study of open source AI repositories is to provide readers with a broad overview of the intimidating AI ecosystem. |
|[Meta AI system is a boost to endangered languages ‚Äî as long as humans aren‚Äôt forgotten.](https://www.nature.com/articles/d41586-024-01619-y) |Automated approaches to translation could provide a lifeline to under-resourced languages, but only if companies engage with the people who speak them. |
|[Misinformation poses a bigger threat to democracy than you might think.](https://www.nature.com/articles/d41586-024-01587-3) |In today‚Äôs polarized political climate, researchers who combat mistruths have come under attack and been labelled as unelected arbiters of truth. But the fight against misinformation is valid, warranted and urgently required. |
|[Is AI misinformation influencing elections in India?](https://www.nature.com/articles/d41586-024-01588-2) |A sample of roughly two million WhatsApp messages highlights urgent concerns about the spread and prevalence of AI-generated political content. |
|[I'm Bearish OpenAI.](https://stovetop.substack.com/p/im-bearish-openai) |A shift toward products and a research brain drain should ring your alarm bells |
|[The future of foundation models is closed-source.](https://blog.johnluttig.com/p/the-future-of-foundation-models-is) |if the centralizing forces of data and compute hold, open and closed-source AI cannot both dominate long-term |
|[A Grand Unified Theory of the AI Hype Cycle.](https://blog.glyph.im/2024/05/grand-unified-ai-hype.html) | Over the years, the AI sector has experienced multiple hype cycles, each of which produced really useful technology and outlasted the previous one. Instead of following an exponential process, every cycle adheres to a sigmoid one. There is an inevitable limit to any technology development strategy, and it is not too difficult to find. Although this AI hype cycle is unlike any other that has come before it, it will probably go in the same direction.|
|[Hi, AI: Our Thesis on AI Voice Agents.](https://a16z.com/ai-voice-agents/) |The current state of AI speech agents is described in a blog post and deck created by Andreessen Horowitz, along with potential areas for advancement and investment. It outlines the present state of the B2B and B2C application layer landscape and covers the top infrastructure stack. |


# ML news: Week 27 May - 2 June

## Research
|Link|description|
|---|---|
|[Golden Gate Claude.](https://www.anthropic.com/news/golden-gate-claude) | we released a major new research paper on interpreting large language models, in which we began to map out the inner workings of our AI model, Claude 3 Sonnet. In the ‚Äúmind‚Äù of Claude, we found millions of concepts that activate when the model reads relevant text or sees relevant images, which we call ‚Äúfeatures‚Äù.|
|[A Better Match for Drivers and Riders: Reinforcement Learning at Lyft.](https://arxiv.org/abs/2310.13810) |The Lyft team matched drivers and riders using online reinforcement learning, which is rewarded by future profits for the drivers. They made an extra $30 million a year for riders and were able to significantly improve in real time. |
|[Lessons from the Trenches on Reproducible Evaluation of Language Models.](https://arxiv.org/abs/2405.14782) | Language model evaluation is a challenging task, and information on the process is scarce outside of the biggest companies. This work presents a robust and repeatable set of assessment criteria. In the appendix, there is a useful discussion of perplexity evaluation.|
|[RectifID: Personalizing Rectified Flow with Anchored Classifier Guidance.](https://arxiv.org/abs/2405.14677v1) | A novel method for tailoring diffusion models to produce identity-preserving images from user-supplied references is presented by researchers. This strategy steers diffusion models without further training by using classifier guidance, in contrast to classic methods that need considerable domain-specific training.|
|[LoRA-Ensemble: Efficient Uncertainty Modelling for Self-attention Networks.](https://github.com/prs-eth/lora-ensemble?utm_source=tldrai) | A parameter-efficient deep ensemble technique for self-attention networks is called LoRA-Ensemble. This method provides accurate and well-calibrated predictions without the significant computational cost associated with typical ensemble methods. It does this by extending Low-Rank Adaptation (LoRA) for implicit ensembling.|
|[Agent Planning with World Knowledge Model.](https://arxiv.org/abs/2405.14205) |demonstrates superior performance compared to various strong baselines when adopting open-source LLMs such as Mistral-7B and Gemma-7B. Introduces a parametric world knowledge model to facilitate agent planning. The agent model can self-synthesize knowledge from expert and sampled trajectories; this is used to train the world knowledge model. Prior task knowledge is used to guide global planning and dynamic state knowledge is used to guide local planning. |
|[Enhancing Answer Selection in LLMs.](https://arxiv.org/abs/2405.12939) |suggests a hierarchical reasoning aggregation framework to enhance LLMs' reasoning capabilities; the method, known as Aggregation of Reasoning (AoR), chooses answers based on the assessment of reasoning chains; AoR employs dynamic sampling to modify the number of reasoning chains in relation to task complexity; it makes use of evaluation phase results to decide whether to sample more reasoning chains; One well-known problem with majority voting is that it doesn't work when the right option is in the minority; AoR concentrates on assessing the reasoning chains to enhance the choice of the concluding response; AoR can be employed with different LLMs to enhance performance on difficult reasoning problems, and it outperforms several well-known ensemble approaches.  |
|[Efficient Inference of LLMs.](https://arxiv.org/abs/2405.10637) | suggests a layer-condensed KV cache to achieve effective inference in LLMs; can achieve up to 26x higher throughput than baseline transformers while maintaining satisfactory performance; only computes and caches the key-values (KVs) of a small number of layers, which leads to reduced memory consumption and improved inference throughput.|
|[Mapping the Mind of a Large Language Model.](https://www.anthropic.com/research/mapping-mind-language-model) |By mapping millions of features that correlate to a wide range of concepts, anthropologists have shown a way to comprehend the inner workings of its huge language model, Claude Sonnet. This interpretability, which permits certain manipulations of these attributes to direct model behaviors, may result in safer AI. The research indicates a noteworthy advancement in comprehending and enhancing the security protocols of artificial intelligence language models. |
|[Object Segmentation in Complex Scenarios.](https://arxiv.org/pdf/2405.15658) | To enhance Generalized Referring Expression Segmentation (GRES), researchers have developed the Hierarchical Semantic Decoding with Counting Assistance (HDC) framework. As opposed to earlier techniques, HDC combines semantic correspondences and transmits complementing modality information across granularities for improved multi-level decoding.|
|[Label-efficient Semantic Scene Completion with Scribble Annotations.](https://arxiv.org/abs/2405.15170v1) |A novel semantic scene completion method called Scribble2Scene lessens the requirement for thorough labeling. |
|[Semantic and Spatial Adaptive Pixel-level Classifier for Semantic Segmentation.](https://arxiv.org/abs/2405.06525v1) | The constraints of semantic segmentation have been addressed with the introduction of a new Semantic and Spatial Adaptive (SSA) classifier. This novel method makes use of coarse masks to direct prototype adjustment, improving fine-grained recognition and delineating mask boundaries.|
|[RSBuilding: Towards General Remote Sensing Image Building Extraction and Change Detection with Foundation Model.](https://github.com/meize0729/rsbuilding) |By integrating building extraction and change detection into a single model, RSBuilding presents a novel method for deciphering buildings from remote sensing photos. |
|[Meteor: Mamba-based traversal of rationale for Large Language and Vision Models.](https://github.com/byungkwanlee/meteor) | This research presents Meteor, a novel massive language and vision model that is efficient and employs several justifications to enhance comprehension and response times.|
|[gzip Predicts Data-dependent Scaling Laws.](https://arxiv.org/abs/2405.16684) |Scaling rules are a means of forecasting the performance of models at specific sizes with a given quantity of data. Getting them is costly. In order to forecast a data-dependent scaling law, this research investigates the use of the gzip compression ratio as a powerful signal. |
|[The Road Less Scheduled.](https://arxiv.org/abs/2405.15682) |A few weeks prior, a brand-new Meta optimizer was circulating as a possible replacement for Adam. The method, including the part about online updates, is described in more depth in this paper. Overall, this appears like a good outcome, particularly in cases when the complete number of planned training steps is not known at the start of the training process. |
|[Transformers Can Do Arithmetic with the Right Embeddings.](https://arxiv.org/abs/2405.17399v1) |Researchers have added embeddings that encode the position of each digit with respect to the start of the number, which has improved transformer performance on arithmetic tasks. |
|[DMPlug: A Plug-in Method for Solving Inverse Problems with Diffusion Models.](https://arxiv.org/abs/2405.16749v1) |DMPlug is a new plug-in technique that solves inverse problems (IPs) by using pretrained diffusion models (DMs). DMPlug efficiently addresses both manifold feasibility and measurement feasibility by treating the reverse diffusion process as a function, in contrast to other interleaving techniques. |
|[PatchScaler: An Efficient Patch-independent Diffusion Model for Super-Resolution.](https://arxiv.org/abs/2405.17158v1) | PatchScaler is a diffusion-based technique that greatly improves inference efficiency for single image super-resolution (SR).|
|[Reason3D: Searching and Reasoning 3D Segmentation via Large Language Model.](https://kuanchihhuang.github.io/project/reason3d/) | A revolutionary multimodal big language model called Reason3D was created for a thorough comprehension of 3D environments.|
|[Yuan 2.0-M32: Mixture of Experts with Attention Router.](https://arxiv.org/abs/2405.17976) |A Mixture of Experts model with 40B parameters and 3.7B active at all times is Yuan 2.0-M32. Even though it only uses 1/19th of the compute, it performs similarly to Llama 3 70B. It appears remarkably powerful considering its size, having been trained on 2T tokens. |
|[Scaling Laws and Compute-Optimal Training Beyond Fixed Training Durations.](https://arxiv.org/abs/2405.18392) |The Cosine learning rate schedule employed in the original scaling laws publications prevents optimal loss if the Cosine period is not in line with the total number of training steps. Because of this, training enough models to produce useful scaling laws is difficult. In order to minimize GPU costs for scaling law development, this study presents the concept of a constant learning rate with a cool down. |
|[Towards Ultra-High-Definition Image Deraining: A Benchmark and An Efficient Method.](https://arxiv.org/abs/2405.17074v1) |To address the problem of deraining ultra-high-definition (UHD) photographs, researchers have released a new dataset dubbed 4K-Rain13k, which consists of 13,000 pairs of 4K resolution images. |
|[EasyAnimate An End-to-End Solution for High-Resolution and Long Video Generation.](https://github.com/aigc-apps/easyanimate) | Transformers are used in the EasyAnimate method to modify the DiT architecture for advanced 3D video production. In order to capture temporal dynamics and guarantee seamless motion transitions and consistent frames, this project integrates a motion module block.|
|[Self-Exploring Language Models (SELM).](https://github.com/shenao-zhang/selm) |Online feedback is used in Self-Exploring Language Models (SELM), a technique that improves preference optimization in LLMs. |
|[T2V-Turbo: Breaking the Quality Bottleneck of Video Consistency Model with Mixed Reward Feedback.](https://t2v-turbo.github.io/) |When applied to video models, consistency distillation significantly lowers the number of processes required to produce content. |

## News
|Link|description|
|---|---|
|[Meta and Elon Musk‚Äôs xAI fight to partner with chatbot group Character.ai .](https://www.ft.com/content/5cf24fdd-30ed-44ec-afe3-aefa6f4ad90e) |AI pioneer Noam Shazeer launched Character.ai, a rapidly expanding role-playing startup, and Silicon Valley companies are vying for a partnership. This occurs at a time when numerous big businesses are investing heavily in startups. |
|[Scarlett Johansson told OpenAI not to use her voice ‚Äî and she‚Äôs not happy they might have anyway.](https://www.theverge.com/2024/5/20/24161253/scarlett-johansson-openai-altman-legal-action) | penAI has denied that its ChatGPT voice is based on Johansson, but it certainly sounds a lot like her.|
|[xAI Series B funding round.](https://x.ai/blog/series-b) |xAI is pleased to announce our series B funding round of $6 billion.|
|[iPhone to get a better Siri, AI emoji creator, smart recaps, and more with iOS 18.](https://timesofindia.indiatimes.com/technology/tech-news/iphone-to-get-a-better-siri-ai-emoji-creator-smart-recaps-and-more-with-ios-18/articleshow/110452936.cms) |in June 2024,  the Cupertino giant will finally unveil its approach to AI |
|[New startup builds digital pets for Apple's Vision Pro.](https://www.axios.com/2024/05/23/apple-vision-pro-digital-dog-bootloader-ai) |A new startup is coming out of stealth with a plan to offer digital pets for the Apple Vision Pro that use AI to read and respond to human emotion. |
|[Humane is looking for a buyer after the AI Pin‚Äôs underwhelming debut.](https://www.theverge.com/2024/5/21/24162185/humane-seeking-acquisition-rumor-ai-pin) |he startup apparently thinks it‚Äôs worth between $750 million and $1 billion despite the deep software flaws and hardware issues of its first product. |
|[OpenAI Board Forms Safety and Security Committee.](https://openai.com/index/openai-board-forms-safety-and-security-committee/) | OpenAI declared that its new foundation model will be trained, and it established a Safety and Security Committee. As model capabilities advance, this committee will be responsible with recommending to the board what steps should be taken.|
|[Anthropic hires former OpenAI safety lead to head up new team.](https://techcrunch.com/2024/05/28/anthropic-hires-former-openai-safety-lead-to-head-up-new-team/) |Jan Leike, a leading AI researcher who earlier this month resigned from OpenAI before publicly criticizing the company‚Äôs approach to AI safety, has joined OpenAI rival Anthropic to lead a new ‚Äúsuperalignment‚Äù team. |
|[New agent capabilities in Microsoft Copilot.](https://www.microsoft.com/en-us/microsoft-365/blog/2024/05/21/new-agent-capabilities-in-microsoft-copilot-unlock-business-value/) |At Build 2024, Microsoft introduced new Copilot capabilities, like as Copilot Extensions and Connectors for simple customization, Team Copilot for team communication, and bespoke AI Agents to automate operations. The goal of these improvements is to increase efficiency in company processes and productivity. The improvements are anticipated to be widely available later in 2024; they are presently in limited private preview. |
|[‚ÄúI lost trust‚Äù: Why the OpenAI team in charge of safeguarding humanity imploded.](https://www.vox.com/future-perfect/2024/5/17/24158403/openai-resignations-ai-safety-ilya-sutskever-jan-leike-artificial-intelligence) | Company insiders explain why safety-conscious employees are leaving.|
|[OpenAI sends internal memo releasing former employees from controversial exit agreements.](https://www.cnbc.com/2024/05/24/openai-sends-internal-memo-releasing-former-employees-from-non-disparagement-agreements-sam-altman.html) |OpenAI on Thursday backtracked on a controversial decision to, in effect, make former employees choose between signing a non-disparagement agreement that would never expire, or keeping their vested equity in the company. |
|[Opera adds Google‚Äôs Gemini to its browsers.](https://www.theverge.com/2024/5/28/24166295/opera-google-gemini-aria-read-aloud-ai) |Users can access Gemini through the Aria AI assistant on Opera browsers. |
|[Two receptors are better than one for AI-designed obesity drugs.](https://www.nature.com/articles/d41586-024-01399-5) |Compounds predicted by machine learning attach to two receptors involved in appetite and weight. |
|[Mistral's New AI Non-Production License .](https://mistral.ai/news/mistral-ai-non-production-license-mnpl/) | Mistral is attempting to strike a balance between corporate success and transparency. It has a new license designed to achieve that equilibrium. It will keep releasing further projects under the new MNPL license in addition to Apache 2.0.|
|[Sonic: A Low-Latency Voice Model for Lifelike Speech.](https://cartesia.ai/blog/sonic) |The makers of Mamba, sub quadratic Transformer versions, and SSMs have released a new model. Crucially, their recently founded business, Cartesia, has developed a realistic-sounding, lightning-fast speech generating technology. This suggests that they want to take up residence in the helpers' area. |
|[Vox Media and The Atlantic sign content deals with OpenAI.](https://www.theverge.com/2024/5/29/24167072/openai-content-copyright-vox-media-the-atlantic) |OpenAI continues to establish media partnerships as it looks to lock down training data ‚Äî and avoid lawsuits.|
|[Mistral's Code Model.](https://mistral.ai/news/codestral/) |We introduce Codestral, our first-ever code model. Codestral is an open-weight generative AI model explicitly designed for code generation tasks. |
|[OpenAI signs 100K PwC workers to ChatGPT‚Äôs enterprise tier as PwC becomes its first resale partner.](https://techcrunch.com/2024/05/29/openai-signs-on-100k-pwc-workers-to-its-chatgpt-enterprise-tier-as-the-consultant-becomes-its-first-resale-partner/) | OpenAI, on Wednesday announced that it has signed a major enterprise customer that it hopes will indicate how a similar effect could play out in the world of work. PwC, the management consulting giant, will become OpenAI‚Äôs biggest customer to date, covering 100,000 users.|
|[Apple's AI plans involves 'black box' for cloud data.](https://appleinsider.com/articles/24/05/29/apples-ai-plans-involves-black-box-for-cloud-data) |  Apple intends to process data from AI applications inside a virtual black box. The concept, known as "Apple Chips in Data Centers" (ACDC) internally, would involve only Apple's hardware being used to perform AI processing in the cloud. The idea is that it will control both the hardware and software on its servers, enabling it to design more secure systems.|
|[Introducing Perplexity Pages.](https://www.perplexity.ai/hub/blog/perplexity-pages) | A new AI-created product for producing shareable, long-lasting research artifacts has been announced by the Perplexity search engine.|
|[Autodesk acquires AI-powered VFX startup Wonder Dynamics.](https://techcrunch.com/2024/05/21/autodesk-acquires-ai-powered-vfx-startup-wonder-dynamics/) |Autodesk ‚Äî the 3D tools behemoth ‚Äî has acquired Wonder Dynamics, a startup that lets creators quickly and easily make complex characters and visual effects using AI-powered image analysis.  |
|[Anthropic‚Äôs AI now lets you create bots to work for you.](https://www.theverge.com/2024/5/30/24167231/anthropic-claude-ai-assistant-automate-tasks) | Anthropic is releasing a new feature for its AI chatbot Claude that will let anyone create an email assistant, a bot to purchase shoes, or other personalized solutions. It‚Äôs called ‚Äútool use‚Äù (or the nerdier ‚Äúfunction calling‚Äù), and it hooks up to any external API of your choosing.|
|[Patronus AI Raises $17 million To Detect LLM Mistakes at Scale.](https://finance.yahoo.com/news/patronus-ai-raises-17-million-140000573.html) | Series A financing led by Glenn Solomon at Notable Capital underscores urgent need for companies to deploy large language models with confidence|
|[Neuralink rival sets brain-chip record with 4,096 electrodes on human brain.](https://arstechnica.com/science/2024/05/neuralink-rival-sets-brain-chip-record-with-4096-electrodes-on-human-brain/) | Brain-computer interface company Precision Neuroscience says that it has set a new world record for the number of neuron-tapping electrodes placed on a living human's brain‚Äî4,096, surpassing the previous record of 2,048 set last year, according to an announcement from the company on Tuesday.|
|[Google adds AI-powered features to Chromebook.](https://techcrunch.com/2024/05/28/google-adds-ai-powered-features-to-chromebook/) |Google announced new AI-powered features today for its Chromebook Plus line of devices, such as a writing assistant, a wallpaper creator and easy access to Google‚Äôs Gemini chatbot. |
|[What is science? Tech heavyweights brawl over definition.](https://www.nature.com/articles/d41586-024-01626-z) |AI pioneer Yann LeCun and Elon Musk went head-to-head in a debate about modern research that drew thousands of comments. |
|[Google to refine AI-generated search summaries in response to bizarre results.](https://www.theguardian.com/technology/article/2024/may/31/google-ai-summaries-sge-changes) |After new feature tells people to eat rocks or add glue to pizza sauce, company to restrict which searches return summaries |
|[A new AI service allows viewers to create TV shows. Are we doomed?](https://www.theguardian.com/tv-and-radio/article/2024/may/31/fable-showrunner-ai-tv) |Showrunner will let users generate episodes with prompts, which could be an alarming next step or a fleeting novelty |

## Resources
|Link|description|
|---|---|
|[Mistral-finetune.](https://github.com/mistralai/mistral-finetune) |mistral-finetune is a light-weight codebase that enables memory-efficient and performant finetuning of Mistral's models. It is based on LoRA, a training paradigm where most weights are frozen and only 1-2% additional weights in the form of low-rank matrix perturbations are trained. |
|[Modula.](https://github.com/jxbz/modula) |A novel technique called modular norm allows neural networks to scale training effectively over a range of network sizes by normalizing weight updates. |
|[MobileNet-V4.](https://huggingface.co/blog/rwightman/mobilenetv4) | Extremely fast and performant computer vision model is called MobileNet. Devices on the edge can run it. This blog article describes the new model and some contemporary modifications that were made to it.|
|[Multi-Dimensional Features.](https://github.com/joshengels/multidimensionalfeatures) |This project challenges the linear representation hypothesis by examining if language models compute using multi-dimensional characteristics. |
|[llamafile 0.8.6 CPU benchmark.](https://github.com/Mozilla-Ocho/llamafile/discussions/450) | It is now possible to run inference for the flagship model from Mistral at 20 tokens per second on a commodity CPU, thanks to recent developments from Mozilla's Llamafile project.|
|[Risks and Opportunities of Open-Source Generative AI.](https://arxiv.org/abs/2405.08597) | examines the potential and hazards associated with open-source generative AI models and makes the case that these models' overall advantages exceed their drawbacks.|
|[How Far Are We From AGI.](https://arxiv.org/abs/2405.10313v1) | offers a summary of the tactics required to attain artificial general intelligence (AGI), including a thorough survey, discussion, and unique viewpoints. It also addresses significant questions regarding the near future of AGI.|
|[Efficient Multimodal LLMs.](https://arxiv.org/abs/2405.10739v1) | offers a thorough and methodical analysis of the state of efficient multimodal big language models at the moment; it covers applications, constraints, possible future directions, and efficient structures and techniques.|
|[Scientific Applications of LLMs.](https://arxiv.org/abs/2405.10725) |introduces INDUS, a full suite of LLMs that comprises small distilled models, an encoder model, and embedding models for Earth science, biology, physics, and planetary sciences, among other subjects. |
|[Guide for Evaluating LLMs.](https://arxiv.org/abs/2405.14782) | offers advice and lessons for assessing large language models (LLMs); it also covers best practices and potential problems, and it introduces an open-source framework for LLM evaluation.|
|[Information Retrieval Measures.](https://ir-measur.es/en/latest/) |It is necessary to understand how effectively the retrieval part is operating in order to build a RAG system. This toolbox provides an extensive range of effective performance metrics for information retrieval. |
|[A Guide to Creating Neural Circuit Diagrams.](https://github.com/vtabbott/Neural-Circuit-Diagrams/blob/main/Guide/Guide.ipynb) |This is a guide to drawing Neural Circuit Diagrams by Vincent Abbott from the paper Neural Circuit Diagrams: Robust Diagrams for the Communication, Implementation, and Analysis of Deep Learning Architectures. It allows for deep learning algorithms to be comprehensively expressed using a novel diagrammatic scheme. |
|[InstructAvatar: Text-Guided Emotion and Motion Control for Avatar Generation.](https://wangyuchi369.github.io/InstructAvatar/) | A novel model called InstructAvatar uses text direction to generate 2D avatars that are emotionally expressive.|
|[Marigold Pipelines for Computer Vision Tasks.](https://huggingface.co/docs/diffusers/main/en/using-diffusers/marigold_usage) |Diffusers can now use one of the best depth models as a pipeline. This tutorial goes over how to utilize the model, what you can do with it, and how to condition on the latents of the first frame to make it work with videos effortlessly. |
|[Reproducing GPT-2 (124M) in llm.c in 90 minutes for $20.](https://github.com/karpathy/llm.c/discussions/481) |A version of LLM C, a solitary self-contained GPT-2 implementation designed to replicate the 2019 model suite, has been made available by Andrej Karpathy. The library can train the simplest of these models in about 90 minutes with this latest release. It has few dependencies and executes from start to finish. |
|[Content-Style Decoupling for Unsupervised Makeup Transfer without Generating Pseudo Ground Truth.](https://github.com/snowfallingplum/csd-mt) |A innovative technique for improving makeup transfer tasks without depending on genuine target images is Content-Style Decoupled Makeup Transfer (CSD-MT). |
|[LaVague.](https://github.com/lavague-ai/LaVague) |LaVague is an open-source Large Action Model framework to develop AI Web Agents. Our web agents take an objective, such as "Print installation steps for Hugging Face's Diffusers library" and performs the required actions to achieve this goal by leveraging our two core components. |
|[PRISM: A foundation model for life‚Äôs chemistry.](https://www.enveda.com/posts/prism-a-foundation-model-for-lifes-chemistry) |Enveda‚Äôs PRISM (Pretrained Representations Informed by Spectral Masking) model was trained on 1.2 billion small molecule mass spectra, the largest training set of small molecule mass spectra ever assembled. |
|[Scale Private Leaderboard.](https://scale.com/leaderboard) |Scale has created a private language model evaluation leaderboard. Although the ordering isn't all that surprising, it's worth noting that the Llama 3 70B frequently outperforms Claude Opus in terms of instruction following. |
|[controlnet-scribble-sdxl-1.0.](https://huggingface.co/xinsir/controlnet-scribble-sdxl-1.0) | Drawing random lines can be used as conditioning data for image creation using Scribble ControlNet. It has strong performance and was trained on a significantly larger number of post-training photos than other ControlNets.|

## Perspectives
|Link|description|
|---|---|
|[AI's Communication Revolution: We're All Talking to Computers Now.](https://www.digitalnative.tech/p/ais-communication-revolution-were) | The most recent AI model from OpenAI, GPT-4o, allows for real-time communication between people and machines by adding vision and audio to its text-based capabilities. The AI revolution brings with it a new wave of interactions between humans and AI, and eventually AI itself. These interactions will probably have an impact on our social habits and business structures. The impact of this technology on human communication will develop as it advances, possibly spurring the development of creative businesses and software.|
|[I Don‚Äôt Want To Spend My One Wild And Precious Life Dealing With Google‚Äôs AI Search.](https://aftermath.site/google-ai-search-god-no-why) |The unwelcome three-second delay that Google's AI search tool adds to search results is driving users crazy by interfering with their experience and displaying irrelevant content. |
|[LLMs are not suitable for (advanced) brainstorming.](https://piaoyang0.wordpress.com/2024/05/15/llms-are-not-suitable-for-brainstorming/) |When it comes to truly creative brainstorming, large language models frequently end up producing consensus-based ideas rather than original notions. |
|[Could AI help cure ‚Äòdownward spiral‚Äô of human loneliness?.](https://www.theguardian.com/technology/article/2024/may/27/could-ai-help-cure-downward-spiral-of-human-loneliness) |One computer scientist says we should embrace human-machine relationships, but other experts are more cautious |
|[Scarlett Johansson‚Äôs OpenAI clash is just the start of legal wrangles over artificial intelligence.](https://www.theguardian.com/technology/article/2024/may/27/scarlett-johansson-openai-legal-artificial-intelligence-chatgpt) |Hollywood star‚Äôs claim ChatGPT update used an imitation of her voice highlights tensions over rapidly accelerating technology |
|[TechScape: What we learned from the global AI summit in South Korea.](https://www.theguardian.com/technology/article/2024/may/28/techscape-ai-global-summit) |One day and six (very long) agreements later, can we call the meeting to hammer out the future of AI regulation a success? |
|[Scarlett Johansson‚Äôs OpenAI clash is just the start of legal wrangles over artificial intelligence.](https://www.theguardian.com/technology/article/2024/may/27/scarlett-johansson-openai-legal-artificial-intelligence-chatgpt) |Hollywood star‚Äôs claim ChatGPT update used an imitation of her voice highlights tensions over rapidly accelerating technology |
|[Trying to tame AI: Seoul summit flags hurdles to regulation.](https://www.theguardian.com/technology/article/2024/may/27/trying-to-tame-ai-seoul-summit-flags-hurdles-to-regulation) |UK touts ‚ÄòBletchley effect‚Äô of safety institutes, but division remains over whether to limit AI abilities |
|[How to Build a Category-Defining AI Startup.](https://playbooks.hypergrowthpartners.com/p/how-to-build-a-category-defining) | AI companies need to adopt a marketing-led strategy in order to stand out from the competition and establish themselves as category leaders as the AI field changes quickly. AI startups may accelerate market acceptance, reshape the industry narrative, and position themselves as visionary leaders in their field by adopting a marketing-led strategy.|
|[Ways to think about AGI.](https://www.ben-evans.com/benedictevans/2024/5/4/ways-to-think-about-agi) | The consensus is unclear because there isn't a well-developed theoretical model of general intelligence or a clear explanation for why or how LLMs work so well, despite the fact that some experts think AGI may be achievable. The conversation highlights the enormous amount of unanswered questions surrounding AGI, recognizing both its possible advantages and disadvantages while drawing comparisons between theology and the empirical methodology of the Apollo Program.|
|[The AI revolution is coming to robots: how will it change them?.](https://www.nature.com/articles/d41586-024-01442-5) |The melding of artificial intelligence and robotics could catapult both to new heights. |
|[What GPT-4o illustrates about AI Regulation.](https://www.hyperdimensional.co/p/what-gpt-4o-illustrates-about-ai) |This article compares and contrasts model-level, use-level, and conduct-level frameworks in order to analyze several approaches to AI regulation. It contends that use-level regulation, which can lead to unneeded complexity and unworkable constraints for the deployment of AI, is inferior to conduct-level regulation, which applies current laws to new technologies with minimal precision. One example of the drawbacks of a use-level approach is the limitations placed on AI's capacity to infer emotions by the recent EU AI Act. |
|[How does ChatGPT ‚Äòthink‚Äô? Psychology and neuroscience crack open AI large language models.](https://www.nature.com/articles/d41586-024-01314-y) | Researchers are striving to reverse-engineer artificial intelligence and scan the ‚Äòbrains‚Äô of LLMs to see what they are doing, how and why.|
|[Anglo-American bias could make generative AI an invisible intellectual cage.](https://www.nature.com/articles/d41586-024-01573-9) |Studies show that applications in generative artificial intelligence (AI) such as ChatGPT and other large language models perform remarkably well in English, but are not as proficient in other languages. This masks a more insidious problem.  |
|[AI won‚Äôt eat your job, but it will eat your salary.](https://medium.com/@sanguit/ai-wont-eat-your-job-but-it-will-eat-your-salary-a810121d89e4) |AI poses a danger to the skill premium associated with tasks as well as the existence of jobs themselves, which could result in lower compensation for skilled workers. AI has the potential to reorganize job duties and reduce obstacles to task completion, which would result in commoditization and a reduction in the ability to demand a premium wage. Managerial advantages may likewise disappear as AI develops, particularly through AI agents, which would put the human-in-the-loop advantage to the test and further erode skill premiums. |
|[‚ÄòAll eyes on Rafah‚Äô: how AI-generated image swept across social media.](https://www.theguardian.com/world/article/2024/may/30/all-eyes-on-rafah-how-ai-generated-image-spread-across-social-media) |Celebrity posts of graphic following IDF strike help make it among most-shared content of Israel-Gaza war |


# ML news: 20-26 May

## Research
|Link|description|
|---|---|
|[LoRA Learns Less and Forgets Less.](https://arxiv.org/abs/2405.09673) | LoRA is a well-liked technique for enhancing models to add flair or expertise. The trade-off between forgetting and power while utilizing LoRAs is examined in this research. LoRAs are found to retain more of the initial "out of distribution" performance while learning less than full fine tuning.|
|[Chameleon: Mixed-Modal Early-Fusion Foundation Models.](https://arxiv.org/abs/2405.09818) | Like GPT-4o, Meta has unveiled Chameleon, a natively multi-modal model that works with both text and graphics at the same time. It performs better than a lot of other models. Since then, the Meta team's work on internal models has greatly advanced.|
|[Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context.](https://storage.googleapis.com/deepmind-media/gemini/gemini_v1_5_report.pdf) |The technical report for Google's most current model family has been updated. While there is a dearth of information regarding the models and data utilized, there is a wealth of information regarding the assessment and safety precautions implemented, providing an intriguing glimpse into large-scale alignment. |
|[Introducing the Frontier Safety Framework.](https://deepmind.google/discover/blog/introducing-the-frontier-safety-framework/) |Frontier Safety Framework was unveiled by Google DeepMind to mitigate the dangers associated with upcoming sophisticated AI models. This framework assesses models against critical capability levels (CCLs) for potentially dangerous AI capabilities and implements mitigation techniques when thresholds are crossed. |
|[ART3D: 3D Gaussian Splatting for Text-Guided Artistic Scenes Generation.](https://arxiv.org/abs/2405.10508) |AI can be creatively and entertainingly used to generate artistic 2D visuals. This work uses text-guided Gaussian Splatting to bring that capacity to 3D. |
|[Grounded 3D-LLM with Referent Tokens.](https://groundedscenellm.github.io/grounded_3d-llm.github.io) | It's difficult to figure out where items are in a 3D setting. You can identify semantic labels for things in 3D space by employing language-guided 3D understanding.|
|[LeMeViT: Efficient Vision Transformer with Learnable Meta Tokens for Remote Sensing Image Interpretation.](https://arxiv.org/abs/2405.09789v1) | LeMeViT is a novel method that uses learnable meta tokens to lower the computational costs associated with Vision Transformers. By effectively capturing important data, these tokens accelerate inference.|
|[Not All Prompts Are Secure: A Switchable Backdoor Attack Against Pre-trained Vision Transformers.](https://arxiv.org/abs/2405.10612v1) |A fresh security risk has been identified for the well-known AI model Vision Transformers by researchers. The attack, known as SWARM, is extremely sneaky and harmful to consumers since it discreetly activates backdoor behavior in a model using a "switch token". |
|[Mapping the Mind of a Large Language Model.](https://www.anthropic.com/research/mapping-mind-language-model) |Today we report a significant advance in understanding the inner workings of AI models. We have identified how millions of concepts are represented inside Claude Sonnet, one of our deployed large language models. This is the first ever detailed look inside a modern, production-grade large language model. This interpretability discovery could, in future, help us make AI models safer. |
|[Smart Expert System: Large Language Models as Text Classifiers.](https://arxiv.org/abs/2405.10523v1) |Text classification is a fundamental task in Natural Language Processing (NLP), and the advent of Large Language Models (LLMs) has revolutionized the field. This paper introduces the Smart Expert System, a novel approach that leverages LLMs as text classifiers.  |
|[CSTA: CNN-based Spatiotemporal Attention for Video Summarization.](https://github.com/thswodnjs3/) | In order to enhance video summarization, this project presents a novel CNN-based SpatioTemporal Attention (CSTA) technique. In contrast to conventional attention processes, CSTA uses a 2D CNN to efficiently extract the visual meaning of frames in order to comprehend relationships and important features in films.|
|[Microsoft introduces Phi-Silica, a 3.3B parameter model made for Copilot+ PC NPUs.](https://venturebeat.com/ai/microsoft-introduces-phi-silica-a-3-3b-parameter-model-made-for-copilot-pc-npus/) |Microsoft is making more investments in the development of small language models (SLMs). At its Build developer conference, the company announced the general availability of its Phi-3 models and previewed Phi-3-vision. However, on the heels of Microsoft‚Äôs Copilot+ PC news, it‚Äôs introducing an SLM built specifically for these device‚Äôs powerful Neural Processing Units (NPUs). |
|[Aurora: A Foundation Model of the Atmosphere.](https://www.microsoft.com/en-us/research/publication/aurora-a-foundation-model-of-the-atmosphere/) |By training a foundation model for atmospheric predictions, Microsoft has achieved a new state-of-the-art in global weather prediction tests lasting five and ten days. |
|[MathBench: Evaluating the Theory and Application Proficiency of LLMs with a Hierarchical Mathematics Benchmark.](https://arxiv.org/abs/2405.12209v1) | A new benchmark called MathBench aims to give a comprehensive evaluation of the mathematical capabilities of large language models.|
|[Wav-KAN: Wavelet Kolmogorov-Arnold Networks.](https://arxiv.org/abs/2405.12832v1) | Wav-KAN is a neural network framework that leverages wavelet functions to enhance performance and interpretability, according to research. Wav-KAN captures both high-frequency and low-frequency data components, which speeds up training and boosts robustness in contrast to standard models.|
|[https://cohere.com/research/aya.](https://arxiv.org/abs/2405.12710v1) |Global-Local Semantic Consistent Learning (GLSCL), a novel technique created by researchers, greatly lowers computational costs while improving text-video retrieval. |
|[ProtT3: Protein-to-Text Generation for Text-based Protein Understanding.](https://arxiv.org/abs/2405.12564v1) |ProtT3, a novel framework that combines conventional Language Models (LMs) with Protein Language Models (PLMs) to improve text-based protein understanding, is presented by researchers. Using a cross-modal projector known as Q-Former, ProtT3 combines a PLM for analyzing amino acid sequences with a language model to produce high-quality textual descriptions. |
|[Diffusion-RSCC: Diffusion Probabilistic Model for Change Captioning in Remote Sensing Images.](https://github.com/fay-y/diffusion-rscc) | In order to better explain how the environment changes over time, a new probabilistic diffusion model for Remote Sensing Image Change Captioning (RSICC) is presented in this study.|

## News
|Link|description|
|---|---|
|[First companies sign up to AI safety standards on eve of Seoul summit.](https://www.theguardian.com/technology/article/2024/may/21/first-companies-sign-up-ai-safety-standards-seoul-summit) | Rishi Sunak says 16 international firms have committed, but standards have been criticised for lacking teeth|
|[World is ill-prepared for breakthroughs in AI, say experts.](https://www.theguardian.com/technology/article/2024/may/20/world-is-ill-prepared-for-breakthroughs-in-ai-say-experts) | Governments have made insufficient regulatory progress, ‚Äògodfathers‚Äô of the technology say before summit|
|[Productivity soars in sectors of global economy most exposed to AI, says report.](https://www.theguardian.com/technology/article/2024/may/21/productivity-soars-in-sectors-of-global-economy-most-exposed-to-ai-says-report) | Employers in UK, one of 15 countries studied, willing to pay 14% wage premium for jobs requiring AI skills|
|[ChatGPT suspends Scarlett Johansson-like voice as actor speaks out against OpenAI.](https://www.theguardian.com/technology/article/2024/may/20/chatgpt-scarlett-johansson-voice) |OpenAI says ‚ÄòSky‚Äô is not an imitation of actor‚Äôs voice after users compare it to AI companion character in film Her |
|[$16k G1 humanoid rises up to smash nuts, twist and twirl.](https://newatlas.com/robotics/unitree-g1-humanoid-agent) |Humanoid development at Chinese robotics company Unitree continues apace. Following its entry into the melee just last year, its fast-walking H1 bot recently got its backflip groove on. Now the faceless and hand-less humanoid is being joined by an impressive all-rounder. |
|[Google I/O 2024: Here‚Äôs everything Google just announced.](https://techcrunch.com/2024/05/15/google-i-o-2024-everything-announced-so-far/) | Google kicked off its developer conference each year with a rapid-fire stream of announcements, including many unveilings of recent things it‚Äôs been working on. Brian already kicked us off by sharing what we are expecting. |
|[Gamma raised $12M in Series A funding to reimagine presentations, powered by AI.](https://gamma.app/docs/Weve-raised-12M-in-Series-A-funding-to-reimagine-presentations-po-1mmk923dzxyrn2t) |Gamma received $12 million from Accel to use AI to reinvent presentations. Over 18 million people have contributed over 60 million Gammas (AI-generated slides) to date. |
|[ Inflection AI reveals new team and plan to embed emotional AI in business bots.](https://venturebeat.com/ai/exclusive-inflection-ai-reveals-new-team-and-plan-to-embed-emotional-ai-in-business-bots) |Inflection AI unveiled its new leadership team, composed of seasoned Silicon Valley veterans. |
|[Scarlett Johansson says Altman insinuated that AI soundalike was intentional.](https://arstechnica.com/tech-policy/2024/05/openai-pauses-chatgpt-4o-voice-that-fans-said-ripped-off-scarlett-johansson/) | OpenAI has paused a voice mode option for ChatGPT-4o, Sky, after backlash accusing the AI company of intentionally ripping off Scarlett Johansson's critically acclaimed voice-acting performance in the 2013 sci-fi film Her.|
|[Perplexity CEO Aravind Srinivas takes shots at Google.](https://www.axios.com/2024/05/14/perplexity-ceo-aravind-srinivas-ai-google) | Google's planned roll-out of AI-summarized search results doesn't faze Perplexity AI CEO and co-founder Aravind Srinivas ‚Äî whose startup has offered a popular AI-driven search tool providing similar digests for nearly two years.|
|[Google still hasn‚Äôt fixed Gemini‚Äôs biased image generator.](https://techcrunch.com/2024/05/15/google-still-hasnt-fixed-geminis-biased-image-generator/) | Back in February, Google paused its AI-powered chatbot Gemini‚Äôs ability to generate images of people after users complained of historical inaccuracies. Well, the problem‚Äôs likely more complex than Hassabis alluded to.|
|[SoundHound AI and Perplexity Partner to Bring Online LLMs to Next Gen Voice Assistants Across Cars and IoT Devices.](https://www.businesswire.com/news/home/20240509196718/en/SoundHound-AI-and-Perplexity-Partner-to-Bring-Online-LLMs-to-Next-Gen-Voice-Assistants-Across-Cars-and-IoT-Devices) | Perplexity‚Äôs capabilities added to SoundHound Chat AI will respond to questions conversationally with real-time knowledge from the web|
|[Stability AI discusses sale amid cash crunch, The Information reports.](https://finance.yahoo.com/news/stability-ai-discusses-sale-amid-235921573.htm) |Artificial Intelligence startup Stability AI held discussions with at least one potential buyer in recent weeks about a sale as it faces a cash crunch, The Information reported on Wednesday, citing a person involved in the talks. |
|[Scale AI raises $1B.](https://scale.com/blog/scale-ai-series-f) |Accel and earlier investors provide the gigantic series F. There is a huge need for the services offered, and Scale is in a unique position to keep driving the current AI data surge. |
|[Elon Musk‚Äôs xAI is working on making Grok multimodal.](https://www.theverge.com/2024/5/21/24161764/elon-musk-xai-grok-multimodal-ai) |Users may soon be able to input images into Grok for text-based answers. |
|[Google CEO Sundar Pichai on AI-powered search and the future of the web.](https://www.theverge.com/24158374/google-ceo-sundar-pichai-ai-search-gemini-future-of-the-internet-web-openai-decoder-interview) |The head of Google sat down with Decoder last week to talk about the biggest advancements in AI, the future of Google Search, and the fate of the web.|
|[Apple announces new accessibility features, including Eye Tracking, Music Haptics, and Vocal Shortcuts.](https://www.apple.com/newsroom/2024/05/apple-announces-new-accessibility-features-including-eye-tracking/) |  Apple today announced new accessibility features coming later this year, including Eye Tracking, a way for users with physical disabilities to control iPad or iPhone with their eyes. |
|[Microsoft announces $3.3 billion investment in Wisconsin to spur artificial intelligence innovation and economic growth.](https://news.microsoft.com/2024/05/08/microsoft-announces-3-3-billion-investment-in-wisconsin-to-spur-artificial-intelligence-innovation-and-economic-growth/) |Microsoft today announced a broad investment package designed to strengthen the role of Southeast Wisconsin as a hub for AI-powered economic activity, innovation, and job creation. These investments include $3.3B in cloud computing and AI infrastructure, the creation of the country‚Äôs first manufacturing-focused AI co-innovation lab, and an AI skilling initiative to equip more than 100,000 of the state‚Äôs residents with essential AI skills. |
|[ElevenLabs has launched a free iPhone app that speaks text on the screen ‚Äî 11 voices and PDF capabilities available.](https://itc.ua/en/news/elevenlabs-has-launched-a-free-iphone-app-that-speaks-text-on-the-screen-11-voices-and-pdf-capabilities-available/) | The unicorn startup ElevenLabs, best known for its AI dubbing site, has launched its first public app.|
|[The US Congress is taking on AI ‚Äî this computer scientist is helping.](https://www.nature.com/articles/d41586-024-01354-4) |Kiri Wagstaff, who temporarily shelved her academic career to provide advice on federal AI legislation, talks about life inside the halls of power. |
|[OpenAI Partners with News Corp.](https://openai.com/index/news-corp-and-openai-sign-landmark-multi-year-global-partnership/) |News Corp, which publishes articles from WSJ, NYP, The Times, and other publications, and OpenAI have partnered to provide News Corp's news material on OpenAI's platform, which they say would improve generations' accuracy and usability. |
|[Stanford HAI Releases Updated Foundation Model Transparency Index.](https://crfm.stanford.edu/2024/05/21/fmti-may-2024.html) |The most recent version of Stanford HAI's Foundation Model Transparency Index, which assesses the transparency of 14 significant AI developers, including Google and OpenAI, was released. These businesses showed a considerable improvement and readiness to engage in a dialogue about their models by disclosing fresh information that was not previously known to the public. The average transparency score was just 58 out of 100, indicating serious deficiencies in areas including downstream impact, data access, and model credibility despite these advancements. |
|[The ChatGPT desktop app is more helpful than I expected - here's why and how to try it.](https://www.zdnet.com/article/the-chatgpt-desktop-app-is-more-helpful-than-i-expected-heres-why-and-how-to-try-it/) |Among OpenAI's many big updates this week was a new ChatGPT app for MacOS. Here's how to use it and when Windows users can get in on the fun. |
|[Suno has raised $125 million to build a future where anyone can make music.](https://suno.com/blog/fundraising-announcement-may-2024) |A platform for creating music called Suno has raised $125 million to keep constructing a world in which anyone can compose music. |
|[Nvidia reports stratospheric growth as AI boom shows no sign of stopping.](https://www.theguardian.com/technology/article/2024/may/22/nvidia-quarterly-earnings) |Chipmaker reports strong demand and higher-than-expected revenue even as other companies spend to develop their own chips |
|[Mistral AI and Harvey Partnership.](https://www.harvey.ai/blog/mistral-announcement) | Mistral and Harvey, a legal company, have teamed. Although there aren't many specifics in the statement, it's likely that they will collaborate to create a unique legal paradigm.|
|[French AI startup H raises $220M seed round.](https://techcrunch.com/2024/05/21/french-ai-startup-h-raises-220-million-seed-round/) |H, a startup based in Paris and previously known as Holistic AI, has announced a $220 million seed round just a few months after the company‚Äôs inception. |
|[Reflections on our Responsible Scaling Policy.](https://www.anthropic.com/news/reflections-on-our-responsible-scaling-policy) |With an emphasis on continuous improvement and cooperation with business and government, Anthropic's Responsible Scaling Policy attempts to prevent catastrophic AI safety failures by identifying high-risk capabilities, testing models often, and enforcing tight safety requirements. |
|[Introducing Aya.](https://cohere.com/research/aya) | A global initiative led by Cohere For AI involving over 3,000 independent researchers across 119 countries. Aya is a state-of-art model and dataset, pushing the boundaries of multilingual AI for 101 languages through open science.|
|[PaliGemma: An Open Multimodal Model by Google.](https://blog.roboflow.com/paligemma-multimodal-vision/) |PaliGemma is a vision language model (VLM) developed and released by Google that has multimodal capabilities. Unlike other VLMs, such as OpenAI‚Äôs GPT-4o, Google Gemini, and Anthropic‚Äôs Claude 3 which have struggled with object detection and segmentation, PaliGemma has a wide range of abilities, paired with the ability to fine-tune for better performance on specific tasks. |
|[Casper Labs Announces AI Governance Solution, Prove AI .](https://casperlabs.io/) |In an effort to improve enterprise AI applications' auditability and transparency, Casper Labs has launched Prove AI, a joint venture with IBM. |
|[Google AI search tool reportedly tells users to jump off a bridge and eat rocks.](https://www.theguardian.com/technology/article/2024/may/24/google-ai-overviews-search-tool-reportedly-tells-users-to-jump-off-bridge-eat-rocks) |Firm‚Äôs AI overviews feature has been rolled out to users in US, but many have reported strange responses |

## Resources
|Link|description|
|---|---|
|[model-explorer.](https://github.com/google-ai-edge/model-explorer/wiki/4.-API-Guide) | A new model explorer from Google makes it simple to see the computation graph of your models. Performance engineering and debugging may find use for it.|
|[real-time inference demo for paligemma.](https://github.com/sumo43/loopvlm) |You may run the latest recent Google VLM in real time by using GPT-Fast. Given how simple it is to fine-tune the model for particular jobs, this opens up a multitude of powerful downstream activities. |
|[Multi AI Agent Systems using OpenAI's Assistants API (Experts.js).](https://github.com/metaskills/experts) | Experts.js is the easiest way to create and deploy OpenAI's Assistants and link them together as Tools to create a Panel of Experts system with expanded memory and attention to detail.|
|[First-ever AI Code Interpreter for R.](https://caesarhq.notion.site/First-ever-AI-Code-Interpreter-for-R-7a596fe5ee8449469fe8f60ec2d3fa21) |Julius is the leading generative AI tool for data analysis. Designed to perform statistical analysis, data science, and computational tasks, it combines cutting-edge foundational models like GPT-4o, Claude 3, and Gemini 1.5 with robust coding capabilities in Python and R. |
|[Moondream WebGPU.](https://huggingface.co/spaces/Xenova/experimental-moondream-webgpu) | 1.86 billion parameter VLM (Vision-Language Model) that is optimized for inference on the web. Once downloaded, the model (1.8 GB) will be cached and reused when you revisit the page. Everything runs directly in your browser using ü§ó Transformers.js and ONNX Runtime Web, meaning your conversations aren't sent to a server. You can even disconnect from the internet after the model has loaded!|
|[Devon: An open-source pair programmer.](https://github.com/entropy-research/Devon) |You can select different models for Multi-file editing, Codebase exploration, Config writing, Test writing, Bug fixing, and Architecture exploration |
|[llama3 implemented from scratch.](https://github.com/naklecha/llama3-from-scratch) | in this file, i implemented llama3 from scratch, one tensor and matrix multiplication at a time. also, im going to load tensors directly from the model file that meta provided for llama3|
|[PSG4D - 4D Panoptic Scene Graph Generation.](https://github.com/jingkang50/psg4d) | The PSG4D (4D Panoptic Scene Graph Generation) Task is a novel task that aims to bridge the gap between raw visual inputs in a dynamic 4D world and high-level visual understanding. It involves generating a comprehensive 4D scene graph from RGB-D video sequences or point cloud video sequences.|
|[microsoft/Phi-3-medium-128k-instruct.](https://huggingface.co/microsoft/Phi-3-medium-128k-instruct) | The Phi-3-Medium-128K-Instruct is a 14B parameters, lightweight, state-of-the-art open model trained with the Phi-3 datasets that includes both synthetic data and the filtered publicly available websites data with a focus on high-quality and reasoning dense properties.|
|[Debiasing Large Visual Language Models .](https://github.com/yfzhang114/llava-align) | Post-Hoc debias method and Visual Debias Decoding strategy. These strategies not only prove beneficial in minimizing hallucinations but also contribute to the generation of more helpful and precise illustrations |
|[ DeepSeek-VL.](https://github.com/deepseek-ai/deepseek-vl) |an open-source Vision-Language (VL) Model designed for real-world vision and language understanding applications. DeepSeek-VL possesses general multimodal understanding capabilities, capable of processing logical diagrams, web pages, formula recognition, scientific literature, natural images, and embodied intelligence in complex scenarios. |
|[MiniCPM-V.](https://github.com/OpenBMB/MiniCPM-V) | MiniCPM-V is a series of end-side multimodal LLMs (MLLMs) designed for vision-language understanding. Models take image and text as inputs and provide high-quality text outputs. Since February 2024, we have released 4 versions of the model, aiming to achieve strong performance and efficient deployment|
|[OLAPH: Improving Factuality in Biomedical Long-form Question Answering.](https://github.com/dmis-lab/olaph) | A new benchmark dataset called MedLFQA was created with the goal of enhancing the factual accuracy of long-form replies from big language models in the medical domain. OLAPH is a framework that uses preference optimization and automatic evaluations to teach LLMs to reduce errors.|
|[Tarsier.](https://github.com/reworkd/tarsier) | Tarsier, a new tool from Reworkd, visually tags webpage items with brackets and IDs to improve LLMs for online interface jobs. Through OCR-generated text representations, Tarsier enables an LLM without vision to comprehend the structure of a webpage, beating vision-language models in benchmarks.|
|[mistralai/Mistral-7B-Instruct-v0.3.](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3) | The Mistral-7B-Instruct-v0.3 Large Language Model (LLM) is an instruct fine-tuned version of the Mistral-7B-v0.3.|
|[Distributed inference on Llama cpp.](https://github.com/ggerganov/llama.cpp/tree/master/examples/rpc) |Distributed inference across several machines is now supported by Llama Cpp. Although it is now restricted to FP16, this is a significant step toward the deployment of open source. |
|[Enhancing Long-Term Memory for Language Models.](https://github.com/zoeyyao27/sirllm) |A novel method called Streaming Infinite Retentive LLM (SirLLM) aids large language models in retaining lengthier memory over the course of lengthy conversations. |
|[Glyph-ByT5: A Customized Text Encoder for Accurate Visual Text Rendering.](https://glyph-byt5.github.io/) | Visual text rendering poses a fundamental challenge for contemporary text-to-image generation models, with the core problem lying in text encoder deficiencies. To achieve accurate text rendering, we identify two crucial requirements for text encoders: character awareness and alignment with glyphs.|

## Perspectives
|Link|description|
|---|---|
|[The people charged with making sure AI doesn‚Äôt destroy humanity have left the building.](https://www.theguardian.com/technology/article/2024/may/21/techscape-openai-sam-altman-superalignment-scarlett-johansson) |If OpenAI can‚Äôt keep its own team together, what hope is there for the rest of the industry? Plus, AI-generated ‚Äòslop‚Äô is taking over the internet |
|[Spam, junk ‚Ä¶ slop? The latest wave of AI behind the ‚Äòzombie internet‚Äô.](https://www.theguardian.com/technology/article/2024/may/19/spam-junk-slop-the-latest-wave-of-ai-behind-the-zombie-internet) |Tech experts hope new term for carelessly automated AI webpages and images can illuminate its damaging impact |
|[As the AI world gathers in Seoul, can an accelerating industry balance progress against safety?](https://www.theguardian.com/technology/article/2024/may/18/ai-seoul-global-summit-safety-openai-meta) | Companies such as OpenAI and Meta push ahead, but it is clear that biggest changes are yet to come|
|[What happened to OpenAI‚Äôs long-term AI risk team?](https://arstechnica.com/ai/2024/05/what-happened-to-openais-long-term-ai-risk-team/) |Former team members have either resigned or been absorbed into other research groups. |
|[What‚Äôs up with Llama 3? Arena data analysis.](https://lmsys.org/blog/2024-05-08-llama3/) |When it comes to open-ended creative activities, Meta's Llama 3-70B language model outperforms competitors in the English Chatbot Arena, but it struggles with more technical suggestions. The results of the analysis show that Llama 3's victory rate drops as the instructions get harder, and that it excels at friendly, conversational responses. Even if Llama 3's approachability might have helped it succeed, more research is needed to determine its true competitive advantage. |
|[ChatGPT can talk, but OpenAI employees sure can‚Äôt.](https://www.vox.com/future-perfect/2024/5/17/24158478/openai-departures-sam-altman-employees-chatgpt-release) | The stringent non-compete agreement (NDA) of OpenAI, which forbids former workers from criticizing the company for fear of forfeiting their invested ownership, has come to light with the exits of Ilya Sutskever and Jan Leike. In response to the article, CEO Sam Altman said there would be a correction.|
|[AlphaFold3 ‚Äî why did Nature publish it without its code?](https://www.nature.com/articles/d41586-024-01463-0) | The latest iteration of the protein-structure-prediction algorithm AlphaFold has generated a great deal of interest since its release, accompanied by a paper in Nature, earlier this month. But its release has also prompted questions, and criticism, of both the AlphaFold team at Google DeepMind in London and Nature.|
|[China‚Äôs ChatGPT: what a boom in Chinese chatbots means for AI.](https://www.nature.com/articles/d41586-024-01495-6) | ChatGLM is one of hundreds of AI language models being developed for the Chinese language. It comes close to ChatGPT on many measures, say its creators.|
|[The Old-Fashioned Library at the Heart of the A.I. Boom.](https://www.nytimes.com/2024/05/15/technology/openai-library-office.html) |OpenAI's remodeled mayonnaise factory headquarters, with its library-themed interior design, is a symbol of the company's success with ChatGPT, which focuses on language. On the other hand, the office reminds people of the current legal disputes around the use of copyrighted content in AI training. The library is seen as a place for inspiration by OpenAI employees, despite these disagreements, which supports their conviction that AI-driven and human creativity can work together harmoniously. |
|[Chaos and tension at OpenAI.](https://garymarcus.substack.com/p/chaos-and-tension-at-openai) |Concerns over OpenAI's dedication to AI safety have led to Ilya Sutskever's departure, which could be concerning given that three other important employees have also quit recently. Concerns are raised regarding how the company's marketing efforts may affect its nonprofit status and safety-focused purpose given these departures. These incidents might also have an impact on the legal and regulatory systems, drawing attention from Washington stakeholders. |
|[AI is the reason interviews are harder now.](https://www.softwaredesign.ing/blog/ai-is-the-reason-interviews-are-harder-now) | This essay addresses how technical interview questions are becoming more complicated and how employers are expecting candidates to answer harder challenges faster. It emphasizes how non-technical users can benefit from using AI technologies like Ultracode to help them pass these kinds of interviews. The article recommends in-person interviews as a way to make sure applicants genuinely have the programming abilities required for the position.|
|[What I've Learned Building Interactive Embedding Visualizations.](https://cprimozic.net/blog/building-embedding-visualizations-from-user-profiles/) | An enthusiast for interactive embedding visualizations describes their well-honed process for producing these kinds of visuals, which illustrate the complex relationships between items depicted as points in three-dimensional areas. Data gathering, co-occurrence matrix construction, sparsification, PyMDE embedding, and 2D projection are the steps in the process that provide a clear visual representation. The author advocates for the accessibility and GPU-accelerated rendering capabilities of web apps by using them for the user interface.|

















