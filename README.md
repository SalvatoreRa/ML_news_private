# ML_news_private

this is just a placeholder, the organized and correct repository is [here](https://github.com/SalvatoreRa/ML-news-of-the-week)

# scheme

# ML news: 

## Research
|Link|description|
|---|---|
|[.]() | |
|[.]() | |
|[.]() | |

## News
|Link|description|
|---|---|
|[.]() | |
|[.]() | |
|[.]() | |


## Resources
|Link|description|
|---|---|
|[.]() | |
|[.]() | |
|[.]() | |

## Perspectives
|Link|description|
|---|---|
|[.]() | |
|[.]() | |
|[.]() | |

# ON WORKING

# ML news: 

## Research
|Link|description|
|---|---|
|[Golden Gate Claude.](https://www.anthropic.com/news/golden-gate-claude) | we released a major new research paper on interpreting large language models, in which we began to map out the inner workings of our AI model, Claude 3 Sonnet. In the “mind” of Claude, we found millions of concepts that activate when the model reads relevant text or sees relevant images, which we call “features”.|
|[A Better Match for Drivers and Riders: Reinforcement Learning at Lyft.](https://arxiv.org/abs/2310.13810) |The Lyft team matched drivers and riders using online reinforcement learning, which is rewarded by future profits for the drivers. They made an extra $30 million a year for riders and were able to significantly improve in real time. |
|[Lessons from the Trenches on Reproducible Evaluation of Language Models.](https://arxiv.org/abs/2405.14782) | Language model evaluation is a challenging task, and information on the process is scarce outside of the biggest companies. This work presents a robust and repeatable set of assessment criteria. In the appendix, there is a useful discussion of perplexity evaluation.|
|[RectifID: Personalizing Rectified Flow with Anchored Classifier Guidance.](https://arxiv.org/abs/2405.14677v1) | A novel method for tailoring diffusion models to produce identity-preserving images from user-supplied references is presented by researchers. This strategy steers diffusion models without further training by using classifier guidance, in contrast to classic methods that need considerable domain-specific training.|
|[LoRA-Ensemble: Efficient Uncertainty Modelling for Self-attention Networks.](https://github.com/prs-eth/lora-ensemble?utm_source=tldrai) | A parameter-efficient deep ensemble technique for self-attention networks is called LoRA-Ensemble. This method provides accurate and well-calibrated predictions without the significant computational cost associated with typical ensemble methods. It does this by extending Low-Rank Adaptation (LoRA) for implicit ensembling.|
|[Agent Planning with World Knowledge Model.](https://arxiv.org/abs/2405.14205) |demonstrates superior performance compared to various strong baselines when adopting open-source LLMs such as Mistral-7B and Gemma-7B. Introduces a parametric world knowledge model to facilitate agent planning. The agent model can self-synthesize knowledge from expert and sampled trajectories; this is used to train the world knowledge model. Prior task knowledge is used to guide global planning and dynamic state knowledge is used to guide local planning. |
|[Enhancing Answer Selection in LLMs.](https://arxiv.org/abs/2405.12939) |suggests a hierarchical reasoning aggregation framework to enhance LLMs' reasoning capabilities; the method, known as Aggregation of Reasoning (AoR), chooses answers based on the assessment of reasoning chains; AoR employs dynamic sampling to modify the number of reasoning chains in relation to task complexity; it makes use of evaluation phase results to decide whether to sample more reasoning chains; One well-known problem with majority voting is that it doesn't work when the right option is in the minority; AoR concentrates on assessing the reasoning chains to enhance the choice of the concluding response; AoR can be employed with different LLMs to enhance performance on difficult reasoning problems, and it outperforms several well-known ensemble approaches.  |
|[Efficient Inference of LLMs.](https://arxiv.org/abs/2405.10637) | suggests a layer-condensed KV cache to achieve effective inference in LLMs; can achieve up to 26x higher throughput than baseline transformers while maintaining satisfactory performance; only computes and caches the key-values (KVs) of a small number of layers, which leads to reduced memory consumption and improved inference throughput.|
|[Mapping the Mind of a Large Language Model.](https://www.anthropic.com/research/mapping-mind-language-model) |By mapping millions of features that correlate to a wide range of concepts, anthropologists have shown a way to comprehend the inner workings of its huge language model, Claude Sonnet. This interpretability, which permits certain manipulations of these attributes to direct model behaviors, may result in safer AI. The research indicates a noteworthy advancement in comprehending and enhancing the security protocols of artificial intelligence language models. |
|[Object Segmentation in Complex Scenarios.](https://arxiv.org/pdf/2405.15658) | To enhance Generalized Referring Expression Segmentation (GRES), researchers have developed the Hierarchical Semantic Decoding with Counting Assistance (HDC) framework. As opposed to earlier techniques, HDC combines semantic correspondences and transmits complementing modality information across granularities for improved multi-level decoding.|
|[Label-efficient Semantic Scene Completion with Scribble Annotations.](https://arxiv.org/abs/2405.15170v1) |A novel semantic scene completion method called Scribble2Scene lessens the requirement for thorough labeling. |
|[Semantic and Spatial Adaptive Pixel-level Classifier for Semantic Segmentation.](https://arxiv.org/abs/2405.06525v1) | The constraints of semantic segmentation have been addressed with the introduction of a new Semantic and Spatial Adaptive (SSA) classifier. This novel method makes use of coarse masks to direct prototype adjustment, improving fine-grained recognition and delineating mask boundaries.|
|[RSBuilding: Towards General Remote Sensing Image Building Extraction and Change Detection with Foundation Model.](https://github.com/meize0729/rsbuilding) |By integrating building extraction and change detection into a single model, RSBuilding presents a novel method for deciphering buildings from remote sensing photos. |
|[Meteor: Mamba-based traversal of rationale for Large Language and Vision Models.](https://github.com/byungkwanlee/meteor) | This research presents Meteor, a novel massive language and vision model that is efficient and employs several justifications to enhance comprehension and response times.|
|[gzip Predicts Data-dependent Scaling Laws.](https://arxiv.org/abs/2405.16684) |Scaling rules are a means of forecasting the performance of models at specific sizes with a given quantity of data. Getting them is costly. In order to forecast a data-dependent scaling law, this research investigates the use of the gzip compression ratio as a powerful signal. |
|[The Road Less Scheduled.](https://arxiv.org/abs/2405.15682) |A few weeks prior, a brand-new Meta optimizer was circulating as a possible replacement for Adam. The method, including the part about online updates, is described in more depth in this paper. Overall, this appears like a good outcome, particularly in cases when the complete number of planned training steps is not known at the start of the training process. |
|[Transformers Can Do Arithmetic with the Right Embeddings.](https://arxiv.org/abs/2405.17399v1) |Researchers have added embeddings that encode the position of each digit with respect to the start of the number, which has improved transformer performance on arithmetic tasks. |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |

## News
|Link|description|
|---|---|
|[Meta and Elon Musk’s xAI fight to partner with chatbot group Character.ai .](https://www.ft.com/content/5cf24fdd-30ed-44ec-afe3-aefa6f4ad90e) |AI pioneer Noam Shazeer launched Character.ai, a rapidly expanding role-playing startup, and Silicon Valley companies are vying for a partnership. This occurs at a time when numerous big businesses are investing heavily in startups. |
|[Scarlett Johansson told OpenAI not to use her voice — and she’s not happy they might have anyway.](https://www.theverge.com/2024/5/20/24161253/scarlett-johansson-openai-altman-legal-action) | penAI has denied that its ChatGPT voice is based on Johansson, but it certainly sounds a lot like her.|
|[xAI Series B funding round.](https://x.ai/blog/series-b) |xAI is pleased to announce our series B funding round of $6 billion.|
|[iPhone to get a better Siri, AI emoji creator, smart recaps, and more with iOS 18.](https://timesofindia.indiatimes.com/technology/tech-news/iphone-to-get-a-better-siri-ai-emoji-creator-smart-recaps-and-more-with-ios-18/articleshow/110452936.cms) |in June 2024,  the Cupertino giant will finally unveil its approach to AI |
|[New startup builds digital pets for Apple's Vision Pro.](https://www.axios.com/2024/05/23/apple-vision-pro-digital-dog-bootloader-ai) |A new startup is coming out of stealth with a plan to offer digital pets for the Apple Vision Pro that use AI to read and respond to human emotion. |
|[Humane is looking for a buyer after the AI Pin’s underwhelming debut.](https://www.theverge.com/2024/5/21/24162185/humane-seeking-acquisition-rumor-ai-pin) |he startup apparently thinks it’s worth between $750 million and $1 billion despite the deep software flaws and hardware issues of its first product. |
|[OpenAI Board Forms Safety and Security Committee.](https://openai.com/index/openai-board-forms-safety-and-security-committee/) | OpenAI declared that its new foundation model will be trained, and it established a Safety and Security Committee. As model capabilities advance, this committee will be responsible with recommending to the board what steps should be taken.|
|[Anthropic hires former OpenAI safety lead to head up new team.](https://techcrunch.com/2024/05/28/anthropic-hires-former-openai-safety-lead-to-head-up-new-team/) |Jan Leike, a leading AI researcher who earlier this month resigned from OpenAI before publicly criticizing the company’s approach to AI safety, has joined OpenAI rival Anthropic to lead a new “superalignment” team. |
|[New agent capabilities in Microsoft Copilot.](https://www.microsoft.com/en-us/microsoft-365/blog/2024/05/21/new-agent-capabilities-in-microsoft-copilot-unlock-business-value/) |At Build 2024, Microsoft introduced new Copilot capabilities, like as Copilot Extensions and Connectors for simple customization, Team Copilot for team communication, and bespoke AI Agents to automate operations. The goal of these improvements is to increase efficiency in company processes and productivity. The improvements are anticipated to be widely available later in 2024; they are presently in limited private preview. |
|[“I lost trust”: Why the OpenAI team in charge of safeguarding humanity imploded.](https://www.vox.com/future-perfect/2024/5/17/24158403/openai-resignations-ai-safety-ilya-sutskever-jan-leike-artificial-intelligence) | Company insiders explain why safety-conscious employees are leaving.|
|[OpenAI sends internal memo releasing former employees from controversial exit agreements.](https://www.cnbc.com/2024/05/24/openai-sends-internal-memo-releasing-former-employees-from-non-disparagement-agreements-sam-altman.html) |OpenAI on Thursday backtracked on a controversial decision to, in effect, make former employees choose between signing a non-disparagement agreement that would never expire, or keeping their vested equity in the company. |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |


## Resources
|Link|description|
|---|---|
|[Mistral-finetune.](https://github.com/mistralai/mistral-finetune) |mistral-finetune is a light-weight codebase that enables memory-efficient and performant finetuning of Mistral's models. It is based on LoRA, a training paradigm where most weights are frozen and only 1-2% additional weights in the form of low-rank matrix perturbations are trained. |
|[Modula.](https://github.com/jxbz/modula) |A novel technique called modular norm allows neural networks to scale training effectively over a range of network sizes by normalizing weight updates. |
|[MobileNet-V4.](https://huggingface.co/blog/rwightman/mobilenetv4) | Extremely fast and performant computer vision model is called MobileNet. Devices on the edge can run it. This blog article describes the new model and some contemporary modifications that were made to it.|
|[Multi-Dimensional Features.](https://github.com/joshengels/multidimensionalfeatures) |This project challenges the linear representation hypothesis by examining if language models compute using multi-dimensional characteristics. |
|[llamafile 0.8.6 CPU benchmark.](https://github.com/Mozilla-Ocho/llamafile/discussions/450) | It is now possible to run inference for the flagship model from Mistral at 20 tokens per second on a commodity CPU, thanks to recent developments from Mozilla's Llamafile project.|
|[Risks and Opportunities of Open-Source Generative AI.](https://arxiv.org/abs/2405.08597) | examines the potential and hazards associated with open-source generative AI models and makes the case that these models' overall advantages exceed their drawbacks.|
|[How Far Are We From AGI.](https://arxiv.org/abs/2405.10313v1) | offers a summary of the tactics required to attain artificial general intelligence (AGI), including a thorough survey, discussion, and unique viewpoints. It also addresses significant questions regarding the near future of AGI.|
|[Efficient Multimodal LLMs.](https://arxiv.org/abs/2405.10739v1) | offers a thorough and methodical analysis of the state of efficient multimodal big language models at the moment; it covers applications, constraints, possible future directions, and efficient structures and techniques.|
|[Scientific Applications of LLMs.](https://arxiv.org/abs/2405.10725) |introduces INDUS, a full suite of LLMs that comprises small distilled models, an encoder model, and embedding models for Earth science, biology, physics, and planetary sciences, among other subjects. |
|[Guide for Evaluating LLMs.](https://arxiv.org/abs/2405.14782) | offers advice and lessons for assessing large language models (LLMs); it also covers best practices and potential problems, and it introduces an open-source framework for LLM evaluation.|
|[Information Retrieval Measures.](https://ir-measur.es/en/latest/) |It is necessary to understand how effectively the retrieval part is operating in order to build a RAG system. This toolbox provides an extensive range of effective performance metrics for information retrieval. |
|[A Guide to Creating Neural Circuit Diagrams.](https://github.com/vtabbott/Neural-Circuit-Diagrams/blob/main/Guide/Guide.ipynb) |This is a guide to drawing Neural Circuit Diagrams by Vincent Abbott from the paper Neural Circuit Diagrams: Robust Diagrams for the Communication, Implementation, and Analysis of Deep Learning Architectures. It allows for deep learning algorithms to be comprehensively expressed using a novel diagrammatic scheme. |
|[InstructAvatar: Text-Guided Emotion and Motion Control for Avatar Generation.](https://wangyuchi369.github.io/InstructAvatar/) | A novel model called InstructAvatar uses text direction to generate 2D avatars that are emotionally expressive.|
|[Marigold Pipelines for Computer Vision Tasks.](https://huggingface.co/docs/diffusers/main/en/using-diffusers/marigold_usage) |Diffusers can now use one of the best depth models as a pipeline. This tutorial goes over how to utilize the model, what you can do with it, and how to condition on the latents of the first frame to make it work with videos effortlessly. |
|[Reproducing GPT-2 (124M) in llm.c in 90 minutes for $20.](https://github.com/karpathy/llm.c/discussions/481) |A version of LLM C, a solitary self-contained GPT-2 implementation designed to replicate the 2019 model suite, has been made available by Andrej Karpathy. The library can train the simplest of these models in about 90 minutes with this latest release. It has few dependencies and executes from start to finish. |
|[Content-Style Decoupling for Unsupervised Makeup Transfer without Generating Pseudo Ground Truth.](https://github.com/snowfallingplum/csd-mt) |A innovative technique for improving makeup transfer tasks without depending on genuine target images is Content-Style Decoupled Makeup Transfer (CSD-MT). |
|[LaVague.](https://github.com/lavague-ai/LaVague) |LaVague is an open-source Large Action Model framework to develop AI Web Agents. Our web agents take an objective, such as "Print installation steps for Hugging Face's Diffusers library" and performs the required actions to achieve this goal by leveraging our two core components. |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |

## Perspectives
|Link|description|
|---|---|
|[AI's Communication Revolution: We're All Talking to Computers Now.](https://www.digitalnative.tech/p/ais-communication-revolution-were) | The most recent AI model from OpenAI, GPT-4o, allows for real-time communication between people and machines by adding vision and audio to its text-based capabilities. The AI revolution brings with it a new wave of interactions between humans and AI, and eventually AI itself. These interactions will probably have an impact on our social habits and business structures. The impact of this technology on human communication will develop as it advances, possibly spurring the development of creative businesses and software.|
|[I Don’t Want To Spend My One Wild And Precious Life Dealing With Google’s AI Search.](https://aftermath.site/google-ai-search-god-no-why) |The unwelcome three-second delay that Google's AI search tool adds to search results is driving users crazy by interfering with their experience and displaying irrelevant content. |
|[LLMs are not suitable for (advanced) brainstorming.](https://piaoyang0.wordpress.com/2024/05/15/llms-are-not-suitable-for-brainstorming/) |When it comes to truly creative brainstorming, large language models frequently end up producing consensus-based ideas rather than original notions. |
|[Could AI help cure ‘downward spiral’ of human loneliness?.](https://www.theguardian.com/technology/article/2024/may/27/could-ai-help-cure-downward-spiral-of-human-loneliness) |One computer scientist says we should embrace human-machine relationships, but other experts are more cautious |
|[Scarlett Johansson’s OpenAI clash is just the start of legal wrangles over artificial intelligence.](https://www.theguardian.com/technology/article/2024/may/27/scarlett-johansson-openai-legal-artificial-intelligence-chatgpt) |Hollywood star’s claim ChatGPT update used an imitation of her voice highlights tensions over rapidly accelerating technology |
|[TechScape: What we learned from the global AI summit in South Korea.](https://www.theguardian.com/technology/article/2024/may/28/techscape-ai-global-summit) |One day and six (very long) agreements later, can we call the meeting to hammer out the future of AI regulation a success? |
|[Scarlett Johansson’s OpenAI clash is just the start of legal wrangles over artificial intelligence.](https://www.theguardian.com/technology/article/2024/may/27/scarlett-johansson-openai-legal-artificial-intelligence-chatgpt) |Hollywood star’s claim ChatGPT update used an imitation of her voice highlights tensions over rapidly accelerating technology |
|[Trying to tame AI: Seoul summit flags hurdles to regulation.](https://www.theguardian.com/technology/article/2024/may/27/trying-to-tame-ai-seoul-summit-flags-hurdles-to-regulation) |UK touts ‘Bletchley effect’ of safety institutes, but division remains over whether to limit AI abilities |
|[How to Build a Category-Defining AI Startup.](https://playbooks.hypergrowthpartners.com/p/how-to-build-a-category-defining) | AI companies need to adopt a marketing-led strategy in order to stand out from the competition and establish themselves as category leaders as the AI field changes quickly. AI startups may accelerate market acceptance, reshape the industry narrative, and position themselves as visionary leaders in their field by adopting a marketing-led strategy.|
|[Ways to think about AGI.](https://www.ben-evans.com/benedictevans/2024/5/4/ways-to-think-about-agi) | The consensus is unclear because there isn't a well-developed theoretical model of general intelligence or a clear explanation for why or how LLMs work so well, despite the fact that some experts think AGI may be achievable. The conversation highlights the enormous amount of unanswered questions surrounding AGI, recognizing both its possible advantages and disadvantages while drawing comparisons between theology and the empirical methodology of the Apollo Program.|
|[The AI revolution is coming to robots: how will it change them?.](https://www.nature.com/articles/d41586-024-01442-5) |The melding of artificial intelligence and robotics could catapult both to new heights. |
|[What GPT-4o illustrates about AI Regulation.](https://www.hyperdimensional.co/p/what-gpt-4o-illustrates-about-ai) |This article compares and contrasts model-level, use-level, and conduct-level frameworks in order to analyze several approaches to AI regulation. It contends that use-level regulation, which can lead to unneeded complexity and unworkable constraints for the deployment of AI, is inferior to conduct-level regulation, which applies current laws to new technologies with minimal precision. One example of the drawbacks of a use-level approach is the limitations placed on AI's capacity to infer emotions by the recent EU AI Act. |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |

# ML news: 20-26 May

## Research
|Link|description|
|---|---|
|[LoRA Learns Less and Forgets Less.](https://arxiv.org/abs/2405.09673) | LoRA is a well-liked technique for enhancing models to add flair or expertise. The trade-off between forgetting and power while utilizing LoRAs is examined in this research. LoRAs are found to retain more of the initial "out of distribution" performance while learning less than full fine tuning.|
|[Chameleon: Mixed-Modal Early-Fusion Foundation Models.](https://arxiv.org/abs/2405.09818) | Like GPT-4o, Meta has unveiled Chameleon, a natively multi-modal model that works with both text and graphics at the same time. It performs better than a lot of other models. Since then, the Meta team's work on internal models has greatly advanced.|
|[Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context.](https://storage.googleapis.com/deepmind-media/gemini/gemini_v1_5_report.pdf) |The technical report for Google's most current model family has been updated. While there is a dearth of information regarding the models and data utilized, there is a wealth of information regarding the assessment and safety precautions implemented, providing an intriguing glimpse into large-scale alignment. |
|[Introducing the Frontier Safety Framework.](https://deepmind.google/discover/blog/introducing-the-frontier-safety-framework/) |Frontier Safety Framework was unveiled by Google DeepMind to mitigate the dangers associated with upcoming sophisticated AI models. This framework assesses models against critical capability levels (CCLs) for potentially dangerous AI capabilities and implements mitigation techniques when thresholds are crossed. |
|[ART3D: 3D Gaussian Splatting for Text-Guided Artistic Scenes Generation.](https://arxiv.org/abs/2405.10508) |AI can be creatively and entertainingly used to generate artistic 2D visuals. This work uses text-guided Gaussian Splatting to bring that capacity to 3D. |
|[Grounded 3D-LLM with Referent Tokens.](https://groundedscenellm.github.io/grounded_3d-llm.github.io) | It's difficult to figure out where items are in a 3D setting. You can identify semantic labels for things in 3D space by employing language-guided 3D understanding.|
|[LeMeViT: Efficient Vision Transformer with Learnable Meta Tokens for Remote Sensing Image Interpretation.](https://arxiv.org/abs/2405.09789v1) | LeMeViT is a novel method that uses learnable meta tokens to lower the computational costs associated with Vision Transformers. By effectively capturing important data, these tokens accelerate inference.|
|[Not All Prompts Are Secure: A Switchable Backdoor Attack Against Pre-trained Vision Transformers.](https://arxiv.org/abs/2405.10612v1) |A fresh security risk has been identified for the well-known AI model Vision Transformers by researchers. The attack, known as SWARM, is extremely sneaky and harmful to consumers since it discreetly activates backdoor behavior in a model using a "switch token". |
|[Mapping the Mind of a Large Language Model.](https://www.anthropic.com/research/mapping-mind-language-model) |Today we report a significant advance in understanding the inner workings of AI models. We have identified how millions of concepts are represented inside Claude Sonnet, one of our deployed large language models. This is the first ever detailed look inside a modern, production-grade large language model. This interpretability discovery could, in future, help us make AI models safer. |
|[Smart Expert System: Large Language Models as Text Classifiers.](https://arxiv.org/abs/2405.10523v1) |Text classification is a fundamental task in Natural Language Processing (NLP), and the advent of Large Language Models (LLMs) has revolutionized the field. This paper introduces the Smart Expert System, a novel approach that leverages LLMs as text classifiers.  |
|[CSTA: CNN-based Spatiotemporal Attention for Video Summarization.](https://github.com/thswodnjs3/) | In order to enhance video summarization, this project presents a novel CNN-based SpatioTemporal Attention (CSTA) technique. In contrast to conventional attention processes, CSTA uses a 2D CNN to efficiently extract the visual meaning of frames in order to comprehend relationships and important features in films.|
|[Microsoft introduces Phi-Silica, a 3.3B parameter model made for Copilot+ PC NPUs.](https://venturebeat.com/ai/microsoft-introduces-phi-silica-a-3-3b-parameter-model-made-for-copilot-pc-npus/) |Microsoft is making more investments in the development of small language models (SLMs). At its Build developer conference, the company announced the general availability of its Phi-3 models and previewed Phi-3-vision. However, on the heels of Microsoft’s Copilot+ PC news, it’s introducing an SLM built specifically for these device’s powerful Neural Processing Units (NPUs). |
|[Aurora: A Foundation Model of the Atmosphere.](https://www.microsoft.com/en-us/research/publication/aurora-a-foundation-model-of-the-atmosphere/) |By training a foundation model for atmospheric predictions, Microsoft has achieved a new state-of-the-art in global weather prediction tests lasting five and ten days. |
|[MathBench: Evaluating the Theory and Application Proficiency of LLMs with a Hierarchical Mathematics Benchmark.](https://arxiv.org/abs/2405.12209v1) | A new benchmark called MathBench aims to give a comprehensive evaluation of the mathematical capabilities of large language models.|
|[Wav-KAN: Wavelet Kolmogorov-Arnold Networks.](https://arxiv.org/abs/2405.12832v1) | Wav-KAN is a neural network framework that leverages wavelet functions to enhance performance and interpretability, according to research. Wav-KAN captures both high-frequency and low-frequency data components, which speeds up training and boosts robustness in contrast to standard models.|
|[https://cohere.com/research/aya.](https://arxiv.org/abs/2405.12710v1) |Global-Local Semantic Consistent Learning (GLSCL), a novel technique created by researchers, greatly lowers computational costs while improving text-video retrieval. |
|[ProtT3: Protein-to-Text Generation for Text-based Protein Understanding.](https://arxiv.org/abs/2405.12564v1) |ProtT3, a novel framework that combines conventional Language Models (LMs) with Protein Language Models (PLMs) to improve text-based protein understanding, is presented by researchers. Using a cross-modal projector known as Q-Former, ProtT3 combines a PLM for analyzing amino acid sequences with a language model to produce high-quality textual descriptions. |
|[Diffusion-RSCC: Diffusion Probabilistic Model for Change Captioning in Remote Sensing Images.](https://github.com/fay-y/diffusion-rscc) | In order to better explain how the environment changes over time, a new probabilistic diffusion model for Remote Sensing Image Change Captioning (RSICC) is presented in this study.|

## News
|Link|description|
|---|---|
|[First companies sign up to AI safety standards on eve of Seoul summit.](https://www.theguardian.com/technology/article/2024/may/21/first-companies-sign-up-ai-safety-standards-seoul-summit) | Rishi Sunak says 16 international firms have committed, but standards have been criticised for lacking teeth|
|[World is ill-prepared for breakthroughs in AI, say experts.](https://www.theguardian.com/technology/article/2024/may/20/world-is-ill-prepared-for-breakthroughs-in-ai-say-experts) | Governments have made insufficient regulatory progress, ‘godfathers’ of the technology say before summit|
|[Productivity soars in sectors of global economy most exposed to AI, says report.](https://www.theguardian.com/technology/article/2024/may/21/productivity-soars-in-sectors-of-global-economy-most-exposed-to-ai-says-report) | Employers in UK, one of 15 countries studied, willing to pay 14% wage premium for jobs requiring AI skills|
|[ChatGPT suspends Scarlett Johansson-like voice as actor speaks out against OpenAI.](https://www.theguardian.com/technology/article/2024/may/20/chatgpt-scarlett-johansson-voice) |OpenAI says ‘Sky’ is not an imitation of actor’s voice after users compare it to AI companion character in film Her |
|[$16k G1 humanoid rises up to smash nuts, twist and twirl.](https://newatlas.com/robotics/unitree-g1-humanoid-agent) |Humanoid development at Chinese robotics company Unitree continues apace. Following its entry into the melee just last year, its fast-walking H1 bot recently got its backflip groove on. Now the faceless and hand-less humanoid is being joined by an impressive all-rounder. |
|[Google I/O 2024: Here’s everything Google just announced.](https://techcrunch.com/2024/05/15/google-i-o-2024-everything-announced-so-far/) | Google kicked off its developer conference each year with a rapid-fire stream of announcements, including many unveilings of recent things it’s been working on. Brian already kicked us off by sharing what we are expecting. |
|[Gamma raised $12M in Series A funding to reimagine presentations, powered by AI.](https://gamma.app/docs/Weve-raised-12M-in-Series-A-funding-to-reimagine-presentations-po-1mmk923dzxyrn2t) |Gamma received $12 million from Accel to use AI to reinvent presentations. Over 18 million people have contributed over 60 million Gammas (AI-generated slides) to date. |
|[ Inflection AI reveals new team and plan to embed emotional AI in business bots.](https://venturebeat.com/ai/exclusive-inflection-ai-reveals-new-team-and-plan-to-embed-emotional-ai-in-business-bots) |Inflection AI unveiled its new leadership team, composed of seasoned Silicon Valley veterans. |
|[Scarlett Johansson says Altman insinuated that AI soundalike was intentional.](https://arstechnica.com/tech-policy/2024/05/openai-pauses-chatgpt-4o-voice-that-fans-said-ripped-off-scarlett-johansson/) | OpenAI has paused a voice mode option for ChatGPT-4o, Sky, after backlash accusing the AI company of intentionally ripping off Scarlett Johansson's critically acclaimed voice-acting performance in the 2013 sci-fi film Her.|
|[Perplexity CEO Aravind Srinivas takes shots at Google.](https://www.axios.com/2024/05/14/perplexity-ceo-aravind-srinivas-ai-google) | Google's planned roll-out of AI-summarized search results doesn't faze Perplexity AI CEO and co-founder Aravind Srinivas — whose startup has offered a popular AI-driven search tool providing similar digests for nearly two years.|
|[Google still hasn’t fixed Gemini’s biased image generator.](https://techcrunch.com/2024/05/15/google-still-hasnt-fixed-geminis-biased-image-generator/) | Back in February, Google paused its AI-powered chatbot Gemini’s ability to generate images of people after users complained of historical inaccuracies. Well, the problem’s likely more complex than Hassabis alluded to.|
|[SoundHound AI and Perplexity Partner to Bring Online LLMs to Next Gen Voice Assistants Across Cars and IoT Devices.](https://www.businesswire.com/news/home/20240509196718/en/SoundHound-AI-and-Perplexity-Partner-to-Bring-Online-LLMs-to-Next-Gen-Voice-Assistants-Across-Cars-and-IoT-Devices) | Perplexity’s capabilities added to SoundHound Chat AI will respond to questions conversationally with real-time knowledge from the web|
|[Stability AI discusses sale amid cash crunch, The Information reports.](https://finance.yahoo.com/news/stability-ai-discusses-sale-amid-235921573.htm) |Artificial Intelligence startup Stability AI held discussions with at least one potential buyer in recent weeks about a sale as it faces a cash crunch, The Information reported on Wednesday, citing a person involved in the talks. |
|[Scale AI raises $1B.](https://scale.com/blog/scale-ai-series-f) |Accel and earlier investors provide the gigantic series F. There is a huge need for the services offered, and Scale is in a unique position to keep driving the current AI data surge. |
|[Elon Musk’s xAI is working on making Grok multimodal.](https://www.theverge.com/2024/5/21/24161764/elon-musk-xai-grok-multimodal-ai) |Users may soon be able to input images into Grok for text-based answers. |
|[Google CEO Sundar Pichai on AI-powered search and the future of the web.](https://www.theverge.com/24158374/google-ceo-sundar-pichai-ai-search-gemini-future-of-the-internet-web-openai-decoder-interview) |The head of Google sat down with Decoder last week to talk about the biggest advancements in AI, the future of Google Search, and the fate of the web.|
|[Apple announces new accessibility features, including Eye Tracking, Music Haptics, and Vocal Shortcuts.](https://www.apple.com/newsroom/2024/05/apple-announces-new-accessibility-features-including-eye-tracking/) |  Apple today announced new accessibility features coming later this year, including Eye Tracking, a way for users with physical disabilities to control iPad or iPhone with their eyes. |
|[Microsoft announces $3.3 billion investment in Wisconsin to spur artificial intelligence innovation and economic growth.](https://news.microsoft.com/2024/05/08/microsoft-announces-3-3-billion-investment-in-wisconsin-to-spur-artificial-intelligence-innovation-and-economic-growth/) |Microsoft today announced a broad investment package designed to strengthen the role of Southeast Wisconsin as a hub for AI-powered economic activity, innovation, and job creation. These investments include $3.3B in cloud computing and AI infrastructure, the creation of the country’s first manufacturing-focused AI co-innovation lab, and an AI skilling initiative to equip more than 100,000 of the state’s residents with essential AI skills. |
|[ElevenLabs has launched a free iPhone app that speaks text on the screen — 11 voices and PDF capabilities available.](https://itc.ua/en/news/elevenlabs-has-launched-a-free-iphone-app-that-speaks-text-on-the-screen-11-voices-and-pdf-capabilities-available/) | The unicorn startup ElevenLabs, best known for its AI dubbing site, has launched its first public app.|
|[The US Congress is taking on AI — this computer scientist is helping.](https://www.nature.com/articles/d41586-024-01354-4) |Kiri Wagstaff, who temporarily shelved her academic career to provide advice on federal AI legislation, talks about life inside the halls of power. |
|[OpenAI Partners with News Corp.](https://openai.com/index/news-corp-and-openai-sign-landmark-multi-year-global-partnership/) |News Corp, which publishes articles from WSJ, NYP, The Times, and other publications, and OpenAI have partnered to provide News Corp's news material on OpenAI's platform, which they say would improve generations' accuracy and usability. |
|[Stanford HAI Releases Updated Foundation Model Transparency Index.](https://crfm.stanford.edu/2024/05/21/fmti-may-2024.html) |The most recent version of Stanford HAI's Foundation Model Transparency Index, which assesses the transparency of 14 significant AI developers, including Google and OpenAI, was released. These businesses showed a considerable improvement and readiness to engage in a dialogue about their models by disclosing fresh information that was not previously known to the public. The average transparency score was just 58 out of 100, indicating serious deficiencies in areas including downstream impact, data access, and model credibility despite these advancements. |
|[The ChatGPT desktop app is more helpful than I expected - here's why and how to try it.](https://www.zdnet.com/article/the-chatgpt-desktop-app-is-more-helpful-than-i-expected-heres-why-and-how-to-try-it/) |Among OpenAI's many big updates this week was a new ChatGPT app for MacOS. Here's how to use it and when Windows users can get in on the fun. |
|[Suno has raised $125 million to build a future where anyone can make music.](https://suno.com/blog/fundraising-announcement-may-2024) |A platform for creating music called Suno has raised $125 million to keep constructing a world in which anyone can compose music. |
|[Nvidia reports stratospheric growth as AI boom shows no sign of stopping.](https://www.theguardian.com/technology/article/2024/may/22/nvidia-quarterly-earnings) |Chipmaker reports strong demand and higher-than-expected revenue even as other companies spend to develop their own chips |
|[Mistral AI and Harvey Partnership.](https://www.harvey.ai/blog/mistral-announcement) | Mistral and Harvey, a legal company, have teamed. Although there aren't many specifics in the statement, it's likely that they will collaborate to create a unique legal paradigm.|
|[French AI startup H raises $220M seed round.](https://techcrunch.com/2024/05/21/french-ai-startup-h-raises-220-million-seed-round/) |H, a startup based in Paris and previously known as Holistic AI, has announced a $220 million seed round just a few months after the company’s inception. |
|[Reflections on our Responsible Scaling Policy.](https://www.anthropic.com/news/reflections-on-our-responsible-scaling-policy) |With an emphasis on continuous improvement and cooperation with business and government, Anthropic's Responsible Scaling Policy attempts to prevent catastrophic AI safety failures by identifying high-risk capabilities, testing models often, and enforcing tight safety requirements. |
|[Introducing Aya.](https://cohere.com/research/aya) | A global initiative led by Cohere For AI involving over 3,000 independent researchers across 119 countries. Aya is a state-of-art model and dataset, pushing the boundaries of multilingual AI for 101 languages through open science.|
|[PaliGemma: An Open Multimodal Model by Google.](https://blog.roboflow.com/paligemma-multimodal-vision/) |PaliGemma is a vision language model (VLM) developed and released by Google that has multimodal capabilities. Unlike other VLMs, such as OpenAI’s GPT-4o, Google Gemini, and Anthropic’s Claude 3 which have struggled with object detection and segmentation, PaliGemma has a wide range of abilities, paired with the ability to fine-tune for better performance on specific tasks. |
|[Casper Labs Announces AI Governance Solution, Prove AI .](https://casperlabs.io/) |In an effort to improve enterprise AI applications' auditability and transparency, Casper Labs has launched Prove AI, a joint venture with IBM. |
|[Google AI search tool reportedly tells users to jump off a bridge and eat rocks.](https://www.theguardian.com/technology/article/2024/may/24/google-ai-overviews-search-tool-reportedly-tells-users-to-jump-off-bridge-eat-rocks) |Firm’s AI overviews feature has been rolled out to users in US, but many have reported strange responses |

## Resources
|Link|description|
|---|---|
|[model-explorer.](https://github.com/google-ai-edge/model-explorer/wiki/4.-API-Guide) | A new model explorer from Google makes it simple to see the computation graph of your models. Performance engineering and debugging may find use for it.|
|[real-time inference demo for paligemma.](https://github.com/sumo43/loopvlm) |You may run the latest recent Google VLM in real time by using GPT-Fast. Given how simple it is to fine-tune the model for particular jobs, this opens up a multitude of powerful downstream activities. |
|[Multi AI Agent Systems using OpenAI's Assistants API (Experts.js).](https://github.com/metaskills/experts) | Experts.js is the easiest way to create and deploy OpenAI's Assistants and link them together as Tools to create a Panel of Experts system with expanded memory and attention to detail.|
|[First-ever AI Code Interpreter for R.](https://caesarhq.notion.site/First-ever-AI-Code-Interpreter-for-R-7a596fe5ee8449469fe8f60ec2d3fa21) |Julius is the leading generative AI tool for data analysis. Designed to perform statistical analysis, data science, and computational tasks, it combines cutting-edge foundational models like GPT-4o, Claude 3, and Gemini 1.5 with robust coding capabilities in Python and R. |
|[Moondream WebGPU.](https://huggingface.co/spaces/Xenova/experimental-moondream-webgpu) | 1.86 billion parameter VLM (Vision-Language Model) that is optimized for inference on the web. Once downloaded, the model (1.8 GB) will be cached and reused when you revisit the page. Everything runs directly in your browser using 🤗 Transformers.js and ONNX Runtime Web, meaning your conversations aren't sent to a server. You can even disconnect from the internet after the model has loaded!|
|[Devon: An open-source pair programmer.](https://github.com/entropy-research/Devon) |You can select different models for Multi-file editing, Codebase exploration, Config writing, Test writing, Bug fixing, and Architecture exploration |
|[llama3 implemented from scratch.](https://github.com/naklecha/llama3-from-scratch) | in this file, i implemented llama3 from scratch, one tensor and matrix multiplication at a time. also, im going to load tensors directly from the model file that meta provided for llama3|
|[PSG4D - 4D Panoptic Scene Graph Generation.](https://github.com/jingkang50/psg4d) | The PSG4D (4D Panoptic Scene Graph Generation) Task is a novel task that aims to bridge the gap between raw visual inputs in a dynamic 4D world and high-level visual understanding. It involves generating a comprehensive 4D scene graph from RGB-D video sequences or point cloud video sequences.|
|[microsoft/Phi-3-medium-128k-instruct.](https://huggingface.co/microsoft/Phi-3-medium-128k-instruct) | The Phi-3-Medium-128K-Instruct is a 14B parameters, lightweight, state-of-the-art open model trained with the Phi-3 datasets that includes both synthetic data and the filtered publicly available websites data with a focus on high-quality and reasoning dense properties.|
|[Debiasing Large Visual Language Models .](https://github.com/yfzhang114/llava-align) | Post-Hoc debias method and Visual Debias Decoding strategy. These strategies not only prove beneficial in minimizing hallucinations but also contribute to the generation of more helpful and precise illustrations |
|[ DeepSeek-VL.](https://github.com/deepseek-ai/deepseek-vl) |an open-source Vision-Language (VL) Model designed for real-world vision and language understanding applications. DeepSeek-VL possesses general multimodal understanding capabilities, capable of processing logical diagrams, web pages, formula recognition, scientific literature, natural images, and embodied intelligence in complex scenarios. |
|[MiniCPM-V.](https://github.com/OpenBMB/MiniCPM-V) | MiniCPM-V is a series of end-side multimodal LLMs (MLLMs) designed for vision-language understanding. Models take image and text as inputs and provide high-quality text outputs. Since February 2024, we have released 4 versions of the model, aiming to achieve strong performance and efficient deployment|
|[OLAPH: Improving Factuality in Biomedical Long-form Question Answering.](https://github.com/dmis-lab/olaph) | A new benchmark dataset called MedLFQA was created with the goal of enhancing the factual accuracy of long-form replies from big language models in the medical domain. OLAPH is a framework that uses preference optimization and automatic evaluations to teach LLMs to reduce errors.|
|[Tarsier.](https://github.com/reworkd/tarsier) | Tarsier, a new tool from Reworkd, visually tags webpage items with brackets and IDs to improve LLMs for online interface jobs. Through OCR-generated text representations, Tarsier enables an LLM without vision to comprehend the structure of a webpage, beating vision-language models in benchmarks.|
|[mistralai/Mistral-7B-Instruct-v0.3.](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3) | The Mistral-7B-Instruct-v0.3 Large Language Model (LLM) is an instruct fine-tuned version of the Mistral-7B-v0.3.|
|[Distributed inference on Llama cpp.](https://github.com/ggerganov/llama.cpp/tree/master/examples/rpc) |Distributed inference across several machines is now supported by Llama Cpp. Although it is now restricted to FP16, this is a significant step toward the deployment of open source. |
|[Enhancing Long-Term Memory for Language Models.](https://github.com/zoeyyao27/sirllm) |A novel method called Streaming Infinite Retentive LLM (SirLLM) aids large language models in retaining lengthier memory over the course of lengthy conversations. |
|[Glyph-ByT5: A Customized Text Encoder for Accurate Visual Text Rendering.](https://glyph-byt5.github.io/) | Visual text rendering poses a fundamental challenge for contemporary text-to-image generation models, with the core problem lying in text encoder deficiencies. To achieve accurate text rendering, we identify two crucial requirements for text encoders: character awareness and alignment with glyphs.|

## Perspectives
|Link|description|
|---|---|
|[The people charged with making sure AI doesn’t destroy humanity have left the building.](https://www.theguardian.com/technology/article/2024/may/21/techscape-openai-sam-altman-superalignment-scarlett-johansson) |If OpenAI can’t keep its own team together, what hope is there for the rest of the industry? Plus, AI-generated ‘slop’ is taking over the internet |
|[Spam, junk … slop? The latest wave of AI behind the ‘zombie internet’.](https://www.theguardian.com/technology/article/2024/may/19/spam-junk-slop-the-latest-wave-of-ai-behind-the-zombie-internet) |Tech experts hope new term for carelessly automated AI webpages and images can illuminate its damaging impact |
|[As the AI world gathers in Seoul, can an accelerating industry balance progress against safety?](https://www.theguardian.com/technology/article/2024/may/18/ai-seoul-global-summit-safety-openai-meta) | Companies such as OpenAI and Meta push ahead, but it is clear that biggest changes are yet to come|
|[What happened to OpenAI’s long-term AI risk team?](https://arstechnica.com/ai/2024/05/what-happened-to-openais-long-term-ai-risk-team/) |Former team members have either resigned or been absorbed into other research groups. |
|[What’s up with Llama 3? Arena data analysis.](https://lmsys.org/blog/2024-05-08-llama3/) |When it comes to open-ended creative activities, Meta's Llama 3-70B language model outperforms competitors in the English Chatbot Arena, but it struggles with more technical suggestions. The results of the analysis show that Llama 3's victory rate drops as the instructions get harder, and that it excels at friendly, conversational responses. Even if Llama 3's approachability might have helped it succeed, more research is needed to determine its true competitive advantage. |
|[ChatGPT can talk, but OpenAI employees sure can’t.](https://www.vox.com/future-perfect/2024/5/17/24158478/openai-departures-sam-altman-employees-chatgpt-release) | The stringent non-compete agreement (NDA) of OpenAI, which forbids former workers from criticizing the company for fear of forfeiting their invested ownership, has come to light with the exits of Ilya Sutskever and Jan Leike. In response to the article, CEO Sam Altman said there would be a correction.|
|[AlphaFold3 — why did Nature publish it without its code?](https://www.nature.com/articles/d41586-024-01463-0) | The latest iteration of the protein-structure-prediction algorithm AlphaFold has generated a great deal of interest since its release, accompanied by a paper in Nature, earlier this month. But its release has also prompted questions, and criticism, of both the AlphaFold team at Google DeepMind in London and Nature.|
|[China’s ChatGPT: what a boom in Chinese chatbots means for AI.](https://www.nature.com/articles/d41586-024-01495-6) | ChatGLM is one of hundreds of AI language models being developed for the Chinese language. It comes close to ChatGPT on many measures, say its creators.|
|[The Old-Fashioned Library at the Heart of the A.I. Boom.](https://www.nytimes.com/2024/05/15/technology/openai-library-office.html) |OpenAI's remodeled mayonnaise factory headquarters, with its library-themed interior design, is a symbol of the company's success with ChatGPT, which focuses on language. On the other hand, the office reminds people of the current legal disputes around the use of copyrighted content in AI training. The library is seen as a place for inspiration by OpenAI employees, despite these disagreements, which supports their conviction that AI-driven and human creativity can work together harmoniously. |
|[Chaos and tension at OpenAI.](https://garymarcus.substack.com/p/chaos-and-tension-at-openai) |Concerns over OpenAI's dedication to AI safety have led to Ilya Sutskever's departure, which could be concerning given that three other important employees have also quit recently. Concerns are raised regarding how the company's marketing efforts may affect its nonprofit status and safety-focused purpose given these departures. These incidents might also have an impact on the legal and regulatory systems, drawing attention from Washington stakeholders. |
|[AI is the reason interviews are harder now.](https://www.softwaredesign.ing/blog/ai-is-the-reason-interviews-are-harder-now) | This essay addresses how technical interview questions are becoming more complicated and how employers are expecting candidates to answer harder challenges faster. It emphasizes how non-technical users can benefit from using AI technologies like Ultracode to help them pass these kinds of interviews. The article recommends in-person interviews as a way to make sure applicants genuinely have the programming abilities required for the position.|
|[What I've Learned Building Interactive Embedding Visualizations.](https://cprimozic.net/blog/building-embedding-visualizations-from-user-profiles/) | An enthusiast for interactive embedding visualizations describes their well-honed process for producing these kinds of visuals, which illustrate the complex relationships between items depicted as points in three-dimensional areas. Data gathering, co-occurrence matrix construction, sparsification, PyMDE embedding, and 2D projection are the steps in the process that provide a clear visual representation. The author advocates for the accessibility and GPU-accelerated rendering capabilities of web apps by using them for the user interface.|


# ML news: Week 13 - 19 May

## Research
|Link|description|
|---|---|
|[Fishing for Magikarp: Automatically Detecting Under-trained Tokens in Large Language Models.](https://arxiv.org/abs/2405.05417) |Separately trained tokenizers are necessary for language models. Tokens that are never encountered during language model training may be produced by these. Even the most potent contemporary language models have a lot. This study investigates this phenomena and offers solutions for locating and handling these tokens. |
|[Unlearning in Recommender Systems.](https://github.com/justarter/e2urec) | With the use of a novel technique called E2URec, huge language model-based recommendation systems may now effectively and efficiently forget user data while maintaining privacy and speed.|
|[Transforming Text into Any Modality, Resolution, and Duration via Flow-based Large Diffusion Transformers.](https://github.com/Alpha-VLLM/Lumina-T2X) |A project called Lumina seeks to provide a single text-to-X generation mechanism. Its training process involves interleaving text, video, audio, and pictures, which enhances downstream performance. |
|[MatterSim: A Deep Learning Atomistic Model Across Elements, Temperatures and Pressures.](https://arxiv.org/abs/2405.04967) | In AI, simulators can be very effective tools for gathering training data or facilitating interactions between models. A wide range of elemental atomic interactions can be modeled with this simulator.|
|[SGTR+: End-to-end Scene Graph Generation with Transformer.](https://arxiv.org/abs/2401.12835v1) |A new, more effective technique for producing scene graphs has been discovered by researchers. Their transformer-based approach aims to enhance the model's comprehension and interconnection of many parts in a picture, resulting in enhanced performance on complex tasks. |
|[InternLM-XComposer2: Mastering Free-form Text-Image Composition and Comprehension in Vision-Language Large Model.](https://arxiv.org/abs/2401.16420v1) | A vision-language model called InternLM-XComposer2 is very good at producing and comprehending intricate text-image information. It surpasses current approaches in multimodal content production and interpretation by introducing a Partial LoRA technique for a balanced vision and text comprehension.|
|[MambaOut: Do We Really Need Mamba for Vision?](https://arxiv.org/abs/2405.07992v1) |While Mamba is not effective for image classification, it shows promise in detection and segmentation tasks that do. The Mamba architecture is often employed for tasks with long-sequence and autoregressive characteristics. Researchers looked into this design and its application in vision tasks. |
|[State-Free Inference of State-Space Models: The Transfer Function Approach.](https://arxiv.org/abs/2405.06147v1) |For deep learning, a new state-space model with a dual transfer function representation has been created. A state-free sequence parallel inference approach is one of its features. |
|[Learning A Spiking Neural Network for Efficient Image Deraining.](https://github.com/mingtian99/esdne) | A Spiking Neural Network (SNN) called ESDNet is intended for picture deraining applications. It increases spike signal strength by taking advantage of the special qualities of rain pixel values.|
|[Controllable and Interactive 3D Assets Generation with Proxy-Guided Conditioning.](https://zju3dv.github.io/coin3d/) | Making 3D models is difficult. A coarse mesh can be entered initially, and then the generation process can be carried out, giving users more precise control and higher-quality model output.|
|[Hunyuan-DiT: A Powerful Multi-Resolution Diffusion Transformer with Fine-Grained Chinese Understanding.](https://arxiv.org/abs/2405.08748v1) | Particularly for Chinese and English, the recently created Hunyuan-DiT establishes a standard for text-to-image diffusion transformers. It has sophisticated data pipeline and transformer structures for ongoing model enhancement.|
|[Self-Rectifying Diffusion Sampling with Perturbed-Attention Guidance.](https://ku-cvlab.github.io/Perturbed-Attention-Guidance/) | An method to improve the quality of images produced by diffusion models without extra training or external modules is called Perturbed-Attention Guidance (PAG). PAG leads to a significant improvement in the structure and fidelity of both unconditional and conditional samples by innovative manipulation of the self-attention mechanisms within the model.|
|[SqueezeTime.](https://github.com/xinghaochen/squeezetime) | SqueezeTime is a new lightweight network that enhances temporal analysis by condensing the time axis of movies into the channel dimension, specifically for mobile video understanding.|

## News
|Link|description|
|---|---|
|[OpenAI confirms May 13 event for ‘some ChatGPT and GPT-4 updates’.](https://9to5google.com/2024/05/10/openai-may-13-event-chatgpt/) |Following a report that the company plans to launch a Google Search competitor next week, OpenAI has just confirmed a May 13 event for new “ChatGPT and GPT-4” updates. |
|[Bye-bye bots: Altera’s game-playing AI agents get backing from Eric Schmidt.](https://techcrunch.com/2024/05/08/bye-bye-bots-alteras-game-playing-ai-agents-get-backing-from-eric-schmidt/) |Autonomous, AI-based players are coming to a gaming experience near you, and a new startup, Altera, is joining the fray to build this new guard of AI agents. |
|[BLIP3.](https://huggingface.co/Salesforce/xgen-mm-phi3-mini-instruct-r-v1) | Salesforce has trained and released the 3rd non-commercial version of the popular BLIP models, vision and language models mainly used for image understanding and captioning.|
|[Asterisk/Zvi on California's AI Bill.](https://www.astralcodexten.com/p/asteriskzvi-on-californias-ai-bill) |Regulations on AI models with processing capacity more than 10^26 FLOPs are proposed by the California SB1047 law. By demanding secure surroundings, quick deactivation capabilities, and thorough misuse possibility testing, it focuses on ensuring these models are used securely. The measure aims to address worries about the possible impact of AI on society by balancing innovation with safeguards against exploitation, and it only targets high-risk scenarios. |
|[Bedrock Studio is Amazon’s attempt to simplify generative AI app development.](https://techcrunch.com/2024/05/07/bedrock-studio-is-amazons-attempt-to-simplify-generative-ai-app-development/) | Amazon is launching a new tool, Bedrock Studio, designed to let organizations experiment with generative AI models, collaborate on those models, and ultimately build generative AI-powered apps.|
|[New GPT-4o AI model is faster and free for all users, OpenAI announces.](https://www.theguardian.com/technology/article/2024/may/13/openai-new-chatgpt-free) |Tech company reveals new flagship model that ‘is the future of interaction between ourselves and the machines’|
|[Introducing GPT-4o and more tools to ChatGPT free users.](https://openai.com/index/gpt-4o-and-more-tools-to-chatgpt-free/) |Today we are introducing our newest model, GPT-4o, and will be rolling out more intelligence and advanced tools to ChatGPT for free. |
|[Open sourcing IBM’s Granite code models.](https://research.ibm.com/blog/granite-code-models-open-source) | In order to make coding across several platforms easier and more efficient, IBM is making its Granite code models—which span a range of programming activities and have between 3 and 34 billion parameters—available to the open-source community.|
|[Bloomberg: Apple finalizing deal with OpenAI to bring ChatGPT features to iOS 18.](https://9to5mac.com/2024/05/10/ios-18-chatgpt-features-apple-openai/) | Apple is finalizing an agreement with OpenAI to bring some of its technology to the iPhone this year, according to a new report from Bloomberg. With this deal, the report explains that Apple will be able to offer “a popular chatbot” powered by ChatGPT as part of its AI-focused features in iOS 18.|
|[OpenAI says it can now identify images generated by OpenAI — mostly.](https://qz.com/openai-dall-e-3-image-detection-1851460817) |The company said its new tool correctly identified 98% of images generated by DALL-E 3 |
|[Microsoft is ‘turning everyone into a prompt engineer’ with new Copilot AI features.](https://www.theverge.com/2024/5/8/24151847/microsoft-copilot-rewrite-prompt-feature-microsoft-365) |Copilot for Microsoft 365 is getting auto-complete, rewrite, and more to improve AI prompts. |
|[Gemini breaks new ground with a faster model, longer context, AI agents and more.](https://blog.google/technology/ai/google-gemini-update-flash-ai-assistant-io-2024/) |At I/O 2024, Google unveiled a slew of new features, including Imagen 3, Veo video creation, Gemini Flash, and Project Astra, its newest assistant. Among the many noteworthy enhancements are the 2 million token context duration, significantly reduced model costs, and enhanced multimodality. |
|[Anthropic is expanding to Europe and raising more money.](https://techcrunch.com/2024/05/13/anthropic-is-expanding-to-europe-and-raising-more-money/) |Anthropic said Monday that Claude, its AI assistant, is now live in Europe with support for “multiple languages,” including French, German, Italian and Spanish across Claude.ai, its iOS app and its business plan for teams. |
|[Elon Musk's xAI nears $10 bln deal to rent Oracle's AI servers, The Information reports.](https://www.reuters.com/technology/elon-musks-xai-nears-10-bln-deal-rent-oracles-ai-servers-information-reports-2024-05-14/) |  - Elon Musk's artificial intelligence startup xAI has been talking to Oracle (ORCL.N), opens new tab executives about spending $10 billion to rent cloud servers from the company over a period of years, The Information reported on Tuesday, citing a person involved in the talks.|
|[OpenAI co-founder who had key role in attempted firing of Sam Altman departs.](https://www.theguardian.com/technology/article/2024/may/15/open-ai-cofounder-ilya-sutskever) |Ilya Sutskever helped orchestrate dramatic firing and rehiring of ChatGPT maker’s CEO last year |
|[Google rolls out AI-generated, summarized search results in US.](https://www.theguardian.com/technology/article/2024/may/14/google-ai-search-results) |Tech giant also reveals AI assistant in progress, currently called Project Astra, and AI video generator Veo at annual I/O conference |
|[OpenAI chief scientist Ilya Sutskever is officially leaving.](https://www.theverge.com/2024/5/14/24156920/openai-chief-scientist-ilya-sutskever-leaves) |Ilya Sutskever, OpenAI’s co-founder and chief scientist who helped lead the infamous failed coup against Sam Altman and then later changed his mind, is officially leaving the company. |
|[Project IDX, Google’s next-gen IDE, is now in open beta.](https://techcrunch.com/2024/05/14/project-idx-googles-next-gen-ide-is-now-in-open-beta/) |At it’s annual Google I/O 2024 developer conference on Tuesday, Google announced that Project IDX, the company’s next-gen, AI-centric browser-based development environment, is now in open beta. The company first launched it as an invite-only service gated by a waitlist in August. |
|[Researchers build AI-driven sarcasm detector.](https://www.theguardian.com/technology/article/2024/may/16/researchers-build-ai-driven-sarcasm-detector) | Being able to detect lowest form of wit could help AI interact with people more naturally, say scientists|
|[Hugging Face is sharing $10 million worth of compute to help beat the big AI companies.](https://www.theverge.com/2024/5/16/24156755/hugging-face-celement-delangue-free-shared-gpus-ai) |ZeroGPU gives everyone the chance to create AI apps without the burden of GPU costs. |
|[OpenAI partners with Reddit to integrate unique user-generated content into ChatGPT.](https://venturebeat.com/ai/openai-partners-with-reddit-to-integrate-unique-user-generated-content-into-chatgpt/) |Reddit, the widely popular social news aggregation and discussion platform, and OpenAI, the renowned AI research laboratory, have announced a strategic partnership that promises to revolutionize the way users interact with online communities and experience AI-powered features. |
|[Meta is reportedly working on camera-equipped AI earphones.](https://www.androidauthority.com/meta-ai-earphones-3442560/) | The company believes earphones are the future of AI-wearable technology.|
|[Cursor's instant full file edits with speculative editing.](https://cursor.sh/blog/instant-apply) |Using a bespoke Llama 3 70B model with a speculative prior, the researchers were able to rewrite files almost instantly at a rate of 1,000 tokens per second. They achieved this with some creative output formatting and no diffs. |
|[Improvements to data analysis in ChatGPT.](https://openai.com/index/improvements-to-data-analysis-in-chatgpt/) |Interact with tables and charts and add files directly from Google Drive and Microsoft OneDrive. |



## Resources
|Link|description|
|---|---|
|[ThunderKittens CUDA DSL.](https://hazyresearch.stanford.edu/blog/2024-05-12-quick-tk) |Hazy research has unveiled a novel DSL for CUDA kernel development. Only 100 lines of code are needed to implement its 30% quicker written flash attention feature. |
|[AnythingLLM.](https://github.com/Mintplex-Labs/anything-llm) |A full-stack application that enables you to turn any document, resource, or piece of content into context that any LLM can use as references during chatting. This application allows you to pick and choose which LLM or Vector Database you want to use as well as supporting multi-user management and permissions. |
|[Mirage: A Multi-level Superoptimizer for Tensor Algebra.](https://github.com/mirage-project/mirage) |Mirage is a tensor algebra superoptimizer that automatically discovers highly-optimized tensor programs for DNNs. Mirage automatically identifies and verifies sophisticated optimizations, many of which require joint optimization at the kernel, thread block, and thread levels of the GPU compute hierarchy. For an input DNN, Mirage searches the space of potential tensor programs that are functionally equivalent to the DNN to discover highly-optimized candidates. This approach allows Mirage to find new custom kernels that outperform existing expert-designed ones. |
|[audio-diffusion-pytorch.](https://github.com/archinetai/audio-diffusion-pytorch) | A fully featured audio diffusion library, for PyTorch. Includes models for unconditional audio generation, text-conditional audio generation, diffusion autoencoding, upsampling, and vocoding. The provided models are waveform-based, however, the U-Net (built using a-unet), DiffusionModel, diffusion method, and diffusion samplers are both generic to any dimension and highly customizable to work on other formats.|
|[Pipecat.](https://github.com/pipecat-ai/pipecat) | pipecat is a framework for building voice (and multimodal) conversational agents. Things like personal coaches, meeting assistants, story-telling toys for kids, customer support bots, intake flows, and snarky social companions.|
|[MRSegmentator: Robust Multi-Modality Segmentation of 40 Classes in MRI and CT Sequences.](https://github.com/hhaentze/mrsegmentator) | A novel tool called MRSegmentator has been developed to improve the segmentation of MRI scans. It can successfully detect 40 distinct organs and structures in the abdominal, pelvic, and thoracic areas.|
|[Time-Evidence-Fusion-Network.](https://github.com/ztxtech/Time-Evidence-Fusion-Network) |A unique deep learning model called the Time-Evidence Fusion Network (TEFN) is intended to improve long-term time series forecasting. Information fusion and evidence theory are combined, and a specific module is used to increase prediction stability and accuracy. |
|[moondream2-coyo-5M-captions.](https://huggingface.co/datasets/isidentical/moondream2-coyo-5M-captions) | 5M novel captions based on the alt-text and images of a portion of the COYO dataset.|
|[WebLlama.](https://github.com/McGill-NLP/webllama) | We are thrilled to release Llama-3-8B-Web, the most capable agent built with 🦙 Llama 3 and finetuned for web navigation with dialogue.|
|[Ollama on Google Firebase.](https://firebase.google.com/docs/genkit/plugins/ollama) |For Firebase, Genkit is a new toolkit for developing and implementing generative applications. Open source language model servers can be launched with it. |
|[Finetune PaliGemma.](https://colab.research.google.com/github/google-research/big_vision/blob/main/big_vision/configs/proj/paligemma/finetune_paligemma.ipynb) |This notebook shows how to finetune PaliGemma on a vision-language task. The training data consists of 90 pairs of images and long captions describing them. To make it runnable on a T4 colab runtime with 16GB HBM and 12GB RAM, we opt to only finetune the attention layers of the language model and freeze the other parameters. |
|[Gemini Flash.](https://deepmind.google/technologies/gemini/flash/) |Google has released a new lightweight model called Gemini Flash, which has a lengthy context window of up to one million tokens and multimodal reasoning. |
|[DeepMind Veo.](https://deepmind.google/technologies/veo) |Google Deepmind has released Veo, a new AI model for creating videos that can produce more than one minute in 1080p HD. |
|[IC-Light.](https://github.com/lllyasviel/IC-Light) |IC-Light is a project to manipulate the illumination of images. |
|[EfficientTrain++.](https://github.com/leaplabthu/efficienttrain) | With ImageNet databases, EfficientTrain++ presents a revolutionary curriculum learning technique that can drastically cut the training periods of popular visual models like ResNet and Swin by up to three times.|
|[NousResearch/Hermes-2-Theta-Llama-3-8B.](https://huggingface.co/NousResearch/Hermes-2-Theta-Llama-3-8B) |Hermes-2 Θ is a merged and then further RLHF'ed version our excellent Hermes 2 Pro model and Meta's Llama-3 Instruct model to form a new model, Hermes-2 Θ, combining the best of both worlds of each model. |
|[Energy-based Hopfield Boosting for Out-of-Distribution Detection.](https://github.com/ml-jku/hopfield-boosting) |A method called Hopfield Boosting makes use of contemporary Hopfield energy to improve machine learning models' ability to recognize out-of-distribution (OOD) data. |
|[OpenAI’s custom GPT Store is now open to all for free.](https://www.theverge.com/2024/5/13/24155582/openai-custom-gpt-store-available-free-subscriber) | OpenAI is making a number of its previously subscription-only features available to free users of ChatGPT, with the biggest being the ability to browse its GPT Store and use custom bots, said CTO Mira Murati during the company’s Spring update livestream today. The company also published today’s updates in a blog on its website.|
|[llama3.np.](https://github.com/likejazz/llama3.np) |llama3.np is pure NumPy implementation for Llama 3 model. For an accurate implementation, I ran the stories15M model trained by Andrej Karpathy. |


## Perspectives
|Link|description|
|---|---|
|[ChatGPT and the like could free up coders to new heights of creativity.](https://www.theguardian.com/commentisfree/article/2024/may/11/chatgpt-ai-will-co-pilot-coders-to-new-heights-of-creativity) | Far from making programmers an endangered species, AI will release them from the grunt work that stifles innovation|
|[Superhuman?](https://www.oneusefulthing.org/p/superhuman) |Top AI labs are focused on achieving artificial general intelligence (AGI), with estimates for its realization ranging from 2027 to 2047. Even though AI hasn't yet reached artificial general intelligence (AGI), certain systems exhibit superhuman abilities in particular tasks, indicating that AI's optimum use right now is as a co-intelligence that complements human efforts rather than replaces them. |
|[Large language models (e.g., ChatGPT) as research assistants.](https://lemire.me/blog/2024/04/27/large-language-models-e-g-chatgpt-as-research-assistants) |Artificial intelligence (AI) systems, such as GPT-4, are helping and even surpassing academics in tasks like producing research articles. According to Liang et al., AI is used in up to 18% of publications in some domains. This AI integration may result in a cycle where academic publications are produced and reviewed by software. The effect on scientific advancement is complex, though; while it may allow for more production, there is also a chance that more research will be done during an era in which knowledge will be less. |
|[What OpenAI did.](https://www.oneusefulthing.org/p/what-openai-did) | The integration of voice and vision in GPT-4o's multimodal skills holds great potential for improving AI's ability to interact with the outside world and laying the groundwork for AI to become a more commonplace presence in day-to-day life.|
|[OpenAI’s new GPT-4o model offers promise of improved smartphone assistants.](https://www.theguardian.com/technology/article/2024/may/14/openai-gpt-4o-model-offers-promise-of-improved-smartphone-assistants) | System can operate directly in speech, speeding up responses and noticing voice quirks, but it still needs the power of Siri|
|[Why mathematics is set to be revolutionized by AI.](https://www.nature.com/articles/d41586-024-01413-w) | Cheap data and the absence of coincidences make maths an ideal testing ground for AI-assisted discovery — but only humans will be able to tell good conjectures from bad ones.|
|[Major AlphaFold upgrade offers boost for drug discovery.](https://www.nature.com/articles/d41586-024-01383-z) |Latest version of the AI models how proteins interact with other molecules — but DeepMind restricts access to the tool. |
|[Lethal AI weapons are here: how can we control them?](https://www.nature.com/articles/d41586-024-01029-0) |Autonomous weapons guided by artificial intelligence are already in use. Researchers, legal experts and ethicists are struggling with what should be allowed on the battlefield. |
|[AI spending grew 293% last year. Here's how companies are using AI to stay ahead.](https://ramp.com/blog/q1-2024-spending-insights) |According to Ramp's Q1 data, its clients' expenditure on AI has increased by 293% year over year, surpassing the rise of all software investment. AI is also being widely used in non-tech businesses including financial services and healthcare, suggesting a wider integration of AI across a range of industries. Even though there is a general slowdown in new investments in AI, businesses who are already utilizing the technology are doubling down. The average amount spent on AI tools has climbed by 138% year over year, and businesses are still cautious when it comes to travel expenses. |
|[AI Copilots Are Changing How Coding Is Taught.](https://spectrum.ieee.org/ai-coding) | Professors are shifting away from syntax and emphasizing higher-level skills|
|[Test Driving ChatGPT-4o.](https://www.sabrina.dev/p/chatgpt4o-vs-math) | Inspired by ChatGPT vs Math (2023), let’s see how ChatGPT-4o performs.|
|[As the AI world gathers in Seoul, can an accelerating industry balance progress against safety?](https://www.theguardian.com/technology/article/2024/may/18/ai-seoul-global-summit-safety-openai-meta) |Companies such as OpenAI and Meta push ahead, but it is clear that biggest changes are yet to come |


# ML news: Week 6 - 12 May

## Research
|Link|description|
|---|---|
|[Mantis: Interleaved Multi-Image Instruction Tuning.](https://tiger-ai-lab.github.io/Mantis/) |A newly developed dataset and trained visual language model that allow for better instruction over a series of images. |
|[FeNNol: an Efficient and Flexible Library for Building Force-field-enhanced Neural Network Potentials.](https://arxiv.org/abs/2405.01491v1) | A state-of-the-art library called FeNNol makes it easier to create and use hybrid neural network potentials in molecular simulations.|
|[Spider: A Unified Framework for Context-dependent Concept Understanding.](https://arxiv.org/abs/2405.01002v1) |Spider is a revolutionary unified paradigm intended to improve comprehension of context-dependent (CD) concepts that rely largely on visual context, like medical lesions and items concealed in the environment. |
|[Frequency-mixed Single-source Domain Generalization for Medical Image Segmentation.](https://github.com/liamheng/non-iid_medical_image_segmentation) | A novel algorithm known as RaffeSDG has been created by researchers to enhance the precision of medical imaging models when evaluating data from various sources.|
|[SlotGAT: Slot-based Message Passing for Heterogeneous Graph Neural Network.](https://arxiv.org/abs/2405.01927v1) |SlotGAT is a new approach that improves heterogeneous graph neural networks by addressing the semantic mixing issue in traditional message passing. |
|[Frequency Masking for Universal Deepfake Detection.](https://arxiv.org/abs/2401.06506v1) |By concentrating on masked picture modeling, particularly in the frequency domain, this novel technique finds deepfakes. The strategy is different from conventional approaches and demonstrates a notable improvement in recognizing artificial images, even from recently developed AI generative techniques. |
|[Auto-Encoding Morph-Tokens for Multimodal LLM.](https://github.com/dcdmllm/morphtokens) | Researchers have created "Morph-Tokens" to enhance AI's capacity for image creation and visual comprehension. These tokens take advantage of the sophisticated processing capabilities of the MLLM framework to convert abstract notions required for comprehension into intricate graphics for image creation.|
|[Introducing AlphaFold 3.](https://blog.google/technology/ai/google-deepmind-isomorphic-alphafold-3-ai-model/) | In a paper published in Nature, we introduce AlphaFold 3, a revolutionary model that can predict the structure and interactions of all life’s molecules with unprecedented accuracy. For the interactions of proteins with other molecule types we see at least a 50% improvement compared with existing prediction methods, and for some important categories of interaction we have doubled prediction accuracy.|
|[ImageInWords: Unlocking Hyper-Detailed Image Descriptions.](https://arxiv.org/abs/2405.02793) | An extraordinarily detailed coupling of images and text was produced via a novel labeling technique that made use of two passes of VLMs. Strong multimodal models can be trained with the help of the captions, which include significantly more detail than any previous dataset. |
|[Inf-DiT: Upsampling Any-Resolution Image with Memory-Efficient Diffusion Transformer.](https://arxiv.org/abs/2405.04312v1) | To get beyond memory constraints in the creation of ultra-high-resolution images, a novel diffusion model presents a unidirectional block attention mechanism.|
|[DocRes: A Generalist Model Toward Unifying Document Image Restoration Tasks.](https://github.com/zzzhang-jx/docres) |A novel model called DocRes handles five tasks in one system: dewarping, deshadowing, appearance enhancement, deblurring, and binarization, making document image restoration easier. |
|[QServe: W4A8KV4 Quantization and System Co-design for Efficient LLM Serving.](https://hanlab.mit.edu/projects/qserve) |QoQ is a unique quantization approach that leverages 4-bit KV cache, 8-bit activations, and 4-bit weights to accelerate big language model inference. |
|[Navigating Chemical Space with Latent Flows.](https://arxiv.org/abs/2405.03987v1) |ChemFlow is a new framework that uses deep generative models to rapidly navigate chemical space, improving molecular science. |
|[Consistency Large Language Models: A Family of Efficient Parallel Decoders.](https://hao-ai-lab.github.io/blogs/cllm/) | One intriguing paradigm of ongoing research is the prediction of many tokens at once. If it works, generation times for many large language models would be significantly reduced. This post's method aims to accelerate generation by using a parallel decoding mechanism on fine-tuned LLMs, akin to consistency models from picture synthetics. Initial findings correspond with a 3x speculative decoding performance.|
|[You Only Cache Once: Decoder-Decoder Architectures for Language Models.](https://arxiv.org/abs/2405.05254) | The decoder-decoder YOCO architecture maintains global attention capabilities while using less GPU RAM. It is made up of a cross-decoder and a self-decoder, which enable effective key-value pair caching and reuse. With notable gains in throughput, latency, and inference memory over standard Transformers, YOCO performs favorably and is appropriate for big language models and extended context lengths.|
|[Optimal Group Fair Classifiers from Linear Post-Processing.](https://arxiv.org/abs/2405.04025v1) |This innovative post-processing approach ensures compliance with many group fairness criteria, including statistical parity, equal opportunity, and equalized odds, by recalibrating output scores after imposing a "fairness cost" to address model bias. |
|[DiffMatch: Visual-Language Guidance Makes Better Semi-supervised Change Detector.](https://arxiv.org/abs/2405.04788v1) |DiffMatch is a new semi-supervised change detection technique that generates pseudo labels for unlabeled data by using visual language models, hence offering extra supervision signals. |
|[Gemma-10M Technical Overview.](https://medium.com/@akshgarg_36829/gemma-10m-technical-overview-900adc4fbeeb) |Language-Vision The ability of models to comprehend and interact with text and visuals is quickly developing, as demonstrated by GPT-4V. Their important limits in visual deductive thinking are revealed by a recent study. Using challenging visual puzzles similar to those in IQ testing, researchers assessed these models and found that they had trouble with multi-step reasoning and abstract pattern recognition. |
|[Vision Mamba: A Comprehensive Survey and Taxonomy.](https://arxiv.org/abs/2405.04404v1) | a thorough examination of Mamba's uses in a range of visual tasks and its changing significance. Keep up with the latest discoveries and developments about the Mamba project.|

## News
|Link|description|
|---|---|
|[Lamini Raises $25M For Enterprises To Develop Top LLMs In-House.](https://www.lamini.ai/blog/series-a) | Software teams within enterprises can now create new LLM capabilities that lessen hallucinations on proprietary data, run their LLMs securely from cloud VPCs to on-premise, and scale their infrastructure with model evaluations that put ROI and business outcomes ahead of hype thanks to Lamini, an Enterprise AI platform. Amplify Partners led a $25 million Series A financing round.|
|[Microsoft-backed OpenAI may launch search, taking on Google's 'biggest product'.](https://timesofindia.indiatimes.com/technology/tech-news/microsoft-backed-openai-may-launch-search-taking-on-googles-biggest-product/articleshow/109794140.cms) |Speculations in the tech world suggest that OpenAI is gearing up for a major announcement, possibly a new search engine. According to Jimmy Apples, who reports the claim as an insider, the company is planning an event this month (May), tentatively scheduled for May 9, 2024, at 10 am. |
|[An AI-controlled fighter jet took the Air Force leader for a historic ride. What that means for war.](https://apnews.com/article/artificial-intelligence-fighter-jets-air-force-6a1100c96a73ca9b7f41cbd6a2753fda) |AI marks one of the biggest advances in military aviation since the introduction of stealth in the early 1990s, and the Air Force has aggressively leaned in. Even though the technology is not fully developed, the service is planning for an AI-enabled fleet of more than 1,000 unmanned warplanes, the first of them operating by 2028. |
|[Stack Overflow and OpenAI Partner to Strengthen the World’s Most Popular Large Language Models.](https://stackoverflow.co/company/press/archive/openai-partnership) |ack Overflow and OpenAI today announced a new API partnership that will empower developers with the collective strengths of the world’s leading knowledge platform for highly technical content with the world’s most popular LLM models for AI development. |
|[Elon Musk’s Plan For AI News.](https://www.bigtechnology.com/p/elon-musks-plan-for-ai-news) |Musk emails with details on AI-powered news inside X. An AI bot will summarize news and commentary, sometimes looking through tens of thousands of posts per story. |
|[Microsoft says it did a lot for responsible AI in inaugural transparency report.](https://www.theverge.com/2024/5/2/24147573/microsoft-ai-transparency-responsible-ignore-mario) |The report covers its responsible AI achievements in 2023 but doesn’t talk about Mario flying a plane to the Twin Towers. |
|[Cohere’s Command R Model Family is Now Available In Amazon Bedrock.](https://cohere.com/blog/command-r-on-amazon-bedrock) | Command R model family is now available in Amazon Bedrock. |
|[Fake Monet and Renoir on eBay among 40 counterfeits identified using AI.](https://www.theguardian.com/artanddesign/article/2024/may/08/fake-monet-and-renoir-on-ebay-among-counterfeits-identified-using-ai) |Paintings identified as fake using cutting-edge technology are ‘tip of the iceberg’ specialist Dr Carina Popovici says |
|[‘A chilling prospect’: should we be scared of AI contestants on reality shows?](https://www.theguardian.com/tv-and-radio/article/2024/may/07/the-circle-max-ai-netflix) |Netflix’s hit show The Circle recently introduced an AI chatbot contestant, a potentially worrying sign of where we’re heading |
|[‘ChatGPT for CRISPR’ creates new gene-editing tools.](https://www.nature.com/articles/d41586-024-01243-w) | In the never-ending quest to discover previously unknown CRISPR gene-editing systems, researchers have scoured microbes in everything from hot springs and peat bogs to poo and even yogurt. Now, thanks to advances in generative artificial intelligence (AI), they might be able to design these systems with the push of a button.|
|[Microsoft Working on ‘Far Larger’ In-House AI Model.](https://www.pymnts.com/artificial-intelligence-2/2024/report-microsoft-working-on-far-larger-in-house-ai-model/) | Microsoft is reportedly working on a new, in-house artificial intelligence (AI) model that is “far larger” than the other open source models it has trained.|
|[Apple unveils M4: Its first chip made for AI from the ground up.](https://9to5mac.com/2024/05/07/apple-unveils-m4-chip-ai/) | Apple on Tuesday unveiled M4, the next generation of its Apple Silicon chip. Built with the 3 nanometer chip architecture, M4 is the first Apple chip to be built for AI from the ground up. M4 is the chip that powers the new generation iPad Pro and will soon be inside Macs |
|[OpenAI Model Spec.](https://cdn.openai.com/spec/model-spec-2024-05-08.html) | This is the first draft of the Model Spec, a document that specifies desired behavior for our models in the OpenAI API and ChatGPT. It includes a set of core objectives, as well as guidance on how to deal with conflicting objectives or instructions.|
|[AI engineers report burnout and rushed rollouts as ‘rat race’ to stay competitive hits tech industry.](https://www.cnbc.com/2024/05/03/ai-engineers-face-burnout-as-rat-race-to-stay-competitive-hits-tech.html) | Artificial intelligence engineers at top tech companies told CNBC that the pressure to roll out AI tools at breakneck speed has come to define their jobs. They say that much of their work is assigned to appease investors rather than to solve problems for end users, and that they are often chasing OpenAI. Burnout is an increasingly common theme as AI workers say their employers are pursuing projects without regard for the technology’s effect on climate change, surveillance and other potential real-world harms.|
|[The teens making friends with AI chatbots.](https://www.theverge.com/2024/5/4/24144763/ai-chatbot-friends-character-teens) |Teens are opening up to AI chatbots as a way to explore friendship. But sometimes, the AI’s advice can go too far. |
|[GPT-2-Chatbot Confirmed As OpenAI.](https://simonwillison.net/2024/May/8/gpt2-chatbot-confirmed-as-openai/) |Recently, the gpt-2-chatbot has been seen in the LMSYS space; after discovering information from OpenAI's API through a 429 rate limit issue, it was verified that this was a new model from OpenAI. |
|[OpenAI Is Readying a Search Product to Rival Google, Perplexity.](https://www.bloomberg.com/news/articles/2024-05-07/openai-is-readying-an-ai-search-product-to-rival-google-perplexity) | The feature would let ChatGPT users search the web and cite sources in its results.|
|[DatologyAI raises $46M Series A.](https://www.datologyai.com/post/datologyai-raises-46m-series-a) |The data curation platform raises additional funds in its September $11 million seed round with the goal of growing its workforce and advancing corporate development. |
|[Yellow raises $5M from A16z for Gen AI-powered 3D modeling tool.](https://venturebeat.com/games/yellow-raises-5m-from-a16z-for-gen-ai-powered-3d-modeling-tool/) | Yellow has raised $5 million in seed funding from A16z Games to fund further development of its Gen AI-powered 3D modeling tool. With its YellowSculpt tool, artists can generate clean, pre-rigged 3D character meshes based on a text prompt in under three minutes.|
|[Stable Artisan: Media Generation and Editing on Discord.](https://stability.ai/news/stable-artisan) |Stable Artisan enables media generation on Discord powered by Stability AI’s cutting-edge image and video models, Stable Diffusion 3, Stable Video Diffusion, and Stable Image Core. In addition to media generation, Stable Artisan offers tools to edit your creations like Search and Replace, Remove Background, Creative Upscale and Outpainting.   |
|[ElevenLabs previews music-generating AI model.](https://venturebeat.com/ai/elevenlabs-previews-music-generating-ai-model/) | Voice AI startup ElevenLabs is offering an early look at a new model that turns a prompt into song lyrics. To raise awareness, it’s following a similar playbook Sam Altman used when OpenAI introduced Sora, its video-generating AI, soliciting ideas on social media and turning them into lyrics.|
|[Sources: Mistral AI raising at a $6B valuation, SoftBank ‘not in’ but DST is.](https://techcrunch.com/2024/05/09/sources-mistral-ai-raising-at-a-6b-valuation-softbank-not-in-but-dst-is/?utm_source=tldrai) | Paris-based Mistral AI, a startup working on open source large language models — the building block for generative AI services — has been raising money at a $6 billion valuation, three times its valuation in December, to compete more keenly against the likes of OpenAI and Anthropic, TechCrunch has learned from multiple sources.|
|[Leaked Deck Reveals How OpenAI Is Pitching Publisher Partnerships.](https://www.adweek.com/media/openai-preferred-publisher-program-deck/) |The generative artificial intelligence firm OpenAI has been pitching partnership opportunities to news publishers through an initiative called the Preferred Publishers Program, according to a deck obtained by ADWEEK and interviews with four industry executives. |
|[TECH
Alibaba rolls out latest version of its large language model to meet robust AI demand.](https://www.cnbc.com/2024/05/09/alibaba-rolls-out-latest-version-of-its-large-language-model.html) | Alibaba Cloud on Thursday said its large language model has seen more than 90,000 deployments in companies across industries. Alibaba Cloud said the latest version of its Tongyi Qianwen model, Qwen2.5, possesses “remarkable advancements in reasoning, code comprehension, and textual understanding compared to its predecessor Qwen2.0.”|

## Resources
|Link|description|
|---|---|
|[Prometheus-Eval.](https://github.com/prometheus-eval/prometheus-eval) |GPT-4 is a widely used performance benchmark for evaluating generation quality. Built upon Mistral, Prometheus is a model that excels at this particular purpose. |
|[Bonito.](https://github.com/BatsResearch/bonito) |Bonito is an open-source model for conditional task generation: the task of converting unannotated text into task-specific training datasets for instruction tuning. This repo is a lightweight library for Bonito to easily create synthetic datasets built on top of the Hugging Face transformers and vllm libraries. |
|[Penzai.](https://github.com/google-deepmind/penzai) |Penzai is a JAX library that provides clear, useful Pytree structures for training and interpreting models. It comes with a wide range of tools for component analysis, debugging, and model visualization. Penzai is easy to install and use, and it offers comprehensive tutorials for learning how to create and interact with neural networks. |
|[Realtime Video Stream Analysis with Computer Vision.](https://blog.roboflow.com/video-stream-analysis/) |This in-depth article shows you how to create a system that generates reports on the density of vehicle traffic. It counts cars over time using state-of-the-art computer vision. |
|[DOCCI - Descriptions of Connected and Contrasting Images.](https://google.github.io/docci/) | A great new dataset from Google that contains detailed and comprehensive labels.|
|[Unsloth.ai: Easily finetune & train LLMs.](https://www.youtube.com/watch?v=MQwryfkydc0&t=46s&ab_channel=EdwardZ.Yang%27sPyTorchandPL) | An animation by Unsloth's founder demonstrating how the team builds kernels, designs API surfaces, and utilizes PyTorch. The framework and library of Unsloth are incredibly robust and user-friendly.|
|[LeRobot.](https://github.com/huggingface/lerobot) | LeRobot aims to provide models, datasets, and tools for real-world robotics in PyTorch. The goal is to lower the barrier to entry to robotics so that everyone can contribute and benefit from sharing datasets and pretrained models. LeRobot contains state-of-the-art approaches that have been shown to transfer to the real-world with a focus on imitation learning and reinforcement learning.|
|[Vibe-Eval.](https://github.com/reka-ai/reka-vibe-eval) | A benchmark for evaluating multimodal chat models, including especially challenging examples.|
|[DeepSeek-V2-Chat.](https://huggingface.co/deepseek-ai/DeepSeek-V2-Chat) | DeepSeek-V2, a strong Mixture-of-Experts (MoE) language model characterized by economical training and efficient inference. It comprises 236B total parameters, of which 21B are activated for each token. Compared with DeepSeek 67B, DeepSeek-V2 achieves stronger performance, and meanwhile saves 42.5% of training costs, reduces the KV cache by 93.3%, and boosts the maximum generation throughput to 5.76 times.|
|[Visual Reasoning Benchmark.](https://github.com/apple/ml-rpm-bench) | Language-Vision The ability of models to comprehend and interact with text and visuals is quickly developing, as demonstrated by GPT-4V. Their important limits in visual deductive thinking are revealed by a recent study. Using challenging visual puzzles similar to those in IQ testing, researchers assessed these models and found that they had trouble with multi-step reasoning and abstract pattern recognition.|
|[AI Index: State of AI in 13 Charts.](https://hai.stanford.edu/news/ai-index-state-ai-13-chart) |In the new report, foundation models dominate, benchmarks fall, prices skyrocket, and on the global stage, the U.S. overshadows. |
|[Buzz Pretraining Dataset.](https://huggingface.co/datasets/H-D-T/Buzz) | Preference data is a new addition to the pretraining mix in Buzz. Multiple models that were trained on this data have also been made available by its researchers. They discovered that the models show good results on several tasks related to human preferences.|


## Perspectives
|Link|description|
|---|---|
|[From Baby Talk to Baby A.I.](https://www.nytimes.com/2024/04/30/science/ai-infants-language-learning.html) |Could a better understanding of how infants acquire language help us build smarter A.I. models? |
|[The AI Hardware Dilemma.](https://every.to/napkin-math/the-ai-hardware-dilemma) |Even while recent AI-powered hardware releases, such as the Humane Pin and Rabbit R1, have drawn criticism, the industry is still receiving a lot of venture capital investment, and well-known individuals like Sam Altman are considering making sizable investments. The appeal is in AI's ability to transform consumer hardware through innovative use of sensors, silicon, and interfaces. Though hardware startups find it difficult to compete with well-established tech giants, AI still needs to evolve, making it difficult to provide a compelling alternative to flexible smartphones. |
|[AI Prompt Engineering Is Dead.](https://spectrum.ieee.org/prompt-engineering-is-dead) |Automating prompt optimization for AI models points to more effective, model-driven prompt generation techniques in the future, possibly rendering human prompt engineering unnecessary. |
|[The Next Big Programming Language Is English.](https://every.to/chain-of-thought/i-spent-24-hours-with-github-copilot-workspaces) | GitHub Copilot Workspace is a robust programming tool that allows users to code in plain English via the browser, from planning to implementation. It is currently available in a limited technical preview. In contrast to ChatGPT, the AI easily integrates with codebases, suggesting block-by-block code execution and managing complex tasks with less active user interaction.|
|[Is AI lying to me? Scientists warn of growing capacity for deception.](https://www.theguardian.com/technology/article/2024/may/10/is-ai-lying-to-me-scientists-warn-of-growing-capacity-for-deception) |Researchers find instances of systems double-crossing opponents, bluffing, pretending to be human and modifying behaviour in tests |

# ML news: Week 29 April - 5 May

## Research
|Link|description|
|---|---|
|[Let's Think Dot by Dot: Hidden Computation in Transformer Language Models.](https://arxiv.org/abs/2404.15758) |This paper demonstrates how '...' tokens can be used to obscure chain-of-thought (CoT) reasoning. This necessitates model training, but it illustrates how the model can conceal thought and make it difficult to comprehend the CoT phases. |
|[Tracking with Human-Intent Reasoning.](https://arxiv.org/abs/2312.17448v1) |TrackGPT transforms object tracking by integrating the capabilities of Large Vision-Language Models. It can interpret implicit tracking instructions, simplifying the procedure and improving performance, as demonstrated by its outstanding performance on the new InsTrack benchmark and other hard datasets. |
|[AAPL: Adding Attributes to Prompt Learning for Vision-Language Models.](https://github.com/Gahyeonkim09/AAPL) |By employing adversarial token embedding, researchers have created a novel technique known as AAPL, which improves AI models' capacity to identify items that are not visible to the human eye. |
|[NExT: Teaching Large Language Models to Reason about Code Execution.](https://arxiv.org/abs/2404.14662) |A fundamental skill among human developers is the ability to understand and reason about program execution.  we propose NExT, a method to teach LLMs to inspect the execution traces of programs (variable states of executed lines) and reason about their run-time behavior through chain-of-thought (CoT) rationales. Specifically, NExT uses self-training to bootstrap a synthetic training set of execution-aware rationales that lead to correct task solutions (e.g., fixed programs) without laborious manual annotation. |
|[Open Gato Replication: JAT.](https://huggingface.co/blog/jat) | DeepMind's GATO was hailed as a generalist agent. JAT is a Jack-of-All-Trades model that has been trained and assessed by a team affiliated with Hugging Face. It has demonstrated reasonable performance across an extensive range of tasks.|
|[FP6-LLM: Efficiently Serving Large Language Models Through FP6-Centric Algorithm-System Co-Design.](https://arxiv.org/abs/2401.14112) |Although it can be unstable, reducing floating point precision speeds up training. This work demonstrates that without common instabilities or slowdowns from naive approaches, full tensor core usage may be achieved in a new packing structure. |
|[StarCoder2-Instruct: Fully Transparent and Permissive Self-Alignment for Code Generation.](https://huggingface.co/blog/sc2-instruct) | Both synthetic and human data are used to train this model. With a permissive license, it receives a humaneval score of 72.6. The creators provide excellent details on how to duplicate their data pipeline and apply the concepts to other issues where the use of synthetic data may be beneficial.|
|[Efficient Inverted Indexes for Approximate Retrieval over Learned Sparse Representations.](https://arxiv.org/abs/2404.18812v1) | Using trained sparse embeddings, Seismic is a novel way to organize inverted indexes that greatly improves text retrieval speed and accuracy.|
|[Learning Invariant Representations of Graph Neural Networks via Cluster Generalization.](https://arxiv.org/abs/2403.03599v1) |A novel technique called Cluster Information Transfer (CIT) mechanism is intended to improve Graph Neural Networks' (GNNs') ability to adapt to various and dynamic graph architectures. |
|[Meta-Prompting.](https://github.com/suzgunmirac/meta-prompting) | Using a technique called meta-prompting, a single language model can become a multi-skilled team. By decomposing intricate activities into smaller components that are managed by specialized instances of the same model, this technique greatly enhances performance on a variety of tasks.|
|[KAN: Kolmogorov-Arnold Networks.](https://arxiv.org/abs/2404.19756) |Today's AI makes extensive use of multi-layer perceptrons, notably in the Transformer that connects the attention levels. They do, nevertheless, employ set activation functions. This study proposes to use the Kolmogorov-Arnold representation to apply learnt activation functions on edges (functions can be represented by a superposition of smaller functions). Here, the researchers use splines in place of weights. Although the building is far more intricate, it has some intriguing characteristics that might help with interpretation. |
|[Lightplane: Highly-Scalable Components for Neural 3D Fields.](https://lightplane.github.io/) | With a new technique, 2D-3D mappings can significantly minimize memory usage by using Lightplane Renderer and Splatter components. The Lightplane Splatter effectively projects these images into 3D Hash structures after the Lightplane Renderer expertly creates images from neural 3D fields.|
|[CLIP-Mamba: CLIP Pretrained Mamba Models with OOD and Hessian Evaluation.](https://arxiv.org/abs/2404.19394v1) |The new Mamba model, trained using contrastive language-image pretraining (CLIP), shows impressive efficiency and performance in zero-shot image classification. |
|[MicroDreamer.](https://github.com/ml-gsai/microdreamer) |Scientists have created a novel 3D creation method called MicroDreamer that greatly speeds up the procedure by lowering the quantity of function evaluations needed. |
|[Model Quantization and Hardware Acceleration for Vision Transformers: A Comprehensive Survey.](https://arxiv.org/abs/2405.00314v1) | This paper explores how optimized hardware combined with algorithmic modifications can improve the performance of ViTs, especially via model quantization.|
|[Spikformer V2: Join the High Accuracy Club on ImageNet with an SNN Ticket.](https://arxiv.org/abs/2401.02020v1) |Spikformer V2 blends the biological efficacy of Spiking Neural Nets (SNNs) with the self-attention mechanism. This novel model improves its energy-efficient visual feature processing through the use of a Convolutional Stem and a Spiking Self-Attention mechanism. |
|[Full-frequency dynamic convolution: a physical frequency-dependent convolution for sound event detection.](https://arxiv.org/abs/2401.04976v1) | A novel technique called Full-Frequency Dynamic Convolution (FFDConv) improves 2D convolution for sound event identification. FFDConv increases sound event detection accuracy by creating distinct frequency kernels for every band, particularly with regard to the frequency properties of the sounds.|
|[Boosting Segment Anything Model with Adversarial Tuning.](https://asam2024.github.io/) | One well-known foundation model in computer vision, Meta AI's Segment Anything Model (SAM), performs well at image segmentation but poorly in other domains. This project introduces ASAM, a performance-enhancing adversarial tuning based reinforcement learning algorithm on top of SAM. |
|[SUNDAE: Spectrally Pruned Gaussian Fields with Neural Compensation.](https://runyiyang.github.io/projects/SUNDAE/) |This work presents SUNDAE, a novel technique that uses neural compensation and spectral pruning to improve memory efficiency.|
|[Long-Context Data Engineering.](https://github.com/franxyao/long-context-data-engineering) | The technique presented in this work allows language models to be greatly extended to context lengths of up to 128K, highlighting the significance of training data diversity and quantity.|
|[StreamMultiDiffusion: Real-Time Interactive Generation with Region-Based Semantic Control.](https://github.com/ironjr/StreamMultiDiffusion) |StreamMultiDiffusion is a framework that enables real-time region-based text-to-image generation. |


## News
|Link|description|
|---|---|
|[BBC presenter’s likeness used in advert after firm tricked by AI-generated voice.](https://www.theguardian.com/technology/2024/apr/28/bbc-presenters-likeness-used-in-advert-after-firm-tricked-by-ai-generated-voice) | Science presenter Liz Bonnin’s accent, as regular BBC viewers know, is Irish. But this voice message, ostensibly granting permission to use her likeness in an ad campaign, seemed to place her on the other side of the world.|
|[Tesla Autopilot feature was involved in 13 fatal crashes, US regulator says.](https://www.theguardian.com/technology/2024/apr/26/tesla-autopilot-fatal-crash) |Federal transportation agency finds Tesla’s claims about feature don’t match their findings and opens second investigation |
|[Apple and OpenAI are reportedly in talks for iOS 18 integration.](https://mashable.com/article/apple-openai-partnership-ios-18) |Apple has been talking to several big AI companies in pursuit of a potential partnership for on-device chatbot capabilities. According to Bloomberg, Apple and OpenAI discussed a potential deal earlier this year. Those talks have since reopened, according to people with knowledge of the matter. The possible agreement could be about OpenAI integrations into iOS 18. |
|[The little smart home platform that could.](https://www.theverge.com/24135207/home-assistant-announces-open-home-foundation) | This week, Home Assistant announced it is now part of the Open Home Foundation. The newly formed non-profit will own and govern all of Home Assistant and its related entities. Its creators and inaugural board members — Schoutsen, Guy Sie, Pascal Vizeli, and J. Nick Koston — all work on Home Assistant, and the foundation has no other members so far.|
|[Jensen Huang and Sam Altman among tech chiefs invited to federal AI Safety Board.](https://www.theregister.com/2024/04/26/jensen_huang_and_sam_altman/) |Leaders of the world's most prominent AI companies are being recruited for the Homeland Security Department's new advisory group. |
|[OpenAI to use Financial Times journalism to train artificial intelligence systems.](https://www.theguardian.com/media/2024/apr/29/chatgpt-openai-ft-journalism-train-artificial-intelligence-systems) | Under deal, ChatGPT users will receive summaries and quotes from Financial Times content and links to articles. The [deal](https://www.engadget.com/openai-will-train-its-ai-models-on-the-financial-times-journalism-173249177.html) is the ChatGPT maker's latest with a media company.|
|[Japan to trial AI bear warning system after record number of attacks.](https://www.theguardian.com/world/2024/apr/30/japan-to-trial-ai-bear-warning-system-after-record-number-of-attacks) |Six people have been killed and more than 200 injured in attacks by bears over the past year |
|[Copilot Workspace.](https://githubnext.com/projects/copilot-workspace/) | A new effort to let language models complete features and address faults in a semi-autonomous manner has been revealed on GitHub.|
|[OpenAI introduces "Memory" feature for ChatGPT Plus users.](https://the-decoder.com/openai-introduces-memory-feature-for-chatgpt-plus-users/) |OpenAI has enabled the "Memory" feature for all ChatGPT Plus users, the company announced via X. Memory allows users to tell ChatGPT things they want it to remember across chats. The feature can be turned on and off in the settings. |
|[Intel brings quantum-computing microchips a step closer.](https://www.nature.com/articles/d41586-024-01208-z) |By adapting methods for fabricating and testing conventional computer chips, researchers have brought silicon-based quantum computers closer to reality — and to accessing the immense benefits of a mature chipmaking industry. |
|[NATO is boosting AI and climate research as scientific diplomacy remains on ice.](https://www.nature.com/articles/d41586-024-01052-1) |As the military alliance created to counter the Soviet Union expands, it is prioritizing studies on how climate change affects security, cyberattacks and election interference. |
|[ChatGPT’s chatbot rival Claude to be introduced on iPhone.](https://www.theguardian.com/technology/2024/may/01/chatgpt-chatbot-rival-claude-to-be-introduced-on-iphone) | Challenger to market leader OpenAI says it wants to ‘meet users where they are’ and become part of users’ everyday life|
|[Amazon sales soar with boost from artificial intelligence and advertising.](https://www.theguardian.com/technology/2024/apr/30/amazon-sales-report-ai) |Revenue at Amazon Web Services increases to $25bn as retail giant releases earnings report surpassing Wall Street expectations |
|[Eight US newspapers sue OpenAI and Microsoft for copyright infringement.](https://www.theguardian.com/technology/2024/apr/30/us-newspaper-openai-lawsuit) | The Chicago Tribune, Denver Post and others file suit saying the tech companies ‘purloin millions’ of articles without permission|
|[Apple poaches AI experts from Google, creates secretive European AI lab.](https://arstechnica.com/ai/2024/04/apple-poaches-ai-experts-from-google-creates-secretive-european-ai-lab/) |Apple has poached dozens of artificial intelligence experts from Google and has created a secretive European laboratory in Zurich, as the tech giant builds a team to battle rivals in developing new AI models and products. |
|[Diddo’s new funding will bring its shoppable TV API to streaming platforms.](https://techcrunch.com/2024/04/24/diddos-new-funding-will-bring-its-shoppable-tv-api-to-streaming-platforms/) | Diddo is an API for streaming services and other platforms to integrate shoppable videos, enabling consumers to buy their favorite characters’ clothing and accessories directly on their screens. The company announced Wednesday that it raised $2.8 million in seed funding.|
|[Cognition Seeks $2 Billion Valuation for AI Code-Writing Tool.](https://www.pymnts.com/artificial-intelligence-2/2024/cognition-seeks-2-billion-valuation-for-ai-code-writing-tool/) |Cognition Labs is reportedly aiming to become the next multibillion-dollar artificial intelligence (AI) startup. The company, which is developing an AI tool for writing code, is in discussions with investors to raise money at a valuation of up to $2 billion, The Wall Street Journal (WSJ) reported Sunday (March 31). |
|[Apple to unveil AI-enabled Safari browser alongside new operating systems.](https://appleinsider.com/articles/24/04/30/apple-to-unveil-ai-enabled-safari-browser-alongside-new-operating-systems) |Apple is testing a version of its Safari web browser that includes UI tweaks, advanced content blocking features, and a new AI-powered tool dubbed Intelligent Search, AppleInsider has learned. The software — expected to debut as Safari 18 later in 2024 — is currently undergoing evaluation alongside internal builds of Apple's next-generation operating system updates, namely iOS 18 and macOS 15, according to people familiar with the matter. Should all of the new features make it to the release candidate stage, users will be treated to a new user interface (UI) for customizing popular page controls, a "Web eraser" feature, and AI-driven content summarization tools. |
|[This AI startup backed by Nvidia is now worth $19 billion.](https://www.marketwatch.com/story/this-ai-startup-backed-by-nvidia-is-now-worth-19-billion-ac240ea0) | Nvidia Corp.-backed AI startup CoreWeave has nearly tripled in value to $19 billion following its latest round of funding. CoreWeave, which rents out chips housed in data centers across the U.S. that customers use to create and deploy AI systems, raised $642 million from investors in its prior funding round.|
|[How Field AI Is Conquering Unstructured Autonomy .](https://spectrum.ieee.org/autonomy-unstructured-field-ai) | One of the biggest challenges for robotics right now is practical autonomous operation in unstructured environments. But over the past few years, this has started to change, thanks in large part to a couple of pivotal robotics challenges put on by DARPA. The DARPA Subterranean Challenge ran from 2018 to 2021, putting mobile robots through a series of unstructured underground environments.|
|[Amazon Q, a generative AI-powered assistant for businesses and developers.](https://www.aboutamazon.com/news/aws/amazon-q-generative-ai-assistant-aws) |With the use of a company's internal data, AWS has introduced Amazon Q, a generative AI assistant designed to enhance software development and decision-making. With natural language interaction, Amazon Q provides data-driven help for business users and makes coding, testing, and app development easier for developers. Amazon Q Apps is another feature of the service that makes it possible to create unique AI apps without any coding experience. |
|[GPT-2?](https://rentry.co/GPT2) |There have been rumors that the enigmatic gpt2-chatbot AI model, which resembles GPT-4.5 in some ways, is an unofficial OpenAI test for their upcoming version when it surfaced on lmsys.org. Important indicators including answer quality, features unique to OpenAI, and rate limits point to a high degree of sophistication and could be signs of an OpenAI-led covert benchmarking project. The AI community is still looking into and debating the origins and capabilities of the gpt2-chatbot. |
|[OpenAI's GPT-4 can exploit real vulnerabilities by reading security advisories.](https://www.theregister.com/2024/04/17/gpt4_can_exploit_real_vulnerabilities/) | AI agents, which combine large language models with automation software, can successfully exploit real world security vulnerabilities by reading security advisories, academics have claimed.|
|[Apple reports slumping iPhone sales as global demand weakens.](https://www.theguardian.com/technology/article/2024/may/02/apple-earnings-iphone-sales-decrease) | iPhone sales fell 10% compared with the same time period last year, but the company still beat Wall Street’s expectations|
|[Microsoft bans US police departments from using enterprise AI tool for facial recognition.](https://techcrunch.com/2024/05/02/microsoft-bans-u-s-police-departments-azure-openai-facial-recognition/) |Microsoft has reaffirmed its ban on U.S. police departments from using generative AI for facial recognition through Azure OpenAI Service, the company’s fully managed, enterprise-focused wrapper around OpenAI tech. |
|[Meta plans to build $800 million, next-generation data center in Montgomery.](https://www.madeinalabama.com/2024/05/meta-plans-to-build-800-million-next-generation-data-center-in-montgomery/) | MONTGOMERY, Alabama — Governor Kay Ivey announced today that technology company Meta Platforms plans to open an $800 million data center in Alabama’s capital city that will support 100 operational jobs and build on the company’s previous investment in the state.|


## Resources
|Link|description|
|---|---|
|[Cohere Launches Developer Toolkit to Accelerate Build Gen AI Apps.](https://cohere.com/blog/cohere-toolkit) |This toolkit is an open-source repository of production-ready applications that you can deploy across cloud providers.  |
|[Video-Language models with PLLaVA.](https://pllava.github.io/) |A novel pooling technique has been developed by researchers to enable the adaptation of image-language AI models for video applications, making the new model known as PLLaVA stand out. |
|[luminal.](https://github.com/jafioti/luminal) | Luminal is a deep learning library that uses composable compilers to achieve high performance.|
|[torchtitan.](https://github.com/pytorch/torchtitan) | torchtitan is a proof-of-concept for Large-scale LLM training using native PyTorch. It is (and will continue to be) a repo to showcase PyTorch's latest distributed training features in a clean, minimal codebase.|
|[OpenLIT.](https://github.com/openlit/openlit) |OpenLIT is an OpenTelemetry-native GenAI and LLM Application Observability tool. It's designed to make the integration process of observability into GenAI projects as easy as pie – literally, with just a single line of code. Whether you're working with popular LLM Libraries such as OpenAI and HuggingFace or leveraging vector databases like ChromaDB, OpenLIT ensures your applications are monitored seamlessly, providing critical insights to improve performance and reliability. |
|[Llamafile’s progress, four months in.](https://hacks.mozilla.org/2024/04/llamafiles-progress-four-months-in/) | Self-contained executables called Llamafiles allow models to run instantly on a variety of platforms. It promises significant portability advantages and a two-fold speed increase.|
|[Implementing FrugalGPT: Reducing LLM Costs & Improving Performance.](https://portkey.ai/blog/implementing-frugalgpt-smarter-llm-usage-for-lower-costs/) |There are steps you can take with FrugalGPT to significantly lower LLM API expenses. Prompt compression, caching, and other things are among them. |
|[Graph Machine Learning in the Era of Large Language Models (LLMs).](https://arxiv.org/abs/2404.14928) |Therefore, in this survey, we first review the recent developments in Graph ML. We then explore how LLMs can be utilized to enhance the quality of graph features, alleviate the reliance on labeled data, and address challenges such as graph heterogeneity and out-of-distribution (OOD) generalization. Afterward, we delve into how graphs can enhance LLMs, highlighting their abilities to enhance LLM pre-training and inference. Furthermore, we investigate various applications and discuss the potential future directions in this promising field. |
|[A Survey on Self-Evolution of Large Language Models.](https://arxiv.org/abs/2404.14387) | In this work, we present a comprehensive survey of self-evolution approaches in LLMs. We first propose a conceptual framework for self-evolution and outline the evolving process as iterative cycles composed of four phases: experience acquisition, experience refinement, updating, and evaluation. Second, we categorize the evolution objectives of LLMs and LLM-based agents |
|[Effort. A possibly new algorithm for LLM Inference.](https://kolinko.github.io/effort/) | In order to strike a compromise between speed and quality, effort allows real-time tweaking of computations during LLM model inference on Apple Silicon CPUs. The technique loads fewer weights into the models, allowing them to run faster, although it involves precomputation and conversion, and does not require retraining. The implementation may be downloaded from GitHub; the creators are looking for help from Swift/Metal engineers to optimize it.|
|[whisper.cpp-cli.](https://github.com/charliermarsh/whisper.cpp-cli) | A fully self-contained speech-to-text system built on top of Whisper|
|[memary: Open-Source Longterm Memory for Autonomous Agents.](https://github.com/kingjulio8238/memary) |Agents use LLMs that are currently constrained to finite context windows. memary overcomes this limitation by allowing your agents to store a large corpus of information in knowledge graphs, infer user knowledge through our memory modules, and only retrieve relevant information for meaningful responses. |
|[mistral.rs.](https://github.com/EricLBuehler/mistral.rs) | Mistral.rs is a fast LLM inference platform supporting inference on a variety of devices, quantization, and easy-to-use application with an Open-AI API compatible HTTP server and Python bindings.|
|[Autodidax: JAX core from scratch.](https://jax.readthedocs.io/en/latest/autodidax.html) | Ever want to learn how JAX works, but the implementation seemed impenetrable? Well, you’re in luck! By reading this tutorial, you’ll learn every big idea in JAX’s core system. You’ll even get clued into our weird jargon!|
|[cjpais/moondream2-llamafile.](https://huggingface.co/cjpais/moondream2-llamafile) |a completely standalone VLM executable with strong performance for its size that may be used on edge devices built on the Moondream 2 model. |
|[The open-source language model computer.](https://github.com/OpenInterpreter/01) | The 01 Project is building an open-source ecosystem for AI devices.|
|[Meta Releases ExecuTorch Framework for LLM on Edge Devices.](https://pytorch.org/blog/executorch-alpha/) | A post-training quantization toolset called Meta's ExecuTorch Framework makes it possible to run Llama models on a variety of iPhone and Galaxy devices. On mobile devices with 7B-sized language models, it can obtain up to 11 tokens per second.|
|[A Survey on Vision Mamba: Models, Applications and Challenges.](https://arxiv.org/abs/2404.18861v1) | Without the computational limitations of conventional Transformers, the Mamba model represents a cutting-edge method that performs exceptionally well when handling lengthy sequences.|
|[The cuda-checkpoint Utility.](https://github.com/NVIDIA/cuda-checkpoint) | a brand-new Nvidia toolbox that enables CUDA state checkpointing for resuming and transferring. Distributed training of very big AI models can benefit from it.|
|[Friends Don't Let Friends Make Bad Graphs.](https://github.com/cxli233/FriendsDontLetFriends) |In the field of AI research nowadays, visualizing model evaluation scores is essential. But a lot of charts do a poor job of communicating the desired data. This repository includes some excellent charts as well as dos and don'ts for result visualization. |
|[phospho: Text Analytics Platform for LLM Apps.](https://github.com/phospho-app/phospho) | Phospho is the text analytics platform for LLM apps. Detect issues and extract insights from text messages of your users or your app. Gather user feedback and measure success. Iterate on your app to create the best conversational experience for your users.|
|[FlowTestAI.](https://github.com/FlowTestAI/FlowTest) | The world's first open-source, GenAI-powered Integrated Development Environment (IDE) created especially for creating, visualizing, and overseeing API-first workflows is called FlowTestAI.|
|[A transformer walk-through, with Gemma.](https://graphcore-research.github.io/posts/gemma/) |Understanding the Transformer is an endeavor that often takes several tries. This blog post walks through the Gemma architecture and explains everything in detail. It is clear and has code and figures. |
|[Vibe-Eval: A new open and hard evaluation suite for measuring progress of multimodal language models.](https://www.reka.ai/news/vibe-eval) |Vibe-Eval is comprised of 269 ultra high quality image-text prompts and their ground truth responses. The quality of prompts and responses has been extensively checked multiple times by our team. Moreover, Vibe-Eval was designed to be difficult, challenging even to the current frontier models, and to induce greater separability among frontier-class models. |
|[RALM_Survey.](https://github.com/2471023025/ralm_survey) | This is a repository of RALM surveys containing a summary of state-of-the-art RAG and other technologies according to according to our survey paper: RAG and RAU: A Survey on Retrieval-Augmented Language Model in Natural Language Processing . In this repository, we will present the most central research approach of our thesis as well as keep up-to-date with work on RALM in the most accessible way possible. |
|[NousResearch/Hermes-2-Pro-Llama-3-8B.](https://huggingface.co/NousResearch/Hermes-2-Pro-Llama-3-8B) | The next iteration of Hermes, which was trained on a freshly cleaned dataset atop Llama 3, is now accessible. This model would be a valuable agent since it is very good at invoking functions.|
|[databonsai.](https://github.com/databonsai/databonsai) |databonsai is a Python library that uses LLMs to perform data cleaning tasks. |
|[InstructDoc: A Dataset for Zero-Shot Generalization of Visual Document Understanding with Instructions.](https://github.com/nttmdlab-nlp/instructdoc) | The InstructDr model is engineered to perform exceptionally well in a range of visual document interpretation tasks, including information extraction and question answering. Through the use of big language models combined with document images, InstructDr can outperform existing models and adapt to new tasks and datasets.|


## Perspectives
|Link|description|
|---|---|
|[The demise of Twitter: how a ‘utopian vision’ for social media became a ‘toxic mess’.](https://www.theguardian.com/technology/2024/apr/28/the-demise-of-twitter-how-a-utopian-vision-for-social-media-became-a-toxic-mess) | In the early days it was seen as a place for ‘genuine public discourse’, but users have fled since Elon Musk took over. What went wrong?|
|[AI isn't useless. But is it worth it?](https://www.citationneeded.news/ai-isnt-useless/) |This article offers a critical analysis of artificial intelligence (AI) and machine learning, contending that although these technologies can be helpful for specific tasks, they frequently fall short of the lofty claims made by AI businesses.  |
|[Binding Public Sector AI Diffusion.](https://digitalspirits.substack.com/p/binding-public-sector-ai-diffusion) | The public sector is the target of the OMB's new AI executive order policy, which could significantly hamper AI progress owing to bureaucratic roadblocks and strict safety regulations. The rules, which are being implemented in the face of declining IT funding, have the potential to stall initiatives that are essential to updating government services in addition to slowing the adoption of AI. Opponents fear that these limitations, in addition to funding reductions, may make it impossible for agencies to stay up with technology advancements in industries like healthcare.|
|[A.I. Start-Ups Face a Rough Financial Reality Check.](https://www.nytimes.com/2024/04/29/technology/ai-startups-financial-reality.html) | The table stakes for small companies to compete with the likes of Microsoft and Google are in the billions of dollars. And even that may not be enough.|
|[The rewards of reusable machine learning code.](https://www.nature.com/articles/s42256-024-00835-5) | Research papers can make a long-lasting impact when the code and software tools supporting the findings are made readily available and can be reused and built on. Our reusability reports explore and highlight examples of good code sharing practices.|
|[The curious case of the test set AUROC.](https://www.nature.com/articles/s42256-024-00817-7) |The area under the receiver operating characteristic curve (AUROC) of the test set is used throughout machine learning (ML) for assessing a model’s performance. However, when concordance is not the only ambition, this gives only a partial insight into performance, masking distribution shifts of model outputs and model instability. |
|[Federated learning is not a cure-all for data ethics.](https://www.nature.com/articles/s42256-024-00813-x) |Although federated learning is often seen as a promising solution to allow AI innovation while addressing privacy concerns, we argue that this technology does not fix all underlying data ethics concerns. Benefiting from federated learning in digital health requires acknowledgement of its limitations. |
|[How scholars armed with cutting-edge technology are unfurling secrets of ancient scrolls.](https://www.theguardian.com/books/article/2024/may/03/how-scholars-armed-with-cutting-edge-technology-are-unfurling-secrets-of-ancient-scrolls) |Researchers and Silicon Valley are using tools powered by AI to uncover lives of ancient philosophers |
|[Friends From the Old Neighborhood Turn Rivals in Big Tech’s A.I. Race.](https://www.nytimes.com/2024/04/29/technology/ai-google-microsoft.html) | Demis Hassabis and Mustafa Suleyman, who both grew up in London, feared a corporate rush to build artificial intelligence. Now they’re driving that competition at Google and Microsoft.|
|[The Great Talent Dividend and NYC's AI Opportunity.](https://www.luxcapital.com/news/the-great-talent-dividend-and-nycs-ai-opportunity) |NYC's leadership in AI is a testament to its rich talent pool and expanding stature as a hub for AI. Tech professionals and AI unicorns have been drawn to NYC's tech ecosystem. Resources such as top institutions and a $400 million fund from the AI Research Consortium power it. |
|[How AI apps make money.](https://www.growthunhinged.com/p/how-ai-apps-make-money) |With an emphasis on per-user fees, most AI apps have embraced traditional subscription-based pricing models in recent years, reflecting their function as digital assistants rather than human worker replacements. Newer AI companies are starting to use creative pricing techniques, like outcome-based models, which charge only for good outcomes, potentially increasing client adoption and revenue.|
|[Danger and opportunity for news industry as AI woos it for vital human-written copy.](https://www.theguardian.com/media/article/2024/may/04/danger-and-opportunity-for-news-industry-as-ai-woos-it-for-vital-human-written-copy) | With large language models needing quality data, some publishers are offering theirs at a price while others are blocking access|










