# ML_news_private

this is just a placeholder, the organized and correct repository is [here](https://github.com/SalvatoreRa/ML-news-of-the-week)

# scheme

# ML news: 

## Research
|Link|description|
|---|---|
|[.]() | |
|[.]() | |
|[.]() | |

## News
|Link|description|
|---|---|
|[.]() | |
|[.]() | |
|[.]() | |


## Resources
|Link|description|
|---|---|
|[.]() | |
|[.]() | |
|[.]() | |

## Perspectives
|Link|description|
|---|---|
|[.]() | |
|[.]() | |
|[.]() | |

#############################################
# On working 

# ML news: 

## Research
|Link|description|
|---|---|
|[Learning high-accuracy error decoding for quantum processors.](https://www.nature.com/articles/s41586-024-08148-8) | A new AI-driven decoder has established a state-of-the-art benchmark for detecting errors in quantum computers. Leveraging transformer architecture, AlphaQubit achieved a 6% reduction in errors compared to tensor network methods and a 30% reduction compared to correlated matching on the Sycamore data. It also demonstrated promising performance in simulations with larger systems of up to 241 qubits. While this marks substantial progress in quantum error correction, the system requires speed enhancements to enable real-time error correction for practical quantum computing applications.|
|[The Dawn of GUI Agent: A Preliminary Case Study with Claude 3.5 Computer Use.](https://arxiv.org/abs/2411.10323) |This work examines Claude 3.5's computer use capabilities across various domains and software, offering a ready-to-use agent framework for deploying API-based GUI automation models. Claude 3.5 showcases an exceptional ability to perform end-to-end tasks, translating language inputs into desktop actions seamlessly. |
|[Adding Error Bars to Evals: A Statistical Approach to Language Model Evaluations.](https://arxiv.org/abs/2411.00640) | The paper proposes five statistical recommendations for improving the evaluation of performance differences in LLMs. These include using the Central Limit Theorem to estimate theoretical averages over all possible questions rather than relying on observed averages, clustering standard errors when questions are related instead of treating them as independent, reducing variance within questions through resampling or next-token probabilities, analyzing paired differences between models by leveraging shared questions across evaluations, and conducting power analysis to determine sufficient sample sizes for identifying meaningful differences. The authors suggest that these approaches will help researchers better identify whether performance differences reflect genuine capability gaps or are merely due to chance, resulting in more accurate and reliable model evaluations.|
|[Marco-o1: Towards Open Reasoning Models for Open-Ended Solutions.](https://arxiv.org/abs/2411.14405) | Marco-o1 is a reasoning model designed for open-ended solutions, leveraging Chain-of-Thought (CoT) fine-tuning, Monte Carlo Tree Search (MCTS), reflection mechanisms, and advanced reasoning strategies. It achieves accuracy gains of +6.17% on the MGSM (English) dataset and +5.60% on the MGSM (Chinese) dataset.|
|[Cut Your Losses in Large-Vocabulary Language Models.](https://arxiv.org/abs/2411.09009) | The paper introduces Cut Cross-Entropy (CCE), a method designed to drastically reduce memory usage in LLM training by optimizing the computation of cross-entropy loss. Traditional cross-entropy layers can consume up to 90% of memory in some models by storing logits for the entire vocabulary. CCE addresses this by calculating logits only for the correct token and dynamically evaluating the log-sum-exp over all logits using flash memory. This approach reduces the memory footprint of Gemma 2 from 24GB to just 1MB. By leveraging the sparsity in softmax calculations, it skips elements that have minimal impact on gradients. The authors demonstrate that CCE achieves this substantial memory reduction without affecting training speed or convergence, allowing for larger batch sizes and potentially more efficient scaling of LLM training.|
|[AIGS: Generating Science from AI-Powered Automated Falsification.](https://arxiv.org/abs/2411.11910v1) | The study presents a multi-agent system for automated scientific discovery, focusing on falsification through automated ablation studies. Tested on three machine learning tasks—data engineering, self-instruct alignment, and language modeling—the system successfully generated meaningful scientific insights. However, its performance remains inferior to that of experienced human researchers.|
|[Does Prompt Formatting Have Any Impact on LLM Performance?](https://arxiv.org/abs/2411.10541) |The study investigates how different prompt formats (plain text, Markdown, JSON, and YAML) influence GPT model performance across various tasks. It finds that GPT-3.5-turbo's performance can vary by up to 40% depending on the format, whereas larger models like GPT-4 are more resilient to such changes. There is no universally optimal format across models or tasks; for example, GPT-3.5-turbo performed better with JSON, while GPT-4 favored Markdown. Models within the same family exhibited similar format preferences, but these preferences did not translate well to different model families. The findings highlight the significant impact of prompt formatting on model performance, emphasizing the importance of considering format choice during prompt engineering, model evaluation, and application development. |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |

## News
|Link|description|
|---|---|
|[Don’t know what to buy your loved ones for Christmas? Just ask ChatGPT.](https://www.theguardian.com/technology/2024/nov/24/dont-know-what-to-buy-your-loved-ones-for-christmas-just-ask-chatgpt) |Santa has a new little helper. But can an AI-powered shopping assistant really master the subtle art of gift giving? |
|[Anthropic x AWS trainium collaboration.](https://www.anthropic.com/news/anthropic-amazon-trainium) |Anthropic is collaborating with AWS to enhance trainium inference and tooling capabilities as part of a recent investment initiative.|
|[Will Sam Altman always win the OpenAI board fight in an AI agent simulation?](https://venturebeat.com/games/can-sam-altman-win-the-openai-board-fight-in-an-ai-agent-simulation/) | Fable, a company specializing in games and AI simulations, used its AI decision-making framework SIM-1 to simulate the OpenAI board dispute involving Sam Altman. The simulation, which incorporated multi-agent competition and GPT-4o, suggested Altman’s return as CEO in only 4 out of 20 scenarios. This research highlights AI's ability to model complex decision-making scenarios.|
|[Anthropic Announces Model Context Protocol.](https://www.anthropic.com/news/model-context-protocol) |The Model Context Protocol (MCP) is an open standard that enables AI systems to connect directly to data sources, such as business tools and content repositories. It streamlines data access by replacing fragmented, custom integrations with a universal protocol, enhancing scalability and efficiency. |
|[OpenAI Shares Insights on Red Teaming for Safer AI.](https://openai.com/index/advancing-red-teaming-with-people-and-ai/) | OpenAI has enhanced its red teaming initiatives by publishing two papers: one outlining the involvement of external experts in red teaming, and another presenting a novel approach to automated testing.|
|[Nvidia’s CEO defends his moat as AI labs change how they improve their AI models.](https://techcrunch.com/2024/11/20/nvidias-ceo-defends-his-moat-as-ai-labs-change-how-they-improve-their-ai-models/) | "Test-time scaling" is gaining significance with the advancement of AI models, and Nvidia is prepared for this transition. This approach, which boosts AI inference by increasing computational power, introduces competitive pressure as startups create faster AI inference chips. While there are concerns about diminishing returns, Nvidia is determined to capitalize on its strong platform advantage for pretraining and expects substantial growth in AI inference.|
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |

## Resources
|Link|description|
|---|---|
|[An Empirical Study on LLM-based Agents for Automated Bug Fixing.](https://arxiv.org/abs/2411.10213) |The study evaluates seven top LLM-based bug fixing systems on the SWE-bench Lite benchmark, identifying MarsCode Agent by ByteDance as the best performer with a 39.33% success rate. It highlights that line-level fault localization accuracy is more crucial than file-level accuracy for error localization, and bug reproduction capabilities play a significant role in fixing success. Notably, 24 out of 168 resolved issues required reproduction techniques, though these sometimes misled LLMs when issue descriptions were already clear. The study concludes that improving LLM reasoning abilities and refining agent workflows are essential for advancing automated bug fixing. |
|[FinRobot: AI Agent for Equity Research and Valuation with Large Language Models.](https://arxiv.org/abs/2411.08804) |The framework introduces an AI agent system for equity research that utilizes multi-agent Chain-of-Thought (CoT) prompting to integrate data analysis with human-like reasoning, producing professional investment reports comparable to those from major brokerages. It employs three specialized agents: the Data-CoT Agent, which aggregates diverse data sources for comprehensive financial integration; the Concept-CoT Agent, which mimics an analyst's reasoning to derive actionable insights; and the Thesis-CoT Agent, which synthesizes these insights into a cohesive investment thesis and report. |
|[Bi-Mamba: Towards Accurate 1-Bit State Space Models.](https://arxiv.org/abs/2411.11843) | The scalable 1-bit Mamba architecture is designed to optimize LLM efficiency across multiple model sizes (780M, 1.3B, and 2.7B). Bi-Mamba delivers performance comparable to full-precision formats like FP16 and BF16, while drastically reducing memory usage. It also achieves higher accuracy than post-training binarization Mamba baselines.|
|[Ai2 OpenScholar: Scientific literature synthesis with retrieval-augmented language models.](https://allenai.org/blog/openscholar) | Ai2 has introduced OpenScholar, a retrieval-augmented language model designed to search for relevant academic papers and provide answers based on those sources, streamlining the process for scientists to locate and synthesize information.|
|[Detecting Human Artifacts from Text-to-Image Models.](https://arxiv.org/abs/2411.13842v1) | This study addresses the issue of distorted human figures in text-to-image models by presenting the Human Artifact Dataset (HAD), a comprehensive dataset containing more than 37,000 annotated images.|
|[UnifiedCrawl: Aggregated Common Crawl for Affordable Adaptation of LLMs on Low-Resource Languages.](https://arxiv.org/abs/2411.14343v1) | UnifiedCrawl is a method that efficiently gathers extensive text data for low-resource languages from the Common Crawl corpus, utilizing minimal computational resources. This approach filters and extracts relevant data, resulting in monolingual datasets significantly larger than previously available sources.|
|[A New Image-to-Video Model.](https://arxiv.org/abs/2411.13975v1) |Researchers have created image-to-video diffusion models capable of generating realistic motion transformations from static images, overcoming the constraints of traditional approaches such as affine transformations. |
|[AIMv2: New Vision Models.](https://github.com/apple/ml-aim) | The AIMv2 vision model family employs a multimodal autoregressive training approach, delivering remarkable performance across various tasks.|
|[A New Attention Mechanism for Training LLMs.](https://github.com/haonan3/anchorcontext) |AnchorAttention: Improved attention for LLMs long-context training |
|[Combining Convolutions and Self-Attentions for Efficient Vision Models.](https://github.com/rayleizhu/glmix) |GLMix is a novel approach that combines convolutions and multi-head self-attentions (MHSAs) at varying granularity levels for vision tasks. Convolutions capture fine-grained local details, while MHSAs focus on coarse-grained semantic slots to provide global context. |
|[Echo Mimic v2.](https://antgroup.github.io/ai/echomimic_v2) |Open weights system to animate partial human bodies with a reference image and audio input. It uses pose specific VAEs to combine the information from various channels and a reference image to animate.|
|[LTX-Video.](https://github.com/Lightricks/LTX-Video) |LTX-Video is the first DiT-based video generation model that can generate high-quality videos in real-time. It can generate 24 FPS videos at 768x512 resolution, faster than it takes to watch them. The model is trained on a large-scale dataset of diverse videos and can generate high-resolution videos with realistic and diverse content. |
|[Documind.](https://github.com/DocumindHQ/documind) | Documind utilizes AI to extract structured data from PDFs by converting them into images and leveraging OpenAI's API.|
|[Coalescence: making LLM inference 5x faster.](https://blog.dottxt.co/coalescence.html) | "Coalescence" is a framework that accelerates LLM inference by up to 5x when producing structured outputs like JSON. It achieves this by transforming structured formats into finite state machines and eliminating redundant paths that result in the same output, reducing the need for unnecessary LLM calls. Although this approach greatly enhances speed, it is crucial to preserve output quality by ensuring that optimization does not exclude more likely sequences.|
|[WildLMa: Long Horizon Loco-Manipulation in the Wild.](https://arxiv.org/abs/2411.15131) | WildLMa is a framework designed to enable quadruped robots to perform advanced manipulation tasks in real-world settings. It integrates three core components: a whole-body controller for teleoperation via VR, a skill library learned through imitation learning (WildLMa-Skill), and a language model-based planner (WildLMa-Planner) that organizes these skills for long-term tasks. The researchers showcase its application in tasks such as cleaning trash from hallways and rearranging bookshelf items. The framework proves effective across various environments and object setups.|
|[MMGenBench: Evaluating the Limits of LMMs from the Text-to-Image Generation Perspective.](https://mmgenbench.alsoai.com/) | MMGenBench is a novel evaluation framework for large multimodal models, emphasizing their capacity to generate and interpret images. In this process, models produce descriptions from input images, which are subsequently used to generate new images for comparison.|
|[Moondream Python Client Library.](https://github.com/vikhyat/moondream/tree/main/clients/python) | Moondream's Python client library provides tools for image analysis and querying, featuring CPU-optimized inference. However, it is not yet suitable for GPU or Mac M1/M2/M3 users. The library can be installed using pip, and model weights are available for download in various formats, including int8, fp16, and int4. |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |

## Perspectives
|Link|description|
|---|---|
|[Jeff Jarvis: ‘Elon Musk’s investment in Twitter seemed insane, but it gave him this power’.](https://www.theguardian.com/technology/2024/nov/23/jeff-jarvis-elon-musks-investment-in-twitter-seemed-insane-but-it-gave-him-this-power) | The US media pundit on the dangers of overregulation online, why he’s more frightened of the tech bros than AI itself, and how to reclaim the web by getting rid of the geeks|
|[Passwords are giving way to better security methods – until those are hacked too, that is.](https://www.theguardian.com/business/2024/nov/24/small-business-data-security-methods) | It’s a war that will never end. But for small-business owners, it’s all about managing risk while reaping rewards|
|[Gwern Branwen - How an Anonymous Researcher Predicted AI's Trajectory.](https://www.dwarkeshpatel.com/p/gwern-branwen) |In this post, Gwern Branwen, an early advocate of LLM scaling, explores AI advancements and their influence on the path to AGI. He highlights the significance of scaling and computational power over traditional algorithmic innovations. Branwen reflects on the interplay between human intelligence and AI, as well as the societal implications of upcoming technologies like weight-loss drugs on behavior. Additionally, he offers thoughts on his writing process and the transformative effects of AI on creative endeavors |
|[The Bitter Religion: AI’s Holy War Over Scaling Laws.](https://www.generalist.com/briefing/the-bitter-religion) | The AI community is currently divided over the emphasis on scaling computation as the primary driver of AI performance, a concept often referred to as "The Bitter Lesson." Proponents, including leaders at OpenAI, believe that achieving artificial general intelligence (AGI) is possible in the near future through continued scaling of computational resources. However, others argue that alternative scientific advancements are necessary, as scaling laws may not be sustainable in the long term. This debate significantly influences investment and development strategies within AI and related fields. |
|[Why LLMs Within Software Development May Be a Dead End.](https://thenewstack.io/why-llms-within-software-development-may-be-a-dead-end/) |LLMs in software development face challenges due to their lack of decomposability and explainability. |
|[How the far right is weaponising AI-generated content in Europ.](https://www.theguardian.com/technology/2024/nov/26/far-right-weaponising-ai-generated-content-europe) | Experts say fake images raising fears around issues such as immigration have proliferated since EU elections|
|[‘What many of us feel’: why ‘enshittification’ is Macquarie Dictionary’s word of the year.](https://www.theguardian.com/science/2024/nov/26/enshittification-macquarie-dictionary-word-of-the-year-explained) |The committee’s honourable mentions went to ‘right to disconnect’ and ‘rawdogging’ |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |

# ML news: ML news: Week 18 - 24 November

## Research
|Link|description|
|---|---|
|[Artificial Intelligence, Scientific Discovery, and Product Innovation.](https://aidantr.github.io/files/AI_innovation.pdf) |indicates that leading scientists use their expertise to focus on the most promising AI-generated suggestions, while others often expend considerable resources on false positives; shows that adopting AI technology for materials discovery boosts productivity, resulting in 44% more materials discovered, a 39% increase in patent filings, and 17% greater product innovation; notes that these improvements come with drawbacks, as 82% of scientists experienced lower job satisfaction, citing reduced creativity and underutilization of their skills. |
|[Scaling Laws for Precision.](https://arxiv.org/abs/2411.04330) | presents "precision-aware" scaling laws that forecast how both training and inference precision impact LLM performance; key insights include: 1) post-training quantization becomes increasingly detrimental as models are trained on larger datasets, to the point where more pretraining may harm performance, 2) training with lower precision necessitates a larger model size to sustain performance levels, and 3) when optimizing model size, data, and precision together, the ideal training precision is around 7-8 bits, independent of compute availability; further notes that with a fixed model size, the optimal precision for compute increases roughly logarithmically with data size; the authors confirm their predictions on models up to 1.7B parameters trained on up to 26B tokens, demonstrating that both very high (16-bit) and very low (under 4-bit) training precisions may be inefficient.|
|[Sequence modeling and design from molecular to genome scale with Evo.](https://www.science.org/doi/10.1126/science.ado9336) |a 7B parameter AI model built to comprehend and generate DNA sequences across various biological scales; trained on 2.7 million prokaryotic and phage genomes, it can handle sequences up to 131 kilobases long while preserving single-nucleotide precision, allowing it to capture both molecular interactions and genome-wide patterns; Evo outperforms in predicting and generating functional DNA, RNA, and protein sequences, achieving the first experimentally validated AI-generated CRISPR-Cas complexes and transposable systems. |
|[The Surprising Effectiveness of Test-Time Training for Abstract Reasoning.](https://ekinakyurek.github.io/papers/ttt.pdf) | examines test-time training (TTT), where model parameters are temporarily updated during inference, to enhance an LLM's abstract reasoning on the ARC benchmark; highlights three essential components: initial fine-tuning on related tasks, using auxiliary task formats and augmentations, and per-instance training; TTT yields substantial performance gains, with accuracy improvements of up to 6x over base fine-tuned models; applying TTT to an 8B LLM results in 53% accuracy on ARC's public validation set, a nearly 25% increase over the previous state-of-the-art for neural approaches; combining their method with program generation techniques achieves a new public validation accuracy of 61.9%, on par with average human performance; the results indicate that explicit symbolic search is not the sole route to better abstract reasoning in LLMs, and that test-time training on few-shot examples can be highly effective.|
|[Toward Optimal Search and Retrieval for RAG.](https://arxiv.org/abs/2411.07396) | investigates the impact of retrieval on performance in RAG pipelines for QA tasks; performs experiments using BGE-base and ColBERT retrievers with LLaMA and Mistral, showing that incorporating more gold (relevant) documents enhances QA accuracy; observes that using approximate nearest neighbor search with lower recall has minimal performance impact while potentially boosting speed and memory efficiency; notes that introducing noisy or irrelevant documents consistently harms performance, refuting prior research claims; concludes that optimizing the retrieval of gold documents is essential for RAG effectiveness and that lower search accuracy can be a practical strategy.|
|[Rapid Response: Mitigating LLM Jailbreaks with a Few Examples.](https://arxiv.org/abs/2411.07494) |presents a novel approach for defending LLMs against jailbreak attacks, emphasizing the rapid adaptation of defenses upon detecting new attacks rather than striving for perfect initial adversarial robustness; using a new benchmark, the top-performing method—fine-tuning an input classifier—reduced attack success rates by over 240x for known attack types and 15x for new variations after observing just one example of each attack strategy; shows that swiftly responding to emerging jailbreaks can be an effective alternative to traditional static defenses. |
|[Solving the Travelling Salesman Problem.](https://arxiv.org/abs/2411.09238v1) |This study highlights the often underestimated value of the "heatmap + Monte Carlo Tree Search (MCTS)" method, demonstrating that well-tuned, straightforward heatmaps can surpass more sophisticated models. |
|[Graph-based AI model maps the future of innovation.](https://news.mit.edu/2024/graph-based-ai-model-maps-future-innovation-1112) | MIT researchers created an AI model that employs generative knowledge extraction and graph reasoning to detect intricate patterns across varied domains such as biology and music. The model efficiently generates knowledge maps from scientific literature, uncovering connections and proposing novel materials inspired by art. This method boosts interdisciplinary research by uncovering hidden insights and fostering innovative concepts for material design.|
|[Teaching Video Models to Understand Time Like a Story.](https://arxiv.org/abs/2411.10332v1) | This paper presents NumPro, an innovative approach designed to assist Video Large Language Models in managing Video Temporal Grounding tasks.|
|[Generative World Explorer.](https://generative-world-explorer.github.io/) |The Generative World Explorer (Genex) is a system capable of simulating exploration in 3D spaces through generation and leveraging those simulations to enhance planning. It employs an ST-VAE and a diffusion pass for its imagination process, leading to better planning outcomes. |
|[Search, Verify and Feedback: Towards Next Generation Post-training Paradigm of Foundation Models via Verifier Engineering.](https://arxiv.org/abs/2411.11504) |The Generative World Explorer (Genex) is a system capable of simulating exploration in 3D spaces through generation and leveraging those simulations to enhance planning. It employs an ST-VAE and a diffusion pass for its imagination process, leading to better planning outcomes. |
|[OneNet: A Channel-Wise 1D Convolutional U-Net.](https://arxiv.org/abs/2411.09838v1) |OneNet is a 1D convolutional encoder optimized for efficient image segmentation, making it well-suited for edge devices. |
|[AI’s math problem: FrontierMath benchmark shows how far technology still has to go.](https://venturebeat.com/ai/ais-math-problem-frontiermath-benchmark-shows-how-far-technology-still-has-to-go/) |Artificial intelligence systems may be good at generating text, recognizing images, and even solving basic math problems—but when it comes to advanced mathematical reasoning, they are hitting a wall. A groundbreaking new benchmark, FrontierMath, is exposing just how far today’s AI is from mastering the complexities of higher mathematics. |
|[Enhancing Reasoning Capabilities of LLMs via Principled Synthetic Logic Corpus.](https://arxiv.org/abs/2411.12498v1) |Researchers have proposed Additional Logic Training to enhance reasoning in LLMs, focusing on teaching them to manage complex deductions involving varied rules and distractions. |
|[Solving Cold Starts in Adaptive Testing.](https://arxiv.org/abs/2411.12182v1) | The "cold start" issue in adaptive testing arises when initial questions fail to align with examinees' abilities. Researchers have addressed this with the Diffusion Cognitive States Transfer Framework (DCSR), which employs diffusion models to utilize prior learning data across different domains.|
|[samurai.](https://github.com/yangchris11/samurai) | Tracking a consistent object over an extended period is a challenging task. This work enhances SAM 2 by integrating motion-aware memory banks, ensuring consistency over time and through occlusions. It stands out as one of the most effective visual tracking systems developed so far.|
|[Compress and Reconstruct Images.](https://github.com/guaishou74851/pcnet) |PCNet is a new compact network for image-compressed sensing. It reduces sampling costs while delivering high-quality reconstructions. |
|[LMM-driven Semantic Image-Text Coding for Ultra Low-bitrate Learned Image Compression.](https://arxiv.org/abs/2411.13033v1) |Large multi-modal models can generate captions and compress images simultaneously within a single system |

## News
|Link|description|
|---|---|
|[Hi-tech recreation of Richard III’s voice has a Yorkshire accent.](https://www.theguardian.com/uk-news/2024/nov/17/technology-used-to-recreate-richard-iiis-voice-with-yorkshire-accent) |A digital avatar of the king’s head, complete with ‘meticulously researched’ voice, is on display in York |
|[OpenAI’s tumultuous early years revealed in emails from Musk, Altman, and others.](https://techcrunch.com/2024/11/15/openais-tumultuous-early-years-revealed-in-emails-from-musk-altman-and-others/) | Elon Musk's lawsuit against OpenAI has unveiled emails from the startup's early days, exposing internal conflicts.|
|[Spotify’s Plans For AI Generated Music, Podcasts, and Recommendations, According To Its Co-President, CTO, and CPO Gustav Söderström.](https://www.bigtechnology.com/p/spotifys-plans-for-ai-generated-music) | Spotify's Gustav Söderström talks about AI music, Notebook LM podcasts, and the nuance of building better discovery using LLMs.|
|[AI cloning of celebrity voices outpacing the law, experts warn.](https://www.theguardian.com/technology/2024/nov/19/ai-cloning-of-celebrity-voices-outpacing-the-law-experts-warn) | David Attenborough among famous people whose voices have been exploited by fraudsters|
|[John Oliver on potential US TikTok ban: ‘May not be necessary, but it isn’t sufficient’.](https://www.theguardian.com/tv-and-radio/2024/nov/18/john-oliver-last-week-tonight-tiktok-ban) | Last Week Tonight host looks into looming US ban over privacy concerns and fear of its Chinese parent company|
|[Shop like a Pro: Perplexity’s new AI-powered shopping assistant.](https://www.perplexity.ai/hub/blog/shop-like-a-pro) | Perplexity has introduced a shopping feature for Pro users in the U.S., enabling them to research and purchase products directly within the platform. This feature includes a "Buy with Pro" button that allows users to order items using saved billing and shipping information, with free shipping on all purchases. |
|[Ben Affleck Shares Candid Take on the Positive Use of AI in Hollywood, but Doesn't See It Threatening Creativity.](https://movieweb.com/ben-affleck-ai-role-in-hollywood/) |During an interview, Ben Affleck reassured Hollywood actors and writers, stating that AI currently poses minimal risk to their jobs because of its existing limitations. |
|[The Dawn of GUI Agent: A Preliminary Case Study with Claude 3.5 Computer Use.](https://arxiv.org/abs/2411.10323) |This work seeks to systematically evaluate the capabilities of new autonomous computer use agents, revealing that Claude is particularly strong at handling traditional linear tasks. |
|[Llama 3.1 405B now runs at 969 tokens/s on Cerebras Inference.](https://cerebras.ai/blog/llama-405b-inference) |Cerebras has developed a 405-billion-parameter Llama 3.1 model, the largest in its class, capable of processing nearly 1,000 tokens per second. This performance is approximately 12 times faster than comparable systems and 18 times faster than some closed-model API providers. The model is expected to be accessible via API at the beginning of next year. |
|[Nous Research Forge.](https://nousresearch.com/introducing-the-forge-reasoning-api-beta-and-nous-chat-an-evolution-in-llm-inference/) |The Forge Reasoning API enhances popular language models by integrating a code interpreter and advanced reasoning capabilities, leading to improved performance. |
|[US justice department plans to push Google to sell off Chrome browser.](https://www.theguardian.com/technology/2024/nov/19/us-doj-sell-chrome-browser-ai-android) |Authorities seek to dismantle monopoly on search market and also want action related to AI and Android |
|[Meta pushes AI bid for UK public sector forward with technology aimed at NHS.](https://www.theguardian.com/technology/2024/nov/19/meta-hackathon-devises-ways-to-use-ai-system-in-uk-public-services) | Tech giant awards funding to project to shorten waits in A&E, after ‘hackathon’ on using Llama system in Britain|
|[Meta hires Salesforce's CEO of AI, Clara Shih.](https://www.axios.com/2024/11/19/meta-new-ai-tools-businesses) | Meta is creating a new product unit to develop AI tools for the 200 million businesses that use its apps.|
|[Rox's Public Beta and $50M Raise.](https://docs.rox.com/development/about-rox/founder-note/make-the-best-better) |Rox, an AI-powered sales productivity platform, boosts enterprise sales reps' performance by over 30% through AI analyst teams that handle tasks like planning and engagement. It integrates effortlessly with existing systems, eliminating the inefficiencies of traditional CRMs, and is already used by leading companies. Rox recently secured $50M in funding, led by Sequoia and other prominent investors, to expand its market presence. |
|[Genies launches Parties for brands and creators to launch their own ‘AI Roblox’.](https://venturebeat.com/games/genies-launches-parties-for-brands-and-creators-to-launch-their-own-ai-roblox/) | Genies, a culture-focused avatar technology company, has launched Parties after developing its foundational technology stack since the last fundraise.|
|[Generative AI taught a robot dog to scramble around a new environment.](https://www.technologyreview.com/2024/11/12/1106811/generative-ai-taught-a-robot-dog-to-scramble-around-a-new-environment) |Teaching robots to navigate new environments is tough. You can train them on physical, real-world data taken from recordings made by humans, but that’s scarce and expensive to collect. Digital simulations are a rapid, scalable way to teach them to do new things, but the robots often fail when they’re pulled out of virtual worlds and asked to do the same tasks in the real one.  |
|[Breakthrough robot nails surgery like a human doctor after watching videos.](https://interestingengineering.com/innovation/robot-nails-surgery-lik-human-doctor) | The model can quickly train robots for diverse surgeries, from basic tasks to full procedures, advancing robotic medical capabilities.|
|[DeepL launches DeepL Voice, real-time, text-based translations from voices and videos.](https://techcrunch.com/2024/11/13/deepl-launches-deepl-voice-real-time-text-based-translations-from-voices-and-videos/) | DeepL has made a name for itself with online text translation it claims is more nuanced and precise than services from the likes of Google — a pitch that has catapulted the German startup to a valuation of $2 billion and more than 100,000 paying customers. Users will now be able to use DeepL Voice to listen to someone speaking in one language and automatically translate it to another, in real time.|
|[Google releases standalone Gemini app for iPhone.](https://www.macworld.com/article/2521235/google-releases-standalone-gemini-app-for-iphone.html) | You've always been able to access this in the Google app, but now there's another way.|
|[ChatGPT can now read some of your Mac’s desktop apps.](https://techcrunch.com/2024/11/14/chatgpt-can-now-read-some-of-your-macs-desktop-apps/) |On Thursday, the startup announced the ChatGPT desktop app for macOS can now read code in a handful of developer-focused coding apps, such as VS Code, Xcode, TextEdit, Terminal, and iTerm2. |
|[Google must sell Chrome to end search monopoly, justice department argues in court filing.](https://www.theguardian.com/technology/2024/nov/21/google-sell-chrome-us-court-filing-demand-competition-laws) |Justice department urges court to force Google to share data with rivals as part of wide-ranging changes to end online giant’s monopoly on web searching |
|[Nvidia earnings: AI chip leader shows no signs of stopping mammoth growth.](https://www.theguardian.com/technology/2024/nov/20/nvidia-earnings-ai-chipmaker) |World’s most valuable company delights investors as it reports $35bn of revenue in quarterly results |
|[DeepSeek r1 reasoning model.](https://threadreaderapp.com/thread/1859200141355536422.html) | DeepSeek has replicated o1 with its r1 Deep Think model, a highly powerful system that the company plans to make fully open-source. The model was trained using reinforcement learning with reasoning traces.|
|[Introducing AI Backgrounds, HD Video Calls, Noise Suppression and More for Messenger Calling.](https://about.fb.com/news/2024/11/introducing-ai-backgrounds-noise-suppression-and-more-messenger-calling/) |Meta has announced new updates for its Messenger app, including HD video calling, noise suppression, and AI-generated backgrounds. HD video calling will be enabled by default on Wi-Fi, but can also be activated using a cell data plan through call settings.  |
|[A.I. Chatbots Defeated Doctors at Diagnosing Illness.](https://www.nytimes.com/2024/11/17/health/chatgpt-ai-doctors-diagnosis.html?unlocked_article_code=1.a04.Pypn.jAqrCrVkp6Z3&smid=url-share) |A small study found ChatGPT outdid human physicians when assessing medical case histories, even when those doctors were using a chatbot. |
|[AlphaQubit tackles one of quantum computing’s biggest challenges.](https://blog.google/technology/google-deepmind/alphaqubit-quantum-error-correction/) |Deepmind and Google Quantum have trained a model that can identify errors in quantum computations and correct them as needed. |
|[Superhuman vision lets robots see through walls, smoke with new LiDAR-like eyes.](https://interestingengineering.com/innovation/superhuman-vision-lets-robots-see-through-walls-smoke) | PanoRadar, developed by researchers at the University of Pennsylvania, is an AI-driven system that transforms radio waves into 3D views, offering robots LiDAR-like vision at a reduced cost. By leveraging AI to process radio wave reflections, it overcomes challenges faced by traditional sensors in conditions like smoke, fog, and glass. The team plans to integrate PanoRadar with existing sensing technologies to enhance multi-modal perception in robotics.|
|[Google DeepMind has a new way to look inside an AI's “mind”.](https://www.technologyreview.com/2024/11/14/1106871/google-deepmind-has-a-new-way-to-look-inside-an-ais-mind/) |DeepMind has introduced Gemma Scope, a tool designed to enhance the understanding of AI models' internal mechanisms and decision-making processes. By employing sparse autoencoders, Gemma Scope dissects and analyzes data layers, aiding in the identification of biases or errors, such as incorrect numerical interpretations. This advancement in model transparency aims to improve AI control and alignment, thereby reducing deployment risks. |
|[AI model identifies overlooked brain tumors in just 10 seconds.](https://newatlas.com/brain/fastglioma-ai-identifies-brain-tumors/) | FastGlioma is an AI model that rapidly detects residual brain tumor tissues during surgery with high accuracy.|
|[It's Surprisingly Easy to Jailbreak LLM-Driven Robots.](https://spectrum.ieee.org/jailbreak-llm) | Researchers induced bots to ignore their safeguards without exception|
|[Nvidia to fuel humanoid robots with ‘Jetson Thor’.](https://iottechnews.com/news/nvidia-fuel-humanoid-robots-jetson-thor/) |Nvidia plans to launch its “Jetson Thor” computing platform in the first half of 2025, providing the processing power needed to bring sophisticated humanoid robots to life. |
|[Introducing FLUX.1 Tools.](https://blackforestlabs.ai/flux-1-tools/) |FLUX.1 Tools is a collection of models designed to enhance control and steerability in the FLUX.1 text-to-image model. It includes utilities and model checkpoints that enable features like inpainting, outpainting, and certain controlnets. These tools are ideal for users looking to expand their creative capabilities using one of the leading models available. |
|[Elon Musk Asked People to Upload Their Health Data. X Users Obliged.](https://www.nytimes.com/2024/11/18/well/x-grok-health-privacy.html?unlocked_article_code=1.a04.k65h.c7aN7-TAu-PB&smid=url-share) |Users are uploading medical images to X's AI chatbot Grok for diagnostic purposes, a practice endorsed by Elon Musk despite concerns about accuracy and privacy. Unlike regulated medical platforms, Grok lacks HIPAA compliance, raising ethical questions about data security. While AI shows promise in healthcare, experts warn of risks related to inaccurate diagnoses and privacy violations. |
|[ElevenLabs now offers ability to build conversational AI agents.](https://techcrunch.com/2024/11/18/elevenlabs-now-offers-ability-to-build-conversational-ai-agents/) | ElevenLabs, a startup that provides AI voice cloning and a text-to-speech API, launched the ability to build conversational AI bots on Monday.|
|[New OpenAI emails reveal a long history of mistrust.](https://www.transformernews.ai/p/openai-emails-altman-trust) | Greg Brockman and Ilya Sutskever had questions about Sam Altman's intentions as early as 2017|
|[Musk’s amended lawsuit against OpenAI names Microsoft as defendant.](https://techcrunch.com/2024/11/14/musks-amended-lawsuit-against-openai-names-microsoft-as-defendant/) |Elon Musk’s lawsuit against OpenAI accusing the company of abandoning its nonprofit mission was withdrawn in July, only to be revived in August. Now, in an amended complaint, the suit names new defendants, including Microsoft, LinkedIn co-founder Reid Hoffman, and former OpenAI board member and Microsoft VP Dee Templeton. |

## Resources
|Link|description|
|---|---|
|[OpenCoder: The Open Cookbook for Top-Tier Code Large Language Models.](https://arxiv.org/abs/2411.04905) | introduces OpenCoder, a completely open-source LLM tailored for code generation and comprehension; the authors highlight key elements for creating top-performing code LLMs: (1) rigorous data cleaning using code-specific heuristic rules for deduplication, (2) effective recall of related text corpus for code context, and (3) high-quality synthetic data utilized in both annealing and supervised fine-tuning phases; OpenCoder outperforms previous open models at the 6B+ parameter level and provides not only the model weights but also the full training pipeline, datasets, and protocols to support reproducible research.|
|[A Taxonomy of AgentOps for Enabling Observability of Foundation Model based Agents.](https://arxiv.org/abs/2411.05285v1) |examines AgentOps platforms and tools, emphasizing the necessity of robust observability and traceability features to maintain reliability in foundation model-based autonomous agent systems throughout their development and production lifecycle. |
|[Mixture-of-Transformers: A Sparse and Scalable Architecture for Multi-Modal Foundation Models.](https://arxiv.org/abs/2411.04996) | presents Mixture-of-Transformers (MoT), a novel sparse multi-modal transformer architecture that achieves performance comparable to traditional models while using nearly half the computational resources for text and image tasks; MoT matches the performance of a dense baseline while utilizing only 55.8% of the FLOPs.|
|[HtmlRAG: HTML is Better Than Plain Text for Modeling Retrieved Knowledge in RAG Systems.](https://arxiv.org/abs/2411.02959v1) | introduces a novel approach that uses HTML instead of plain text for constructing RAG systems; the core insight is that preserving HTML structure retains richer semantic and structural information compared to plain text conversion, which often loses critical formatting like headings, tables, and semantic tags; to handle the challenge of long HTML documents exceeding LLM context windows, the authors design a two-step pruning method: first, cleaning unnecessary HTML elements to cut length by 94%, and then applying a block-tree-based pruning approach that integrates embedding-based and generative pruning to retain essential content; experiments on six QA datasets show that HtmlRAG surpasses existing plain-text methods, confirming the benefits of maintaining HTML structure in RAG systems.|
|[LLaMA-Mesh: Unifying 3D Mesh Generation with Language Models.](https://research.nvidia.com/labs/toronto-ai/LLaMA-Mesh/) | NVIDIA has developed LLaMA-Mesh, a method that fine-tunes the LLaMA language model to generate 3D meshes from text prompts. By training LLaMA on a curated dataset of 3D dialogues, LLaMA-Mesh enables the model to represent and generate 3D mesh data in plain text format, integrating 3D mesh generation with language understanding.|
|[Your Fixed Watermark is Fragile: Towards Semantic-Aware Watermark for EaaS Copyright Protection.](https://arxiv.org/abs/2411.09359v1) |Researchers have introduced the Semantic Perturbation Attack (SPA) to exploit vulnerabilities in current watermarking schemes for Embedding-as-a-Service (EaaS) systems. Traditional watermarking methods often inject fixed signals into embeddings, regardless of the input's semantics, making them susceptible to adaptive attacks. SPA leverages semantic perturbations to identify and bypass these static watermark signals, effectively compromising watermark verification. |
|[Don’t Look Twice: Faster Video Transformers with Run-Length Tokenization.](https://github.com/rccchoudhury/rlt) | By adaptively caching video tokens that remain unchanged across frames, you can significantly accelerate run time without sacrificing performance or requiring extra training.|
|[Region-Aware Text-to-Image Generation via Hard Binding and Soft Refinement.](https://github.com/NJU-PCALab/RAG-Diffusion) |An improved technique for generating images with improved control based on chosen regions. |
|[Accurate Image Matching.](https://github.com/fb82/miho) |MOP+MiHo+NCC is a non-deep, modular method for improving image matches using a combination of three techniques. Multiple Overlapping Planes (MOP) clusters inlier matches and uses RANSAC to remove outliers. Middle Homography (MiHo) minimizes distortion during planar reprojection. Normalized Cross Correlation (NCC) adjusts keypoint positions post-transformation. |
|[The Beginner's Guide to Visual Prompt Injections.](https://www.lakera.ai/blog/visual-prompt-injections) |Visual prompt injections present security threats to LLMs like GPT-4V by embedding harmful instructions within images, potentially causing unintended model behavior. These vulnerabilities can manipulate outputs, for instance, by causing the model to overlook certain individuals in images or misrepresent described contexts. With the increasing adoption of generative AI, companies must implement strong security measures to address these risks. |
|[PyGen: Turning Your Ideas into Python Package.](https://github.com/GitsSaikat/Pygen) | PyGen simplifies the process of turning your ideas into software, making coding more accessible and enjoyable. Leveraging advanced language models, PyGen acts like a tech-savvy assistant, transforming abstract concepts into complete Python tools, including testing and documentation. |
|[UltraVox Audio Language Models.](https://huggingface.co/collections/reach-vb/ultravox-audio-language-model-release-67373b602af0a52b2a88ae71) |A suite of open weight models that can take text and audio as input modalities. |
|[https://arxiv.org/abs/2410.17758.](https://mistral.ai/news/pixtral-large/) | Pixtral Large is a 124B open-weight multimodal model built upon Mistral Large 2. As the second model in this multimodal series, it showcases advanced image comprehension, capable of interpreting documents, charts, and natural images, while retaining the top-tier text understanding of Mistral Large 2.|
|[LLaVA-o1: Let Vision Language Models Reason Step-by-Step.](https://arxiv.org/abs/2411.10440) |Although this isn't an exact replication of the training process used for o1, it remains a robust VLM trained on reasoning traces. |
|[CLIP for Semantic Segmentation.](https://github.com/YuHengsss/Trident) |Although CLIP has excelled in open-vocabulary tasks, it faces challenges in semantic segmentation due to noisy features and limited resolution. Trident tackles the resolution problem with a training-free framework, integrating CLIP and DINO features from sub-images and employing SAM's encoder for global feature aggregation. |
|[Confidence-aware Denoised Fine-tuning of Off-the-shelf Models for Certified Robustness.](https://github.com/suhyeok24/ft-cadis) |This work focuses on improving the certified robustness of smoothed classifiers by fine-tuning off-the-shelf models |
|[ReCapture: Generative Video Camera Controls for User-Provided Videos using Masked Video Fine-Tuning.](https://generative-video-camera-controls.github.io/) | This paper from Google demonstrates a method for altering the camera viewpoint of an existing video.|
|[Evaluating-Constitutions.](https://github.com/saskia-rr/Evaluating-Constitutions) | Code to assist in evaluating constitutions based on human feedback.|
|[StableV2V: Stablizing Shape Consistency in Video-to-Video Editing.](https://alonzoleeeooo.github.io/StableV2V) | StableV2V is a novel video editing framework that maintains shape consistency across frames, even when user prompts require significant transformations. This method ensures smooth and precise modifications throughout the video, preserving structural integrity|
|[CCExpert: Advancing MLLM Capability in Remote Sensing Change Captioning with Difference-Aware Integration and a Foundational Dataset.](https://github.com/meize0729/ccexpert) |CCExpert is an AI model developed to describe changes in images using natural language. It can identify what has changed, where the change occurred, and how it happened. |
|[SAM Decoding: Speculative Decoding via Suffix Automaton.](https://arxiv.org/abs/2411.10666v1) | SAM-Decoding offers a faster method for text generation in LLMs by utilizing a suffix automaton to create drafts efficiently and accurately.|
|[That Chip Has Sailed: A Critique of Unfounded Skepticism Around AI for Chip Design.](https://arxiv.org/abs/2411.10053) |DeepMind has issued a robust defense of its AlphaChip project, which has faced criticism from some academic circles despite widespread industry adoption. In a recent paper titled "That Chip Has Sailed: A Critique of Unfounded Skepticism Around AI for Chip Design," DeepMind addresses these critiques, emphasizing AlphaChip's significant contributions to chip design. The paper highlights AlphaChip's role in creating superhuman chip layouts for Google's Tensor Processing Units (TPUs) and its influence on hardware used globally. |
|[PoM: Efficient Image and Video Generation with the Polynomial Mixer.](https://arxiv.org/abs/2411.12663v1) |Polynomial Mixer offers a faster and more memory-efficient alternative to Multi-Head Attention (MHA) in diffusion models used for image and video generation. |
|[Cross-View Geo-Localization.](https://github.com/gaoshuang98/cvcities) | Researchers have created a framework to address the challenges of cross-view geo-localization, including variations in viewpoints and large-scale global contexts.|
|[A statistical approach to model evaluations.](https://www.anthropic.com/research/statistical-approach-to-model-evals) | When two models are evaluated on a benchmark, declaring one as superior to the other often lacks strong confidence. This research from Anthropic introduces robust statistical methods to reliably determine when one model genuinely outperforms the other.|
|[Software is a team sport.](https://github.blog/news-insights/company-news/software-is-a-team-sport-building-the-future-of-software-development-together/) | GitHub Copilot, utilized by over 2.8 million developers, enhances the development experience with AI-powered features such as code completion, debugging, and secure code reviews. Developers can select AI models from providers like OpenAI and Google within Visual Studio Code. Integration with Azure and tools like GitHub Actions streamlines cloud deployments and continuous integration/continuous deployment (CI/CD) processes. |
|[Prompt Injecting Your Way To Shell: OpenAI's Containerized ChatGPT Environment.](https://0din.ai/blog/prompt-injecting-your-way-to-shell-openai-s-containerized-chatgpt-environment) |This article examines the interactive features of OpenAI's Debian-based sandbox environment for ChatGPT, revealing surprising details about its structure. Users can run Python scripts, manage files, and possibly expose core instructions through prompt engineering. These capabilities have sparked debates around transparency and privacy. While designed as intentional features, OpenAI does not consider them security vulnerabilities unless they result in breaches of the sandbox environment. |


## Perspectives
|Link|description|
|---|---|
|[AI could cause ‘social ruptures’ between people who disagree on its sentience.](https://www.theguardian.com/technology/2024/nov/17/ai-could-cause-social-ruptures-between-people-who-disagree-on-its-sentience) |AI could cause ‘social ruptures’ between people who disagree on its sentience |
|[Is this (finally) the end for X? Delicate Musk-Trump relationship and growing rivals spell trouble for platform.](https://www.theguardian.com/technology/2024/nov/17/bluesky-musk-trump-x-twitter-authoritarian-world) | The former Twitter could fade away, or help shape a dark future hosting voices of a new authoritarian world|
|[‘Have your bot speak to my bot’: can AI productivity apps turbocharge my life?](https://www.theguardian.com/technology/2024/nov/17/have-your-bot-speak-to-my-bot-can-ai-productivity-apps-turbocharge-my-life) |I tried out organisational software to help streamline my work and build a ‘second brain’. I never knew there were so many different ways to take notes… |
|[Is “AI welfare” the new frontier in ethics?](https://arstechnica.com/ai/2024/11/anthropic-hires-its-first-ai-welfare-researcher) | A few months ago, Anthropic quietly hired its first dedicated "AI welfare" researcher, Kyle Fish, to explore whether future AI models might deserve moral consideration and protection, reports AI newsletter Transformer. While sentience in AI models is an extremely controversial and contentious topic, the hire could signal a shift toward AI companies examining ethical questions about the consciousness and rights of AI systems.|
|[What if AI doesn’t just keep getting better forever?](https://arstechnica.com/ai/2024/11/what-if-ai-doesnt-just-keep-getting-better-forever/) |Recent reports suggest that traditional large language model (LLM) training is encountering diminishing returns, with newer models like OpenAI's Orion showing only modest improvements over predecessors. Experts are concerned about the scarcity of high-quality textual data for LLM training, leading to a shift towards synthetic data and specialized AI models. Future advancements may prioritize enhancing reasoning capabilities and developing task-specific models over general scaling. |
|[AI Makes Tech Debt More Expensive.](https://www.gauge.sh/blog/ai-makes-tech-debt-more-expensive) |AI amplifies the cost of tech debt by widening the velocity gap between low-debt and high-debt codebases. |
|[Where's My Robot Butler?](https://spectrum.ieee.org/ai-robots) | Advancements in AI and robotics are speeding up the creation of humanoid robots like Atlas, Optimus, and Neo, designed to handle domestic tasks similar to Rosie from "The Jetsons." However, developing cost-effective, safe, and efficient actuators remains a challenge. AI models play a vital role in training these robots for autonomous, complex tasks. Although there has been notable progress, these robots are currently better suited for industrial applications and may only become practical for home use with major breakthroughs.|
|[Google's head of research on whether 'learn to code' is still good advice in the age of AI.](https://www.businessinsider.com/google-research-head-career-advice-learn-to-code-2024-11) |Even though AI can manage some coding tasks, having a fundamental understanding of coding remains essential and opens up new opportunities in various fields, such as healthcare and education. |
|[Why are we using LLMs as calculators?](https://vickiboykis.com/2024/11/09/why-are-we-using-llms-as-calculators/) |Researchers are experimenting with LLMs' ability to solve math problems to assess their reasoning capabilities. |
|[GPTs Are Maxed Out.](https://www.thealgorithmicbridge.com/p/gpts-are-maxed-out) | OpenAI's next-generation model, internally called Orion, is said to fall short of expectations set by Sam Altman, hinting at a possible limit to the scalability of AI model improvements.|
|[Can Google Scholar survive the AI revolution?](https://www.nature.com/articles/d41586-024-03746-y) |The largest scholarly search engine is celebrating its 20th birthday, but AI-driven competitors offer advantages. |
|[Computational technologies of the Human Cell Atlas.](https://www.nature.com/articles/d41586-024-03762-y) |As the international effort reaches a ‘critical mass’ of achievements, Nature highlights seven tools that are poised to enable the next set of discoveries. |
|[Can a fluffy robot really replace a cat or dog? My weird, emotional week with an AI pet.](https://www.theguardian.com/technology/2024/nov/20/fluffy-robot-weird-emotional-week-ai-pet-moflin) |Casio says Moflin can develop its own personality and build a rapport with its owner – and it doesn’t need food, exercise or a litter tray. But is it essentially comforting or alienating? |
|[The Evolution of the Creator.](https://www.digitalnative.tech/p/the-evolution-of-the-creator) |Generative AI is transforming the creator economy by reducing production barriers, allowing creators to produce high-quality content effortlessly. Innovations like digital clones are reshaping content distribution and engagement, unlocking new monetization opportunities by scaling interactions and fan transactions. With AI revolutionizing creation, distribution, and monetization, the creator economy is poised to give rise to a new generation of major tech companies. |
|[‘A place of joy’: why scientists are joining the rush to Bluesky.](https://www.nature.com/articles/d41586-024-03784-6) | Researchers say the social-media platform — an alternative to X — offers more control over the content they see and the people they engage with.|
|[Tülu 3: The next era in open post-training.](https://www.interconnects.ai/p/tulu-3) |An open-source, cutting-edge post-training framework offering open data, training code, model weights, and scientific insights. It may be the most comprehensive resource for understanding modern post-training techniques for large language models. |
|[We can all be AI engineers – and we can do it with open source models.](https://blog.helix.ml/p/we-can-all-be-ai-engineers) |The barriers to AI engineering are quickly lowering as improved tools and standardized workflows streamline complex processes. Creating AI applications now involves applying basic engineering skills to utilize models, prompts, integrations, testing, and deployment. Open-source models ensure data privacy, while existing DevOps tools support the development and management of AI applications. |
|[‘An AI Fukushima is inevitable’: scientists discuss technology’s immense potential and dangers.](https://www.theguardian.com/science/2024/nov/22/an-ai-fukushima-is-inevitable-scientists-discuss-technologys-immense-potential-and-dangers) |Experts are optimistic about energy and drug production breakthroughs but also fear its potential misuse |


# ML news: Week 11 - 17 November

## Research
|Link|description|
|---|---|
|[Project Sid: Many-agent simulations toward AI civilization.](https://arxiv.org/abs/2411.00114) | This work illustrates the behavior and evolution of societies composed of 10-1000+ AI agents. It introduces PIANO, an architecture that allows agents to interact with both humans and other agents in real-time. The study reveals that agents can autonomously adopt specialized roles, follow and modify collective rules, and participate in cultural and religious transmissions.|
|[Mixtures of In-Context Learners.](https://arxiv.org/abs/2411.02830) |utilizes subsets of demonstrations to train experts through in-context learning; a trainable weighting function is then employed to merge the next-token predictions from these experts based on the training set. This method is compatible with black-box LLMs, as it does not require access to their internal parameters. Key advantages include: 1) being competitive with standard ICL while offering much greater efficiency in terms of data, memory, and computation, and 2) demonstrating robustness to noisy demonstrations and label imbalance. |
|[Attacking Vision-Language Computer Agents via Pop-ups.](https://arxiv.org/abs/2411.02391) | demonstrates that incorporating adversarial pop-ups into current agent testing environments results in an attack success rate of 86%, reducing the agents' task success rate by 47%. It also notes that simple defense methods, like instructing the agent to ignore pop-ups, prove ineffective.|
|[Multi-expert Prompting Improves Reliability, Safety, and Usefulness of Large Language Models.](https://arxiv.org/abs/2411.00492) |enhances LLM responses by simulating multiple experts and combining their outputs; it directs an LLM to complete input instructions by simulating several experts and choosing the best response from both individual and aggregated perspectives. This approach sets a new state-of-the-art on TruthfulQA-Generation with ChatGPT, surpassing the previous record of 87.97%. Additionally, it improves performance in terms of factuality and usefulness while reducing toxicity and hurtfulness. |
|[Number Cookbook: Number Understanding of Language Models and How to Improve It.](https://arxiv.org/abs/2411.03766) |offers a thorough analysis of the numerical understanding and processing ability (NUPA) of LLMs; reveals that while naive finetuning significantly boosts NUPA on many tasks, it doesn’t work for all. It also finds that methods specifically developed to improve NUPA are ineffective when finetuning pretrained models. The study examines the application of chain-of-thought techniques to NUPA and notes that these methods encounter scalability issues, limiting their practical use. |
|[WebRL: Training LLM Web Agents via Self-Evolving Online Curriculum Reinforcement Learning.](https://arxiv.org/abs/2411.02337) | introduces a self-evolving online curriculum RL framework aimed at closing the performance gap between open and proprietary LLM-based web agents. It boosts the success rate of Llama-3.1-8B from 4.8% to 42.4% and GLM4-9B from 6.1% to 43%, with the open models significantly outperforming GPT-4-Turbo (17.6%) and GPT-4o (13.9%). The framework addresses the limited availability of web agent training tasks using a robust outcome-supervised reward model for task success evaluation. An adaptive RL strategy manages distribution drift in online learning, ensuring steady performance improvements.|
|[Adapting While Learning: Grounding LLMs for Scientific Problems with Intelligent Tool Usage Adaptation.](https://arxiv.org/abs/2411.00412) |introduces a two-stage fine-tuning method where LLMs first learn from tool-generated solutions and then are trained to decide when to solve problems independently versus using tools. Evaluations on benchmarks in math, climate science, and epidemiology demonstrate significant gains, with a 28% increase in accuracy and a 14% improvement in tool usage precision over top models like GPT-4 and Claude-3.5. This approach enables the LLM to flexibly handle scientific problems of varying complexity. |
|[Google's Flood Forecasting AI to Reach 700 Million People.](https://blog.google/technology/ai/expanding-flood-forecasting-coverage-helping-partners/) | Google is expanding riverine flood forecasting coverage to over 100 countries and 700 million people, and enabling partners and researchers to better understand flood forecasting through more data and the development of a new API|
|[Mixture-of-Transformers: A Sparse and Scalable Architecture for Multi-Modal Foundation Models.](https://arxiv.org/abs/2411.04996) |The Mixture-of-Transformers (MoT) architecture features a sparse multi-modal transformer that separates parameters based on modality (text, images, and speech), allowing for efficient processing while preserving performance. In various evaluations, such as Chameleon 7B and Transfusion settings, MoT matches or outperforms dense baselines, utilizing significantly fewer resources—only 37.2% of the FLOPs for speech processing and 47.2% of the wall-clock time for image generation. |
|[Exploring the Alignment Landscape: LLMs and Geometric Deep Models in Protein Representation.](https://arxiv.org/abs/2411.05316v1) | This study investigates methods to enhance alignment between LLMs and protein-focused geometric deep models, aiming to improve cross-modal understanding.|
|[Can LLMs Follow Threads Through Near-Million-Scale Haystacks?](https://needle-threading.github.io/) | Large Language Models (LLMs) with extended context windows support a wider range of applications. Recent research on 17 top LLMs shows that although many can manage multiple information threads simultaneously, their practical context limits are often shorter than the stated maximum. While several models demonstrate "thread-safety" by handling concurrent threads without a drop in performance, accuracy typically decreases as the context window approaches its upper limit.|
|[Compressing Mesh Data for 3D Generation.](https://whaohan.github.io/bpt/) | By reducing the mesh sequence length by about 75%, a mesh compression method known as Blocked and Patchified Tokenization (BPT) effectively produces meshes with more than 8k faces.|
|[Successor Feature Matching.](https://github.com/arnavkj1995/sfm) |A new non-adversarial method for inverse reinforcement learning that avoids reward function learning is called Successor Feature Matching. |
|[Oasis: A Universe in a Transformer.](https://oasis-model.github.io/) | A 500M parameter foundation model without a game engine powers Oasis, a fully AI-generated, real-time open-world video game model. It is tailored for Etched's Sohu ASIC to achieve great frame rate efficiencies and uses quick transformer inference to generate gameplay. Despite showing great promise, issues like long-context consistency and domain generalization still exist.|
|[OpenAI to present plans for U.S. AI strategy and an alliance to compete with China.](https://www.cnbc.com/2024/11/13/openai-to-present-plans-for-us-ai-strategy-and-an-alliance-to-compete-with-china.html) | OpenAI's AI infrastructure blueprint suggests establishing AI economic zones and collaborating with the U.S. Navy on nuclear energy to promote AI-driven economic growth and innovation. The proposal features a North American AI alliance and initiatives modeled after the National Interstate and Defense Highways Act to address infrastructure demands. It stresses the importance of investing in U.S. data centers and energy projects to stay competitive with China.|
|[Introducing Athene-V2: Advancing Beyond the Limits of Scaling with Targeted Post-training.](https://nexusflow.ai/blogs/athene-v2) | Athene V2 consists of models built upon Qwen 2.5 72B, optimized for agentic and chat-based workflows, and outperform GPT-4o on several key benchmarks.|

## News
|Link|description|
|---|---|
|[Modal buys Tidbyt.](https://modal.com/blog/tidbyt-is-joining-modal) |The elastic scaling GPU company made its first acquisition by purchasing Tidbyt, a hardware firm based in NYC, to gain the in-house expertise of its team specializing in infrastructure and containerization. |
|[OpenAI reportedly developing new strategies to deal with AI improvement slowdown.](https://techcrunch.com/2024/11/09/openai-reportedly-developing-new-strategies-to-deal-with-ai-improvement-slowdown/) |OpenAI's forthcoming model, codenamed "Orion," reportedly exhibits only modest improvements over its predecessors, indicating a potential deceleration in AI advancement. To address this, OpenAI has established a foundations team dedicated to enhancing models through alternative approaches, including synthetic data training and post-training adjustments, in response to the diminishing availability of new data. |
|[Near plans to build world’s largest 1.4T parameter open-source AI model.](https://cointelegraph.com/news/near-plans-to-create-world-s-largest-1-4-t-parameter-open-source-ai-model) | Near Protocol has announced plans to develop a 1.4 trillion-parameter open-source AI model, aiming to surpass existing models like Meta's Llama. This initiative reflects Near Protocol's commitment to advancing AI capabilities and contributing to the open-source community.|
|[Samsung debuts AI-powered ‘Next-generation Bixby,’ but you can’t use it yet.](https://9to5google.com/2024/11/06/samsung-next-generation-bixby-china/) |Samsung has launched a "next-generation Bixby" with enhanced AI capabilities on the Galaxy W25 and W25 Flip in China. |
|[Even Microsoft Notepad is getting AI text editing now.](https://www.theverge.com/2024/11/6/24289707/microsoft-notepad-ai-text-editing-rewrite) |Along with adding AI to a text editor that launched in 1983, Microsoft will let Windows Insiders test generative fill-and-erase tools in Paint, too. |
|[Ofcom warns tech firms after chatbots imitate Brianna Ghey and Molly Russell.](https://www.theguardian.com/technology/2024/nov/09/ofcom-warns-tech-firms-after-chatbots-imitate-brianna-ghey-and-molly-russell) | After ‘distressing incidents’, watchdog says content from user-made bots would be covered by UK Online Safety Act|
|[AI protein-prediction tool AlphaFold3 is now open source.](https://www.nature.com/articles/d41586-024-03708-4) |The code underlying the Nobel-prize-winning tool for modelling protein structures can now be downloaded by academics. |
|[Qwen 2.5 Coder 32B Instruct is here.](https://qwenlm.github.io/blog/qwen2.5-coder-family) |The Qwen 2.5 Coder series consists of language models tailored for coding tasks. The latest 32B parameter model outperforms GPT-4o and is compact enough for local use by many. It also matches Claude Sonnet 3.5 on several benchmarks. |
|[X is testing a free version of AI chatbot Grok.](https://techcrunch.com/2024/11/10/x-is-testing-a-free-version-of-ai-chatbot-grok/) |Social network X has so far limited its AI chatbot Grok (built by Elon Musk’s other company xAI) to its premium, paying users. However, the platform is seemingly preparing to open up the chatbot to free users. |
|[Octoverse: AI leads Python to top language as the number of global developers surges.](https://github.blog/news-insights/octoverse/octoverse-2024/) | In this year’s Octoverse report, we study how public and open source activity on GitHub shows how AI is expanding as the global developer community surges in size.|
|[Google accidentally leaked a preview of its Jarvis AI that can take over computers.](https://www.engadget.com/ai/google-accidentally-leaked-a-preview-of-its-jarvis-ai-that-can-take-over-computers-203125686.html) |Google's new AI prototype, Jarvis, briefly appeared on the Chrome Web Store. |
|[AI-powered parenting is here and a16z is ready to back it.](https://techcrunch.com/2024/11/07/ai-powered-parenting-is-here-and-a16z-is-ready-to-back-it/) | Andreessen Horowitz partner Justine Moore introduced a new investment thesis for the firm on X on Thursday, endorsing “a new wave of ‘parenting co-pilots’ built with LLMs and agents.” She pointed to companies like Cradlewise, makers of an AI-powered baby monitor to detect a baby’s sleep pattern and rock the crib, and Nanit, which uses AI to process crib footage to tell if a baby is breathing. |
|[French news titles sue X over allegedly running their content without payment.](https://www.theguardian.com/world/2024/nov/12/french-news-titles-sue-x-over-allegedly-running-their-content-without-payment) | Social media site accused of violating law that requires platforms to pay media when republishing articles|
|[Musk’s influence on Trump could lead to tougher AI standards, says scientist.](https://www.theguardian.com/technology/2024/nov/12/elon-musk-donald-trump-ai-artificial-general-intelligence) |Tycoon might help president-elect realise race for artificial general intelligence is a ‘suicide race’, says Max Tegmark |
|[Bluesky adds 700,000 new members as users flee X after the US election.](https://www.theguardian.com/technology/2024/nov/12/us-election-bluesky-users-flee-x-twitter-trump-musk) | Social media platform has become a ‘refuge’ from the far-right activism on X, experts say, after Elon Musk teamed up with Donald Trump|
|[Baidu announces its own pair of AI smart glasses.](https://www.engadget.com/ai/baidu-announces-its-own-pair-of-ai-smart-glasses-143044805.html) |Baidu, which is often called China's answer to Google, has launched its own pair of AI-powered smart glasses at its annual World Conference event in Shanghai. |
|[OpenAI co-founder Greg Brockman returns after three months of leave.](https://www.cnbc.com/2024/11/12/openai-co-founder-greg-brockman-returns-after-three-months-of-leave.html) | In the midst of major management departures and controversy over OpenAI's transition to a for-profit business model, co-founder Greg Brockman has returned to the company as president after taking a sabbatical. In its most recent fundraising round, OpenAI was valued at $157 billion. Due to the departure of executives like Lilian Weng, Bob McGrew, and Mira Murati, the company is experiencing internal issues.|
|[European Google rivals partner on search engine infrastructure to counter Big Tech.](https://www.cnbc.com/2024/11/12/ecosia-qwant-partner-on-search-engine-tech-to-counter-googles-power.html) |To improve AI skills and lessen dependency on U.S. Big Tech, Ecosia and Qwant are collaborating to create a European search index. Using a "privacy-first" strategy, the project seeks to promote AI developments by developing a new search infrastructure. Since generative AI is becoming more and more prevalent in search, alternative search providers are better positioned to compete as a result of the rising API expenses. |
|[Robotic exoskeleton adapts to changes in leg movements in real time.](https://www.nature.com/articles/d41586-024-03546-4) |Wearable robots that assist leg movements could transform the lives of people with reduced mobility — but only if the devices can adapt in real time to support a vast range of human activities. Machine learning provides a way forward. |
|[OpenAI’s take on AI agents could come in January.](https://techcrunch.com/2024/11/13/openais-take-on-ai-agents-could-come-in-january/) | OpenAI is reportedly preparing to launch "Operator," an AI agent tool, as early as January. Bloomberg states that Operator may be able to execute tasks directly on a user's computer. It will initially be accessible as a research preview through OpenAI's developer API.|
|[Google's AI Initiative to Boost MENA Economy by $320 Billion.](https://blog.google/around-the-globe/google-middle-east/ai-opportunity-initiative-middle-east-north-africa/) |Google.org has launched the AI Opportunity Initiative, its largest AI investment in the Middle East and North Africa (MENA) region, aiming to develop essential AI skills, fund research, and expand AI access. This initiative is projected to contribute $320 billion to MENA's economy by 2030 |
|[Two Trillion Token Common Corpus.](https://huggingface.co/blog/Pclanglais/two-trillion-tokens-open) | the release of Common Corpus (part of the AI Alliance Open Trusted Data Initiative)—the largest fully open multilingual dataset for training LLMs, containing over 2 trillion tokens of permissibly licensed content with provenance information (2,003,039,184,047 tokens).|
|[Lume raises $4.2M Seed Round led by General Catalyst.](https://lume.ai/blog/lume-raises-4-2m-seed-round-led-by-general-catalyst) | Lume automates data mapping with AI, streamlining mapping, cleaning, and validation of data.|
|[Amazon launches under-$20 online storefront to compete with Temu.](https://www.theguardian.com/technology/2024/nov/13/amazon-haul-low-cost-storefront-temu-shein) | Company says Amazon Haul will mostly feature products under $10, which it plans to ship from China warehouse|
|[Francois Chollet leaves Google.](https://developers.googleblog.com/en/farewell-and-thank-you-for-the-continued-partnership-francois-chollet/) |The founder of Keras and Arc eval, among other contributions, has departed from Google. He will continue to support the Jax and Keras communities while exploring new opportunities. |
|[OpenAI launches ChatGPT desktop integrations, rivaling Copilot.](https://venturebeat.com/ai/openai-launches-chatgpt-desktop-integrations-rivaling-copilot/) | When OpenAI released desktop app versions of ChatGPT, it was clear the goal was to get more users to bring ChatGPT into their daily workflows. Now, new updates to Mac OS and Windows PC versions encourage users to stay in the ChatGPT apps for most of their tasks. |
|[Supermaven joins Cursor.](https://supermaven.com/blog/cursor-announcement) |The team behind the code editing plugin is joining Cursor to further enhance the user experience. |
|[Google’s AI ‘learning companion’ takes chatbot answers a step further.](https://www.theverge.com/2024/11/11/24293891/google-learn-about-ai-search-educational) |Google’s Learn About AI tool has more educational, textbook-style responses to guide you through new topics. |

## Resources
|Link|description|
|---|---|
|[FrontierMath.](https://epochai.org/frontiermath) |Epoch AI has introduced FrontierMath, a benchmark comprising expert-level mathematics problems to assess AI's mathematical reasoning capabilities. Notably, leading AI models have solved less than 2% of these problems, highlighting the benchmark's difficulty and the current limitations of AI in advanced mathematical reasoning. |
|[BitNet a4.8: 4-bit Activations for 1-bit LLMs.](https://arxiv.org/abs/2411.04965) | A major challenge with 1.58bit LLMs has been the absence of hardware acceleration support. This research introduces 4.8bit activations to leverage the INT4/FP4 kernels available in new hardware, achieving this with no added runtime cost.|
|[LLM2CLIP.](https://microsoft.github.io/LLM2CLIP/) | LLM2CLIP combines CLIP's visual and textual alignment with the advanced language understanding of LLMs.|
|[Torch Compatible Muon Optimizer.](https://github.com/KellerJordan/Muon) | Muon is the optimizer that set the training record for GPT-2. It is a momentum-adapted method similar to SGD. This repository provides an implementation that can be easily used as a replacement for AdamW.|
|[Mochi video model with optimized inference.](https://github.com/xdit-project/mochi-xdit) |Mochi 1, an open-source text-to-video model, initially required eight H100 GPUs for operation. Thanks to community efforts, it can now run on a single 48GB L40 GPU without compromising quality. |
|[A trainable PyTorch reproduction of AlphaFold 3.](https://github.com/bytedance/Protenix) | Protenix is a functional and trainable reproduction of AlphaFold 3, DeepMind's protein folding project, developed by ByteDance's 'AI for Science' team. This open-source initiative aims to advance protein structure prediction by providing a customizable platform for researchers.|
|[LlamaPReview.](https://github.com/marketplace/llamapreview) | LlamaPReview is an AI assistant for GitHub that provides easy one-click installation and automatically reviews pull requests with context-aware analysis. It supports various programming languages and integrates seamlessly with GitHub Actions, delivering insightful feedback directly on PRs. Offered for free, it improves code quality by detecting issues and recommending optimizations.|
|[SmolLM2.](https://simonwillison.net/2024/Nov/2/smollm2/) | Hugging Face's SmolLM2 is a compact family of language models, ranging from 135M to 1.7B parameters, trained on 11 trillion tokens. These models are designed to run efficiently on-device and support various tasks. The weights are released under the Apache 2 license, and quantized versions, such as the 1.7GB and 138MB models, offer flexibility to meet different computational requirements.|
|[AI for Real-time Fusion Plasma Behavior Prediction and Manipulation.](https://control.princeton.edu/machine-learning-for-rt-profile-control-in-tokamaks/) |A novel multimodal machine learning approach improves super-resolution data, enabling better analysis of complex fusion plasma phenomena like Edge Localized Modes (ELM), and supports the stabilization of future fusion reactors. |
|[A Comprehensive Survey of Small Language Models in the Era of Large Language Models.](https://arxiv.org/abs/2411.03350) | a review of small language models (SLMs), covering topics such as definitions, applications, improvements, reliability, and related concerns.|
|[Magentic-One: A Generalist Multi-Agent System for Solving Complex Tasks.](https://www.microsoft.com/en-us/research/publication/magentic-one-a-generalist-multi-agent-system-for-solving-complex-tasks/) | A new generalist multi-agent system capable of managing complex web and file-based tasks, featuring an Orchestrator agent that coordinates four specialized agents: WebSurfer for browser tasks, FileSurfer for file management, Coder for programming, and ComputerTerminal for console operations. Magentic-One performs competitively on various benchmarks, such as GAIA, AssistantBench, and WebArena, without needing any changes to its core architecture.|
|[Personalization of Large Language Models: A Survey.](https://arxiv.org/abs/2411.00027) |offers a comprehensive framework for understanding personalized LLMs, introducing taxonomies for various personalization aspects and consolidating existing research in personalized text generation and downstream applications. |
|[StdGEN: Semantic-Decomposed 3D Character Generation from Single Images.](https://stdgen.github.io/) | StdGen is a novel approach for generating 3D characters from a single image. It breaks down the process into distinct components, such as hair and jackets, enhancing the overall quality of the output.|
|[alphafold3.](https://github.com/google-deepmind/alphafold3) | DeepMind has open-sourced the code and weights of AlphaFold 3 for academic research, marking a significant advancement in protein structure prediction. This release is expected to accelerate AI applications in scientific research, particularly in molecular biology and drug discovery.|
|[Online-LoRA.](https://github.com/christina200/online-lora-official) |Online-LoRA is a framework developed to mitigate catastrophic forgetting in online continual learning (OCL) by enabling real-time fine-tuning of pre-trained Vision Transformers (ViTs) without the use of rehearsal buffers. |
|[DeepArUco++: Improved detection of square fiducial markers in challenging lighting conditions.](https://arxiv.org/abs/2411.05552v1) |DeepArUco++ presents a deep learning-based method for enhancing fiducial marker detection, especially in difficult lighting conditions where traditional techniques typically struggle. |
|[Hermes 3.](https://nousresearch.com/hermes3/) | Hermes 3, fine-tuned from Llama 3.1, excels in both reasoning and creativity, showcasing outstanding performance across models with 8B, 70B, and 405B parameters. It introduces new possibilities in AI alignment and artificial consciousness.|
|[ENAT: Rethinking Spatial-temporal Interactions in Token-based Image Synthesis.](https://arxiv.org/abs/2411.06959v1) |To improve the speed and quality of token-based picture production, EfficientNAT is an improved non-autoregressive Transformer model. |
|[UniGAD: Unifying Multi-level Graph Anomaly Detection.](https://arxiv.org/abs/2411.06427v1) |A novel framework for graph anomaly detection (GAD), UniGAD simultaneously detects anomalies in nodes, edges, and complete graphs. |
|[Object and Attribute Matching in Images with Token Merging.](https://github.com/hutaihang/tome) | Token Merging tackles a prevalent problem in text-to-image models: semantic binding, or the inability to associate things with their particular properties.|
|[DataChain.](https://github.com/iterative/datachain) |Without abstracting AI models, DataChain is a Pythonic data-frame toolkit for AI that enables effective processing and dataset structuring of unstructured data. It facilitates the creation of metadata, filtering, and vector search by integrating with AI tools like PyTorch, TensorFlow, and LLM APIs. Additionally, the library has built-in vectorized operations on Python object fields, out-of-memory computation, and parallelization. |
|[browser-use.](https://github.com/gregpr07/browser-use) |Through a streamlined UI, this open-source web automation application enables LLMs to communicate with websites. It is compatible with models such as Claude 3.5 Sonnet and GPT-4o. XPath extraction, customisable actions, and multi-tab management are important features. Data extraction and smooth web navigation are made possible by the program. Message length is one of its drawbacks, as it impacts task repetition and LLM speed. Robustness and cost reduction will be the main goals of further development. |
|[CUDA Programming Course – High-Performance Computing with GPUs.](https://www.youtube.com/watch?v=86FAWCzIe_4&ab_channel=freeCodeCamp.org) |A great course from freeCodeCamp on CUDA programming from start to finish. |
|[Masked Token Modeling for Zero-Shot Anything-to-Drums Conversion.](https://oreillyp.github.io/tria/) |Zero-shot drum style transfer for any input rhythm presents an exciting music application for artists. This is achieved using a masked token modeling objective, which is particularly effective for audio. |
|[HiCoM: Hierarchical Coherent Motion for Streamable Dynamic Scene with 3D Gaussian Splatting.](https://arxiv.org/abs/2411.07541v1) |HiCoM is a cutting-edge framework designed to enhance real-time 3D reconstruction from multi-view streaming videos. It effectively addresses key challenges in storage, training speed, and rendering quality, making it a significant advancement in the field. |
|[Janus.](https://github.com/deepseek-ai/Janus) |Janus, DeepSeek's multimodal model, has a new version incorporating rectified flows, similar to Meta Movie Gen, for image generation and understanding. The results are highly impressive. |
|[Link Conversation with Reference Materials.](https://github.com/rosewang2008/posr) |Problem-Oriented Segmentation & Retrieval (POSR) is a method that breaks conversations into meaningful segments and connects each segment to relevant reference materials, like worksheets or meeting notes. |
|[MureObjectStitch: Multi-reference Image Composition.](https://arxiv.org/abs/2411.07462v1) |Researchers have presented an improved fine-tuning method for generative image composition, which seamlessly merges a specified foreground object with a new background to generate realistic images. |
|[StoryTeller.](https://github.com/hyc2026/StoryTeller) | StoryTeller is a system created to generate coherent descriptions for long videos, tackling issues like plot consistency and character tracking throughout different scenes.|
|[SAMPart3D: Segment Any Part in 3D Objects.](https://yhyang-myron.github.io/SAMPart3D-website/) | SAMPart3D, developed by the University of Hong Kong, is a robust method for segmenting 3D objects into semantically meaningful components.|
|[Convolutional Differentiable Logic Gate Networks.](https://arxiv.org/abs/2411.04732) | 
Researchers have developed a method to train image recognition networks that are 29 times smaller and more efficient than traditional convolutional neural networks (CNNs) by making logic gates differentiable. They have also provided efficient CUDA kernels in their paper release|
|[Physics Informed Distillation for Diffusion Models.](https://arxiv.org/abs/2411.08378v1) |Physics Informed Distillation (PID) is a method that employs a student model to simplify and accelerate diffusion models by framing them as solutions to differential equations. |
|[MinerU: high-quality data extraction tool.](https://github.com/opendatalab/MinerU) | MinerU is a robust tool built on StructTable-InternVL2-1B, enabling the extraction of information from PDFs into various machine-readable formats.|
|[Isotonic regression.](https://josephsalmon.eu/blog/isotonic/) |A powerful technique for fitting a monotonic function to data. It can be differentiated really well for a number of applications outside of curve fitting. |
|[Text-to-SQL Query.](https://github.com/XGenerationLab/XiYan-SQL) |XiYan-SQL is an innovative framework aimed at enhancing both the accuracy and diversity of SQL queries produced from natural language input. |
|[X-Portrait 2: Highly Expressive Portrait Animation.](https://byteaigc.github.io/X-Portrait2/) | ByteDance's AI group has unveiled X-Portrait 2, an advanced portrait animation technology that transforms static images into highly expressive, realistic videos. Building upon its predecessor, X-Portrait, this new model excels in capturing subtle facial expressions and complex movements, such as pouting, tongue-out gestures, cheek-puffing, and frowning. It achieves high fidelity in emotion preservation, ensuring the generated videos maintain the subject's identity and emotional nuances.|
|[MVSplat360: Feed-Forward 360 Scene Synthesis from Sparse Views.](https://donydchen.github.io/mvsplat360/) |The MVSplat360 model offers a new way to create realistic 360° views of real-world scenes, even from just a few sparse images. |
|[Improved Multi-Task Brain Tumour Segmentation with Synthetic Data Augmentation.](https://arxiv.org/abs/2411.04632v1) | This paper presents the leading approach for brain tumor segmentation in the BraTS challenge, demonstrating how synthetic data can improve AI models for medical imaging applications.|

## Perspectives
|Link|description|
|---|---|
|[Embeddings are underrated.](https://technicalwriting.dev/data/embeddings.html) | Machine learning embeddings can revolutionize technical writing by enabling mathematical comparisons of any text, enhancing features like recommendation systems through semantic similarities. By positioning text in a multi-dimensional space, they reveal intuitive semantic relationships, which are valuable for tasks such as finding related content. Documentation site owners who provide embeddings for their content could inspire innovative applications from their communities.|
|[The images of Spain’s floods weren’t created by AI. The trouble is, people think they were.](https://www.theguardian.com/commentisfree/2024/nov/09/the-images-of-spains-floods-werent-created-by-ai-the-trouble-is-people-think-they-were) |The rapid growth of ‘AI slop’ – content created by artificial tools – is starting to warp our perception of what is, or could be, real |
|[What Trump’s election win could mean for AI, climate and health.](https://www.nature.com/articles/d41586-024-03667-w) |Donald Trump made numerous promises during his presidential campaign that could affect scientists and science policy. Will they be implemented once he is president? |
|[The case for targeted regulation.](https://www.anthropic.com/news/the-case-for-targeted-regulation) | Advancements in AI are significantly enhancing capabilities in mathematics, coding, and science, presenting both opportunities and risks. Effective regulation is crucial to prevent misuse in areas such as cybersecurity and chemical, biological, radiological, and nuclear (CBRN) threats. Anthropic's Responsible Scaling Policy emphasizes transparency and advocates for a balanced legislative approach that ensures safety while fostering innovation. |
|[AI-powered parenting is here and a16z is ready to back it .](https://techcrunch.com/2024/11/07/ai-powered-parenting-is-here-and-a16z-is-ready-to-back-it/) | Andreessen Horowitz partner Justine Moore introduced a new investment thesis for the firm on X on Thursday, endorsing “a new wave of ‘parenting co-pilots’ built with LLMs and agents.” She pointed to companies like Cradlewise, makers of an AI-powered baby monitor to detect a baby’s sleep pattern and rock the crib, and Nanit, which uses AI to process crib footage to tell if a baby is breathing. |
|[Speculation on Test Time Compute.](https://www.youtube.com/watch?v=6PEJ96k1kiw&ab_channel=SashaRush%F0%9F%A4%97) | This video discusses O1 models, their capacity for replication, and their potential utility for a range of future tasks.|
|[Can AI review the scientific literature — and figure out what it all means?](https://www.nature.com/articles/d41586-024-03676-9) |Artificial intelligence could help speedily summarize research. But it comes with risks. |
|[Why we are all lab rats in the digital world.](https://www.nature.com/articles/d41586-024-03674-x) |Researchers need to establish robust ethical protocols for online experiments. |
|[Don’t blame search engines for sending users to unreliable sites.](https://www.nature.com/articles/d41586-024-03574-0) |Analysis of billions of pages of results from searches using the Bing algorithm suggests that reliable sites appear in search results 19 to 45 times more often than do sites with low-quality content. |
|[AI-generated images threaten science — here’s how researchers hope to spot them.](https://www.nature.com/articles/d41586-024-03542-8) | Generative-AI technologies can create convincing scientific data with ease — publishers and integrity specialists fear a torrent of faked science.|
|[The quest to build bionic limbs that feel like the real thing.](https://www.nature.com/articles/d41586-024-03675-w) | Through brain implants, neural interfaces and skin grafts, researchers are starting to restore sensation for paralysed or amputated limbs.|
|[How AI is reshaping science and society.](https://www.nature.com/articles/d41586-024-03679-6) | Artificial-intelligence tools such as ChatGPT might soon become fully autonomous by learning to perceive and interact with their environment.|
|[‘It gets more and more confused’: can AI replace translators?](https://www.theguardian.com/books/2024/nov/11/it-gets-more-and-more-confused-can-ai-replace-translators) |A Dutch publisher has announced that it will use AI to translate some of its books – but those in the industry are worried about the consequences if this becomes the norm |
|[StackBlitz achieves $4M ARR in 4 weeks for their AI web development platform with Claude.](https://www.anthropic.com/customers/stackblitz) |StackBlitz developed an online developer tool that integrates closely with Claude 3.5 Sonnet. This post details how the company achieved $4 million in annual recurring revenue within a few months. |
|[Why the deep learning boom caught almost everyone by surprise.](https://www.understandingai.org/p/why-the-deep-learning-boom-caught) |Fei-Fei Li's development of the extensive ImageNet dataset played a crucial role in the revival of neural networks. It supplied the training data essential for landmark models such as AlexNet. Using GPUs and Geoffrey Hinton's backpropagation method, AlexNet showcased the potential of deep learning on large datasets, igniting the current AI revolution. This key event highlighted the significance of integrating neural networks, big data, and GPU computing to drive AI advancements. |
|[Just Have AI Build an App for That.](https://davidgomes.com/just-have-ai-build-an-app-for-that/) | AI agents are increasingly being used to quickly create functional apps for tasks like resizing SVGs.|
|[AI isn’t about unleashing our imaginations, it’s about outsourcing them. The real purpose is profit.](https://www.theguardian.com/technology/2024/nov/16/ai-isnt-about-unleashing-our-imaginations-its-about-outsourcing-them-the-real-purpose-is-profit) |Artificial intelligence doesn’t just incrementally erode the rights of authors and other creators. These technologies are designed to replace creative workers altogether |
|[Companies building AI-powered tech are using your posts. Here’s how to opt out.](https://www.theguardian.com/technology/2024/nov/15/x-ai-gmail-meta-privacy-settings) | ven if you haven’t knowingly opted in, companies are still scraping your personal information to train their systems|







# ML news: Week 3 - 10 November

## Research
|Link|description|
|---|---|
|[The Geometry of Concepts: Sparse Autoencoder Feature Structure.](https://arxiv.org/abs/2410.19750) |This study investigates the geometric structure of concept representations in sparse autoencoders (SAEs) across three scales: (1) atomic-level parallelogram patterns among related concepts (e.g., man:woman::king:queen), (2) brain-like functional "lobes" dedicated to different knowledge types such as math or code, and (3) galaxy-level eigenvalue distributions, revealing a specialized structure within the middle layers of the model. |
|[Arithmetic Without Algorithms: Language Models Solve Math With a Bag of Heuristics.](https://arxiv.org/abs/2410.21272) | This approach employs causal analysis to identify neurons that reveal an LLM's behavior when performing basic arithmetic logic. It discovers and theorizes that a combination of heuristic neurons serves as the mechanism for generating accurate arithmetic answers, with the unordered blend of various heuristic types accounting for most of the model's accuracy on arithmetic prompts.|
|[Relaxed Recursive Transformers: Effective Parameter Sharing with Layer-wise LoRA.](https://arxiv.org/abs/2410.20672) | The Relaxed Recursive Transformer introduces a novel method for reducing LLM size by sharing parameters across layers without sacrificing performance. Initialized from standard pretrained Transformers, it employs a single block of unique layers repeated multiple times in a loop, adding flexibility through depth-wise low-rank adaptation (LoRA) modules. This approach demonstrates potential for significant (2-3×) improvements in inference throughput.|
|[What Happened in LLMs Layers when Trained for Fast vs. Slow Thinking: A Gradient Perspective.](https://github.com/mingliiii/layer_gradient) | This project examines how varying "thinking" styles—fast (concise) versus slow (detailed, such as chain-of-thought reasoning)—affect layer-wise gradients and stability in LLMs.|
|[B-cosification: Transforming Deep Neural Networks to be Inherently Interpretable.](https://arxiv.org/abs/2411.00715v1) |"B-cosification" is a technique that adjusts existing pre-trained models to provide highly interpretable explanations of their predictions. |
|[Learning Graph Quantized Tokenizers for Transformers.](https://arxiv.org/abs/2410.13798v1) | GQT (Graph Quantized Tokenizer) is a novel tokenizer for graph data in geometric deep learning.|
|[V-DPO: Mitigating Hallucination in Large Vision Language Models via Vision-Guided Direct Preference Optimization.](https://arxiv.org/abs/2411.02712v1) |Vision-guided Direct Preference Optimization (V-DPO) tackles hallucination problems in large vision-language models (LVLMs), where text responses may diverge from visual input due to an excessive focus on language. |
|[Adam Alternative for Deep Learning Optimization.](https://arxiv.org/abs/2411.02853v1) |ADOPT is an adaptive gradient optimizer designed to resolve the non-convergence problems of Adam, without depending on restrictive assumptions regarding gradient noise. |
|[A faster, better way to train general-purpose robots.](https://news.mit.edu/2024/training-general-purpose-robots-faster-better-1028) |Inspired by large language models, researchers develop a training technique that pools diverse data to teach robots new skills. |
|[Vision Language Models are In-Context Value Learners.](https://generative-value-learning.github.io/) |Visual Language Models (VLMs) are capable of learning skills through the use of prompts. |


## News
|Link|description|
|---|---|
|[Elon Musk’s ‘election integrity community’ on X is full of baseless claims.](https://www.theguardian.com/technology/2024/oct/31/elon-musk-election-integrity-community-misinformation-disinformation) | Feed is rife with posts of individuals deemed suspicious and calls for doxxing with little evidence provided of fault|
|[Microsoft sails as AI boom fuels double-digit growth in cloud business.](https://www.theguardian.com/technology/2024/oct/30/microsoft-earnings-increase-ai) |Revenue from Azure cloud business increased by 22% as company focuses attention on artificial intelligence |
|[Apple reports robust demand for iPhone 16 even as overall sales in China slow.](https://www.theguardian.com/technology/2024/oct/31/apple-quarterly-earnings-iphone-16-china) | Company reports $94.9bn in revenue, slightly beating Wall Street projections in first look at demand for its new phone|
|[Distinguishing Ignorance from Error in LLM Hallucinations.](https://arxiv.org/abs/2410.22071) |This report describes efforts to replicate the capabilities of OpenAI's o1 model, introducing a journey learning technique that promotes a comprehensive exploration process rather than shortcut-based learning. This approach includes trial and error, reflection, and backtracking. With just 327 training samples, the journey learning technique outperformed shortcut learning by 8.0% on the MATH dataset. |
|[Investigating the Role of Prompting and External Tools in Hallucination Rates of Large Language Models.](https://arxiv.org/abs/2410.19385) |This study evaluates various prompting strategies and frameworks to minimize hallucinations in LLMs, finding that simpler prompting techniques outperform more complex approaches. It also reports that LLM agents show higher hallucination rates due to the increased complexity involved in using tools. |
|[Introducing the First AMD 1B Language Models: AMD OLMo.](https://www.amd.com/en/developer/resources/technical-articles/introducing-the-first-amd-1b-language-model.html) |AMD utilized the OLMo codebase to train and release a language model on its accelerators. The OLMo (Open Language Model) project, developed by the Allen Institute for AI (AI2), provides an open-source framework for training and using state-of-the-art language models.  |
|[OpenAI will start using AMD chips and could make its own AI hardware in 2026.](https://www.theverge.com/2024/10/29/24282843/openai-custom-hardware-amd-nvidia-ai-chips) | Reuters reports an updated hardware strategy to run ChatGPT and OpenAI’s other projects involves using AMD chips via Microsoft Azure in addition to Nvidia.|
|[Can Language Models Perform Robust Reasoning in Chain-of-thought Prompting with Noisy Rationales?](https://arxiv.org/abs/2410.23856v1) | This study addresses a specific challenge in LLMs: evaluating how effectively they process reasoning prompts that include irrelevant or incorrect rationale snippets.|
|[What is Wrong with Perplexity for Long-context Language Modeling?](https://arxiv.org/abs/2410.23771v1) | This study uncovers a significant limitation of using perplexity (PPL) to assess LLMs' long-context abilities, as PPL averages across all tokens, overlooking critical ones necessary for interpreting extended inputs. To address this, the authors propose LongPPL, a metric that emphasizes these essential tokens, providing a more accurate measure of long-context performance.|
|[Google’s AI search summaries are rolling out to over 100 more countrie.](https://www.theverge.com/2024/10/28/24281860/google-ai-search-summaries-expand-more-countries) |Google’s AI Overviews are expanding across more than 100 countries this week. The AI-generated search summaries will appear for users in Canada, Australia, New Zealand, South Africa, Colombia, Chile, the Phillippines, Nigeria, and many more locations. |
|[Elon Musk finally admits Tesla’s HW3 might not support full self-driving.](https://electrek.co/2024/10/23/elon-musk-finally-admits-teslas-hw3-might-not-support-full-self-driving/) | Elon Musk finally admits Tesla’s HW3 might not support full self-driving and that he doesn’t actually know what it will take. Millions of Tesla vehicles are equipped with HW3 computers.|
|[NVIDIA Ethernet Networking Accelerates World’s Largest AI Supercomputer, Built by xAI.](https://nvidianews.nvidia.com/news/spectrum-x-ethernet-networking-xai-colossus) |xAI's Colossus is powered by NVIDIA's Spectrum-X Ethernet networking platform. |
|[French parents whose children took own lives sue TikTok over harmful content.](https://www.theguardian.com/technology/2024/nov/04/french-families-sue-tiktok-exposure-harmful-content-suicide-self-harm-eating-disorders) |Lawsuit alleges TikTok’s algorithm exposed teenagers to videos promoting suicide, self-harm and eating disorders |
|[Claude 3.5 Haiku now available.](https://www.anthropic.com/claude/haiku) | Claude 3.5 Haiku is slightly inferior to GPT-4o and lacks vision capabilities, but it remains highly intelligent and is cost-effective compared to other models of similar quality.|
|[7 AI news that Google announced in October.](https://blog.google/technology/ai/google-ai-updates-october-2024/) |This article summarizes seven AI updates from October, including Google Maps' largest AI enhancement, guidance on using NotebookLM, and additional methods for asking questions, searching for information, and accessing an AI Overview. |
|[Sapien Raises $8.7M Seed Led by General Catalyst.](https://www.getsapien.com/blog-posts/sapien-raises-8-7m-seed-led-by-general-catalyst) | Sapien is advancing AI-driven financial analysis tools that convert intricate, error-prone tasks into swift insights, revolutionizing the role of Chief Financial Officers (CFOs). The platform consolidates data from diverse sources to deliver dynamic, context-aware analyses, aiming to eradicate human errors in financial processes. Recently, Sapien secured $8.7 million in funding, with plans to expand and enhance its AI capabilities to empower finance teams across various industries|
|[ElevenLabs has hired the team behind Omnivore, a reader app.](https://techcrunch.com/2024/10/29/elevenlabs-has-hired-the-team-behind-omnivore-a-reader-app/) |Generative AI company ElevenLabs has hired the team behind Omnivore, an open source read-it-later app. |
|[LinkedIn launches its first AI agent to take on the role of job recruiters.](https://techcrunch.com/2024/10/29/linkedin-launches-its-first-ai-agent-to-take-on-the-role-of-job-recruiters/) |  Hiring Assistant is a new product designed to take on a wide array of recruitment tasks, from ingesting scrappy notes and thoughts to turn into longer job descriptions to sourcing candidates and engaging with them. |
|[Anthropic’s Claude AI chatbot now has a desktop app.](https://www.theverge.com/2024/10/31/24284742/claude-ai-macos-windows-desktop-app) | Claude, the AI chatbot made by Anthropic, now has a desktop app. You can download the Mac and Windows versions of the app from Anthropic’s website for free.|
|[Meta is making a robot hand that can ‘feel’ touch.](https://techcrunch.com/2024/10/31/meta-is-making-a-robot-hand-that-can-feel-touch/) |Meta says it’s partnering with sensor firm GelSight and Wonik Robotics, a South Korean robotics company, to commercialize tactile sensors for AI. |
|[Elon Musk sued over $1m-a-day election giveaway.](https://www.theguardian.com/technology/2024/nov/05/elon-musk-america-pac-election-giveaway-lawsuit) | Complaint alleges Musk’s America Pac deceived voters by falsely claiming prize winners would be chosen at random|
|[AI chatbot launches on Gov.UK to help business users – with mixed results.](https://www.theguardian.com/technology/2024/nov/05/ai-chatbot-launches-on-govuk-to-help-business-users-with-mixed-results) | Initial test run of GPT-4o technology can help with regulations but ‘cannot provide predictions or opinions’|
|[OpenAI’s o1 model leaked on Friday and it is wild — here’s what happened.](https://www.tomsguide.com/ai/chatgpt/openais-o1-model-leaked-on-friday-and-it-is-wild-heres-what-happened) |OpenAI's o1 model demonstrates notable advancements in reasoning and accuracy compared to GPT-4, featuring image analysis and web tool capabilities. The complete version is expected to significantly enhance AI and multimedia processing, with an official release anticipated shortly after the U.S. Presidential election. |
|[Meta’s former hardware lead for Orion is joining OpenAI.](https://techcrunch.com/2024/11/04/metas-former-hardware-lead-for-orion-is-joining-openai/) | The former head of Meta’s augmented reality glasses efforts announced on Monday she is joining OpenAI to lead robotics and consumer hardware, according to a post on LinkedIn.|
|[Waymo explores using Google’s Gemini to train its robotaxis.](https://www.theverge.com/2024/10/30/24283516/waymo-google-gemini-llm-ai-robotaxi) | The company used Gemini to build its own ‘End-to-End Multimodal Model for Autonomous Driving.’|
|[More than a quarter of new code at Google is generated by AI .](https://www.theverge.com/2024/10/29/24282757/google-new-code-generated-ai-q3-2024) |AI is hugely important to Google’s products, and it sounds like the company relies on it internally, too. |
|[Meta is using more than 100,000 Nvidia H100 AI GPUs to train Llama-4 — Mark Zuckerberg says that Llama 4 is being trained on a cluster “bigger than anything that I’ve seen”.](https://www.tomshardware.com/tech-industry/artificial-intelligence/meta-is-using-more-than-100-000-nvidia-h100-ai-gpus-to-train-llama-4-mark-zuckerberg-says-that-llama-4-is-being-trained-on-a-cluster-bigger-than-anything-that-ive-seen) |Llama 4 slated to have new modalities, stronger reasoning, and faster performance |
|[Wonder Dynamics now lets you go straight from multi-camera video to fully animated 3D scene.](https://techcrunch.com/2024/10/30/wonder-dynamics-now-lets-you-go-straight-from-multi-camera-video-to-fully-animated-3d-scene/) |Wonder Dynamics launched a tool that automates converting videos into fully editable 3D scenes. |
|[Facebook asks US supreme court to dismiss fraud suit over Cambridge Analytica scandal.](https://www.theguardian.com/technology/2024/nov/06/facebook-cambridge-analytica-lawsuit) | Securities fraud lawsuit brought by shareholders accuses the social media platform of misleading them about misuse of user data|
|[Anthropic hikes the price of its Haiku model.](https://techcrunch.com/2024/11/04/anthropic-hikes-the-price-of-its-haiku-model/) | Anthropic's latest AI model, Claude 3.5 Haiku, delivers better performance than Claude 3 Opus but comes with a much higher cost. While it doesn’t support image analysis, it excels in tasks like coding, data extraction, and content moderation. The price hike prompts concerns about Anthropic's future pricing approach.|
|[OpenAI acquired Chat.com.](https://techcrunch.com/2024/11/06/openai-acquired-chat-com/) |OpenAI bought Chat.com, adding to its collection of high-profile domain names. As of this morning, Chat.com now redirects to OpenAI’s AI-powered chatbot, ChatGPT. An OpenAI spokesperson confirmed the acquisition via email. |
|[Pushing the frontiers of audio generation.](https://deepmind.google/discover/blog/pushing-the-frontiers-of-audio-generation/) |ADOPT is an adaptive gradient optimizer designed to resolve the non-convergence problems of Adam, without depending on restrictive assumptions regarding gradient noise. |
|[Octoverse: AI leads Python to top language as the number of global developers surges.](https://github.blog/news-insights/octoverse/octoverse-2024/) | AI project engagement has surged rapidly due to a rise in data science and machine learning activities. Python has now become more popular than JavaScript. The developer community is experiencing global growth, particularly in Africa, Latin America, and Asia, driven by tools like GitHub Copilot. There is also a growing trend toward creating smaller, more efficient AI models. Additionally, generative AI projects have almost doubled worldwide.|
|[Nvidia to join Dow Jones Industrial Average, replacing rival chipmaker Intel.](https://www.cnbc.com/2024/11/01/nvidia-to-join-dow-jones-industrial-average-replacing-intel.html) |Nvidia is replacing Intel in the Dow Jones Industrial Average, a shakeup that reflects a massive change in the semiconductor industry. Nvidia shares have gained more than 170% this year, while Intel has lost over half its value.|
|[Google's 'Big Sleep' AI Project Uncovers Real Software Vulnerabilities.](https://www.pcmag.com/news/googles-big-sleep-ai-project-uncovers-real-software-vulnerabilities) | The company's experimental AI agent finds a previously unknown and exploitable software bug in SQLite, an open-source database engine.|
|[Amazon will now use AI to recap what you're watching.](https://www.engadget.com/entertainment/streaming/amazon-will-now-use-ai-to-recap-what-youre-watching-194551857.html) | Amazon's X-Ray Recaps is an AI-driven feature on Prime Video that generates personalized summaries for TV shows. It utilizes generative AI to create concise recaps of entire seasons, individual episodes, or specific segments, enhancing the viewing experience by helping users recall previous content without revealing spoilers. Currently in beta, X-Ray Recaps is available on Fire TV devices, with plans to expand to additional devices by the end of the year.|
|[Google is opening an AI hub in oil-rich Saudi Arabia.](https://techcrunch.com/2024/11/05/google-is-opening-an-ai-hub-in-oil-rich-saudi-arabia/) | The new AI hub will support research into Arab language AI models and “Saudi-specific AI applications,” according to an announcement from the Saudi Public Investment fund and Google.|
|[First artwork painted by humanoid robot to sell at auction fetches $1m.](https://www.theguardian.com/artanddesign/2024/nov/08/alan-turing-portrait-ai-da-robot-painting-sale-price-auction) | Portrait of English mathematician Alan Turing was created by Ai-Da, one of the most advanced robots in the world|
|[Mistral launches a moderation API.](https://techcrunch.com/2024/11/07/mistral-launches-a-moderation-api/) |AI startup Mistral has launched a new API for content moderation. |
|[Anthropic and Palantir Partner to Bring Claude AI Models to AWS for U.S. Government Intelligence and Defense Operations.](https://investors.palantir.com/news-details/2024/Anthropic-and-Palantir-Partner-to-Bring-Claude-AI-Models-to-AWS-for-U.S.-Government-Intelligence-and-Defense-Operations/) | Palantir and Anthropic have collaborated to make the Claude suite of models available on AWS for U.S. intelligence agencies and defense operations.|
|[ChatGPT Can Now Control a Robot Arm.](https://futurism.com/the-byte/chatgpt-control-robot-arm-clean-spill) |Researchers from UC Berkeley and ETH Zurich utilized GPT-4 to train cost-effective robot arms for cleaning spills. They accomplished this by incorporating a multimodal agent called LangChain, which translates LLM inputs into robotic actions. This research demonstrates a novel proof-of-concept for human-robot interaction and democratizes robotics using open-source technology. |
|[OpenAI in talks with regulators to become a for-profit company: Report.](https://cointelegraph.com/news/chat-gpt-creator-openai-in-talks-for-profit-company) |The $157 billion artificial intelligence giant wants to retain a nonprofit arm to pursue its mission of benevolent AI development.  |



## Resources
|Link|description|
|---|---|
|[AFlow: Automating Agentic Workflow Generation.](https://arxiv.org/abs/2410.10762) |A novel framework for automating agentic workflow generation, AFlow, reframes workflow optimization as a search problem over code-based workflows, where nodes invoking LLMs are linked by edges. It efficiently navigates the search space using a modified MCTS, refining workflows through code adjustments, tree-structured experience, and execution feedback. Tests on six benchmark datasets show AFlow’s effectiveness, with a 5.7% improvement over manual methods and a 19.5% boost over other automated approaches. AFlow also allows smaller models to outperform GPT-4 on specific tasks, requiring only 4.55% of its inference cost. |
|[O1 Replication Journey: A Strategic Progress Report -- Part 1.](https://arxiv.org/abs/2410.18982) | This report describes efforts to replicate the capabilities of OpenAI's o1 model, introducing a journey learning technique that promotes a comprehensive exploration process rather than shortcut-based learning. This approach includes trial and error, reflection, and backtracking. With just 327 training samples, the journey learning technique outperformed shortcut learning by 8.0% on the MATH dataset.|
|[Beyond Text: Optimizing RAG with Multimodal Inputs for Industrial Applications.](https://arxiv.org/abs/2410.21943) |This work offers insights on effectively integrating multimodal models into Retrieval-Augmented Generation (RAG) systems for the industrial sector. It also delves into evaluating these systems, utilizing LLM-as-a-Judge for comprehensive assessment. |
|[You won't believe this.](https://www.science.org/content/article/can-people-be-inoculated-against-misinformation) |Researchers are trying to “inoculate” people against misinformation by giving them small doses ahead of time |
|[3D Scene Reconstruction Without Camera Pose.](https://noposplat.github.io/) | NoPoSplat is a feed-forward model capable of reconstructing 3D scenes from sparse, multi-view images without requiring precise camera poses.|
|[ImOV3D: Learning Open Vocabulary Point Clouds 3D Object Detection from Only 2D Images.](https://github.com/yangtiming/imov3d) |ImOV3D is a framework that enhances open-vocabulary 3D object detection (OV-3Det) by utilizing 2D images to address the limited availability of 3D annotations. |
|[Enhancing Motion in Text-to-Video Generation with Decomposed Encoding and Conditioning.](https://pr-ryan.github.io/DEMO-project/) | DEMO is a framework that divides text and conditioning into content and motion elements. By employing separate encoders and conditioning for static content and dynamic motion, DEMO improves its ability to interpret and generate motion based on text prompts.|
|[Project Sid.](https://threadreaderapp.com/thread/1852397383939960926.html) |Project Sid demonstrates civilizational progress, specialization, governance, and the creation and dissemination of memes and religion. These developments are enabled by Altera's innovative cognitive architecture, PIANO. |
|[Using Reinforcement Learning and $4.80 of GPU Time to Find the Best HN Post Ever.](https://openpipe.ai/blog/hacker-news-rlhf-part-1) | This article explores the use of reinforcement learning from human feedback (RLHF) to create a reward model that predicts upvote counts for Hacker News stories. Using a rich dataset and only $4.80 of GPU time, the model was trained on attributes like titles, authors, and content to prioritize post quality. The goal is to apply RLHF to foster the generation of high-value content. While not flawless, the model effectively identifies overlooked stories and can anticipate potential front-page hits.|
|[Models for PII detection.](https://gretel.ai/blog/gliner-models-for-pii-detection) | The GLINER models and dataset are synthetic datasets designed specifically for use with synthetic data.|
|[Randomized Autoregressive Visual Generation.](https://arxiv.org/abs/2411.00776v1) |This study presents Randomized AutoRegressive (RAR) modeling for image generation, achieving state-of-the-art performance on the ImageNet-256 benchmark with an impressive FID score of 1.48. |
|[hertz-dev-open source speech-to-speech.](https://github.com/Standard-Intelligence/hertz-dev) | An exceptionally impressive open release with a permissive license, this model was trained to generate human speech from various input modalities. The code is of high quality and includes intriguing details about the encoder and decoder architectures.|
|[DiffeRT.](https://github.com/jeertmans/DiffeRT) |This project introduces an innovative Machine Learning-assisted Ray Tracing method for radio propagation modeling, aimed at reducing the high computational demands of conventional approaches. |
|[How I write code using Cursor: A review.](https://www.arguingwithalgorithms.com/posts/cursor-review.html) |Cursor, a VS Code fork, incorporates LLM-powered features like tab completion and chat interfaces to simplify coding by automating boilerplate and repetitive changes. Although tab completion is quick and efficient, it occasionally provides incorrect suggestions. The tool promotes new workflow patterns, minimizing dependency on libraries for boilerplate and enabling faster iteration in unfamiliar languages or frameworks.|
|[MVPaint: Synchronized Multi-View Diffusion for Painting Anything 3D.](https://mvpaint.github.io/) | MVPaint addresses the challenges of texture and UV generation for 3D assets by synchronizing these processes, resulting in high-quality, multi-view consistent textures|
|[OS-ATLAS: A Foundation Action Model For Generalist GUI Agents.](https://osatlas.github.io/) | MVPaint tackles the difficulties of texture and UV generation for 3D assets by synchronizing these tasks, producing high-quality, multi-view consistent textures.|
|[PPLLaVA: Short and Long Video Understanding.](https://github.com/farewellthree/ppllava) |PPLLaVA is a novel model designed to effectively comprehend both short and long videos, addressing a significant challenge in video-based AI. It employs a unique pooling strategy that compresses visual tokens and aggregates features based on user instructions, enhancing its ability to process varied video lengths. This approach enables PPLLaVA to achieve state-of-the-art performance across various video benchmarks, excelling in tasks from caption generation to multiple-choice questions |
|[Hunyuan3D-1.](https://github.com/tencent/Hunyuan3D-1) |Hunyuan3D-1.0 is an advanced generative 3D model with robust multi-view synthesis capabilities. While its outputs may not yet be production-ready, they provide a valuable foundation for artists aiming to create assets. |
|[AndroidLab.](https://github.com/THUDM/Android-Lab) | Benchmark for autonomous agents on the Android mobile operating system.|
|[Constrained Human-AI Cooperation: An Inclusive Embodied Social Intelligence Challenge.](https://vis-www.cs.umass.edu/CHAIC) |Constrained Human-AI Cooperation (CHAIC) is a challenge aimed at evaluating the ability of AI agents to work effectively with humans who have physical constraints. |
|[A Scalable Communication Protocol for Networks of Large Language Models.](https://agoraprotocol.org/) | Agora is a straightforward, cross-platform protocol designed for efficient communication between LLM agents, allowing diverse agents to interact at a significantly reduced cost. It seamlessly integrates with existing multiagent frameworks like Camel AI, LangChain, and Swarm.|
|[Classification Done Right for Vision-Language Pre-Training.](https://arxiv.org/abs/2411.03313v2) | SuperClass is a simple classification model for vision-language tasks that bypasses the need for a text encoder, unlike contrastive models such as CLIP. It eliminates the need for complex text filtering and large batch sizes by using tokenized raw text directly as classification labels.|
|[Enhancing RAG with HTML Data.](https://github.com/plageon/HtmlRAG) |HtmlRAG is an innovative approach that enhances retrieval-augmented generation (RAG) by preserving the HTML structure of retrieved web content rather than simplifying it to plain text. |
|[LiVOS: Light Video Object Segmentation with Gated Linear Matching.](https://github.com/uncbiag/livos) |LiVOS is a lightweight video object segmentation (VOS) model designed to lower memory usage, making it possible to segment long, high-resolution videos with reduced hardware requirements. |
|[How To Create Software Diagrams With ChatGPT and Claude.](https://thenewstack.io/how-to-create-software-diagrams-with-chatgpt-and-claude/) |The article discusses how developers can leverage ChatGPT and Claude to generate software architecture diagrams. It emphasizes the iterative process of refining diagrams with the help of multimodal AI and tools such as Mermaid and Whimsical. The author showcases the advantages of using LLMs for diagramming, illustrating how they handle images and offer real-time feedback. |
|[Magentic-One: A Generalist Multi-Agent System for Solving Complex Tasks.](https://www.microsoft.com/en-us/research/articles/magentic-one-a-generalist-multi-agent-system-for-solving-complex-tasks/) |Microsoft has introduced Magnetic-One, a multi-agent system built upon its open-source AutoGen framework. This system utilizes GPT-4o as the backend model to facilitate agentic behavior, enabling the orchestration of multiple AI agents to perform complex tasks.  |
|[Cosmos Tokenizer: A suite of image and video neural tokenizers.](https://research.nvidia.com/labs/dir/cosmos-tokenizer/) | NVIDIA has introduced the Cosmos Tokenizer, a state-of-the-art image and video tokenizer and compression model. This model is designed to facilitate the training of video generation systems, visual language models (VLMs), and other multimodal models. NVIDIA has made available the inference code, a research paper detailing the model, and the associated model weights.|
|[SA3DIP: Segment Any 3D Instance with Potential 3D Priors.](https://arxiv.org/abs/2411.03819v1) |SA3DIP is a novel method for enhancing 3D instance segmentation by integrating additional 3D priors beyond standard 2D models. This approach addresses the limitations of relying solely on 2D segmentation models, which often struggle with complex 3D structures. By incorporating 3D priors, SA3DIP achieves more accurate and robust segmentation in three-dimensional spaces. |
|[gsplat.](https://docs.gsplat.studio/main/) |G Splat is a robust package and studio designed for conducting research on Gaussian splatting. |
|[RaVL: Discovering and Mitigating Spurious Correlations in Fine-Tuned Vision-Language Models.](https://github.com/stanford-aimi/ravl) | RaVL is a novel approach that enhances the accuracy of vision-language models by concentrating on local image features instead of the whole image, aiming to reduce misleading correlations.|
|[Structure Consistent Gaussian Splatting with Matching Prior for Few-shot Novel View Synthesis.](https://arxiv.org/abs/2411.03637v1) | SCGaussian is an innovative method for 3D scene synthesis that preserves structural consistency, even when working with sparse input data.|


## Perspectives
|Link|description|
|---|---|
|[The chatbot optimisation game: can we trust AI web searches?](https://www.theguardian.com/technology/2024/nov/03/the-chatbot-optimisation-game-can-we-trust-ai-web-searches) |Google and its rivals are increasingly employing AI-generated summaries, but research indicates their results are far from authoritative and open to manipulation |
|[Addicted to love: how dating apps ‘exploit’ their users.](https://www.theguardian.com/lifeandstyle/2024/nov/03/addicted-to-love-how-dating-apps-exploit-their-users) | Online services that promise to find people romantic matches have been likened to gambling products designed to keep customers hooked|
|[Concerned about your data use? Here is the carbon footprint of an average day of emails, WhatsApps and more.](https://www.theguardian.com/environment/2024/oct/31/concerned-about-your-data-use-here-is-the-carbon-footprint-of-an-average-day-of-emails-whatsapps-and-more) | Vast datacentres are being built worldwide, amid growing concerns about the environmental costs. So should we all be considering a data diet – if not complete digital sobriety?|
|[A field’s dilemmas.](https://www.science.org/content/article/five-biggest-challenges-facing-misinformation-researchers) |Misinformation research has exploded. But scientists are still grappling with fundamental challenges |
|[We're forking Flutter. This is why.](https://flutterfoundation.dev/blog/posts/we-are-forking-flutter-this-is-why/) |Google's strategic shift towards AI has led to a deprioritization of Flutter's desktop platforms, resulting in a labor shortage for this previously fast-growing UI toolkit. In response, a fork named Flock is being developed to incorporate essential bug fixes and features that the Flutter team is unable to address, aiming to accelerate Flutter's growth through community involvement. Flock plans to enhance contribution processes and streamline PR reviews, bridging the gap in support and development pace left by the main Flutter team.  |
|[Devious humour and painful puns: will the cryptic crossword remain the last thing AI can’t conquer?](https://www.theguardian.com/crosswords/crossword-blog/2024/nov/04/cryptic-crossword-ai-conquer-human-solvers-artificial-intelligence-software) |When human solvers battle artificial intelligence, who is able to think more cryptically, faster? And are some devious clues just too tough for software? |
|[Meta’s AI Abundance.](https://stratechery.com/2024/metas-ai-abundance/) |Meta is strategically poised to leverage generative AI, particularly in digital advertising. The company's investments in AI, including its Llama models, support innovative advertising strategies like generative ads and AI-driven chat agents. These advancements aim to enhance ad targeting and efficiency, potentially boosting demand and revenue. Meta's focus on integrating AI across its platforms underscores its commitment to maintaining a competitive edge in the rapidly evolving AI landscape. |
|[The AI Services Wave: Lessons from Palantir in The New Age of AI.](https://www.8vc.com/resources/the-ai-services-wave-lessons-from-palantir-in-the-new-age-of-ai) |Artificial intelligence (AI) is transforming service industries by enhancing scalability and efficiency. Companies like Palantir are at the forefront, integrating AI into operations to streamline processes. Startups are also leveraging AI to automate complex tasks, creating significant value and reshaping business models. The emphasis is on developing AI-driven "tech-services" that blend software capabilities with human expertise, leading to improved outcomes and increased market competitiveness. |
|[X reaches its final form: Elon Musk has bent it to his will.](https://www.theguardian.com/technology/2024/nov/04/elon-musk-x-network-donald-trump) |The evolution of Musk’s X network is complete; why Reddit is profitable; and niche Halloween costumes |
|[AI for Startups.](https://blogs.microsoft.com/on-the-issues/2024/11/01/ai-for-startups/) |Microsoft and a16z are advocating for collaboration between large and small tech companies to promote AI innovation and competition. They support open-source AI and have proposed policies to assist startups and level the playing field in the AI economy. Their joint focus is on creating a robust, competitive ecosystem that leverages AI to drive economic growth and innovation. |
|[How The New York Times is using generative AI as a reporting tool.](https://arstechnica.com/ai/2024/10/the-new-york-times-shows-how-ai-can-aid-reporters-without-replacing-them) |New York Times reporters utilized AI tools, specifically LLMs, to transcribe and analyze over 400 hours of audio for an investigation. Automated transcription greatly accelerated the work, with LLMs accurately identifying key themes and topics. Human reporters ensured proper interpretation and contextual understanding, highlighting the significance of human-AI collaboration. |
|[Writing as a Way of Thinking.](https://every.to/chain-of-thought/writing-as-a-way-of-thinking) | The article explores AI's influence on writing and thinking, challenging the idea that writing is the sole form of thinking. Tools like ChatGPT can enhance thinking through dialogue. Rather than replacing thought processes, AI can augment them. It will transform writing by automating routine tasks, freeing up space for more creative and thought-provoking content.|
|[ChatGPT is transforming peer review — how can we use it responsibly?](https://www.nature.com/articles/d41586-024-03588-8) |At major computer-science publication venues, up to 17% of the peer reviews are now written by artificial intelligence. We need guidelines before things get out of hand. |
|[Will AI’s huge energy demands spur a nuclear renaissance?](https://www.nature.com/articles/d41586-024-03490-3) |Contracts with Google and Amazon could help, but bringing new types of reactor online will take larger investments — and time. |
|[Five protein-design questions that still challenge AI.](https://www.nature.com/articles/d41586-024-03595-9) |Tools such as Rosetta and AlphaFold have redefined the protein-engineering landscape. But some problems remain out of reach — for now. |
|[AI may displace 3m jobs but long-term losses ‘relatively modest’, says Tony Blair’s thinktank.](https://www.theguardian.com/technology/2024/nov/08/ai-may-displace-3m-jobs-but-long-term-losses-relatively-modest-says-thinktank) | Rise in unemployment in low hundreds of thousands as technology creates roles, Tony Blair Institute suggests|
|[The Rise of the Agentic Web.](https://paragraph.xyz/@cryptso/onchain-ai) | The Agentic Web is advancing the capabilities of AI agents with on-chain features, enabling their creation, ownership, and transactional abilities. Platforms like Replit, VIRTUALS.io, and Wayfinder are integrating AI with blockchain, facilitating activities such as asset management, data retrieval, and decentralized applications. This shift supports AI-driven automation for payments, trading, and decentralized finance within blockchain ecosystems.|
|[The Present Future: AI's Impact Long Before Superintelligence.](https://www.oneusefulthing.org/p/the-present-future-ais-impact-long) | Stronger AI models are on the verge of surpassing human intelligence, driving transformative changes in work and society. Current AI systems, such as Claude, are already reshaping industries by automating tasks, offering safety monitoring, and enabling interactions through multimodal inputs and outputs. Organizations must carefully address ethical concerns to ensure AI complements and enhances human abilities, rather than replacing them.|


# ML news: Week 28 October - 3 November

## Research

|Link|description|
|---|---|
|[A Theoretical Understanding of Chain-of-Thought.](https://arxiv.org/abs/2410.16540) |reveals that incorporating both correct and incorrect reasoning paths in demonstrations enhances the accuracy of intermediate steps and Chain-of-Thought (CoT) processes. The new approach, called Coherent CoT, substantially boosts performance across multiple benchmarks. Specifically, Gemini Pro shows a 6.60% improvement on the Tracking Shuffled Objects dataset (rising from 58.20% to 64.80%), while DeepSeek 67B achieves a 6.17% increase on the Penguins in a Table dataset (from 73.97% to 80.14%). |
|[LongRAG: A Dual-Perspective Retrieval-Augmented Generation Paradigm for Long-Context Question Answering.](https://arxiv.org/abs/2410.18050) |improves RAG's comprehension of long-context knowledge, incorporating global insights and factual specifics. It features a hybrid retriever, an LLM-enhanced information extractor, a Chain-of-Thought (CoT) guided filter, and an LLM-augmented generator. These core components empower the RAG system to extract global long-context information and accurately capture factual details. LongRAG demonstrates superior performance, surpassing long-context LLMs by 6.94%, advanced RAG by 6.16%, and Vanilla RAG by 17.25%. |
|[Evaluating feature steering: A case study in mitigating social biases.](https://www.anthropic.com/research/evaluating-feature-steering) |examines feature steering in LLMs through an experiment that adjusts various features to observe shifts in model outputs, specifically focusing on 29 features related to social biases to determine if feature steering can reduce these biases. Findings reveal that while feature steering can sometimes cause unintended effects, incorporating a neutrality feature effectively reduces social biases across 9 social dimensions without compromising text quality. |
|[Large Language Models Reflect the Ideology of their Creators.](https://arxiv.org/abs/2410.18417) |reveals that LLMs display varied ideological perspectives, often mirroring the worldview of their creators. It observes consistent normative differences in responses when the same LLM operates in Chinese versus English and highlights normative disagreements between Western and non-Western LLMs regarding prominent figures in geopolitical conflicts. |
|[Scalable watermarking for identifying large language model outputs.](https://www.nature.com/articles/s41586-024-08025-4) |introduces SynthID-Text, a text-watermarking approach designed to maintain text quality in LLM outputs, achieve high detection accuracy, and reduce latency. It incorporates watermarking through speculative sampling, using a final score pattern for model word choices alongside adjusted probability scores. The authors evaluate the method's feasibility and scalability by analyzing feedback on nearly 10 million Gemini responses. |
|[A Comparative Study on Reasoning Patterns of OpenAI's o1 Model.](https://arxiv.org/abs/2410.13639) |outperformed other test-time compute methods across most datasets. The authors note that the primary reasoning patterns in o1 are divide and conquer and self-refinement, with the model adapting its reasoning strategy to specific tasks. For commonsense reasoning, o1 frequently employs context identification and focuses on constraints, while for math and coding tasks, it predominantly utilizes method reuse and divide and conquer approaches. |
|[Sparse Crosscoders for Cross-Layer Features and Model Diffing.](https://transformer-circuits.pub/2024/crosscoders/index.html) |Crosscoders are an advanced form of sparse autoencoders designed to enhance the understanding of language models' internal mechanisms. |
|[Distill Visual Chart Reasoning Ability
from LLMs to MLLMs.](https://github.com/hewei2001/reachqa) | Code-as-Intermediary Translation (CIT) is an innovative technique aimed at improving visual reasoning in multimodal language models (MLLMs) by leveraging code to convert chart visuals into textual descriptions.|
|[Probabilistic Language-Image Pre-Training.](https://arxiv.org/abs/2410.18857v1) |Probabilistic Language-Image Pre-training (ProLIP) is a vision-language model (VLM) designed to learn probabilistically from image-text pairs. Unlike traditional models that rely on a strict one-to-one correspondence, ProLIP captures the complex many-to-many relationships inherent in real-world data. |
|[A faster, better way to train general-purpose robots.](https://news.mit.edu/2024/training-general-purpose-robots-faster-better-1028) | MIT researchers have developed Heterogeneous Pretrained Transformers (HPT), a novel model architecture inspired by large language models, designed to train adaptable robots by utilizing data from multiple domains and modalities.|
|[A Little Help Goes a Long Way: Efficient LLM Training by Leveraging Small LMs.](https://arxiv.org/abs/2410.18779) |In this work, DeepMind demonstrates how a small language model can be used to provide soft supervision labels and identify informative or challenging data points for pretraining, significantly accelerating the pretraining process. |
|[NeuroClips: Towards High-fidelity and Smooth fMRI-to-Video Reconstruction.](https://arxiv.org/abs/2410.19452v1) |The NeuroClips framework introduces advancements in reconstructing continuous videos from fMRI brain scans by decoding both high-level semantic information and fine-grained perceptual details. |
|[Machine-guided design of cell-type-targeting cis-regulatory elements.](https://www.nature.com/articles/s41586-024-08070-z) |A generalizable framework to prospectively engineer cis-regulatory elements from massively parallel reporter assay models can be used to write fit-for-purpose regulatory code. |


## News
|Link|description|
|---|---|
|[Keir Starmer says media firms should have control of output used in AI.](https://www.theguardian.com/media/2024/oct/28/keir-starmer-says-media-firms-should-have-control-of-output-used-in-ai) | PM says content creators must be paid and vows to ensure technology ‘does not begin to chip away’ at press freedoms|
|[Waymo raises $5.6B.](https://waymo.com/blog/2024/10/investing-to-bring-the-waymo-driver-to-more-riders/) | Waymo's driverless taxi service has gained significant popularity. The company has secured additional funding to extend its reach beyond the current cities and millions of miles it already covers.|
|[Meta Introduces Spirit LM open source model that combines text and speech inputs/outputs.](https://venturebeat.com/ai/meta-introduces-spirit-lm-open-source-model-that-combines-text-and-speech-inputs-outputs/?utm_source=tldrai) | Just in time for Halloween 2024, Meta has unveiled Meta Spirit LM, the company’s first open-source multimodal language model capable of seamlessly integrating text and speech inputs and outputs.|
|[IBM debuts open source Granite 3.0 LLMs for enterprise AI.](https://venturebeat.com/ai/ibm-debuts-open-source-granite-3-0-llms-for-enterprise-ai/) |IBM is enhancing its enterprise AI suite with Granite 3.0 LLMs, prioritizing open-source options and optimized performance. Available across various platforms, these models come with built-in safety features and are customized for diverse enterprise applications. IBM highlights the significance of true open-source licensing with Apache 2.0, enabling flexible adoption and fostering enterprise-driven innovation. |
|[Microsoft introduces ‘AI employees’ that can handle client queries.](https://www.theguardian.com/technology/2024/oct/21/microsoft-launches-ai-employees-that-can-perform-some-business-tasks) |US company gives customers the ability to build own virtual agents as well as releasing 10 off-the-shelf bots |
|[Microsoft Excel’s bloopers reel: 40 years of spreadsheet errors.](https://www.theguardian.com/technology/2024/oct/28/microsoft-excels-bloopers-reel-40-years-of-spreadsheet-errors) | As the software used by millions around the world celebrates its birthday, here are some of the low points|
|[Google Expands Voice Technology Support to 15 More African Languages .](https://blog.google/around-the-globe/google-africa/africas-digital-decade/) | Google has expanded voice recognition support to include 15 more African languages across its platforms, such as Voice Search, Gboard talk-to-type, and Translate dictation. This enhancement enables an estimated 300 million additional Africans to engage with digital content in their native languages.|
|[Cohere releases state-of-the-art multimodal AI search model.](https://cohere.com/blog/multimodal-embed-3) |Cohere has unveiled that its Embed 3 AI model is now multimodal, allowing for rapid and precise search across essential enterprise image data sources such as graphs, charts, product catalogs, and design files. This enhancement makes Embed 3 the most broadly capable multimodal embedding model available today. |
|[Bringing developer choice to Copilot with Anthropic’s Claude 3.5 Sonnet, Google’s Gemini 1.5 Pro, and OpenAI’s o1-preview.](https://github.blog/news-insights/product-news/bringing-developer-choice-to-copilot/) | You can now access models like Claude, Gemini, and o1, among others, through GitHub Copilot.|
|[Apple releases first batch of Apple Intelligence features, debuts new iMac.](https://siliconangle.com/2024/10/28/apple-releases-first-batch-apple-intelligence-features-debuts-new-imac/) |Apple introduced new AI features, branded as Apple Intelligence, on its latest devices, focusing on text processing and photo editing capabilities. The updated iMac now runs on the M4 chip, which includes a Neural Engine that delivers three times the AI performance of previous models. Upcoming AI updates aim to improve Siri's capabilities and incorporate ChatGPT for handling more advanced queries. |
|[How Advex creates synthetic data to improve machine vision for manufacturers.](https://techcrunch.com/2024/10/28/how-advex-creates-synthetic-data-to-improve-machine-vision-for-manufacturers/) |Advex AI addresses data shortages in AI training by leveraging generative AI to create synthetic images tailored for computer vision systems. |
|[Coframe raises $9 million for websites that optimize themselves using AI.](https://www.reuters.com/technology/artificial-intelligence/coframe-raises-9-million-websites-that-optimize-themselves-using-ai-2024-10-29/) |AI startup Coframe has raised $9.3 million in seed funding to further develop its platform, which leverages generative AI to optimize websites and deliver personalized marketing experiences. |
|[Google unveils invisible ‘watermark’ for AI-generated text.](https://www.nature.com/articles/d41586-024-03462-7) | Real-world demonstration in chatbot responses could encourage other firms to label material produced by AI.|
|[Reddit shares soar after company turns first-ever profit.](https://www.theguardian.com/technology/2024/oct/30/reddit-stock) |Monthly users rose by nearly half thanks to AI translation feature, and deals for AI training with Google and OpenAI boosted revenue |
|[Google parent Alphabet sees double-digit growth as AI bets boost cloud business.](https://www.theguardian.com/technology/2024/oct/29/alphabet-google-earnings-report) |Analysts expected 12% year-on-year revenue gains, but company reports 15%, buoyed by performance in ads and cloud services |
|[EU events on curbing big tech ‘distorted’ by attenders with industry links.](https://www.theguardian.com/world/2024/oct/29/eu-events-curbing-big-tech-distorted-attenders-hidden-industry-links) |Campaigners say 21% of people at workshops did not disclose on their applications relationships with firms being discussed |
|[Indonesia blocks Apple iPhone 16 sales over lack of investment.](https://www.theguardian.com/technology/2024/oct/28/indonesia-apple-iphone-16-ban) |Marketing and sale of model prohibited after tech giant fails to meet rule 40% of phones be made from local parts |
|[25% of Smartphone Owners Don't Want AI as Apple Intelligence Debuts.](https://www.cnet.com/tech/mobile/25-of-smartphone-owners-dont-want-ai-as-apple-intelligence-debuts/) | What's a bigger priority? Longer battery life, according to a new CNET survey.|
|[Google preps ‘Jarvis’ AI agent that works in Chrome.](https://9to5google.com/2024/10/26/google-jarvis-agent-chrome) |Google's Project Jarvis, powered by Gemini 2.0, aims to automate web-based tasks in Chrome by using AI agents capable of reasoning and planning. |
|[OpenAI’s Whisper transcription tool has hallucination issues, researchers say.](https://techcrunch.com/2024/10/26/openais-whisper-transcription-tool-has-hallucination-issues-researchers-say/) | OpenAI's Whisper, an AI transcription tool, has been found to produce hallucinations—fabricated text not present in the original audio—even in medical settings. Despite OpenAI's advisories against using Whisper in high-risk domains, over 30,000 medical professionals across 40 health systems have adopted it for transcribing patient consultations|
|[Forerunner K2 humanoid robot can carry 33 lb in each dexterous hand.](https://newatlas.com/ai-humanoids/kepler-forerunner-k2-humanoid-robot/) |Kepler has introduced the Forerunner K2, a humanoid robot featuring advanced AI, upgraded hardware, and enhanced vision and navigation systems for improved real-time interaction. |
|[Introducing ChatGPT search.](https://openai.com/index/introducing-chatgpt-search/) |ChatGPT now offers an improved web search capability, providing quick, current answers with links to relevant sources—answers you'd typically seek through a search engine. This feature combines the ease of a natural language interface with access to real-time information, such as sports scores, news, stock prices, and more. |
|[Advancing embodied AI through progress in touch perception, dexterity, and human-robot interaction.](https://ai.meta.com/blog/fair-robotics-open-source/) | This work features several components, including vision-based tactical sensing, innovative hardware touch sensors, and noteworthy strategic partnerships within robotics.|
|[Elon Musk’s xAI adds image understanding capabilities to Grok.](https://techcrunch.com/2024/10/28/xai-adds-image-understanding-capabilities-to-grok/) | This means that paid users on his social platform X, who have access to the AI chatbot, can upload an image and ask the AI questions about it.|
|[OpenAI CFO Says 75% of Its Revenue Comes From Paying Consumers.](https://finance.yahoo.com/news/openai-cfo-says-75-revenue-163713534.html) |OpenAI generates the vast majority of its revenue from consumers who pay for its products, Chief Financial Officer Sarah Friar said, even as the artificial intelligence startup competes in a crowded market to sign up more corporate customers. |
|[Hello Patient.](https://www.hellopatient.com/) | Hello Patient has emerged from stealth mode, securing a $6.3 million seed funding round led by 8VC. The company, founded by Alex Cohen, is based in Austin, Texas. |
|[Google plans to announce its next Gemini model soon.](https://www.theverge.com/2024/10/25/24279600/google-next-gemini-ai-model-openai-december) |December is shaping up to be a month of dueling announcements from OpenAI and Google.  |
|[Meta is reportedly developing a search engine for its chatbot.](https://www.engadget.com/ai/meta-is-reportedly-developing-a-search-engine-for-its-chatbot-172505704.html) | The company wants to decrease Meta AI’s reliance on Google and Microsoft.|
|[A mysterious new image generation model has appeared.](https://techcrunch.com/2024/10/28/a-mysterious-new-image-generation-model-has-appeared/) |A mysterious new image generation model is beating models from Midjourney, Black Forest Labs, and OpenAI on the crowdsourced Artificial Analysis benchmark. The model, which goes by the name “red_panda,” is around 40 Elo points ahead of the next-best-ranking model, Black Forest Labs’ Flux1.1 Pro, on Artificial Analysis’ text-to-image leaderboard.|


## Resources
|Link|description|
|---|---|
|[Agentic Information Retrieval.](https://arxiv.org/abs/2410.09713) | offers an overview of agentic information retrieval, driven by the abilities of LLM agents; explores various advanced applications of agentic information retrieval and addresses related challenges.|
|[Aya Expanse.](https://cohere.com/blog/aya-expanse-connecting-our-world) |introduces a suite of open-weight foundation models designed for multilingual proficiency, featuring 8B and 32B parameter models and one of the largest multilingual datasets to date, containing 513 million examples. The release also includes Aya-101, which is claimed to be the most extensive multilingual model, supporting 101 languages. Aya Expanse 32B surpasses the performance of Gemma 2 27B, Mistral 8x22B, and Llama 3.1 70B, even though it is half the size of the latter. |
|[A Survey on Data Synthesis and Augmentation for Large Language Models.](https://arxiv.org/abs/2410.12896) |offers an in-depth overview of data generation techniques throughout the LLM lifecycle, covering topics such as data preparation, pre-training, fine-tuning, instruction-tuning, preference alignment, and practical applications. |
|[granite-3.0-language-models.](https://github.com/ibm-granite/granite-3.0-language-models/blob/main/paper.pdf) | introduces a range of lightweight foundation models from 400 million to 8 billion parameters, optimized for tasks such as coding, retrieval-augmented generation (RAG), reasoning, and function calling. Designed for enterprise applications, these models support on-premise and on-device deployment, showing robust performance across academic benchmarks in language understanding, reasoning, coding, function calling, and safety.|
|[Pixtral-12B-Base-2409.](https://huggingface.co/mistralai/Pixtral-12B-Base-2409) | Pixtral 12B base model weights have been released on Hugging Face.|
|[Arcade, a new AI product creation platform, designed this necklace.](https://techcrunch.com/2024/10/27/arcade-a-new-ai-product-creation-platform-designed-this-necklace/) |Arcade AI has developed a generative platform that allows users to create distinctive, high-quality jewelry items simply from text prompts—and the exciting part is, you can purchase the designs you generate. |
|[Retrieval-Augmented Diffusion Models for Time Series Forecasting.](https://arxiv.org/abs/2410.18712v1) | The Retrieval-Augmented Time Series Diffusion model (RATD) introduces a retrieval and guidance mechanism to enhance stability and performance in time series diffusion models. RATD operates in two steps: first, it retrieves relevant historical data from a database, then uses this information as a reference to guide the denoising phase.|
|[NotebookLlama: An Open Source version of NotebookLM.](https://github.com/meta-llama/llama-recipes/tree/main/recipes/quickstart/NotebookLlama) |Meta has published a quick start guide to help users build a simplified version of Google’s popular NotebookLM system. |
|[How I Studied LLMs in Two Weeks: A Comprehensive Roadmap.](https://towardsdatascience.com/how-i-studied-llms-in-two-weeks-a-comprehensive-roadmap-e8ac19667a31) |This article presents a 14-day roadmap for mastering LLM fundamentals, covering key topics such as self-attention, hallucinations, and advanced methods like Mixture of Experts. It offers resources for building an LLM from the ground up, alongside curated literature and online materials, all organized within a GitHub repository. Emphasizing a tailored learning experience, the article underscores the importance of foundational skills in math, programming, and deep learning. |
|[Marly.](https://github.com/marly-ai/marly) | Marly is an open-source data processor enabling agents to query unstructured data using JSON, streamlining data interaction and retrieval.|
|[LVSM: A Large View Synthesis Model with Minimal 3D Inductive Bias.](https://haian-jin.github.io/projects/LVSM/) | It was previously believed that novel view synthesis depended heavily on strong 3D inductive biases. This study demonstrates that, with scale and a minimal inductive bias, it's possible to significantly surpass these previously assumed limitations.|
|[Continuous Speech Synthesis using per-token Latent Diffusion.](https://arxiv.org/abs/2410.16048) |Autoregressive models continue to excel in many applications, yet recent advancements with diffusion heads in image generation have led to the concept of continuous autoregressive diffusion. This research broadens the scope of per-token diffusion to accommodate variable-length outputs. |
|[CDChat: A Large Multimodal Model for Remote Sensing Change Description.](https://arxiv.org/abs/2409.16261v1) | This paper presents a change description instruction dataset aimed at fine-tuning large multimodal models (LMMs) to enhance change detection in remote sensing.|
|[IC-Light V2 (Flux-based IC-Light models).](https://github.com/lllyasviel/IC-Light/discussions/98) |IC Light currently offers the most effective method for associating images with a pretrained text-to-image backbone. This discussion marks the initial steps toward expanding that capability to the robust Flux models. |
|[The Scene Language: Representing Scenes with Programs, Words, and Embeddings.](https://github.com/zzyunzhi/scene-language) |Creating 3D scenes from scratch presents significant challenges, including data limitations. This research introduces a programming-like language for describing 3D scenes and demonstrates that Claude Sonnet can produce highly realistic scenes even without specific training for this task. |
|[3D Semantic Segmentation.](https://arxiv.org/abs/2410.19446v1) |FtD++ is a cross-modal learning approach designed to enhance unsupervised domain adaptation in 3D semantic segmentation tasks. |
|[Open source replication of crosscoder on Gemma 2B.](https://www.lesswrong.com/posts/srt6JXsRMtmqAJavD/open-source-replication-of-anthropic-s-crosscoder-paper-for) | Anthropic recently published two studies showcasing its novel interpretability method. This post provides an open replication of the crosscoder on the Gemma 2B model.|
|[Awesome-Graph-OOD-Learning.](https://github.com/kaize0409/awesome-graph-ood) |This repository lists papers on graph out-of-distribution learning, covering three primary scenarios: graph OOD generalization, training-time graph OOD adaptation, and test-time graph OOD adaptation. |
|[OpenWebVoyager: Building Multimodal Web Agents.](https://github.com/minorjerry/openwebvoyager) |OpenWebVoyager offers tools, datasets, and models designed to build multimodal web agents that can navigate and learn from real-world web interactions. |
|[Automated Colorization for Animation.](https://ykdai.github.io/projects/InclusionMatching) | Researchers have introduced an innovative inclusion-matching technique that overcomes challenges in automated colorization, particularly for animations where occlusions and wrinkles complicate traditional segment matching.|
|[Lofi Music Dataset.](https://huggingface.co/datasets/vikhyatk/lofi) | A dataset containing music clips paired with detailed text descriptions, generated by a music creation model.|
|[Learning to Handle Complex Constraints for Vehicle Routing Problems.](https://arxiv.org/abs/2410.21066v1) | Researchers have developed a Proactive Infeasibility Prevention (PIP) framework designed to enhance neural network performance on Vehicle Routing Problems (VRPs) that involve challenging constraints.|
|[Unleashing the Power of AI on Mobile: LLM Inference for Llama 3.2 Quantized Models with ExecuTorch and KleidiAI.](https://pytorch.org/blog/unleashing-ai-mobile/) |PyTorch has made significant strides with ExecuTorch, a tool that enables AI model deployment at the edge, greatly enhancing the performance and efficiency of various end systems. |
|[CompassJudger-1: All-in-one Judge Model Helps Model Evaluation and Evolution.](https://arxiv.org/abs/2410.16256v1) |CompassJudger-1 is the first open-source, comprehensive judge model created to enhance the evaluation process for large language models (LLMs). |
|[MINT-1T.](https://github.com/mlfoundations/MINT-1T) | MINT-1T, a vast open-source multimodal dataset, has been released with one trillion text tokens and 3.4 billion images, incorporating diverse content from HTML, PDFs, and ArXiv papers. This dataset, roughly ten times larger than previous collections, is intended to accelerate advancements in large-scale multimodal machine learning research.|
|[LARP: Tokenizing Videos 🎬 with a Learned Autoregressive Generative Prior 🚀.](https://hywang66.github.io/larp/) |LARP is a novel video tokenizer designed to enhance video generation in autoregressive (AR) models by prioritizing global visual features over individual patch-based details. |
|[OpenAI's new hallucination benchmark.](https://openai.com/index/introducing-simpleqa/) |OpenAI has released the SimpleQA benchmark, which measures models' abilities around simple factual questions. |
|[ThunderKittens.](https://hazyresearch.stanford.edu/blog/2024-10-29-tk2) |Thunder Kittens is a framework designed for creating highly efficient GPU kernels. It leverages the principle that GPUs are optimized for working with compact 16x16 data tiles, resulting in high usability. With this approach, achieving 40% faster kernels requires only a few hundred lines of code.  |
|[Skinned Motion Retargeting with Dense Geometric Interaction Perception.](https://abcyzj.github.io/MeshRet/) |MeshRet has developed an innovative method for enhancing motion retargeting for 3D characters, prioritizing the preservation of body geometry interactions from the outset. |
|[Unlocking the Capabilities of Masked Generative Models for Image Synthesis via Self-Guidance.](https://arxiv.org/abs/2410.13136v1) | Researchers have improved Masked Generative Models (MGMs) by introducing a self-guidance sampling technique, which enhances image generation quality without compromising diversity.|
|[Speeding Up Transformers with Token Merging.](https://github.com/hchautran/PiToMe) |This project presents PiToMe, an algorithm that compresses Vision Transformers by gradually merging tokens after each layer, thereby decreasing the number of tokens processed. |
|[PF3plat : Pose-Free Feed-Forward 3D Gaussian Splatting.](https://cvlab-kaist.github.io/PF3plat/) |PF3plat addresses the challenge of 3D reconstruction and novel view synthesis from RGB images without requiring additional data. |
|[Fine-tuning LLMs to 1.58bit: extreme quantization made easy.](https://huggingface.co/blog/1_58_llm_extreme_quantization) |BitNet, created by Microsoft Research, presents a transformer architecture that lowers the computational and memory demands of large language models by employing ternary precision (-1, 0, 1), equating to 1.58 bits per parameter. This architecture requires models to be trained from scratch, but it can also fine-tune existing models to this low-precision format while retaining high performance on downstream tasks. This technique greatly reduces energy consumption and enhances inference speed through specialized kernels that enable efficient matrix multiplication. |
|[SELECT: A Large-Scale Benchmark of Data Curation Strategies for Image Recognition.](https://github.com/jimmyxu123/select) | SELECT is the inaugural extensive benchmark designed to evaluate various data curation methods in image classification. ImageNet++ is a newly developed dataset that augments ImageNet-1K by incorporating five additional training-data variations, each curated through distinct techniques.|
|[ODRL: A Benchmark for Off-Dynamics Reinforcement Learning.](https://arxiv.org/abs/2410.20750v1) |ODRL is the first standardized benchmark designed to assess reinforcement learning methods in environments with differing dynamics. |
|[Text-to-Image Model to Generate Memes.](https://arxiv.org/abs/2410.22901v1) | Researchers have created an innovative adapter method for text-to-image models, enabling them to tackle complex tasks such as meme video generation while preserving the base model's strong generalization abilities.|
|[Anomaly Classification in Industry.](https://arxiv.org/abs/2410.14379v1) | AnomalyNCD is a multi-class anomaly classification framework intended to enhance traditional anomaly detection techniques in industrial environments.|
|[MrT5: Dynamic Token Merging for Efficient Byte-level Language Models.](https://github.com/jkallini/mrt5) |Byte-level language models represent a move toward a token-free future, but the challenge of sequence length remains significant. Dynamically merging tokens can help increase the number of tokens within the context. |
|[BART vectoriZed.](https://github.com/gattocrucco/bartz) |A new GPU-enabled implementation of Bayesian Additive Regression Trees (BART) significantly accelerates processing speed, making it up to 200 times faster than conventional CPU-based versions. |
|[Huge new Diffusers release.](https://github.com/huggingface/diffusers/releases/tag/v0.30.0) |The Hugging Face Diffusers package now includes new pipelines like Flux, Stable Audio, Kolors, CogVideoX, Latte, and others, alongside new methods such as FreeNoise and SparseCtrl, plus various refactors. |
|[4 experiments with voice AI models to help you explore culture.](https://blog.google/outreach-initiatives/arts-culture/4-experimentations-with-voice-ai-models-to-help-you-explore-culture/) |Google’s voice AI models allow users to engage with culture in innovative ways. Projects like Talking Tours provide AI-guided virtual tours, Mice in the Museum offers art narration, and Lip Sync animates lips to discuss cultural topics. These entertaining tools offer new perspectives on art and design. |


## Perspectives
|Link|description|
|---|---|
|[ByteDance intern fired for planting malicious code in AI models.](https://arstechnica.com/tech-policy/2024/10/bytedance-intern-fired-for-planting-malicious-code-in-ai-models/) |After rumors swirled that TikTok owner ByteDance had lost tens of millions after an intern sabotaged its AI models, ByteDance issued a statement this weekend hoping to silence all the social media chatter in China. |
|[Thinking Like an AI.](https://www.oneusefulthing.org/p/thinking-like-an-ai) |Large language models (LLMs) operate as advanced autocomplete systems, generating the next token based on a combination of their training data and current input. Small variations in input can influence predictions, resulting in different responses to the same question. Gaining insight into token prediction, training data context, and memory constraints can enhance effective AI usage. |
|[An Interview with Salesforce CEO Marc Benioff about AI Abundance.](https://stratechery.com/2024/an-interview-with-salesforce-ceo-marc-benioff-about-ai-abundance) | Salesforce CEO Marc Benioff recently spoke about the company's new AI initiative, Agentforce, showcasing its potential to transform enterprise applications and customer interactions. He contrasted Salesforce's approach with Microsoft’s Copilot, describing Salesforce’s solution as more cohesive and impactful, thanks to its strong platform and data infrastructure. During the interview, Benioff stressed the significance of AI-driven "agentic" layers designed to boost customer service and improve operational efficiency across various industries.|
|[How GPU Access Helps Startups Be Agile.](https://a16z.com/podcast/how-gpu-access-helps-startups-be-agile/) |Andreessen Horowitz's Oxygen program tackles GPU shortages by offering startups in its portfolio more accessible and flexible GPU resources, allowing them to bypass price surges and supply limitations. This initiative enables AI startups to concentrate on product development without the pressure of long-term capital expenditure, emphasizing the need for equitable access to critical resources in the competitive AI field. |
|[The Mask Comes Off: At What Price?](https://thezvi.substack.com/p/the-mask-comes-off-at-what-price) | OpenAI is approaching its shift to a Public Benefit B-Corporation, a move that could impact its investor dynamics and collaboration with Microsoft. This transition brings up questions around control and valuation, particularly concerning the nonprofit's stake, which could be substantial given OpenAI's role in advancing AGI. The company’s future profitability and strategic course are closely tied to the safe development of AGI, a pursuit with enormous potential value.|
|[What's so special about the human brain?.](https://www.nature.com/immersive/d41586-024-03425-y/index.html) |Torrents of data from cell atlases, brain organoids and other methods are finally delivering answers to an age-old question. |
|[‘Educational’ apps are worth billions. We need to make sure they work.](https://www.nature.com/articles/d41586-024-03471-6) |Partnerships between developers and researchers could help to improve the quality of educational apps and other technologies. |
|[The huge protein database that spawned AlphaFold and biology’s AI revolution.](https://www.nature.com/articles/d41586-024-03423-0) |Pioneering crystallographer Helen Berman helped to set up the massive collection of protein structures that underpins the Nobel-prize-winning tool’s success. |
|[Extreme fire seasons are looming — science can help us adapt.](https://www.nature.com/articles/d41586-024-03433-y) | Not all wildfires can be averted, but data, models and collaborations can help to chart a course to a fire-resilient future.|
|[AI-designed DNA sequences regulate cell-type-specific gene expression.](https://www.nature.com/articles/d41586-024-03170-2) |Researchers have used artificial-intelligence models to create regulatory DNA sequences that drive gene expression in specific cell types. Such synthetic sequences could be used to target gene therapies to particular cell populations. |
|[Pushing the frontiers of audio generation.](https://deepmind.google/discover/blog/pushing-the-frontiers-of-audio-generation/) | DeepMind has shared additional details about the audio generation models behind NotebookLM.|
|[Evaluating feature steering: A case study in mitigating social biases.](https://www.anthropic.com/research/evaluating-feature-steering) | This study investigates the use of feature steering in AI models to adjust outputs in an interpretable way. It identifies a "steering sweet spot," where modifications do not compromise performance. Results demonstrate that steering can adjust social biases within specific areas but may also produce unintended effects outside those targets. Continued research is necessary to enhance feature steering, aiming for safer and more dependable AI outcomes.|
|[How we saved hundreds of engineering hours by writing tests with LLMs.](https://www.assembled.com/blog/how-we-saved-hundreds-of-engineering-hours-by-writing-tests-with-llms) | Assembled leverages LLMs to speed up and enhance software testing, allowing tests to be generated in minutes rather than hours. This approach boosts engineering productivity, saving time and enabling a stronger focus on feature development. LLMs create thorough and precise tests that uphold code quality and sustain development speed.|
|[How to train LLM as a judge to drive business value.](https://hamel.dev/blog/posts/llm-judge/) |"LLM As a Judge" is an approach for leveraging an existing language model to rank and score natural language. This post provides guidelines for effectively using this method to process or assess data. |

# ML news: Week 21 - 27 October

## Research
|Link|description|
|---|---|
|[Thinking LLMs: General Instruction Following with Thought Generation.](https://arxiv.org/abs/2410.10630) | The proposed training method aims to enhance LLMs with thinking capabilities for general instruction-following without relying on human-annotated data. It employs an iterative search and optimization process to facilitate thought generation, allowing the model to learn without direct supervision. For each user instruction, potential thoughts are evaluated using a judge model, which scores only the responses to identify the best and worst options. The resulting full outputs are then used as selected and rejected pairs for DPO (termed Thought Preference Optimization in this paper). This approach demonstrates superior performance on AlpacaEval and Arena-Hard.|
|[Model Swarms: Collaborative Search to Adapt LLM Experts via Swarm Intelligence.](https://arxiv.org/abs/2410.11163) | A new collaborative search algorithm is proposed to adapt LLMs using swarm intelligence, where a group of LLM experts collaboratively navigates the weight space to optimize a utility function that reflects various adaptation objectives. Experiments show that Model Swarms can effectively adjust LLM experts for a single task, multi-task domains, reward models, and a range of human interests. This approach outperforms 12 model composition baselines by up to 21.0% across different tasks and contexts.|
|[First-Person Fairness in Chatbots.](https://cdn.openai.com/papers/first-person-fairness-in-chatbots.pdf) |This study explores first-person fairness, focusing on the fairness of interactions between users and ChatGPT, particularly examining any biases related to users' names. It utilizes a model powered by GPT-4o to analyze patterns and name sensitivity in the chatbot's responses based on different user names. The findings suggest that post-training significantly reduces harmful stereotypes overall. However, in areas such as entertainment and art, especially with open-ended tasks, the study reveals a higher level of bias, indicating a tendency to create narratives featuring protagonists whose gender aligns with the gender inferred from the user's name. |
|[Looking Inward: Language Models Can Learn About Themselves by Introspection.](https://arxiv.org/abs/2410.13787) |The report indicates that LLMs can gain knowledge through introspection that is not directly derivable from their training data. It suggests that these models possess privileged information about themselves, which could contribute to creating more interpretable and controllable systems. However, it also notes that this introspective ability has limitations, as models often struggle to predict their own behavior on tasks that require reasoning over extended outputs. |
|[Janus: Decoupling Visual Encoding for Unified Multimodal Understanding and Generation.](https://arxiv.org/abs/2410.13848) |This proposal introduces a unified autoregressive framework for multimodal understanding and generation, which decouples visual encoding into independent pathways. By utilizing a single transformer architecture, it enhances flexibility and performance in both visual understanding and generation tasks. The framework claims to mitigate the trade-offs typically associated with vision tasks found in methods relying on a single visual encoder. As a result, it outperforms previous unified models and matches or exceeds the performance of task-specific models. |
|[Inference Scaling for Long-Context Retrieval Augmented Generation.](https://arxiv.org/abs/2410.04343) |This study employs two strategies to explore scaling laws for Retrieval-Augmented Generation (RAG): in-context learning (DRAG) and iterative prompting (IterRAG). It discovers that RAG performance steadily enhances with an increase in effective context length when configurations are optimized. Additionally, under optimal conditions, increasing inference computation yields linear improvements in long-context RAG performance. This insight leads to the creation of a computation allocation model designed to offer practical guidance for optimal computation distribution in long-context RAG situations. |
|[Agent S: An Open Agentic Framework that Uses Computers Like a Human.](https://arxiv.org/abs/2410.08164v1) |A novel open agentic framework has been developed to facilitate autonomous interactions with computers via a graphical user interface (GUI). Named Agent S, this framework addresses challenges such as knowledge acquisition, long-horizon planning, and managing dynamic interfaces. It introduces experience-augmented hierarchical planning that combines search and retrieval methods. Additionally, it utilizes an agent-computer interface to enable reasoning and control over GUI agents. Evaluation on the OSWorld benchmark demonstrates that Agent S surpasses the baseline by 9.37% in success rate, representing an 83.6% relative improvement, and sets a new state-of-the-art performance. |
|[Exploring Model Kinship for Merging Large Language Models.](https://arxiv.org/abs/2410.12613) |The study introduces the concept of model kinship to assess the similarity between LLMs. This measure is utilized to develop a model merging strategy called Top-k Greedy Merging with Model Kinship, which enhances performance. The authors discover that this new criterion allows for effective and continuous model merging. |
|[On The Planning Abilities of OpenAI's o1 Models: Feasibility, Optimality, and Generalizability.](https://www.arxiv.org/abs/2409.19924) |The report highlights that the o1-preview model excels in self-evaluation and constraint-following. However, it also points out that these o1 models exhibit bottlenecks in decision-making and memory management, particularly in the context of spatial reasoning. Specifically, the models tend to generate redundant actions and face challenges in generalizing across spatially complex tasks. |
|[Sabotage evaluations for frontier models.](https://www.anthropic.com/research/sabotage-evaluations) |Anthropic has conducted several innovative evaluations to identify vulnerabilities and assess misalignment in large, powerful models. |
|[Mini-Omni2: Towards Open-source GPT-4o with Vision, Speech and Duplex Capabilities.](https://arxiv.org/abs/2410.11190) |A powerful open-source initiative aimed at replicating GPT-4's speech capabilities has emerged. This model was trained by aligning multiple modalities using pre-trained audio and speech encoders, allowing it to achieve advanced speech recognition and generation functionalities. |
|[Automatically Interpreting Millions of Features in Large Language Models.](https://arxiv.org/abs/2410.13928) |Interpreting SAE features on a large scale can be difficult. To address this, Eleuther has introduced a set of automatic interpreter features designed to help understand the meaning of elements within their context. |
|[Mitigating Object Hallucination via Concentric Causal Attention.](https://github.com/xing0047/cca-llava) |Object hallucination in vision-language models has been associated with Rotary Position Encoding (RoPE), which faces challenges in managing long-term dependencies between visual and textual inputs. To overcome this, the authors introduce Concentric Causal Attention (CCA), a novel positional alignment method that enhances the interaction between visual elements and instruction tokens. |
|[Simplifying, stabilizing, and scaling continuous-time consistency models.](https://openai.com/index/simplifying-stabilizing-and-scaling-continuous-time-consistency-models/) | OpenAI has published work focusing on enhancing consistency models, which operate in two steps rather than the 1,000 steps typically used in diffusion models. While these models still depend on distillation from an existing diffusion model, the research seeks to improve their performance and stability as they scale.|
|[All you need are 32 tokens to represent video.](https://www.salesforceairesearch.com/opensource/xGen-MM-Vid/index.html) |Salesforce's new approach introduces a novel video encoder that significantly reduces the number of tokens needed for accurate representation. While similar attempts in the past have seen limited success, the breakthrough appears to come from combining an explicit temporal encoder with a spatial encoder, enabling more efficient video processing. |
|[CoPS: Empowering LLM Agents with Provable Cross-Task Experience Sharing.](https://github.com/uclaml/cops) | CoPS is a novel algorithm that improves agents' sequential reasoning by allowing them to share experiences across various tasks, enhancing their overall learning and adaptability.|

## News
|Link|description|
|---|---|
|[US investigates 2.4m Tesla self-driving vehicles after reported collisions.](https://www.theguardian.com/technology/2024/oct/18/tesla-self-driving-car-investigation) | Road safety agency opens evaluation over reported collisions in low visibility|
|[Anthropic just made it harder for AI to go rogue with its updated safety policy.](https://venturebeat.com/ai/anthropic-just-made-it-harder-for-ai-to-go-rogue-with-its-updated-safety-policy/) | Anthropic has revised its Responsible Scaling Policy to incorporate Capability Thresholds for AI models that present substantial risks, including bioweapons and autonomous AI research. This policy is designed to establish industry standards by introducing AI Safety Levels, which mandate stricter safeguards according to the model's capabilities. By transparently sharing safety practices and appointing a Responsible Scaling Officer, Anthropic aims to take a leadership role in AI governance and encourage similar initiatives across the industry.|
|[Sam Altman’s Worldcoin becomes World and shows new iris-scanning Orb to prove your humanity.](https://techcrunch.com/2024/10/17/sam-altmans-worldcoin-becomes-world-and-shows-new-iris-scanning-orb-to-prove-your-humanity/) | The World project, co-founded by Sam Altman, seeks to authenticate human identity online through iris-scanning technology, addressing privacy issues and ongoing investigations in the EU. The initiative plans to integrate human verification into AI platforms and may redistribute wealth generated by AI through Worldcoins. Recent updates include the launch of a new blockchain, an app, and tools such as Deep Face to help combat deep fakes.|
|[Google - Gemini Long Context.](https://www.kaggle.com/competitions/gemini-long-context/overview) | The Gemini team has set aside $100,000 for the most effective applications of their long context model capabilities.|
|[Unleashing System 2 Thinking? AlphaCodium Outperforms Direct Prompting of OpenAI o1.](https://www.qodo.ai/blog/system-2-thinking-alphacodium-outperforms-direct-prompting-of-openai-o1/?utm_source=tldrai) |OpenAI's o1 model, demonstrating System 1.5 thinking, exhibits improved reasoning abilities compared to earlier LLMs but still lacks the comprehensive problem-solving capabilities of full System 2 thinking. AlphaCodium enhances o1's coding performance by offering a structured framework that supports reasoning and iterative refinement, resulting in greater accuracy on Codeforces benchmarks. Although the combination of o1 and AlphaCodium shows potential for advancing AI toward more profound reasoning, significant effort is still needed to incorporate complete System 2 thinking in AI models. |
|[Amazon's AI Generator Tool Can Now Create Audio Ads.](https://www.adweek.com/commerce/amazons-ai-generator-tool-can-now-create-audio-ads/) | Soon, you’ll hear more audio ads on Amazon’s properties that were created with generative AI.|
|[Google Shopping is getting a ‘for you’ feed of products.](https://www.theverge.com/2024/10/15/24268117/google-shopping-personalized-feed-products-ai) | Google Shopping is rolling out a personalized feed that shows you a stream of products you might like. The new feature, which is coming to mobile and desktop devices, shows up when you head to shopping.google.com.|
|[TikTok owner sacks intern for allegedly sabotaging AI project.](https://www.theguardian.com/technology/2024/oct/21/tiktok-owner-bytedance-sacks-intern-for-allegedly-sabotaging-ai-project) | ByteDance dismissed person in August it says ‘maliciously interfered’ with training of artificial intelligence models |
|[AlphaFold reveals how sperm and egg hook up in intimate detail.](https://www.nature.com/articles/d41586-024-03319-z) |Three sperm proteins work together as matchmakers to enable fertilization in vertebrates. |
|[xAI, Elon Musk’s AI startup, launches an API.](https://techcrunch.com/2024/10/21/xai-elon-musks-ai-startup-launches-an-api/) | In August, Elon Musk’s xAI promised to make Grok, the company’s flagship generative AI model powering a number of features on X, available via an API. Now, that API has arrived — albeit a bit bare-bones at the moment.|
|[Jane Street Real-Time Market Data Forecasting.](https://www.kaggle.com/competitions/jane-street-real-time-market-data-forecasting) |This competition, hosted by Jane Street, challenges participants to build models using real-world data from production systems. The goal is to provide insights into the complexities of financial markets, requiring participants to apply their skills in data analysis and modeling to navigate the dynamic nature of market behavior. |
|[OCP Summit 2024: The open future of networking hardware for AI.](https://engineering.fb.com/2024/10/15/data-infrastructure/open-future-networking-hardware-ai-ocp-2024-meta/) | At OCP 2024, Meta unveiled a next-generation disaggregated network fabric and new network hardware specifically designed for AI clusters. The company introduced the Disaggregated Scheduled Fabric (DSF), aimed at improving scalability and performance in AI training systems. Both the newly developed and existing hardware are optimized for high throughput and efficiency, providing open, vendor-agnostic solutions to support advanced AI applications.|
|[Serve confirms delivery by robot expansion plans with Gen3 rollout.](https://newatlas.com/technology/serve-robotics-third-generation-autonomous-delivery-robot/) | Serve Robotics' third-generation delivery robot is equipped with NVIDIA's Jetson Orin module, significantly boosting its AI processing capabilities. This upgrade allows the robot to make faster, real-time autonomous navigation decisions, improving its efficiency and performance in delivery tasks.|
|[Boston Dynamics teams with TRI to bring AI smarts to Atlas humanoid robot.](https://techcrunch.com/2024/10/16/boston-dynamics-teams-with-tri-to-bring-ai-smarts-to-atlas-humanoid-robot/) |Boston Dynamics and Toyota Research Institute are partnering to integrate advanced AI and large behavior models into the electric Atlas humanoid robot. This collaboration aims to enhance the robot's capabilities, enabling more sophisticated and autonomous behaviors in tasks that require human-like movement and decision-making. |
|[Microsoft introduces ‘AI employees’ that can handle client queries.](https://www.theguardian.com/technology/2024/oct/21/microsoft-launches-ai-employees-that-can-perform-some-business-tasks) |US company gives customers the ability to build own virtual agents as well as releasing 10 off-the-shelf bots |
|[Thom Yorke and Julianne Moore join thousands of creatives in AI warning.](https://www.theguardian.com/film/2024/oct/22/thom-yorke-and-julianne-moore-join-thousands-of-creatives-in-ai-warning) | Statement comes as tech firms try to use creative professionals’ work to train AI models|
|[Claude AI tool can now carry out jobs such as filling forms and booking trips, says creator.](https://www.theguardian.com/technology/2024/oct/23/claude-ai-anthropic-computer-tasks-form-filling-booking-trips) |Anthropic says model is able to carry out computer tasks – as fears mount such technology will replace workers |
|[Introducing computer use, a new Claude 3.5 Sonnet, and Claude 3.5 Haiku.](https://www.anthropic.com/news/3-5-models-and-computer-use) |Anthropic has enhanced Sonnet 3.5's capabilities and introduced a more affordable version that delivers the same performance as the previous Claude 3 Opus. Furthermore, Sonnet 3.5 has been trained with screen recordings, enabling it to operate computers and interact with user interfaces. |
|[ChatGPT has a Windows app now .](https://www.theverge.com/2024/10/17/24273040/chatgpt-windows-app-subscribers-openai) | The app, which is currently in testing, is only available to ChatGPT subscribers for now.|
|[Adobe's new image rotation tool is one of the most impressive AI concepts we've seen.](https://www.creativebloq.com/design/adobes-new-image-rotation-tool-is-one-of-the-most-impressive-ai-concepts-weve-seen) |Adobe's Project Turntable leverages AI to rotate 2D vector art in 3D, allowing the artwork to be viewed from various angles while preserving its 2D look and design integrity. This innovative technique ensures that the visual style remains consistent, even as the artwork is transformed in three-dimensional space. |
|[Perplexity lets you search your internal enterprise files and the web.](https://venturebeat.com/ai/perplexity-lets-you-search-your-internal-enterprise-files-and-the-web/) |Enterprises can use their Perplexity dashboards to search for internal information and combine it with knowledge from the internet, but this will only be limited to specific files they deem important. |
|[OpenAI, Microsoft reportedly hire banks to renegotiate partnership terms.](https://siliconangle.com/2024/10/18/openai-microsoft-reportedly-hire-banks-renegotiate-partnership-terms/) |OpenAI and Microsoft are in discussions regarding the terms of their partnership, with Microsoft aiming to acquire a substantial stake in OpenAI following its restructuring. |
|[Former OpenAI CTO Mira Murati is reportedly fundraising for a new AI startup.](https://techcrunch.com/2024/10/19/former-openai-cto-mira-murati-is-reportedly-fundraising-for-a-new-ai-startup/) |This startup will reportedly focus on building AI products based on proprietary models and could raise more than $100 million in this round. |
|[Midjourney plans to let anyone on the web edit images with AI.](https://techcrunch.com/2024/10/19/midjourney-plans-to-let-anyone-on-the-web-edit-images-with-ai/) | Midjourney is planning to release an upgraded web tool that’ll let users edit any uploaded images from the web using Midjourney’s generative AI.|
|[Intel wins lengthy EU legal battle over £880m competition fine.](https://www.theguardian.com/technology/2024/oct/24/intel-legal-battle-against-eu-880m-fine-competition) |Chipmaker disputed 2009 decision that it abused its market position in case dating back two decades |
|[Cohere's multilingual model's dramatic improvement.](https://cohere.com/blog/aya-expanse-connecting-our-world) |The Aya project, a standout initiative in multilingual language model training, has made impressive strides since its launch earlier this year. Much of its performance improvement is attributed to effective post-training strategies. Additionally, Aya can handle audio input and create images, all from non-English sources. |
|[Introducing the analysis tool in Claude.ai.](https://www.anthropic.com/news/analysis-tool) | Claude can now write and execute code as part of artifacts.|
|[Gurman: Apple internally believes that it’s at least two years behind in AI development.](https://9to5mac.com/2024/10/20/gurman-apple-intelligence-ai-two-years/) |According to the latest edition of Mark Gurman’s Power On newsletter, some employees at Apple believe that the company is around two years behind in artificial intelligence development. |
|[Perplexity is reportedly looking to fundraise at an $8B valuation.](https://techcrunch.com/2024/10/20/perplexity-is-reportedly-looking-to-fundraise-at-an-8b-valuation/) | AI search engine Perplexity is in fundraising talks and hopes to raise around $500 million at an $8 billion valuation, according to The Wall Street Journal.|
|[Chinese humanoid robot is the 'fastest in the world' thanks to its trusty pair of sneakers.](https://www.livescience.com/technology/robotics/chinese-scientists-build-fastest-humanoid-robot-in-the-world-watch-it-run-across-the-gobi-desert) |The STAR1 robot can reach a top speed of 8 mph with the added help of a pair of sneakers. |
|[From Rupert Murdoch to Thom Yorke: the growing backlash to AI.](https://www.theguardian.com/technology/2024/oct/25/unjust-threat-murdoch-and-artists-align-in-fight-over-ai-content-scraping) | Media mogul and leading artists join fight to stop tech firms using creative works for free as training data|
|[Talk to your plants? Now the first AI-powered garden will allow them to talk back.](https://www.theguardian.com/lifeandstyle/2024/oct/25/ai-powered-garden-chelsea-flower-show) |Collaboration between leading garden designer and Microsoft to go on display at Chelsea flower show 2025 |

































































