# ML_news_private

this is just a placeholder, the organized and correct repository is [here](https://github.com/SalvatoreRa/ML-news-of-the-week)

# scheme

# ML news: 

## Research
|Link|description|
|---|---|
|[.]() | |
|[.]() | |
|[.]() | |

## News
|Link|description|
|---|---|
|[.]() | |
|[.]() | |
|[.]() | |


## Resources
|Link|description|
|---|---|
|[.]() | |
|[.]() | |
|[.]() | |

## Perspectives
|Link|description|
|---|---|
|[.]() | |
|[.]() | |
|[.]() | |

# ON WORKING

# ML news: 

## Research
|Link|description|
|---|---|
|[Fishing for Magikarp: Automatically Detecting Under-trained Tokens in Large Language Models.](https://arxiv.org/abs/2405.05417) |Separately trained tokenizers are necessary for language models. Tokens that are never encountered during language model training may be produced by these. Even the most potent contemporary language models have a lot. This study investigates this phenomena and offers solutions for locating and handling these tokens. |
|[Unlearning in Recommender Systems.](https://github.com/justarter/e2urec) | With the use of a novel technique called E2URec, huge language model-based recommendation systems may now effectively and efficiently forget user data while maintaining privacy and speed.|
|[Transforming Text into Any Modality, Resolution, and Duration via Flow-based Large Diffusion Transformers.](https://github.com/Alpha-VLLM/Lumina-T2X) |A project called Lumina seeks to provide a single text-to-X generation mechanism. Its training process involves interleaving text, video, audio, and pictures, which enhances downstream performance. |
|[MatterSim: A Deep Learning Atomistic Model Across Elements, Temperatures and Pressures.](https://arxiv.org/abs/2405.04967) | In AI, simulators can be very effective tools for gathering training data or facilitating interactions between models. A wide range of elemental atomic interactions can be modeled with this simulator.|
|[SGTR+: End-to-end Scene Graph Generation with Transformer.](https://arxiv.org/abs/2401.12835v1) |A new, more effective technique for producing scene graphs has been discovered by researchers. Their transformer-based approach aims to enhance the model's comprehension and interconnection of many parts in a picture, resulting in enhanced performance on complex tasks. |
|[InternLM-XComposer2: Mastering Free-form Text-Image Composition and Comprehension in Vision-Language Large Model.](https://arxiv.org/abs/2401.16420v1) | A vision-language model called InternLM-XComposer2 is very good at producing and comprehending intricate text-image information. It surpasses current approaches in multimodal content production and interpretation by introducing a Partial LoRA technique for a balanced vision and text comprehension.|
|[MambaOut: Do We Really Need Mamba for Vision?](https://arxiv.org/abs/2405.07992v1) |While Mamba is not effective for image classification, it shows promise in detection and segmentation tasks that do. The Mamba architecture is often employed for tasks with long-sequence and autoregressive characteristics. Researchers looked into this design and its application in vision tasks. |
|[State-Free Inference of State-Space Models: The Transfer Function Approach.](https://arxiv.org/abs/2405.06147v1) |For deep learning, a new state-space model with a dual transfer function representation has been created. A state-free sequence parallel inference approach is one of its features. |
|[Learning A Spiking Neural Network for Efficient Image Deraining.](https://github.com/mingtian99/esdne) | A Spiking Neural Network (SNN) called ESDNet is intended for picture deraining applications. It increases spike signal strength by taking advantage of the special qualities of rain pixel values.|
|[Controllable and Interactive 3D Assets Generation with Proxy-Guided Conditioning.](https://zju3dv.github.io/coin3d/) | Making 3D models is difficult. A coarse mesh can be entered initially, and then the generation process can be carried out, giving users more precise control and higher-quality model output.|
|[Hunyuan-DiT: A Powerful Multi-Resolution Diffusion Transformer with Fine-Grained Chinese Understanding.](https://arxiv.org/abs/2405.08748v1) | Particularly for Chinese and English, the recently created Hunyuan-DiT establishes a standard for text-to-image diffusion transformers. It has sophisticated data pipeline and transformer structures for ongoing model enhancement.|
|[Self-Rectifying Diffusion Sampling with Perturbed-Attention Guidance.](https://ku-cvlab.github.io/Perturbed-Attention-Guidance/) | An method to improve the quality of images produced by diffusion models without extra training or external modules is called Perturbed-Attention Guidance (PAG). PAG leads to a significant improvement in the structure and fidelity of both unconditional and conditional samples by innovative manipulation of the self-attention mechanisms within the model.|
|[SqueezeTime.](https://github.com/xinghaochen/squeezetime) | SqueezeTime is a new lightweight network that enhances temporal analysis by condensing the time axis of movies into the channel dimension, specifically for mobile video understanding.|
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |

## News
|Link|description|
|---|---|
|[OpenAI confirms May 13 event for ‘some ChatGPT and GPT-4 updates’.](https://9to5google.com/2024/05/10/openai-may-13-event-chatgpt/) |Following a report that the company plans to launch a Google Search competitor next week, OpenAI has just confirmed a May 13 event for new “ChatGPT and GPT-4” updates. |
|[Bye-bye bots: Altera’s game-playing AI agents get backing from Eric Schmidt.](https://techcrunch.com/2024/05/08/bye-bye-bots-alteras-game-playing-ai-agents-get-backing-from-eric-schmidt/) |Autonomous, AI-based players are coming to a gaming experience near you, and a new startup, Altera, is joining the fray to build this new guard of AI agents. |
|[BLIP3.](https://huggingface.co/Salesforce/xgen-mm-phi3-mini-instruct-r-v1) | Salesforce has trained and released the 3rd non-commercial version of the popular BLIP models, vision and language models mainly used for image understanding and captioning.|
|[Asterisk/Zvi on California's AI Bill.](https://www.astralcodexten.com/p/asteriskzvi-on-californias-ai-bill) |Regulations on AI models with processing capacity more than 10^26 FLOPs are proposed by the California SB1047 law. By demanding secure surroundings, quick deactivation capabilities, and thorough misuse possibility testing, it focuses on ensuring these models are used securely. The measure aims to address worries about the possible impact of AI on society by balancing innovation with safeguards against exploitation, and it only targets high-risk scenarios. |
|[Bedrock Studio is Amazon’s attempt to simplify generative AI app development.](https://techcrunch.com/2024/05/07/bedrock-studio-is-amazons-attempt-to-simplify-generative-ai-app-development/) | Amazon is launching a new tool, Bedrock Studio, designed to let organizations experiment with generative AI models, collaborate on those models, and ultimately build generative AI-powered apps.|
|[New GPT-4o AI model is faster and free for all users, OpenAI announces.](https://www.theguardian.com/technology/article/2024/may/13/openai-new-chatgpt-free) |Tech company reveals new flagship model that ‘is the future of interaction between ourselves and the machines’|
|[Introducing GPT-4o and more tools to ChatGPT free users.](https://openai.com/index/gpt-4o-and-more-tools-to-chatgpt-free/) |Today we are introducing our newest model, GPT-4o, and will be rolling out more intelligence and advanced tools to ChatGPT for free. |
|[Open sourcing IBM’s Granite code models.](https://research.ibm.com/blog/granite-code-models-open-source) | In order to make coding across several platforms easier and more efficient, IBM is making its Granite code models—which span a range of programming activities and have between 3 and 34 billion parameters—available to the open-source community.|
|[Bloomberg: Apple finalizing deal with OpenAI to bring ChatGPT features to iOS 18.](https://9to5mac.com/2024/05/10/ios-18-chatgpt-features-apple-openai/) | Apple is finalizing an agreement with OpenAI to bring some of its technology to the iPhone this year, according to a new report from Bloomberg. With this deal, the report explains that Apple will be able to offer “a popular chatbot” powered by ChatGPT as part of its AI-focused features in iOS 18.|
|[OpenAI says it can now identify images generated by OpenAI — mostly.](https://qz.com/openai-dall-e-3-image-detection-1851460817) |The company said its new tool correctly identified 98% of images generated by DALL-E 3 |
|[Microsoft is ‘turning everyone into a prompt engineer’ with new Copilot AI features.](https://www.theverge.com/2024/5/8/24151847/microsoft-copilot-rewrite-prompt-feature-microsoft-365) |Copilot for Microsoft 365 is getting auto-complete, rewrite, and more to improve AI prompts. |
|[Gemini breaks new ground with a faster model, longer context, AI agents and more.](https://blog.google/technology/ai/google-gemini-update-flash-ai-assistant-io-2024/) |At I/O 2024, Google unveiled a slew of new features, including Imagen 3, Veo video creation, Gemini Flash, and Project Astra, its newest assistant. Among the many noteworthy enhancements are the 2 million token context duration, significantly reduced model costs, and enhanced multimodality. |
|[Anthropic is expanding to Europe and raising more money.](https://techcrunch.com/2024/05/13/anthropic-is-expanding-to-europe-and-raising-more-money/) |Anthropic said Monday that Claude, its AI assistant, is now live in Europe with support for “multiple languages,” including French, German, Italian and Spanish across Claude.ai, its iOS app and its business plan for teams. |
|[Elon Musk's xAI nears $10 bln deal to rent Oracle's AI servers, The Information reports.](https://www.reuters.com/technology/elon-musks-xai-nears-10-bln-deal-rent-oracles-ai-servers-information-reports-2024-05-14/) |  - Elon Musk's artificial intelligence startup xAI has been talking to Oracle (ORCL.N), opens new tab executives about spending $10 billion to rent cloud servers from the company over a period of years, The Information reported on Tuesday, citing a person involved in the talks.|
|[OpenAI co-founder who had key role in attempted firing of Sam Altman departs.](https://www.theguardian.com/technology/article/2024/may/15/open-ai-cofounder-ilya-sutskever) |Ilya Sutskever helped orchestrate dramatic firing and rehiring of ChatGPT maker’s CEO last year |
|[Google rolls out AI-generated, summarized search results in US.](https://www.theguardian.com/technology/article/2024/may/14/google-ai-search-results) |Tech giant also reveals AI assistant in progress, currently called Project Astra, and AI video generator Veo at annual I/O conference |
|[OpenAI chief scientist Ilya Sutskever is officially leaving.](https://www.theverge.com/2024/5/14/24156920/openai-chief-scientist-ilya-sutskever-leaves) |Ilya Sutskever, OpenAI’s co-founder and chief scientist who helped lead the infamous failed coup against Sam Altman and then later changed his mind, is officially leaving the company. |
|[Project IDX, Google’s next-gen IDE, is now in open beta.](https://techcrunch.com/2024/05/14/project-idx-googles-next-gen-ide-is-now-in-open-beta/) |At it’s annual Google I/O 2024 developer conference on Tuesday, Google announced that Project IDX, the company’s next-gen, AI-centric browser-based development environment, is now in open beta. The company first launched it as an invite-only service gated by a waitlist in August. |
|[Researchers build AI-driven sarcasm detector.](https://www.theguardian.com/technology/article/2024/may/16/researchers-build-ai-driven-sarcasm-detector) | Being able to detect lowest form of wit could help AI interact with people more naturally, say scientists|
|[Hugging Face is sharing $10 million worth of compute to help beat the big AI companies.](https://www.theverge.com/2024/5/16/24156755/hugging-face-celement-delangue-free-shared-gpus-ai) |ZeroGPU gives everyone the chance to create AI apps without the burden of GPU costs. |
|[OpenAI partners with Reddit to integrate unique user-generated content into ChatGPT.](https://venturebeat.com/ai/openai-partners-with-reddit-to-integrate-unique-user-generated-content-into-chatgpt/) |Reddit, the widely popular social news aggregation and discussion platform, and OpenAI, the renowned AI research laboratory, have announced a strategic partnership that promises to revolutionize the way users interact with online communities and experience AI-powered features. |
|[Meta is reportedly working on camera-equipped AI earphones.](https://www.androidauthority.com/meta-ai-earphones-3442560/) | The company believes earphones are the future of AI-wearable technology.|
|[Cursor's instant full file edits with speculative editing.](https://cursor.sh/blog/instant-apply) |Using a bespoke Llama 3 70B model with a speculative prior, the researchers were able to rewrite files almost instantly at a rate of 1,000 tokens per second. They achieved this with some creative output formatting and no diffs. |
|[Improvements to data analysis in ChatGPT.](https://openai.com/index/improvements-to-data-analysis-in-chatgpt/) |Interact with tables and charts and add files directly from Google Drive and Microsoft OneDrive. |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |


## Resources
|Link|description|
|---|---|
|[ThunderKittens CUDA DSL.](https://hazyresearch.stanford.edu/blog/2024-05-12-quick-tk) |Hazy research has unveiled a novel DSL for CUDA kernel development. Only 100 lines of code are needed to implement its 30% quicker written flash attention feature. |
|[AnythingLLM.](https://github.com/Mintplex-Labs/anything-llm) |A full-stack application that enables you to turn any document, resource, or piece of content into context that any LLM can use as references during chatting. This application allows you to pick and choose which LLM or Vector Database you want to use as well as supporting multi-user management and permissions. |
|[Mirage: A Multi-level Superoptimizer for Tensor Algebra.](https://github.com/mirage-project/mirage) |Mirage is a tensor algebra superoptimizer that automatically discovers highly-optimized tensor programs for DNNs. Mirage automatically identifies and verifies sophisticated optimizations, many of which require joint optimization at the kernel, thread block, and thread levels of the GPU compute hierarchy. For an input DNN, Mirage searches the space of potential tensor programs that are functionally equivalent to the DNN to discover highly-optimized candidates. This approach allows Mirage to find new custom kernels that outperform existing expert-designed ones. |
|[audio-diffusion-pytorch.](https://github.com/archinetai/audio-diffusion-pytorch) | A fully featured audio diffusion library, for PyTorch. Includes models for unconditional audio generation, text-conditional audio generation, diffusion autoencoding, upsampling, and vocoding. The provided models are waveform-based, however, the U-Net (built using a-unet), DiffusionModel, diffusion method, and diffusion samplers are both generic to any dimension and highly customizable to work on other formats.|
|[Pipecat.](https://github.com/pipecat-ai/pipecat) | pipecat is a framework for building voice (and multimodal) conversational agents. Things like personal coaches, meeting assistants, story-telling toys for kids, customer support bots, intake flows, and snarky social companions.|
|[MRSegmentator: Robust Multi-Modality Segmentation of 40 Classes in MRI and CT Sequences.](https://github.com/hhaentze/mrsegmentator) | A novel tool called MRSegmentator has been developed to improve the segmentation of MRI scans. It can successfully detect 40 distinct organs and structures in the abdominal, pelvic, and thoracic areas.|
|[Time-Evidence-Fusion-Network.](https://github.com/ztxtech/Time-Evidence-Fusion-Network) |A unique deep learning model called the Time-Evidence Fusion Network (TEFN) is intended to improve long-term time series forecasting. Information fusion and evidence theory are combined, and a specific module is used to increase prediction stability and accuracy. |
|[moondream2-coyo-5M-captions.](https://huggingface.co/datasets/isidentical/moondream2-coyo-5M-captions) | 5M novel captions based on the alt-text and images of a portion of the COYO dataset.|
|[WebLlama.](https://github.com/McGill-NLP/webllama) | We are thrilled to release Llama-3-8B-Web, the most capable agent built with 🦙 Llama 3 and finetuned for web navigation with dialogue.|
|[Ollama on Google Firebase.](https://firebase.google.com/docs/genkit/plugins/ollama) |For Firebase, Genkit is a new toolkit for developing and implementing generative applications. Open source language model servers can be launched with it. |
|[Finetune PaliGemma.](https://colab.research.google.com/github/google-research/big_vision/blob/main/big_vision/configs/proj/paligemma/finetune_paligemma.ipynb) |This notebook shows how to finetune PaliGemma on a vision-language task. The training data consists of 90 pairs of images and long captions describing them. To make it runnable on a T4 colab runtime with 16GB HBM and 12GB RAM, we opt to only finetune the attention layers of the language model and freeze the other parameters. |
|[Gemini Flash.](https://deepmind.google/technologies/gemini/flash/) |Google has released a new lightweight model called Gemini Flash, which has a lengthy context window of up to one million tokens and multimodal reasoning. |
|[DeepMind Veo.](https://deepmind.google/technologies/veo) |Google Deepmind has released Veo, a new AI model for creating videos that can produce more than one minute in 1080p HD. |
|[IC-Light.](https://github.com/lllyasviel/IC-Light) |IC-Light is a project to manipulate the illumination of images. |
|[EfficientTrain++.](https://github.com/leaplabthu/efficienttrain) | With ImageNet databases, EfficientTrain++ presents a revolutionary curriculum learning technique that can drastically cut the training periods of popular visual models like ResNet and Swin by up to three times.|
|[NousResearch/Hermes-2-Theta-Llama-3-8B.](https://huggingface.co/NousResearch/Hermes-2-Theta-Llama-3-8B) |Hermes-2 Θ is a merged and then further RLHF'ed version our excellent Hermes 2 Pro model and Meta's Llama-3 Instruct model to form a new model, Hermes-2 Θ, combining the best of both worlds of each model. |
|[Energy-based Hopfield Boosting for Out-of-Distribution Detection.](https://github.com/ml-jku/hopfield-boosting) |A method called Hopfield Boosting makes use of contemporary Hopfield energy to improve machine learning models' ability to recognize out-of-distribution (OOD) data. |
|[OpenAI’s custom GPT Store is now open to all for free.](https://www.theverge.com/2024/5/13/24155582/openai-custom-gpt-store-available-free-subscriber) | OpenAI is making a number of its previously subscription-only features available to free users of ChatGPT, with the biggest being the ability to browse its GPT Store and use custom bots, said CTO Mira Murati during the company’s Spring update livestream today. The company also published today’s updates in a blog on its website.|
|[llama3.np.](https://github.com/likejazz/llama3.np) |llama3.np is pure NumPy implementation for Llama 3 model. For an accurate implementation, I ran the stories15M model trained by Andrej Karpathy. |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |

## Perspectives
|Link|description|
|---|---|
|[ChatGPT and the like could free up coders to new heights of creativity.](https://www.theguardian.com/commentisfree/article/2024/may/11/chatgpt-ai-will-co-pilot-coders-to-new-heights-of-creativity) | Far from making programmers an endangered species, AI will release them from the grunt work that stifles innovation|
|[Superhuman?](https://www.oneusefulthing.org/p/superhuman) |Top AI labs are focused on achieving artificial general intelligence (AGI), with estimates for its realization ranging from 2027 to 2047. Even though AI hasn't yet reached artificial general intelligence (AGI), certain systems exhibit superhuman abilities in particular tasks, indicating that AI's optimum use right now is as a co-intelligence that complements human efforts rather than replaces them. |
|[Large language models (e.g., ChatGPT) as research assistants.](https://lemire.me/blog/2024/04/27/large-language-models-e-g-chatgpt-as-research-assistants) |Artificial intelligence (AI) systems, such as GPT-4, are helping and even surpassing academics in tasks like producing research articles. According to Liang et al., AI is used in up to 18% of publications in some domains. This AI integration may result in a cycle where academic publications are produced and reviewed by software. The effect on scientific advancement is complex, though; while it may allow for more production, there is also a chance that more research will be done during an era in which knowledge will be less. |
|[What OpenAI did.](https://www.oneusefulthing.org/p/what-openai-did) | The integration of voice and vision in GPT-4o's multimodal skills holds great potential for improving AI's ability to interact with the outside world and laying the groundwork for AI to become a more commonplace presence in day-to-day life.|
|[OpenAI’s new GPT-4o model offers promise of improved smartphone assistants.](https://www.theguardian.com/technology/article/2024/may/14/openai-gpt-4o-model-offers-promise-of-improved-smartphone-assistants) | System can operate directly in speech, speeding up responses and noticing voice quirks, but it still needs the power of Siri|
|[Why mathematics is set to be revolutionized by AI.](https://www.nature.com/articles/d41586-024-01413-w) | Cheap data and the absence of coincidences make maths an ideal testing ground for AI-assisted discovery — but only humans will be able to tell good conjectures from bad ones.|
|[Major AlphaFold upgrade offers boost for drug discovery.](https://www.nature.com/articles/d41586-024-01383-z) |Latest version of the AI models how proteins interact with other molecules — but DeepMind restricts access to the tool. |
|[Lethal AI weapons are here: how can we control them?](https://www.nature.com/articles/d41586-024-01029-0) |Autonomous weapons guided by artificial intelligence are already in use. Researchers, legal experts and ethicists are struggling with what should be allowed on the battlefield. |
|[AI spending grew 293% last year. Here's how companies are using AI to stay ahead.](https://ramp.com/blog/q1-2024-spending-insights) |According to Ramp's Q1 data, its clients' expenditure on AI has increased by 293% year over year, surpassing the rise of all software investment. AI is also being widely used in non-tech businesses including financial services and healthcare, suggesting a wider integration of AI across a range of industries. Even though there is a general slowdown in new investments in AI, businesses who are already utilizing the technology are doubling down. The average amount spent on AI tools has climbed by 138% year over year, and businesses are still cautious when it comes to travel expenses. |
|[AI Copilots Are Changing How Coding Is Taught.](https://spectrum.ieee.org/ai-coding) | Professors are shifting away from syntax and emphasizing higher-level skills|
|[Test Driving ChatGPT-4o.](https://www.sabrina.dev/p/chatgpt4o-vs-math) | Inspired by ChatGPT vs Math (2023), let’s see how ChatGPT-4o performs.|
|[As the AI world gathers in Seoul, can an accelerating industry balance progress against safety?](https://www.theguardian.com/technology/article/2024/may/18/ai-seoul-global-summit-safety-openai-meta) |Companies such as OpenAI and Meta push ahead, but it is clear that biggest changes are yet to come |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |

# ML news: Week 6 - 12 May

## Research
|Link|description|
|---|---|
|[Mantis: Interleaved Multi-Image Instruction Tuning.](https://tiger-ai-lab.github.io/Mantis/) |A newly developed dataset and trained visual language model that allow for better instruction over a series of images. |
|[FeNNol: an Efficient and Flexible Library for Building Force-field-enhanced Neural Network Potentials.](https://arxiv.org/abs/2405.01491v1) | A state-of-the-art library called FeNNol makes it easier to create and use hybrid neural network potentials in molecular simulations.|
|[Spider: A Unified Framework for Context-dependent Concept Understanding.](https://arxiv.org/abs/2405.01002v1) |Spider is a revolutionary unified paradigm intended to improve comprehension of context-dependent (CD) concepts that rely largely on visual context, like medical lesions and items concealed in the environment. |
|[Frequency-mixed Single-source Domain Generalization for Medical Image Segmentation.](https://github.com/liamheng/non-iid_medical_image_segmentation) | A novel algorithm known as RaffeSDG has been created by researchers to enhance the precision of medical imaging models when evaluating data from various sources.|
|[SlotGAT: Slot-based Message Passing for Heterogeneous Graph Neural Network.](https://arxiv.org/abs/2405.01927v1) |SlotGAT is a new approach that improves heterogeneous graph neural networks by addressing the semantic mixing issue in traditional message passing. |
|[Frequency Masking for Universal Deepfake Detection.](https://arxiv.org/abs/2401.06506v1) |By concentrating on masked picture modeling, particularly in the frequency domain, this novel technique finds deepfakes. The strategy is different from conventional approaches and demonstrates a notable improvement in recognizing artificial images, even from recently developed AI generative techniques. |
|[Auto-Encoding Morph-Tokens for Multimodal LLM.](https://github.com/dcdmllm/morphtokens) | Researchers have created "Morph-Tokens" to enhance AI's capacity for image creation and visual comprehension. These tokens take advantage of the sophisticated processing capabilities of the MLLM framework to convert abstract notions required for comprehension into intricate graphics for image creation.|
|[Introducing AlphaFold 3.](https://blog.google/technology/ai/google-deepmind-isomorphic-alphafold-3-ai-model/) | In a paper published in Nature, we introduce AlphaFold 3, a revolutionary model that can predict the structure and interactions of all life’s molecules with unprecedented accuracy. For the interactions of proteins with other molecule types we see at least a 50% improvement compared with existing prediction methods, and for some important categories of interaction we have doubled prediction accuracy.|
|[ImageInWords: Unlocking Hyper-Detailed Image Descriptions.](https://arxiv.org/abs/2405.02793) | An extraordinarily detailed coupling of images and text was produced via a novel labeling technique that made use of two passes of VLMs. Strong multimodal models can be trained with the help of the captions, which include significantly more detail than any previous dataset. |
|[Inf-DiT: Upsampling Any-Resolution Image with Memory-Efficient Diffusion Transformer.](https://arxiv.org/abs/2405.04312v1) | To get beyond memory constraints in the creation of ultra-high-resolution images, a novel diffusion model presents a unidirectional block attention mechanism.|
|[DocRes: A Generalist Model Toward Unifying Document Image Restoration Tasks.](https://github.com/zzzhang-jx/docres) |A novel model called DocRes handles five tasks in one system: dewarping, deshadowing, appearance enhancement, deblurring, and binarization, making document image restoration easier. |
|[QServe: W4A8KV4 Quantization and System Co-design for Efficient LLM Serving.](https://hanlab.mit.edu/projects/qserve) |QoQ is a unique quantization approach that leverages 4-bit KV cache, 8-bit activations, and 4-bit weights to accelerate big language model inference. |
|[Navigating Chemical Space with Latent Flows.](https://arxiv.org/abs/2405.03987v1) |ChemFlow is a new framework that uses deep generative models to rapidly navigate chemical space, improving molecular science. |
|[Consistency Large Language Models: A Family of Efficient Parallel Decoders.](https://hao-ai-lab.github.io/blogs/cllm/) | One intriguing paradigm of ongoing research is the prediction of many tokens at once. If it works, generation times for many large language models would be significantly reduced. This post's method aims to accelerate generation by using a parallel decoding mechanism on fine-tuned LLMs, akin to consistency models from picture synthetics. Initial findings correspond with a 3x speculative decoding performance.|
|[You Only Cache Once: Decoder-Decoder Architectures for Language Models.](https://arxiv.org/abs/2405.05254) | The decoder-decoder YOCO architecture maintains global attention capabilities while using less GPU RAM. It is made up of a cross-decoder and a self-decoder, which enable effective key-value pair caching and reuse. With notable gains in throughput, latency, and inference memory over standard Transformers, YOCO performs favorably and is appropriate for big language models and extended context lengths.|
|[Optimal Group Fair Classifiers from Linear Post-Processing.](https://arxiv.org/abs/2405.04025v1) |This innovative post-processing approach ensures compliance with many group fairness criteria, including statistical parity, equal opportunity, and equalized odds, by recalibrating output scores after imposing a "fairness cost" to address model bias. |
|[DiffMatch: Visual-Language Guidance Makes Better Semi-supervised Change Detector.](https://arxiv.org/abs/2405.04788v1) |DiffMatch is a new semi-supervised change detection technique that generates pseudo labels for unlabeled data by using visual language models, hence offering extra supervision signals. |
|[Gemma-10M Technical Overview.](https://medium.com/@akshgarg_36829/gemma-10m-technical-overview-900adc4fbeeb) |Language-Vision The ability of models to comprehend and interact with text and visuals is quickly developing, as demonstrated by GPT-4V. Their important limits in visual deductive thinking are revealed by a recent study. Using challenging visual puzzles similar to those in IQ testing, researchers assessed these models and found that they had trouble with multi-step reasoning and abstract pattern recognition. |
|[Vision Mamba: A Comprehensive Survey and Taxonomy.](https://arxiv.org/abs/2405.04404v1) | a thorough examination of Mamba's uses in a range of visual tasks and its changing significance. Keep up with the latest discoveries and developments about the Mamba project.|

## News
|Link|description|
|---|---|
|[Lamini Raises $25M For Enterprises To Develop Top LLMs In-House.](https://www.lamini.ai/blog/series-a) | Software teams within enterprises can now create new LLM capabilities that lessen hallucinations on proprietary data, run their LLMs securely from cloud VPCs to on-premise, and scale their infrastructure with model evaluations that put ROI and business outcomes ahead of hype thanks to Lamini, an Enterprise AI platform. Amplify Partners led a $25 million Series A financing round.|
|[Microsoft-backed OpenAI may launch search, taking on Google's 'biggest product'.](https://timesofindia.indiatimes.com/technology/tech-news/microsoft-backed-openai-may-launch-search-taking-on-googles-biggest-product/articleshow/109794140.cms) |Speculations in the tech world suggest that OpenAI is gearing up for a major announcement, possibly a new search engine. According to Jimmy Apples, who reports the claim as an insider, the company is planning an event this month (May), tentatively scheduled for May 9, 2024, at 10 am. |
|[An AI-controlled fighter jet took the Air Force leader for a historic ride. What that means for war.](https://apnews.com/article/artificial-intelligence-fighter-jets-air-force-6a1100c96a73ca9b7f41cbd6a2753fda) |AI marks one of the biggest advances in military aviation since the introduction of stealth in the early 1990s, and the Air Force has aggressively leaned in. Even though the technology is not fully developed, the service is planning for an AI-enabled fleet of more than 1,000 unmanned warplanes, the first of them operating by 2028. |
|[Stack Overflow and OpenAI Partner to Strengthen the World’s Most Popular Large Language Models.](https://stackoverflow.co/company/press/archive/openai-partnership) |ack Overflow and OpenAI today announced a new API partnership that will empower developers with the collective strengths of the world’s leading knowledge platform for highly technical content with the world’s most popular LLM models for AI development. |
|[Elon Musk’s Plan For AI News.](https://www.bigtechnology.com/p/elon-musks-plan-for-ai-news) |Musk emails with details on AI-powered news inside X. An AI bot will summarize news and commentary, sometimes looking through tens of thousands of posts per story. |
|[Microsoft says it did a lot for responsible AI in inaugural transparency report.](https://www.theverge.com/2024/5/2/24147573/microsoft-ai-transparency-responsible-ignore-mario) |The report covers its responsible AI achievements in 2023 but doesn’t talk about Mario flying a plane to the Twin Towers. |
|[Cohere’s Command R Model Family is Now Available In Amazon Bedrock.](https://cohere.com/blog/command-r-on-amazon-bedrock) | Command R model family is now available in Amazon Bedrock. |
|[Fake Monet and Renoir on eBay among 40 counterfeits identified using AI.](https://www.theguardian.com/artanddesign/article/2024/may/08/fake-monet-and-renoir-on-ebay-among-counterfeits-identified-using-ai) |Paintings identified as fake using cutting-edge technology are ‘tip of the iceberg’ specialist Dr Carina Popovici says |
|[‘A chilling prospect’: should we be scared of AI contestants on reality shows?](https://www.theguardian.com/tv-and-radio/article/2024/may/07/the-circle-max-ai-netflix) |Netflix’s hit show The Circle recently introduced an AI chatbot contestant, a potentially worrying sign of where we’re heading |
|[‘ChatGPT for CRISPR’ creates new gene-editing tools.](https://www.nature.com/articles/d41586-024-01243-w) | In the never-ending quest to discover previously unknown CRISPR gene-editing systems, researchers have scoured microbes in everything from hot springs and peat bogs to poo and even yogurt. Now, thanks to advances in generative artificial intelligence (AI), they might be able to design these systems with the push of a button.|
|[Microsoft Working on ‘Far Larger’ In-House AI Model.](https://www.pymnts.com/artificial-intelligence-2/2024/report-microsoft-working-on-far-larger-in-house-ai-model/) | Microsoft is reportedly working on a new, in-house artificial intelligence (AI) model that is “far larger” than the other open source models it has trained.|
|[Apple unveils M4: Its first chip made for AI from the ground up.](https://9to5mac.com/2024/05/07/apple-unveils-m4-chip-ai/) | Apple on Tuesday unveiled M4, the next generation of its Apple Silicon chip. Built with the 3 nanometer chip architecture, M4 is the first Apple chip to be built for AI from the ground up. M4 is the chip that powers the new generation iPad Pro and will soon be inside Macs |
|[OpenAI Model Spec.](https://cdn.openai.com/spec/model-spec-2024-05-08.html) | This is the first draft of the Model Spec, a document that specifies desired behavior for our models in the OpenAI API and ChatGPT. It includes a set of core objectives, as well as guidance on how to deal with conflicting objectives or instructions.|
|[AI engineers report burnout and rushed rollouts as ‘rat race’ to stay competitive hits tech industry.](https://www.cnbc.com/2024/05/03/ai-engineers-face-burnout-as-rat-race-to-stay-competitive-hits-tech.html) | Artificial intelligence engineers at top tech companies told CNBC that the pressure to roll out AI tools at breakneck speed has come to define their jobs. They say that much of their work is assigned to appease investors rather than to solve problems for end users, and that they are often chasing OpenAI. Burnout is an increasingly common theme as AI workers say their employers are pursuing projects without regard for the technology’s effect on climate change, surveillance and other potential real-world harms.|
|[The teens making friends with AI chatbots.](https://www.theverge.com/2024/5/4/24144763/ai-chatbot-friends-character-teens) |Teens are opening up to AI chatbots as a way to explore friendship. But sometimes, the AI’s advice can go too far. |
|[GPT-2-Chatbot Confirmed As OpenAI.](https://simonwillison.net/2024/May/8/gpt2-chatbot-confirmed-as-openai/) |Recently, the gpt-2-chatbot has been seen in the LMSYS space; after discovering information from OpenAI's API through a 429 rate limit issue, it was verified that this was a new model from OpenAI. |
|[OpenAI Is Readying a Search Product to Rival Google, Perplexity.](https://www.bloomberg.com/news/articles/2024-05-07/openai-is-readying-an-ai-search-product-to-rival-google-perplexity) | The feature would let ChatGPT users search the web and cite sources in its results.|
|[DatologyAI raises $46M Series A.](https://www.datologyai.com/post/datologyai-raises-46m-series-a) |The data curation platform raises additional funds in its September $11 million seed round with the goal of growing its workforce and advancing corporate development. |
|[Yellow raises $5M from A16z for Gen AI-powered 3D modeling tool.](https://venturebeat.com/games/yellow-raises-5m-from-a16z-for-gen-ai-powered-3d-modeling-tool/) | Yellow has raised $5 million in seed funding from A16z Games to fund further development of its Gen AI-powered 3D modeling tool. With its YellowSculpt tool, artists can generate clean, pre-rigged 3D character meshes based on a text prompt in under three minutes.|
|[Stable Artisan: Media Generation and Editing on Discord.](https://stability.ai/news/stable-artisan) |Stable Artisan enables media generation on Discord powered by Stability AI’s cutting-edge image and video models, Stable Diffusion 3, Stable Video Diffusion, and Stable Image Core. In addition to media generation, Stable Artisan offers tools to edit your creations like Search and Replace, Remove Background, Creative Upscale and Outpainting.   |
|[ElevenLabs previews music-generating AI model.](https://venturebeat.com/ai/elevenlabs-previews-music-generating-ai-model/) | Voice AI startup ElevenLabs is offering an early look at a new model that turns a prompt into song lyrics. To raise awareness, it’s following a similar playbook Sam Altman used when OpenAI introduced Sora, its video-generating AI, soliciting ideas on social media and turning them into lyrics.|
|[Sources: Mistral AI raising at a $6B valuation, SoftBank ‘not in’ but DST is.](https://techcrunch.com/2024/05/09/sources-mistral-ai-raising-at-a-6b-valuation-softbank-not-in-but-dst-is/?utm_source=tldrai) | Paris-based Mistral AI, a startup working on open source large language models — the building block for generative AI services — has been raising money at a $6 billion valuation, three times its valuation in December, to compete more keenly against the likes of OpenAI and Anthropic, TechCrunch has learned from multiple sources.|
|[Leaked Deck Reveals How OpenAI Is Pitching Publisher Partnerships.](https://www.adweek.com/media/openai-preferred-publisher-program-deck/) |The generative artificial intelligence firm OpenAI has been pitching partnership opportunities to news publishers through an initiative called the Preferred Publishers Program, according to a deck obtained by ADWEEK and interviews with four industry executives. |
|[TECH
Alibaba rolls out latest version of its large language model to meet robust AI demand.](https://www.cnbc.com/2024/05/09/alibaba-rolls-out-latest-version-of-its-large-language-model.html) | Alibaba Cloud on Thursday said its large language model has seen more than 90,000 deployments in companies across industries. Alibaba Cloud said the latest version of its Tongyi Qianwen model, Qwen2.5, possesses “remarkable advancements in reasoning, code comprehension, and textual understanding compared to its predecessor Qwen2.0.”|

## Resources
|Link|description|
|---|---|
|[Prometheus-Eval.](https://github.com/prometheus-eval/prometheus-eval) |GPT-4 is a widely used performance benchmark for evaluating generation quality. Built upon Mistral, Prometheus is a model that excels at this particular purpose. |
|[Bonito.](https://github.com/BatsResearch/bonito) |Bonito is an open-source model for conditional task generation: the task of converting unannotated text into task-specific training datasets for instruction tuning. This repo is a lightweight library for Bonito to easily create synthetic datasets built on top of the Hugging Face transformers and vllm libraries. |
|[Penzai.](https://github.com/google-deepmind/penzai) |Penzai is a JAX library that provides clear, useful Pytree structures for training and interpreting models. It comes with a wide range of tools for component analysis, debugging, and model visualization. Penzai is easy to install and use, and it offers comprehensive tutorials for learning how to create and interact with neural networks. |
|[Realtime Video Stream Analysis with Computer Vision.](https://blog.roboflow.com/video-stream-analysis/) |This in-depth article shows you how to create a system that generates reports on the density of vehicle traffic. It counts cars over time using state-of-the-art computer vision. |
|[DOCCI - Descriptions of Connected and Contrasting Images.](https://google.github.io/docci/) | A great new dataset from Google that contains detailed and comprehensive labels.|
|[Unsloth.ai: Easily finetune & train LLMs.](https://www.youtube.com/watch?v=MQwryfkydc0&t=46s&ab_channel=EdwardZ.Yang%27sPyTorchandPL) | An animation by Unsloth's founder demonstrating how the team builds kernels, designs API surfaces, and utilizes PyTorch. The framework and library of Unsloth are incredibly robust and user-friendly.|
|[LeRobot.](https://github.com/huggingface/lerobot) | LeRobot aims to provide models, datasets, and tools for real-world robotics in PyTorch. The goal is to lower the barrier to entry to robotics so that everyone can contribute and benefit from sharing datasets and pretrained models. LeRobot contains state-of-the-art approaches that have been shown to transfer to the real-world with a focus on imitation learning and reinforcement learning.|
|[Vibe-Eval.](https://github.com/reka-ai/reka-vibe-eval) | A benchmark for evaluating multimodal chat models, including especially challenging examples.|
|[DeepSeek-V2-Chat.](https://huggingface.co/deepseek-ai/DeepSeek-V2-Chat) | DeepSeek-V2, a strong Mixture-of-Experts (MoE) language model characterized by economical training and efficient inference. It comprises 236B total parameters, of which 21B are activated for each token. Compared with DeepSeek 67B, DeepSeek-V2 achieves stronger performance, and meanwhile saves 42.5% of training costs, reduces the KV cache by 93.3%, and boosts the maximum generation throughput to 5.76 times.|
|[Visual Reasoning Benchmark.](https://github.com/apple/ml-rpm-bench) | Language-Vision The ability of models to comprehend and interact with text and visuals is quickly developing, as demonstrated by GPT-4V. Their important limits in visual deductive thinking are revealed by a recent study. Using challenging visual puzzles similar to those in IQ testing, researchers assessed these models and found that they had trouble with multi-step reasoning and abstract pattern recognition.|
|[AI Index: State of AI in 13 Charts.](https://hai.stanford.edu/news/ai-index-state-ai-13-chart) |In the new report, foundation models dominate, benchmarks fall, prices skyrocket, and on the global stage, the U.S. overshadows. |
|[Buzz Pretraining Dataset.](https://huggingface.co/datasets/H-D-T/Buzz) | Preference data is a new addition to the pretraining mix in Buzz. Multiple models that were trained on this data have also been made available by its researchers. They discovered that the models show good results on several tasks related to human preferences.|


## Perspectives
|Link|description|
|---|---|
|[From Baby Talk to Baby A.I.](https://www.nytimes.com/2024/04/30/science/ai-infants-language-learning.html) |Could a better understanding of how infants acquire language help us build smarter A.I. models? |
|[The AI Hardware Dilemma.](https://every.to/napkin-math/the-ai-hardware-dilemma) |Even while recent AI-powered hardware releases, such as the Humane Pin and Rabbit R1, have drawn criticism, the industry is still receiving a lot of venture capital investment, and well-known individuals like Sam Altman are considering making sizable investments. The appeal is in AI's ability to transform consumer hardware through innovative use of sensors, silicon, and interfaces. Though hardware startups find it difficult to compete with well-established tech giants, AI still needs to evolve, making it difficult to provide a compelling alternative to flexible smartphones. |
|[AI Prompt Engineering Is Dead.](https://spectrum.ieee.org/prompt-engineering-is-dead) |Automating prompt optimization for AI models points to more effective, model-driven prompt generation techniques in the future, possibly rendering human prompt engineering unnecessary. |
|[The Next Big Programming Language Is English.](https://every.to/chain-of-thought/i-spent-24-hours-with-github-copilot-workspaces) | GitHub Copilot Workspace is a robust programming tool that allows users to code in plain English via the browser, from planning to implementation. It is currently available in a limited technical preview. In contrast to ChatGPT, the AI easily integrates with codebases, suggesting block-by-block code execution and managing complex tasks with less active user interaction.|
|[Is AI lying to me? Scientists warn of growing capacity for deception.](https://www.theguardian.com/technology/article/2024/may/10/is-ai-lying-to-me-scientists-warn-of-growing-capacity-for-deception) |Researchers find instances of systems double-crossing opponents, bluffing, pretending to be human and modifying behaviour in tests |

# ML news: Week 29 April - 5 May

## Research
|Link|description|
|---|---|
|[Let's Think Dot by Dot: Hidden Computation in Transformer Language Models.](https://arxiv.org/abs/2404.15758) |This paper demonstrates how '...' tokens can be used to obscure chain-of-thought (CoT) reasoning. This necessitates model training, but it illustrates how the model can conceal thought and make it difficult to comprehend the CoT phases. |
|[Tracking with Human-Intent Reasoning.](https://arxiv.org/abs/2312.17448v1) |TrackGPT transforms object tracking by integrating the capabilities of Large Vision-Language Models. It can interpret implicit tracking instructions, simplifying the procedure and improving performance, as demonstrated by its outstanding performance on the new InsTrack benchmark and other hard datasets. |
|[AAPL: Adding Attributes to Prompt Learning for Vision-Language Models.](https://github.com/Gahyeonkim09/AAPL) |By employing adversarial token embedding, researchers have created a novel technique known as AAPL, which improves AI models' capacity to identify items that are not visible to the human eye. |
|[NExT: Teaching Large Language Models to Reason about Code Execution.](https://arxiv.org/abs/2404.14662) |A fundamental skill among human developers is the ability to understand and reason about program execution.  we propose NExT, a method to teach LLMs to inspect the execution traces of programs (variable states of executed lines) and reason about their run-time behavior through chain-of-thought (CoT) rationales. Specifically, NExT uses self-training to bootstrap a synthetic training set of execution-aware rationales that lead to correct task solutions (e.g., fixed programs) without laborious manual annotation. |
|[Open Gato Replication: JAT.](https://huggingface.co/blog/jat) | DeepMind's GATO was hailed as a generalist agent. JAT is a Jack-of-All-Trades model that has been trained and assessed by a team affiliated with Hugging Face. It has demonstrated reasonable performance across an extensive range of tasks.|
|[FP6-LLM: Efficiently Serving Large Language Models Through FP6-Centric Algorithm-System Co-Design.](https://arxiv.org/abs/2401.14112) |Although it can be unstable, reducing floating point precision speeds up training. This work demonstrates that without common instabilities or slowdowns from naive approaches, full tensor core usage may be achieved in a new packing structure. |
|[StarCoder2-Instruct: Fully Transparent and Permissive Self-Alignment for Code Generation.](https://huggingface.co/blog/sc2-instruct) | Both synthetic and human data are used to train this model. With a permissive license, it receives a humaneval score of 72.6. The creators provide excellent details on how to duplicate their data pipeline and apply the concepts to other issues where the use of synthetic data may be beneficial.|
|[Efficient Inverted Indexes for Approximate Retrieval over Learned Sparse Representations.](https://arxiv.org/abs/2404.18812v1) | Using trained sparse embeddings, Seismic is a novel way to organize inverted indexes that greatly improves text retrieval speed and accuracy.|
|[Learning Invariant Representations of Graph Neural Networks via Cluster Generalization.](https://arxiv.org/abs/2403.03599v1) |A novel technique called Cluster Information Transfer (CIT) mechanism is intended to improve Graph Neural Networks' (GNNs') ability to adapt to various and dynamic graph architectures. |
|[Meta-Prompting.](https://github.com/suzgunmirac/meta-prompting) | Using a technique called meta-prompting, a single language model can become a multi-skilled team. By decomposing intricate activities into smaller components that are managed by specialized instances of the same model, this technique greatly enhances performance on a variety of tasks.|
|[KAN: Kolmogorov-Arnold Networks.](https://arxiv.org/abs/2404.19756) |Today's AI makes extensive use of multi-layer perceptrons, notably in the Transformer that connects the attention levels. They do, nevertheless, employ set activation functions. This study proposes to use the Kolmogorov-Arnold representation to apply learnt activation functions on edges (functions can be represented by a superposition of smaller functions). Here, the researchers use splines in place of weights. Although the building is far more intricate, it has some intriguing characteristics that might help with interpretation. |
|[Lightplane: Highly-Scalable Components for Neural 3D Fields.](https://lightplane.github.io/) | With a new technique, 2D-3D mappings can significantly minimize memory usage by using Lightplane Renderer and Splatter components. The Lightplane Splatter effectively projects these images into 3D Hash structures after the Lightplane Renderer expertly creates images from neural 3D fields.|
|[CLIP-Mamba: CLIP Pretrained Mamba Models with OOD and Hessian Evaluation.](https://arxiv.org/abs/2404.19394v1) |The new Mamba model, trained using contrastive language-image pretraining (CLIP), shows impressive efficiency and performance in zero-shot image classification. |
|[MicroDreamer.](https://github.com/ml-gsai/microdreamer) |Scientists have created a novel 3D creation method called MicroDreamer that greatly speeds up the procedure by lowering the quantity of function evaluations needed. |
|[Model Quantization and Hardware Acceleration for Vision Transformers: A Comprehensive Survey.](https://arxiv.org/abs/2405.00314v1) | This paper explores how optimized hardware combined with algorithmic modifications can improve the performance of ViTs, especially via model quantization.|
|[Spikformer V2: Join the High Accuracy Club on ImageNet with an SNN Ticket.](https://arxiv.org/abs/2401.02020v1) |Spikformer V2 blends the biological efficacy of Spiking Neural Nets (SNNs) with the self-attention mechanism. This novel model improves its energy-efficient visual feature processing through the use of a Convolutional Stem and a Spiking Self-Attention mechanism. |
|[Full-frequency dynamic convolution: a physical frequency-dependent convolution for sound event detection.](https://arxiv.org/abs/2401.04976v1) | A novel technique called Full-Frequency Dynamic Convolution (FFDConv) improves 2D convolution for sound event identification. FFDConv increases sound event detection accuracy by creating distinct frequency kernels for every band, particularly with regard to the frequency properties of the sounds.|
|[Boosting Segment Anything Model with Adversarial Tuning.](https://asam2024.github.io/) | One well-known foundation model in computer vision, Meta AI's Segment Anything Model (SAM), performs well at image segmentation but poorly in other domains. This project introduces ASAM, a performance-enhancing adversarial tuning based reinforcement learning algorithm on top of SAM. |
|[SUNDAE: Spectrally Pruned Gaussian Fields with Neural Compensation.](https://runyiyang.github.io/projects/SUNDAE/) |This work presents SUNDAE, a novel technique that uses neural compensation and spectral pruning to improve memory efficiency.|
|[Long-Context Data Engineering.](https://github.com/franxyao/long-context-data-engineering) | The technique presented in this work allows language models to be greatly extended to context lengths of up to 128K, highlighting the significance of training data diversity and quantity.|
|[StreamMultiDiffusion: Real-Time Interactive Generation with Region-Based Semantic Control.](https://github.com/ironjr/StreamMultiDiffusion) |StreamMultiDiffusion is a framework that enables real-time region-based text-to-image generation. |


## News
|Link|description|
|---|---|
|[BBC presenter’s likeness used in advert after firm tricked by AI-generated voice.](https://www.theguardian.com/technology/2024/apr/28/bbc-presenters-likeness-used-in-advert-after-firm-tricked-by-ai-generated-voice) | Science presenter Liz Bonnin’s accent, as regular BBC viewers know, is Irish. But this voice message, ostensibly granting permission to use her likeness in an ad campaign, seemed to place her on the other side of the world.|
|[Tesla Autopilot feature was involved in 13 fatal crashes, US regulator says.](https://www.theguardian.com/technology/2024/apr/26/tesla-autopilot-fatal-crash) |Federal transportation agency finds Tesla’s claims about feature don’t match their findings and opens second investigation |
|[Apple and OpenAI are reportedly in talks for iOS 18 integration.](https://mashable.com/article/apple-openai-partnership-ios-18) |Apple has been talking to several big AI companies in pursuit of a potential partnership for on-device chatbot capabilities. According to Bloomberg, Apple and OpenAI discussed a potential deal earlier this year. Those talks have since reopened, according to people with knowledge of the matter. The possible agreement could be about OpenAI integrations into iOS 18. |
|[The little smart home platform that could.](https://www.theverge.com/24135207/home-assistant-announces-open-home-foundation) | This week, Home Assistant announced it is now part of the Open Home Foundation. The newly formed non-profit will own and govern all of Home Assistant and its related entities. Its creators and inaugural board members — Schoutsen, Guy Sie, Pascal Vizeli, and J. Nick Koston — all work on Home Assistant, and the foundation has no other members so far.|
|[Jensen Huang and Sam Altman among tech chiefs invited to federal AI Safety Board.](https://www.theregister.com/2024/04/26/jensen_huang_and_sam_altman/) |Leaders of the world's most prominent AI companies are being recruited for the Homeland Security Department's new advisory group. |
|[OpenAI to use Financial Times journalism to train artificial intelligence systems.](https://www.theguardian.com/media/2024/apr/29/chatgpt-openai-ft-journalism-train-artificial-intelligence-systems) | Under deal, ChatGPT users will receive summaries and quotes from Financial Times content and links to articles. The [deal](https://www.engadget.com/openai-will-train-its-ai-models-on-the-financial-times-journalism-173249177.html) is the ChatGPT maker's latest with a media company.|
|[Japan to trial AI bear warning system after record number of attacks.](https://www.theguardian.com/world/2024/apr/30/japan-to-trial-ai-bear-warning-system-after-record-number-of-attacks) |Six people have been killed and more than 200 injured in attacks by bears over the past year |
|[Copilot Workspace.](https://githubnext.com/projects/copilot-workspace/) | A new effort to let language models complete features and address faults in a semi-autonomous manner has been revealed on GitHub.|
|[OpenAI introduces "Memory" feature for ChatGPT Plus users.](https://the-decoder.com/openai-introduces-memory-feature-for-chatgpt-plus-users/) |OpenAI has enabled the "Memory" feature for all ChatGPT Plus users, the company announced via X. Memory allows users to tell ChatGPT things they want it to remember across chats. The feature can be turned on and off in the settings. |
|[Intel brings quantum-computing microchips a step closer.](https://www.nature.com/articles/d41586-024-01208-z) |By adapting methods for fabricating and testing conventional computer chips, researchers have brought silicon-based quantum computers closer to reality — and to accessing the immense benefits of a mature chipmaking industry. |
|[NATO is boosting AI and climate research as scientific diplomacy remains on ice.](https://www.nature.com/articles/d41586-024-01052-1) |As the military alliance created to counter the Soviet Union expands, it is prioritizing studies on how climate change affects security, cyberattacks and election interference. |
|[ChatGPT’s chatbot rival Claude to be introduced on iPhone.](https://www.theguardian.com/technology/2024/may/01/chatgpt-chatbot-rival-claude-to-be-introduced-on-iphone) | Challenger to market leader OpenAI says it wants to ‘meet users where they are’ and become part of users’ everyday life|
|[Amazon sales soar with boost from artificial intelligence and advertising.](https://www.theguardian.com/technology/2024/apr/30/amazon-sales-report-ai) |Revenue at Amazon Web Services increases to $25bn as retail giant releases earnings report surpassing Wall Street expectations |
|[Eight US newspapers sue OpenAI and Microsoft for copyright infringement.](https://www.theguardian.com/technology/2024/apr/30/us-newspaper-openai-lawsuit) | The Chicago Tribune, Denver Post and others file suit saying the tech companies ‘purloin millions’ of articles without permission|
|[Apple poaches AI experts from Google, creates secretive European AI lab.](https://arstechnica.com/ai/2024/04/apple-poaches-ai-experts-from-google-creates-secretive-european-ai-lab/) |Apple has poached dozens of artificial intelligence experts from Google and has created a secretive European laboratory in Zurich, as the tech giant builds a team to battle rivals in developing new AI models and products. |
|[Diddo’s new funding will bring its shoppable TV API to streaming platforms.](https://techcrunch.com/2024/04/24/diddos-new-funding-will-bring-its-shoppable-tv-api-to-streaming-platforms/) | Diddo is an API for streaming services and other platforms to integrate shoppable videos, enabling consumers to buy their favorite characters’ clothing and accessories directly on their screens. The company announced Wednesday that it raised $2.8 million in seed funding.|
|[Cognition Seeks $2 Billion Valuation for AI Code-Writing Tool.](https://www.pymnts.com/artificial-intelligence-2/2024/cognition-seeks-2-billion-valuation-for-ai-code-writing-tool/) |Cognition Labs is reportedly aiming to become the next multibillion-dollar artificial intelligence (AI) startup. The company, which is developing an AI tool for writing code, is in discussions with investors to raise money at a valuation of up to $2 billion, The Wall Street Journal (WSJ) reported Sunday (March 31). |
|[Apple to unveil AI-enabled Safari browser alongside new operating systems.](https://appleinsider.com/articles/24/04/30/apple-to-unveil-ai-enabled-safari-browser-alongside-new-operating-systems) |Apple is testing a version of its Safari web browser that includes UI tweaks, advanced content blocking features, and a new AI-powered tool dubbed Intelligent Search, AppleInsider has learned. The software — expected to debut as Safari 18 later in 2024 — is currently undergoing evaluation alongside internal builds of Apple's next-generation operating system updates, namely iOS 18 and macOS 15, according to people familiar with the matter. Should all of the new features make it to the release candidate stage, users will be treated to a new user interface (UI) for customizing popular page controls, a "Web eraser" feature, and AI-driven content summarization tools. |
|[This AI startup backed by Nvidia is now worth $19 billion.](https://www.marketwatch.com/story/this-ai-startup-backed-by-nvidia-is-now-worth-19-billion-ac240ea0) | Nvidia Corp.-backed AI startup CoreWeave has nearly tripled in value to $19 billion following its latest round of funding. CoreWeave, which rents out chips housed in data centers across the U.S. that customers use to create and deploy AI systems, raised $642 million from investors in its prior funding round.|
|[How Field AI Is Conquering Unstructured Autonomy .](https://spectrum.ieee.org/autonomy-unstructured-field-ai) | One of the biggest challenges for robotics right now is practical autonomous operation in unstructured environments. But over the past few years, this has started to change, thanks in large part to a couple of pivotal robotics challenges put on by DARPA. The DARPA Subterranean Challenge ran from 2018 to 2021, putting mobile robots through a series of unstructured underground environments.|
|[Amazon Q, a generative AI-powered assistant for businesses and developers.](https://www.aboutamazon.com/news/aws/amazon-q-generative-ai-assistant-aws) |With the use of a company's internal data, AWS has introduced Amazon Q, a generative AI assistant designed to enhance software development and decision-making. With natural language interaction, Amazon Q provides data-driven help for business users and makes coding, testing, and app development easier for developers. Amazon Q Apps is another feature of the service that makes it possible to create unique AI apps without any coding experience. |
|[GPT-2?](https://rentry.co/GPT2) |There have been rumors that the enigmatic gpt2-chatbot AI model, which resembles GPT-4.5 in some ways, is an unofficial OpenAI test for their upcoming version when it surfaced on lmsys.org. Important indicators including answer quality, features unique to OpenAI, and rate limits point to a high degree of sophistication and could be signs of an OpenAI-led covert benchmarking project. The AI community is still looking into and debating the origins and capabilities of the gpt2-chatbot. |
|[OpenAI's GPT-4 can exploit real vulnerabilities by reading security advisories.](https://www.theregister.com/2024/04/17/gpt4_can_exploit_real_vulnerabilities/) | AI agents, which combine large language models with automation software, can successfully exploit real world security vulnerabilities by reading security advisories, academics have claimed.|
|[Apple reports slumping iPhone sales as global demand weakens.](https://www.theguardian.com/technology/article/2024/may/02/apple-earnings-iphone-sales-decrease) | iPhone sales fell 10% compared with the same time period last year, but the company still beat Wall Street’s expectations|
|[Microsoft bans US police departments from using enterprise AI tool for facial recognition.](https://techcrunch.com/2024/05/02/microsoft-bans-u-s-police-departments-azure-openai-facial-recognition/) |Microsoft has reaffirmed its ban on U.S. police departments from using generative AI for facial recognition through Azure OpenAI Service, the company’s fully managed, enterprise-focused wrapper around OpenAI tech. |
|[Meta plans to build $800 million, next-generation data center in Montgomery.](https://www.madeinalabama.com/2024/05/meta-plans-to-build-800-million-next-generation-data-center-in-montgomery/) | MONTGOMERY, Alabama — Governor Kay Ivey announced today that technology company Meta Platforms plans to open an $800 million data center in Alabama’s capital city that will support 100 operational jobs and build on the company’s previous investment in the state.|


## Resources
|Link|description|
|---|---|
|[Cohere Launches Developer Toolkit to Accelerate Build Gen AI Apps.](https://cohere.com/blog/cohere-toolkit) |This toolkit is an open-source repository of production-ready applications that you can deploy across cloud providers.  |
|[Video-Language models with PLLaVA.](https://pllava.github.io/) |A novel pooling technique has been developed by researchers to enable the adaptation of image-language AI models for video applications, making the new model known as PLLaVA stand out. |
|[luminal.](https://github.com/jafioti/luminal) | Luminal is a deep learning library that uses composable compilers to achieve high performance.|
|[torchtitan.](https://github.com/pytorch/torchtitan) | torchtitan is a proof-of-concept for Large-scale LLM training using native PyTorch. It is (and will continue to be) a repo to showcase PyTorch's latest distributed training features in a clean, minimal codebase.|
|[OpenLIT.](https://github.com/openlit/openlit) |OpenLIT is an OpenTelemetry-native GenAI and LLM Application Observability tool. It's designed to make the integration process of observability into GenAI projects as easy as pie – literally, with just a single line of code. Whether you're working with popular LLM Libraries such as OpenAI and HuggingFace or leveraging vector databases like ChromaDB, OpenLIT ensures your applications are monitored seamlessly, providing critical insights to improve performance and reliability. |
|[Llamafile’s progress, four months in.](https://hacks.mozilla.org/2024/04/llamafiles-progress-four-months-in/) | Self-contained executables called Llamafiles allow models to run instantly on a variety of platforms. It promises significant portability advantages and a two-fold speed increase.|
|[Implementing FrugalGPT: Reducing LLM Costs & Improving Performance.](https://portkey.ai/blog/implementing-frugalgpt-smarter-llm-usage-for-lower-costs/) |There are steps you can take with FrugalGPT to significantly lower LLM API expenses. Prompt compression, caching, and other things are among them. |
|[Graph Machine Learning in the Era of Large Language Models (LLMs).](https://arxiv.org/abs/2404.14928) |Therefore, in this survey, we first review the recent developments in Graph ML. We then explore how LLMs can be utilized to enhance the quality of graph features, alleviate the reliance on labeled data, and address challenges such as graph heterogeneity and out-of-distribution (OOD) generalization. Afterward, we delve into how graphs can enhance LLMs, highlighting their abilities to enhance LLM pre-training and inference. Furthermore, we investigate various applications and discuss the potential future directions in this promising field. |
|[A Survey on Self-Evolution of Large Language Models.](https://arxiv.org/abs/2404.14387) | In this work, we present a comprehensive survey of self-evolution approaches in LLMs. We first propose a conceptual framework for self-evolution and outline the evolving process as iterative cycles composed of four phases: experience acquisition, experience refinement, updating, and evaluation. Second, we categorize the evolution objectives of LLMs and LLM-based agents |
|[Effort. A possibly new algorithm for LLM Inference.](https://kolinko.github.io/effort/) | In order to strike a compromise between speed and quality, effort allows real-time tweaking of computations during LLM model inference on Apple Silicon CPUs. The technique loads fewer weights into the models, allowing them to run faster, although it involves precomputation and conversion, and does not require retraining. The implementation may be downloaded from GitHub; the creators are looking for help from Swift/Metal engineers to optimize it.|
|[whisper.cpp-cli.](https://github.com/charliermarsh/whisper.cpp-cli) | A fully self-contained speech-to-text system built on top of Whisper|
|[memary: Open-Source Longterm Memory for Autonomous Agents.](https://github.com/kingjulio8238/memary) |Agents use LLMs that are currently constrained to finite context windows. memary overcomes this limitation by allowing your agents to store a large corpus of information in knowledge graphs, infer user knowledge through our memory modules, and only retrieve relevant information for meaningful responses. |
|[mistral.rs.](https://github.com/EricLBuehler/mistral.rs) | Mistral.rs is a fast LLM inference platform supporting inference on a variety of devices, quantization, and easy-to-use application with an Open-AI API compatible HTTP server and Python bindings.|
|[Autodidax: JAX core from scratch.](https://jax.readthedocs.io/en/latest/autodidax.html) | Ever want to learn how JAX works, but the implementation seemed impenetrable? Well, you’re in luck! By reading this tutorial, you’ll learn every big idea in JAX’s core system. You’ll even get clued into our weird jargon!|
|[cjpais/moondream2-llamafile.](https://huggingface.co/cjpais/moondream2-llamafile) |a completely standalone VLM executable with strong performance for its size that may be used on edge devices built on the Moondream 2 model. |
|[The open-source language model computer.](https://github.com/OpenInterpreter/01) | The 01 Project is building an open-source ecosystem for AI devices.|
|[Meta Releases ExecuTorch Framework for LLM on Edge Devices.](https://pytorch.org/blog/executorch-alpha/) | A post-training quantization toolset called Meta's ExecuTorch Framework makes it possible to run Llama models on a variety of iPhone and Galaxy devices. On mobile devices with 7B-sized language models, it can obtain up to 11 tokens per second.|
|[A Survey on Vision Mamba: Models, Applications and Challenges.](https://arxiv.org/abs/2404.18861v1) | Without the computational limitations of conventional Transformers, the Mamba model represents a cutting-edge method that performs exceptionally well when handling lengthy sequences.|
|[The cuda-checkpoint Utility.](https://github.com/NVIDIA/cuda-checkpoint) | a brand-new Nvidia toolbox that enables CUDA state checkpointing for resuming and transferring. Distributed training of very big AI models can benefit from it.|
|[Friends Don't Let Friends Make Bad Graphs.](https://github.com/cxli233/FriendsDontLetFriends) |In the field of AI research nowadays, visualizing model evaluation scores is essential. But a lot of charts do a poor job of communicating the desired data. This repository includes some excellent charts as well as dos and don'ts for result visualization. |
|[phospho: Text Analytics Platform for LLM Apps.](https://github.com/phospho-app/phospho) | Phospho is the text analytics platform for LLM apps. Detect issues and extract insights from text messages of your users or your app. Gather user feedback and measure success. Iterate on your app to create the best conversational experience for your users.|
|[FlowTestAI.](https://github.com/FlowTestAI/FlowTest) | The world's first open-source, GenAI-powered Integrated Development Environment (IDE) created especially for creating, visualizing, and overseeing API-first workflows is called FlowTestAI.|
|[A transformer walk-through, with Gemma.](https://graphcore-research.github.io/posts/gemma/) |Understanding the Transformer is an endeavor that often takes several tries. This blog post walks through the Gemma architecture and explains everything in detail. It is clear and has code and figures. |
|[Vibe-Eval: A new open and hard evaluation suite for measuring progress of multimodal language models.](https://www.reka.ai/news/vibe-eval) |Vibe-Eval is comprised of 269 ultra high quality image-text prompts and their ground truth responses. The quality of prompts and responses has been extensively checked multiple times by our team. Moreover, Vibe-Eval was designed to be difficult, challenging even to the current frontier models, and to induce greater separability among frontier-class models. |
|[RALM_Survey.](https://github.com/2471023025/ralm_survey) | This is a repository of RALM surveys containing a summary of state-of-the-art RAG and other technologies according to according to our survey paper: RAG and RAU: A Survey on Retrieval-Augmented Language Model in Natural Language Processing . In this repository, we will present the most central research approach of our thesis as well as keep up-to-date with work on RALM in the most accessible way possible. |
|[NousResearch/Hermes-2-Pro-Llama-3-8B.](https://huggingface.co/NousResearch/Hermes-2-Pro-Llama-3-8B) | The next iteration of Hermes, which was trained on a freshly cleaned dataset atop Llama 3, is now accessible. This model would be a valuable agent since it is very good at invoking functions.|
|[databonsai.](https://github.com/databonsai/databonsai) |databonsai is a Python library that uses LLMs to perform data cleaning tasks. |
|[InstructDoc: A Dataset for Zero-Shot Generalization of Visual Document Understanding with Instructions.](https://github.com/nttmdlab-nlp/instructdoc) | The InstructDr model is engineered to perform exceptionally well in a range of visual document interpretation tasks, including information extraction and question answering. Through the use of big language models combined with document images, InstructDr can outperform existing models and adapt to new tasks and datasets.|


## Perspectives
|Link|description|
|---|---|
|[The demise of Twitter: how a ‘utopian vision’ for social media became a ‘toxic mess’.](https://www.theguardian.com/technology/2024/apr/28/the-demise-of-twitter-how-a-utopian-vision-for-social-media-became-a-toxic-mess) | In the early days it was seen as a place for ‘genuine public discourse’, but users have fled since Elon Musk took over. What went wrong?|
|[AI isn't useless. But is it worth it?](https://www.citationneeded.news/ai-isnt-useless/) |This article offers a critical analysis of artificial intelligence (AI) and machine learning, contending that although these technologies can be helpful for specific tasks, they frequently fall short of the lofty claims made by AI businesses.  |
|[Binding Public Sector AI Diffusion.](https://digitalspirits.substack.com/p/binding-public-sector-ai-diffusion) | The public sector is the target of the OMB's new AI executive order policy, which could significantly hamper AI progress owing to bureaucratic roadblocks and strict safety regulations. The rules, which are being implemented in the face of declining IT funding, have the potential to stall initiatives that are essential to updating government services in addition to slowing the adoption of AI. Opponents fear that these limitations, in addition to funding reductions, may make it impossible for agencies to stay up with technology advancements in industries like healthcare.|
|[A.I. Start-Ups Face a Rough Financial Reality Check.](https://www.nytimes.com/2024/04/29/technology/ai-startups-financial-reality.html) | The table stakes for small companies to compete with the likes of Microsoft and Google are in the billions of dollars. And even that may not be enough.|
|[The rewards of reusable machine learning code.](https://www.nature.com/articles/s42256-024-00835-5) | Research papers can make a long-lasting impact when the code and software tools supporting the findings are made readily available and can be reused and built on. Our reusability reports explore and highlight examples of good code sharing practices.|
|[The curious case of the test set AUROC.](https://www.nature.com/articles/s42256-024-00817-7) |The area under the receiver operating characteristic curve (AUROC) of the test set is used throughout machine learning (ML) for assessing a model’s performance. However, when concordance is not the only ambition, this gives only a partial insight into performance, masking distribution shifts of model outputs and model instability. |
|[Federated learning is not a cure-all for data ethics.](https://www.nature.com/articles/s42256-024-00813-x) |Although federated learning is often seen as a promising solution to allow AI innovation while addressing privacy concerns, we argue that this technology does not fix all underlying data ethics concerns. Benefiting from federated learning in digital health requires acknowledgement of its limitations. |
|[How scholars armed with cutting-edge technology are unfurling secrets of ancient scrolls.](https://www.theguardian.com/books/article/2024/may/03/how-scholars-armed-with-cutting-edge-technology-are-unfurling-secrets-of-ancient-scrolls) |Researchers and Silicon Valley are using tools powered by AI to uncover lives of ancient philosophers |
|[Friends From the Old Neighborhood Turn Rivals in Big Tech’s A.I. Race.](https://www.nytimes.com/2024/04/29/technology/ai-google-microsoft.html) | Demis Hassabis and Mustafa Suleyman, who both grew up in London, feared a corporate rush to build artificial intelligence. Now they’re driving that competition at Google and Microsoft.|
|[The Great Talent Dividend and NYC's AI Opportunity.](https://www.luxcapital.com/news/the-great-talent-dividend-and-nycs-ai-opportunity) |NYC's leadership in AI is a testament to its rich talent pool and expanding stature as a hub for AI. Tech professionals and AI unicorns have been drawn to NYC's tech ecosystem. Resources such as top institutions and a $400 million fund from the AI Research Consortium power it. |
|[How AI apps make money.](https://www.growthunhinged.com/p/how-ai-apps-make-money) |With an emphasis on per-user fees, most AI apps have embraced traditional subscription-based pricing models in recent years, reflecting their function as digital assistants rather than human worker replacements. Newer AI companies are starting to use creative pricing techniques, like outcome-based models, which charge only for good outcomes, potentially increasing client adoption and revenue.|
|[Danger and opportunity for news industry as AI woos it for vital human-written copy.](https://www.theguardian.com/media/article/2024/may/04/danger-and-opportunity-for-news-industry-as-ai-woos-it-for-vital-human-written-copy) | With large language models needing quality data, some publishers are offering theirs at a price while others are blocking access|

# ML news: Week 21 - 28 April

## Research
|Link|description|
|---|---|
|[Moving Object Segmentation: All You Need Is SAM (and Flow).](https://www.robots.ox.ac.uk/~vgg/research/flowsam/) |The temporal consistency of videos makes object segmentation difficult. This work presents the use of optical flow in conjunction with a potent image segmentation model to achieve compelling performance on this task. |
|[From r to Q∗: Your Language Model is Secretly a Q-Function.](https://arxiv.org/abs/2404.12358) |A somewhat technical paper on reinforcement learning that demonstrates the theoretical foundation of language reward models and base models. |
|[decoupleQ: Towards 2-bit Post-Training Uniform Quantization via decoupling Parameters into Integer and Floating Points.](https://arxiv.org/abs/2404.12759v1) | A quantization technique called DecoupleQ dramatically improves large model accuracy at ultra-low bit levels. By dividing the model parameters into integer and floating-point components, which are subsequently optimized using conventional techniques, this approach reorganizes the quantization process.|
|[MoVA: Adapting Mixture of Vision Experts to Multimodal Context.](https://arxiv.org/abs/2404.13046v1) | MoVA is a multimodal large language model (MLLM) that integrates various visual encoders selectively to enhance the understanding of image material. By employing a context-aware expert routing method and a mixture-of-vision expert adaptor to dynamically fuse knowledge from many sources, it overcomes the drawbacks of existing encoders such as CLIP.|
|[MambaMOS: LiDAR-based 3D Moving Object Segmentation with Motion-aware State Space Model.](https://arxiv.org/abs/2404.12794v1) |MambaMOS is a novel method that researchers have created for segmenting moving objects in LiDAR point clouds. |
|[Training-and-pormpt Free General Painterly Image Harmonization Using image-wise attention sharing.](https://github.com/bluedyee/tf-gph) | TF-GPH is a novel Painterly Image Harmonization technique that uses a novel "share-attention module" to avoid the need for training data or prompts.|
|[FinLangNet: A Novel Deep Learning Framework for Credit Risk Prediction Using Linguistic Analogy in Financial Data.](https://github.com/leiyu0210/finlangnet) |A model called FinLangNet was created to improve risk prediction in the financial industry. FinLangNet is a unique model that resembles linguistic structures in that it uses natural language processing techniques to simulate credit loan trajectories. |
|[Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone.](https://arxiv.org/abs/2404.14219) |Phi 3 is a family of models that ranges in size from 3B to 14B and does remarkably well on contemporary benchmarks. The original ChatGPT model is said to perform worse than the 3B model. The weights are no longer in place. A variation with a context length of 128k is offered. |
|[SEED-X: Multimodal Models with Unified Multi-granularity Comprehension and Generation.](https://arxiv.org/abs/2404.14396v1) |SEED-X addresses practical application issues to develop multimodal foundation models. It can generate images with different levels of detail and comprehend images of any size and aspect ratio. |
|[The Instruction Hierarchy: Training LLMs to Prioritize Privileged Instructions.](https://arxiv.org/abs/2404.13208) | Stronger weighting for system prompts was discovered by OpenAI, and this significantly increases the model's resistance to adversarial attacks and jailbreaks.|
|[MultiBooth: Towards Generating All Your Concepts in an Image from Text.](https://multibooth.github.io/) | In order to improve multi-concept image generation, MultiBooth presents a two-phase methodology that addresses the issues of idea integrity and high costs associated with alternative approaches.|
|[6Img-to-3D.](https://6img-to-3d.github.io/) |With just six input photographs, a unique technique called 6Img-to-3D employs transformers to produce 3D-consistent graphics. |
|[Simple probes can catch sleeper agents.](https://www.anthropic.com/research/probes-catch-sleeper-agents) | Language models known as "sleeper agents" have been trained to carry out malevolent deeds in response to a predetermined set of wake words. The question "are you going to do something dangerous?" combined with simple linear heads in language models allows for the incredibly accurate identification of these previously undetected malevolent individuals.|
|[Taming Diffusion Probabilistic Models for Character Control.](https://aiganimation.github.io/CAMDM/) |È stato introdotto un framework per il controllo dei personaggi che sfrutta i modelli probabilistici di diffusione del movimento per produrre una serie di animazioni di alta qualità che rispondono istantaneamente ai comandi dinamici dell'utente. |
|[CutDiffusion: A Simple, Fast, Cheap, and Strong Diffusion Extrapolation Method.](https://arxiv.org/abs/2404.15141v1) | CutDiffusion è un nuovo approccio che trasforma i modelli di diffusione a bassa risoluzione per soddisfare le esigenze di alta risoluzione senza le complessità del tuning tradizionale.|
|[Graph Neural Networks for Vulnerability Detection: A Counterfactual Explanation.](https://arxiv.org/abs/2404.15687v1) |A new tool called CFExplainer enhances the ability of AI models—more especially, Graph Neural Networks—to comprehend and recognize security flaws in software. |
|[Conformal Predictive Systems Under Covariate Shift.](https://arxiv.org/abs/2404.15018v1) |A kind of conformal predictive systems that responds to modifications in data settings, particularly covariate alterations, is called weighted CPS (WCPS). |
|[Masked Modeling with Multi-View Video for Autonomous Driving Representation Learning.](https://github.com/hustvl/mim4d) | MIM4D is a novel method that uses dual masked image modeling to extract temporal and spatial features from multi-view films, improving visual representation learning in autonomous driving.|
|[FR-NAS: Forward-and-Reverse Graph Predictor for Efficient Neural Architecture Search.](https://arxiv.org/abs/2404.15622v1) |A Graph Neural Network (GNN) predictor that improves the effectiveness of finding the best neural network configurations for particular tasks is introduced by creative work in Neural Architecture Search (NAS). |
|[Raformer: Redundancy-Aware Transformer for Video Wire Inpainting.](https://github.com/Suyimu/WRV2) |A new dataset and technique for enhancing wire removal in videos—a frequent visual effect problem in movies and TV shows—have been presented by researchers. |

## News
|Link|description|
|---|---|
|[Updates from Google DeepMind Alignment research.](https://www.alignmentforum.org/posts/HpAr8k74mW4ivCvCu/progress-update-from-the-gdm-mech-interp-team-summary) | GDM has published some of the results of its alignment efforts after Anthropic. The use of sparse autoencoders on Gemini Ultra is the most insightful article in this article. This is a significant increase in the size of interpretation.|
|[NVIDIA To Collaborate With Japan On Their Cutting-Edge ABCI-Q Quantum Supercomputer.](https://wccftech.com/nvidia-japan-abci-q-quantum-supercomputer/) | Japan To Rapidly Progressing In Quantum and AI Computing Segments Through Large-Scale Developments With The Help of NVIDIA's AI & HPC Infrastructure|
|[Brave Search is adopting AI to answer your queries.](https://techcrunch.com/2024/04/17/brave-search-is-adopting-ai-to-answer-your-queries/) | Privacy-focused search engine Brave announced Wednesday that it is revamping its answer engine to return AI-powered synthesized answers. The new feature is available to users across the globe.|
|[Llama 3 is not very censored.](https://ollama.com/blog/llama-3-is-not-very-censored) | Llama 3 feels significantly less censored than its predecessor. The Llama 3 models have substantially lower false refusal rates, with less than 1⁄3 the amount of false refusals when compared to Llama 2, making it possible to discuss a wider range of interesting topics!|
|[OpenAI's GPT-4 can exploit real vulnerabilities by reading security advisories.](https://www.theregister.com/2024/04/17/gpt4_can_exploit_real_vulnerabilities/) | Researchers have shown that OpenAI's GPT-4 model outperforms other models and tools like vulnerability scanners, with an 87% success rate in autonomously exploiting security vulnerabilities listed in CVE advisories.|
|[US Air Force confirms first successful AI dogfight.](https://www.theverge.com/2024/4/18/24133870/us-air-force-ai-dogfight-test-x-62a) |The US Air Force is putting AI in the pilot’s seat. In an update on Thursday, the Defense Advanced Research Projects Agency (DARPA) revealed that an AI-controlled jet successfully faced a human pilot during an in-air dogfight test carried out last year. |
|[Intel completes assembly of first commercial High-NA EUV chipmaking tool — addresses cost concerns, preps for 14A process development in 2025.](https://www.tomshardware.com/pc-components/cpus/intel-completes-assembly-of-first-commercial-high-na-euv-chipmaking-tool-as-it-preps-for-14a-process) | Intel Foundry announced Thursday that it had completed the assembly of the industry's first commercial High Numerical Aperture (High-NA) Extreme Ultraviolet (EUV) machine in its D1X fab in Oregon -- an important milestone as the company readies research and development for its 14A process in 2025. |
|[Adobe previews AI innovations to advance professional video workflows.](https://news.adobe.com/news/news-details/2024/Adobe-previews-breakthrough-AI-innovations-to-advance-professional-video-workflows-within-Adobe-Premiere-Pro/) | With the help of its Firefly video model, Adobe is incorporating generative AI video tools into Premiere Pro, which include new features for shot extension, object addition/removal, and text-to-video functionality. The changes are intended to improve the effectiveness and creativity of video creation. They include a technological preview and the broad availability of AI-powered audio workflows.|
|[The Ray-Ban Meta Smart Glasses have multimodal AI now.](https://www.theverge.com/2024/4/23/24138090/ray-ban-meta-smart-glasses-ai-wearables) | It can be handy, confidently wrong, and just plain finicky — but smart glasses are a much more comfortable form factor for this tech.|
|[OpenAI shrugs off Meta’s Llama 3 ascent with new enterprise AI features.](https://venturebeat.com/ai/openai-shrugs-off-metas-llama-3-ascent-with-new-enterprise-ai-features/) | Even as Meta’s new Llama 3 has quickly rocketed up the charts of most-used and most customized large language models (LLMs), the rival company that ushered in the generative AI era, OpenAI, is shrugging off the competition by introducing new enterprise-grade features for building and programming atop its GPT-4 Turbo LLM and other models.|
|[Gurman: Apple Working on On-Device LLM for Generative AI Features.](https://www.macrumors.com/2024/04/21/apple-working-on-on-device-llm/) |Writing in his "Power On" newsletter, Gurman said that Apple's LLM underpins upcoming generative AI features. "All indications" apparently suggests that it will run entirely on-device, rather than via the cloud like most existing AI services. |
|[Los Angeles is using AI in a pilot program to try to predict homelessness and allocate aid.](https://www.cnbc.com/2024/04/19/los-angeles-is-using-an-ai-pilot-program-to-try-to-predict-homelessness.html) |In Los Angeles, the Homelessness Prevention Program uses predictive AI to identify individuals and families at risk of becoming homeless, offering aid to help them get stabilized and remain housed. |
|[Startup Uses AI To Edit Human Data.](https://futurism.com/neoscope/startup-uses-ai-edit-human-dna) |A team of researchers at a Berkeley-based startup called Profluent say they've used generative AI technologies to edit human DNA. As the New York Times reports, the startup fed huge amounts of biological data into a large language model (LLM) to come up with new editors based on the groundbreaking gene-editing technique CRISPR, as detailed in a yet-to-be-peer-reviewed paper.|
|[Apple releases OpenELM: small, open source AI models designed to run on-device.](https://venturebeat.com/ai/apple-releases-openelm-small-open-source-ai-models-designed-to-run-on-device/) |Just as Google, Samsung and Microsoft continue to push their efforts with generative AI on PCs and mobile devices, Apple is moving to join the party with OpenELM, a new family of open-source large language models (LLMs) that can run entirely on a single device rather than having to connect to cloud servers. |
|[Eric Schmidt-backed Augment, a GitHub Copilot rival, launches out of stealth with $252M.](https://techcrunch.com/2024/04/24/eric-schmidt-backed-augment-a-github-copilot-rival-launches-out-of-stealth-with-252m/) |In a recent StackOverflow poll, 44% of software engineers said that they use AI tools as part of their development processes now and 26% plan to soon. Gartner estimates that over half of organizations are currently piloting or have already deployed AI-driven coding assistants, and that 75% of developers will use coding assistants in some form by 2028. |
|[Sakana releases Japanese image model.](https://sakana.ai/evosdxl-jp/) |a high-speed image generation model optimized for Japanese language prompts  |
|[Generative A.I. Arrives in the Gene Editing World of CRISPR.](https://www.nytimes.com/2024/04/22/technology/generative-ai-gene-editing-crispr.html?unlocked_article_code=1.mk0.JQS0.P95fZ2M-SfYp) | Much as ChatGPT generates poetry, a new A.I. system devises blueprints for microscopic mechanisms that can edit your DNA.Generative A.I. technologies can write poetry and computer programs or create images of teddy bears and videos of cartoon characters that look like something from a Hollywood movie. Now, new A.I. technology is generating blueprints for microscopic biological mechanisms that can edit your DNA, pointing to a future when scientists can battle illness and diseases with even greater precision and speed than they can today.|
|[FlexAI Launches with $30 Million in Seed Funding to Deliver Universal AI Compute.](https://www.globenewswire.com/news-release/2024/04/24/2868408/0/en/FlexAI-Launches-with-30-Million-in-Seed-Funding-to-Deliver-Universal-AI-Compute.html) |Ex-Apple, Intel, NVIDIA, and Tesla veterans rearchitect compute infrastructure to accelerate AI innovation.  FlexAI, the universal AI compute company, today launched with $30 million (€28.5 million) in seed funding led by Alpha Intelligence Capital (AIC), Elaia Partners, and Heartcore Capital. |
|[Report: Google will update Gemini Nano in time for Galaxy S25.](https://9to5google.com/2024/04/24/google-gemini-nano-2-report/) |Google’s Gemini AI models are constantly advancing, so it comes as no surprise that a new report claims Google will have a “version 2” of Gemini Nano available by the time the Galaxy S25 launches next year. |
|[Microsoft’s heavy bet on AI pays off as it beats expectations in latest quarter.](https://www.theguardian.com/technology/2024/apr/25/microsoft-earnings) |World’s largest public company reports $61.86bn revenue after investing billions into artificial intelligence |
|[Alphabet hails ‘once-in-a-generation’ AI opportunity as revenue rises.](https://www.theguardian.com/technology/2024/apr/25/google-revenue-quarter-one) |Shares surge after tech giant issues first ever dividend and posts revenue of $80.5bn, up 15% since last year, despite staff turmoil |
|[Meta value falls $190bn as investors react to plan to increase spending on AI.](https://www.theguardian.com/technology/2024/apr/25/meta-value-falls-190bn-as-investors-react-to-plan-to-increase-spending-on-ai) | Shares slumped 15% after Mark Zuckerberg said AI spending would have to grow before Meta could make much revenue from products|
|[Snowflake Arctic - LLM for Enterprise AI.](https://www.snowflake.com/blog/arctic-open-efficient-foundation-language-models-snowflake/) |The enterprise-grade LLM known as Snowflake Arctic, developed by the Snowflake AI Research Team, outperforms competitors in instruction-following benchmarks, coding, and SQL creation at a quarter of the usual cost. Arctic makes sophisticated LLM capabilities available to a larger audience by utilizing an open-source methodology and a distinctive design. Hugging Face offers the model, which will also be incorporated into other platforms and services. |
|[Nvidia acquires AI workload management startup Run:ai for $700M, sources say.](https://techcrunch.com/2024/04/24/nvidia-acquires-ai-workload-management-startup-runai) |Nvidia is acquiring Run:ai, a Tel Aviv-based company that makes it easier for developers and operations teams to manage and optimize their AI hardware infrastructure. Terms of the deal aren’t being disclosed publicly, but two sources close to the matter tell TechCrunch that the price tag was $700 million |
|[Apple has acquired the Paris-based artificial intelligence startup Datakalab amid its push to deliver on-device AI tools.](https://www.macrumors.com/2024/04/22/apple-acquires-french-ai-company/) | Apple has acquired the Paris-based artificial intelligence startup Datakalab amid its push to deliver on-device AI tools.|
|[Drake Uses AI Tupac and Snoop Dogg Vocals on ‘Taylor Made Freestyle,’ References Taylor Swift’s New Album ‘The Tortured Poets Department’.](https://variety.com/2024/music/news/drake-taylor-made-freestyle-tupac-shakur-taylor-swift-snoop-dogg-1235977178/) | On Friday night (April 19), the rapper released a song on his social media entitled “Taylor Made Freestyle,” which uses AI vocals from Tupac Shakur and Snoop Dogg on a stopgap between diss records as he awaits Kendrick Lamar’s reply to his freshly released “Push Ups.”|

## Resources
|Link|description|
|---|---|
|[Fine-tune Llama 3 with ORPO.](https://mlabonne.github.io/blog/posts/2024-04-19_Fine_tune_Llama_3_with_ORPO.html) | ORPO is a new exciting fine-tuning technique that combines the traditional supervised fine-tuning and preference alignment stages into a single process. This reduces the computational resources and time required for training. Moreover, empirical results demonstrate that ORPO outperforms other alignment methods on various model sizes and benchmarks.|
|[Mistral Common.](https://github.com/mistralai/mistral-common) | mistral-common is a set of tools to help you work with Mistral models. Our first release contains tokenization. Our tokenizers go beyond the usual text <-> tokens, adding parsing of tools and structured conversation. We also release the validation and normalization code that is used in our API.|
|[LongEmbed.](https://github.com/dwzhu-pku/LongEmbed) |This repository is the official implementation for the paper "LongEmbed: Extending Embedding Models for Long Context Retrieval" |
|[FineWeb: 15T high quality web tokens.](https://huggingface.co/datasets/HuggingFaceFW/fineweb) |15T tokens were used to train the most recent Llama 3 models. This new dataset yields high-quality models and includes a large deduplicated corpus from common crawl. |
|[A Visual Guide to Vision Transformers.](https://blog.mdturp.ch/posts/2024-04-05-visual_guide_to_vision_transformer.html) | This is a visual guide to Vision Transformers (ViTs), a class of deep learning models that have achieved state-of-the-art performance on image classification tasks. This guide will walk you through the key components of Vision Transformers in a scroll story format, using visualizations and simple explanations to help you understand how these models work and how the flow of the data through the model looks like.|
|[The Cauldron VLM data.](https://huggingface.co/datasets/HuggingFaceM4/the_cauldron) |50 language and vision datasets merged into a single format to enable better model training. |
|[MAexpA Generic Platform for RL-based Multi-Agent Exploration.](https://github.com/duangzhu/maexp) |MAexp, a generic high-efficiency platform designed for multi-agent exploration, encompassing a diverse range of scenarios and MARL algorithms.  |
|[Practitioners Guide to Triton.](https://www.youtube.com/watch?v=DdTsX6DQk24&ab_channel=CUDAMODE) |A high-level language for creating low-level CUDA kernels is called Triton. It lets you write in a Python-style format and significantly improves the efficiency of your AI model. |
|[Efficiently fine-tune Llama 3 with PyTorch FSDP and Q-Lora.](https://www.philschmid.de/fsdp-qlora-llama3) |Great blog covering a quick and efficient fine-tuning method using PyTorch on the recent Llama 3 model. |
|[Layer Pruning of Large Language Models.](https://github.com/arcee-ai/PruneMe/) | This repository hosts the unofficial implementation of a layer pruning strategy for Large Language Models (LLMs) based on the insights from the paper "The Unreasonable Ineffectiveness of the Deeper Layers" by Andrey Gromov et al. |
|[A Trivial Jailbreak Against Llama 3.](https://github.com/haizelabs/llama3-jailbreak) | A trivial programmatic Llama 3 jailbreak. |
|[LLaMA3-Quantization.](https://github.com/macaronlin/llama3-quantization) |Given the wide application of low-bit quantization for LLMs in resource-limited scenarios, we explore LLaMa3's capabilities when quantized to low bit-width. This exploration holds the potential to unveil new insights and challenges for low-bit quantization of LLaMa3 and other forthcoming LLMs, especially in addressing performance degradation problems that suffer in LLM compression.  |
|[Instructor: Structured LLM Outputs.](https://github.com/jxnl/instructor) | Instructor is a Python library that makes it a breeze to work with structured outputs from large language models (LLMs). Built on top of Pydantic, it provides a simple, transparent, and user-friendly API to manage validation, retries, and streaming responses. Get ready to supercharge your LLM workflows!|
|[How does ChatGPT work? As explained by the ChatGPT team.](https://blog.pragmaticengineer.com/how-does-chatgpt-work/) | Sometimes the best explanations of how a technology solution works come from the software engineers who built it. To explain how ChatGPT (and other large language models) operate, I turned to the ChatGPT engineering team.|
|[BitBLAS.](https://github.com/microsoft/BitBLAS) | A collection of GPU-accelerated kernels for BitNet-style model training has been made available by Microsoft. These devices offer a significant reduction in memory usage without sacrificing much accuracy.|
|[CoreNet: A library for training deep neural networks.](https://github.com/apple/corenet) |CoreNet is a deep neural network toolkit from Apple that allows researchers and engineers to train standard and novel small and large-scale models for variety of tasks, including foundation models (e.g., CLIP and LLM), object classification, object detection, and semantic segmentation. |
|[MaxText.](https://github.com/google/maxtext) | MaxText is a high performance, highly scalable, open-source LLM written in pure Python/Jax and targeting Google Cloud TPUs and GPUs for training and inference. MaxText achieves high MFUs and scales from single host to very large clusters while staying simple and "optimization-free" thanks to the power of Jax and the XLA compiler.|
|[Cohere Toolkit.](https://github.com/cohere-ai/cohere-toolkit/) | A chat interface with numerous useful capabilities for creating AI-powered chat apps has been made available by Cohere.|
|[BAAI/Bunny-Llama-3-8B-V.](BAAI/Bunny-Llama-3-8B-V) |Bunny is a family of lightweight but powerful multimodal models. It offers multiple plug-and-play vision encoders, like EVA-CLIP, SigLIP and language backbones, including Llama-3-8B, Phi-1.5, StableLM-2 and Phi-2. To compensate for the decrease in model size, we construct more informative training data by curated selection from a broader data source. |
|[Finetune Llama 3 - 2x faster + 6x longer context + 68% less VRAM.](https://unsloth.ai/blog/llama3) |6x long context length with dramatically less VRAM usage than HF with flash attention. |


## Perspectives
|Link|description|
|---|---|
|[Self-Reasoning Tokens, teaching models to think ahead.](https://reasoning-tokens.ghost.io/reasoning-tokens/) |This paper presents "reasoning tokens" for language models, which produce more tokens intended to forecast future tokens instead of the one that is immediately next, improving the model's anticipatory capacity. Experiments show notable increases in prediction accuracy, indicating that more sophisticated reasoning may be possible without the need for explicit step-by-step training. |
|[Looking for AI use-cases.](https://www.ben-evans.com/benedictevans/2024/4/19/looking-for-ai-use-cases) | This article explores the potential for transformation and the existing constraints of generative AI, such as ChatGPT. It points out that although ChatGPT performs well on simple tasks like coding and creating drafts, it has trouble with more complicated tasks that call for specialized programming. It emphasizes the necessity of a vision that links AI solutions with useful applications and stresses how difficult it is to find and incorporate these into regular workflows.|
|[Building reliable systems out of unreliable agents.](https://www.rainforestqa.com/blog/building-reliable-systems-out-of-unreliable-agents) | Although AI agents aren't always dependable, they can be used to create dependable systems. A few strategies are to start with basic prompts and build an iterative improvement evaluation system; to deploy with observability; to use Retrieval Augmented Generation (RAG); to think about fine-tuning the model; and to use complementary agents to strengthen each other's weaknesses and increase the overall reliability of the system.|
|[AI leads a service-as-software paradigm shift.](https://foundationcapital.com/ai-service-as-software/) | Many VCs are talking about AI taking a bite out of the services business. Foundation Capital believes there is $4.6 trillion worth of work to be automated, thanks to AI: both for in-house functions and outsourced services. We're entering the era of Service-as-Software.|
|[How AI is improving climate forecasts.](https://www.nature.com/articles/d41586-024-00780-8) |Researchers are using various machine-learning strategies to speed up climate modelling, reduce its energy costs and hopefully improve accuracy. |
|[Will AI accelerate or delay the race to net-zero emissions?](https://www.nature.com/articles/d41586-024-01137-x) |As artificial intelligence transforms the global economy, researchers need to explore scenarios to assess how it can help, rather than harm, the climate. |
|[The Biggest Open-Source Week in the History of AI.](https://www.ai-supremacy.com/p/the-biggest-open-source-week-in-the) |The last week of March, 2024 will go down as a unique moment for Open-source LLMs. China's open-source scene hits the ground running. |
|[‘Miss AI’ is billed as a leap forward – but feels like a monumental step backwards.](https://www.theguardian.com/commentisfree/2024/apr/23/miss-ai-artificial-intelligence-models-gendered-beauty-norms) |AI models take every toxic gendered beauty norm and bundle them up into completely unrealistic package |
|[Why reliable AI requires a paradigm shift.](https://blog.apiad.net/p/reliable-ai-is-harder-than-you-think) | Hallucinations are the fundamental barrier for the widespread use of AI, and they won't be solved anytime soon.|
|[Should Apple Kill Siri and Start Over?](https://www.macrumors.com/2024/04/18/should-apple-kill-siri/) |The vision was grand: A personal assistant in your pocket, capable of understanding and acting upon a wide array of voice commands with ease and accuracy. So what happened? |


# ML news: Week 15 - 21 April

## Research
|Link|description|
|---|---|
|[DGMamba: Domain Generalization via Generalized State Space Model.](https://arxiv.org/abs/2404.07794v1) | DGMamba is a new framework that makes use of the novel state space model Mamba to address domain generalization problems.|
|[Manipulating Large Language Models to Increase Product Visibility.](https://arxiv.org/abs/2404.07981v1) |Search engines' extensive language models can be manipulated by adding strategic text sequences to product descriptions to promote specific products. |
|[MindBridge: A Cross-Subject Brain Decoding Framework.](https://littlepure2333.github.io/MindBridge/) | MindBridge is a single model that can interpret brain activity from several subjects. |
|[Taming Stable Diffusion for Text to 360° Panorama Image Generation.](https://chengzhag.github.io/publication/panfusion/) | With the help of text prompts, this project presents PanFusion, a dual-branch diffusion model that creates 360-degree panoramic images. In order to minimize visual distortion, the technique combines the Stable Diffusion approach with a customized panoramic branch, which is further improved by a special cross-attention mechanism. |
|[The Physics of Language Models.](https://arxiv.org/abs/2404.05405) | Scaling laws describe the relationship between the size of language models and their capabilities. Unlike prior studies that evaluate a model's capability via loss or benchmarks, we estimate the number of knowledge bits a model stores. |
|[The Influence Between NLP and Other Fields.](https://aclanthology.org/2023.emnlp-main.797/) | attempts to measure the level of influence that NLP has over 23 different fields of study; the cross-field engagement of NLP has decreased from 0.58 in 1980 to 0.31 in 2022; the study also reveals that CS dominates NLP citations, accounting for over 80% of citations with a focus on information retrieval, AI, and ML; in general, NLP is becoming more isolated, with a rise in intra-field citations and a fall in multidisciplinary works.|
|[EventEgo3D: 3D Human Motion Capture from Egocentric Event Streams.](https://4dqv.mpi-inf.mpg.de/EventEgo3D/) | Researchers present a unique technique utilizing a fisheye event camera to address the difficulties in monocular egocentric 3D human motion capture, particularly in challenging lighting conditions and with rapid motions. |
|[MPPE-DST: Mixture of Prefix Prompt Experts for LLM in Zero-Shot Dialogue State Tracking.](https://github.com/ttw1018/mope-dst) | Mixture of Prefix Prompt Experts (MPPE) is a novel approach that has been created by researchers to improve zero-shot dialogue state tracking. This technique allows knowledge to be transferred to new domains without requiring additional dataset annotations. |
|[Any2Point: Empowering Any-modality Large Models for Efficient 3D Understanding.](https://github.com/ivan-tang-3d/any2point) | A novel technique called Any2Point effectively transfers vision, language, and audio model capabilities into the 3D space while preserving spatial geometries. |
|[Google’s new technique gives LLMs infinite context.](https://venturebeat.com/ai/googles-new-technique-gives-llms-infinite-context/) | A new paper by researchers at Google claims to give large language models (LLMs) the ability to work with text of infinite length. The paper introduces Infini-attention, a technique that configures language models in a way that extends their “context window” while keeping memory and compute requirements constant.|
|[Compression Represents Intelligence Linearly.](https://arxiv.org/abs/2404.09937) | The concept of compressing a training dataset into a model is the foundation of most contemporary AI. The model gets better the better the compression. This research establishes a high correlation between scale benchmark scores and a model's capacity to condense novel material by thoroughly demonstrating that relationship. |
|[TransformerFAM: Feedback attention is working memory.](https://arxiv.org/abs/2404.09173) | Transformers may take care of their own latent representations thanks to TransformerFAM's feedback system. In theory, this might allow the model to process incredibly long inputs in context by adding repetition. |
|[Megalodon: Efficient LLM Pretraining and Inference with Unlimited Context Length.](https://arxiv.org/abs/2404.08801) | Another lengthy context paper, but this one is about a new design that makes use of two cutting-edge weight updating techniques. In comparison, Llama 2 is underperformed on the same training token count (2T). Additionally, at inference time, it scales to an indefinite context length. |
|[STORM: Synthesis of Topic Outlines through Retrieval and Multi-perspective Question Asking.](https://github.com/stanford-oval/storm) | Retrieval guided language models are used by Stanford's innovative research system, Storm, to generate reports for particular subjects. |
|[Homography Guided Temporal Fusion for Road Line and Marking Segmentation.](https://arxiv.org/abs/2404.07626v1) | Road lines and markings must be accurately segmented for autonomous driving, however this is difficult because of sunlight, shadows, and car occlusions. The Homography Guided Fusion (HomoFusion) module employs a pixel-by-pixel attention mechanism and a unique surface normal estimator to recognize and classify obscured road lines from video frames. |
|[LaSagnA: vLLM-based Segmentation Assistant for Complex Queries.](https://github.com/congvvc/lasagna) | Vision Language Models (vLLMs) sometimes face difficulties in distinguishing absent objects and handling many queries per image. In order to address these problems, this work presents a novel question style and integrates semantic segmentation into the training procedure.|
|[A collective AI via lifelong learning and sharing at the edge.](https://www.nature.com/articles/s42256-024-00800-2) | Here we review recent machine learning advances converging towards creating a collective machine-learned intelligence. We propose that the convergence of such scientific and technological advances will lead to the emergence of new types of scalable, resilient and sustainable AI systems. |
|[Challenges and opportunities in translating ethical AI principles into practice for children.](https://www.nature.com/articles/s42256-024-00805-x) |This Perspective first maps the current global landscape of existing ethics guidelines for AI and analyses their correlation with children. |
|[Mistral 8x22B Report and Instruction Model.](https://mistral.ai/news/mixtral-8x22b/) |Mixtral 8x22B is our latest open model. It sets a new standard for performance and efficiency within the AI community. It is a sparse Mixture-of-Experts (SMoE) model that uses only 39B active parameters out of 141B, offering unparalleled cost efficiency for its size. |
|[Long-form music generation with latent diffusion.](https://arxiv.org/abs/2404.10301) | Stability AI's diffusion transformer model for audio synthesis.|
|[LaDiC: A Diffusion-based Image Captioning Model.](https://github.com/wangyuchi369/ladic) | The use of diffusion models for image-to-text generation is revisited in this work. It presents the LaDiC architecture, which improves the image captioning tasks performance of diffusion models.|
|[LINGO-2: Driving with Natural Language.](https://wayve.ai/thinking/lingo-2-driving-with-language/) |This blog introduces LINGO-2, a driving model that links vision, language, and action to explain and determine driving behavior, opening up a new dimension of control and customization for an autonomous driving experience. LINGO-2 is the first closed-loop vision-language-action driving model (VLAM) tested on public roads. |
|[Towards a general-purpose foundation model for computational pathology.](https://www.nature.com/articles/s41591-024-02857-3) | We introduce UNI, a general-purpose self-supervised model for pathology, pretrained using more than 100 million images from over 100,000 diagnostic H&E-stained WSIs (>77 TB of data) across 20 major tissue types. |
|[A visual-language foundation model for computational pathology.](https://www.nature.com/articles/s41591-024-02856-4) |We introduce CONtrastive learning from Captions for Histopathology (CONCH), a visual-language foundation model developed using diverse sources of histopathology images, biomedical text and, notably, over 1.17 million image–caption pairs through task-agnostic pretraining. |
|[FedPFT: Federated Proxy Fine-Tuning of Foundation Models.](https://arxiv.org/abs/2404.11536v1) | Federated Proxy Fine-Tuning (FedPFT), a novel technique created by researchers, enhances foundation models' ability to adjust for certain tasks while maintaining data privacy. |
|[In-Context Learning State Vector with Inner and Momentum Optimization.](https://arxiv.org/abs/2404.11225v1) | In this research, a novel method for improving In-Context Learning (ICL) in big language models such as GPT-J and Llama-2 is presented. The authors introduce a novel optimization technique that enhances compressed representations of the model's knowledge, referred to as "state vectors." |
|[Decomposing and Editing Predictionsby Modeling Model Computation.](https://github.com/madrylab/modelcomponents) | To determine each component's precise contribution to the final result, component modeling dissects a model's prediction process into its most fundamental parts, such as attention heads and convolution filters.|

## News
|Link|description|
|---|---|
|[Grok-1.5 Vision Preview.](https://x.ai/blog/grok-1.5v) | Introducing Grok-1.5V, our first-generation multimodal model. In addition to its strong text capabilities, Grok can now process a wide variety of visual information, including documents, diagrams, charts, screenshots, and photographs. Grok-1.5V will be available soon to our early testers and existing Grok users.|
|[Google’s new chips look to challenge Nvidia, Microsoft and Amazon.](https://qz.com/google-ai-chip-nvidia-axion-arm-microsoft-1851397201) | Google’s new AI chip is a rival to Nvidia, and its Arm-based CPU will compete with Microsoft and Amazon|
|[OpenAI Fires Researchers For Leaking Information.](https://futurism.com/the-byte/openai-fires-researchers-leaks) | After months of leaks, OpenAI has apparently fired two researchers who are said to be linked to company secrets going public.|
|[BabyLM Challenge.](https://babylm.github.io/) | The goal of this shared task is to incentivize researchers with an interest in pretraining or cognitive modeling to focus their efforts on optimizing pretraining given data limitations inspired by human development. Additionally, we hope to democratize research on pretraining—which is typically thought to be practical only for large industry groups—by drawing attention to open problems that can be addressed on a university budget.|
|[Dr. Andrew Ng appointed to Amazon’s Board of Directors.](https://www.aboutamazon.com/news/company-news/dr-andrew-ng-joins-amazon-board-of-directors) | Dr. Andrew Ng is currently the Managing General Partner of AI Fund and is joining Amazon's Board of Directors.|
|[Creating sexually explicit deepfake images to be made offence in UK.](https://www.theguardian.com/technology/2024/apr/16/creating-sexually-explicit-deepfake-images-to-be-made-offence-in-uk) | Offenders could face jail if image is widely shared under proposed amendment to criminal justice bill|
|[Leisure centres scrap biometric systems to keep tabs on staff amid UK data watchdog clampdown.](https://www.theguardian.com/business/2024/apr/16/leisure-centres-scrap-biometric-systems-to-keep-tabs-on-staff-amid-uk-data-watchdog-clampdown) | Firms such as Serco and Virgin Active pull facial recognition and fingerprint scan systems used to monitor staff attendance|
|[Introducing OpenAI Japan.](https://openai.com/blog/introducing-openai-japan) |We are excited to announce our first office in Asia and we’re releasing a GPT-4 custom model optimized for the Japanese language. |
|[Adobe’s working on generative video, too.](https://techcrunch.com/2024/04/15/adobes-working-on-generative-video-too/) | Adobe says it’s building an AI model to generate video. But it’s not revealing when this model will launch, exactly — or much about it besides the fact that it exists.|
|[OpenAI and Meta Reportedly Preparing New AI Models Capable of Reasoning.](https://futurism.com/the-byte/openai-meta-new-ai-models-capable-reasoning) | OpenAI and Meta are on the verge of releasing next versions of their AI models that will supposedly be capable of reasoning and planning, the Financial Times reports. But, as with any hype coming out of big tech, take it all with a grain of salt.|
|[Humane’s Ai Pin Isn't Ready to Replace Your Phone, But One Day It Might.](https://www.inverse.com/tech/humane-ai-pin-in-depth-review) |AI-powered wearable Humane's Ai Pin has numerous technical problems, ranging from AI assistant glitches to music streaming concerns. Though future software updates are promised, the first-generation gadget lacks crucial functions and experiences performance gaps despite its intention to create an ambient computing experience. The Ai Pin is positioned as a companion device for a more present and less screen-focused lifestyle, yet it struggles to replace conventional smartphones despite its meticulous design. |
|[TikTok may add AI avatars that can make ads.](https://www.theverge.com/2024/4/11/24127579/tiktok-ai-virtual-influencers-advertising) | he new feature will let advertisers and TikTok Shop sellers generate scripts for a virtual influencer to read.|
|[Google launches Code Assist, its latest challenger to GitHub’s Copilot.](https://techcrunch.com/2024/04/09/google-launches-code-assist-its-latest-challenger-to-githubs-copilot/) |At its Cloud Next conference, Google on Tuesday unveiled Gemini Code Assist, its enterprise-focused AI code completion and assistance tool. |
|[AI traces mysterious metastatic cancers to their source.](https://www.nature.com/articles/d41586-024-01110-8) | lgorithm examines images of metastatic cells to identify the location of the primary tumour. Some stealthy cancers remain undetected until they have spread from their source to distant organs. Now scientists have developed an artificial intelligence (AI) tool that outperforms pathologists at identifying the origins of metastatic cancer cells that circulate in the body|
|[Apple's iOS 18 AI will be on-device preserving privacy, and not server-side.](https://appleinsider.com/articles/24/04/15/apples-ios-18-ai-will-be-on-device-preserving-privacy-and-not-server-side) | Apple's AI push in iOS 18 is rumored to focus on privacy with processing done directly on the iPhone, that won't connect to cloud services.|
|[Introducing ALOHA Unleashed.](https://twitter.com/tonyzzhao/status/1780263497584230432) |Google DeepMind's ALOHA Unleashed is a program that pushes the boundaries of dexterity with low-cost robots and AI. |
|[France's Mistral AI seeks funding at $5 bln valuation, The Information reports.](https://www.reuters.com/technology/frances-mistral-ai-seeks-funding-5-bln-valuation-information-reports-2024-04-17/) |French tech startup Mistral AI has been speaking to investors about raising several hundred million dollars at a valuation of $5 billion, The Information reported on Tuesday. |
|[Stability AI is giving more developers access to its next-gen text-to-image generator.](https://www.theverge.com/2024/4/17/24132927/stable-diffusion-3-api-availability-stability-ai) | Developers can now access the API for the latest version of Stability AI’s text-to-image model.|
|[European car manufacturer will pilot Sanctuary AI’s humanoid robot.](https://techcrunch.com/2024/04/11/european-car-manufacturer-will-pilot-sanctuary-ais-humanoid-robot) | Sanctuary AI announced that it will be delivering its humanoid robot to a Magna manufacturing facility. Based in Canada, with auto manufacturing facilities in Austria, Magna manufactures and assembles cars for a number of Europe’s top automakers, including Mercedes, Jaguar and BMW. As is often the nature of these deals, the parties have not disclosed how many of Sanctuary AI’s robots will be deployed.|
|[Google Maps will use AI to help you find out-of-the-way EV chargers .](https://www.theverge.com/2024/4/17/24132254/google-maps-ev-charging-directions-ai-summaries) |The company will use AI to summarize directions to EV chargers as well as reliability and wait times. |
|[Introducing Meta Llama 3: The most capable openly available LLM to date.](https://ai.meta.com/blog/meta-llama-3/) |Today, we’re introducing Meta Llama 3, the next generation of our state-of-the-art open source large language model. Llama 3 models will soon be available on AWS, Databricks, Google Cloud, Hugging Face, Kaggle, IBM WatsonX, Microsoft Azure, NVIDIA NIM, and Snowflake, and with support from hardware platforms offered by AMD, AWS, Dell, Intel, NVIDIA, and Qualcomm.|
|[Google’s Deep Mind AI can help engineers predict “catastrophic failure”.](https://www.freethink.com/robots-ai/googles-deep-mind-ai-catastrophic-failure) | AI and a popular card game can help engineers predict catastrophic failure by finding the absence of a pattern.|
|[OpenAI winds down AI image generator that blew minds and forged friendships in 2022.](https://arstechnica.com/information-technology/2024/04/when-ai-images-were-mind-blowing-early-users-recall-the-first-days-of-dall-e-2/) |When OpenAI's DALL-E 2 debuted on April 6, 2022, the idea that a computer could create relatively photorealistic images on demand based on just text descriptions caught a lot of people off guard. The launch began an innovative and tumultuous period in AI history, marked by a sense of wonder and a polarizing ethical debate that reverberates in the AI space to this day. Last week, OpenAI turned off the ability for new customers to purchase generation credits for the web version of DALL-E 2, effectively killing it. |
|[Stability AI lays off roughly 10 percent of its workforce.](https://www.theverge.com/2024/4/18/24133996/stability-ai-lay-off-emad-mostaque) | Stability AI laid off 20 employees just a day after announcing the expansion of access to its new flagship model. This comes after weeks of upheaval that saw its founding CEO leave the company.|
|[The Humane AI Pin is lost in translation.](https://www.theverge.com/2024/4/18/24134180/humane-ai-pin-translation-wearables) |Though the Humane AI Pin has a lot of drawbacks, its translation feature might be the worst. |


## Resources
|Link|description|
|---|---|
|[LLM friendly HTML conversion.](https://github.com/jina-ai/reader/) | Reader converts any URL to an LLM-friendly input with a simple prefix https://r.jina.ai/. Get improved output for your agent and RAG systems at no cost.|
|[Minimal Implementation of a D3PM (Structured Denoising Diffusion Models in Discrete State-Spaces), in pytorch.](https://github.com/cloneofsimo/d3pm) |This is minimal (400 LOC), but fully faithful implementation of a D3PM Structured Denoising Diffusion Models in Discrete State-Spaces. in pytorch. |
|[Cerule - A Tiny Mighty Vision Model.](https://huggingface.co/Tensoic/Cerule-v0.1) |We train and release "Cerule", a tiny yet powerful Vision Lanuage Model based on the newly released Google's Gemma-2b and Google's SigLIP. |
|[Diffusion Models for Video Generation.](https://lilianweng.github.io/posts/2024-04-12-diffusion-video/) |This article looks at adapting image models, training diffusion models to produce video, and even producing video directly from an image model without further training. |
|[Pile-T5.](https://blog.eleuther.ai/pile-t5/) | The contemporary AI workhorse is called T5. Eleuther retrained it using a more recent tokenizer and a longer training period. As a consequence, the fundamental model for encoding tasks is significantly enhanced.|
|[GitHub Repository to File Converter.](https://github.com/cognitivecomputations/github2file) |This Python script allows you to download and process files from a GitHub repository, making it easier to share code with chatbots that have large context capabilities but don't automatically download code from GitHub. |
|[AI Index Report.](https://hai.stanford.edu/research/ai-index-report) |The 2024 Index is our most comprehensive to date and arrives at an important moment when AI’s influence on society has never been more pronounced. This year, we have broadened our scope to more extensively cover essential trends such as technical advancements in AI, public perceptions of the technology, and the geopolitical dynamics surrounding its development. |
|[Accelerating AI: Harnessing Intel(R) Gaudi(R) 3 with Ray 2.10.](https://www.anyscale.com/blog/accelerating-ai-harnessing-intel-gaudi-3-with-ray-2-10) | Ray 2.10, the most recent version from Anyscale, now supports Intel Gaudi 3. In addition to provisioning Ray Core Task and Actors on a Gaudi fleet directly through Ray Core APIs, developers can now spin up and manage their own Ray Clusters. For an enhanced experience, they can also utilize Ray Serve on Gaudi via Ray Serve APIs and set up Intel Gaudi accelerator infrastructure for use at the Ray Train layer.|
|[Code with CodeQwen1.5.](https://qwenlm.github.io/blog/codeqwen1.5/) |Notwithstanding these advancements, dominant coding assistants like Github Copilot, built upon proprietary LLMs, pose notable challenges in terms of cost, privacy, security, and potential copyright infringement. Today, we are delighted to introduce a new member of the Qwen1.5 open-source family, the CodeQwen1.5-7B, a specialized codeLLM built upon the Qwen1.5 language model. CodeQwen1.5-7B has been pretrained with around 3 trillion tokens of code-related data. It supports an extensive repertoire of 92 programming languages, and it exhibits exceptional capacity in long-context understanding and generation with the ability to process information of 64K tokens. |
|[OLMo 1.7–7B: A 24 point improvement on MMLU.](https://blog.allenai.org/olmo-1-7-7b-a-24-point-improvement-on-mmlu-92b43f7d269d) |Today, we’ve released an updated version of our 7 billion parameter Open Language Model, OLMo 1.7–7B. This model scores 52 on MMLU, sitting above Llama 2–7B and approaching Llama 2–13B, and outperforms Llama 2–13B on GSM8K. |
|[Effort.](https://kolinko.github.io/effort/) | With the use of the Effort library, one can alter in real-time how many calculations are made when inferring an LLM model, which can significantly increase performance while maintaining a high level of quality. Initial findings indicate that the Effort library has the potential to greatly increase LLM inference speed while preserving quality, even with modest implementation overhead. In order to further enhance the library, the author invites others to test the 0.0.1B version and offer feedback.|
|[luminal.](https://github.com/jafioti/luminal) |Luminal is a deep learning library that uses composable compilers to achieve high performance. |
|[SoccerNet Game State Reconstruction: End-to-End Athlete Tracking and Identification on a Minimap.](https://arxiv.org/abs/2404.11335v1) | A new dataset called SoccerNet-GSR aims to improve game state reconstruction from football video footage captured by a single camera.|
|[AI Gateway.](https://github.com/Portkey-AI/gateway) |Gateway streamlines requests to 100+ open & closed source models with a unified API. It is also production-ready with support for caching, fallbacks, retries, timeouts, loadbalancing, and can be edge-deployed for minimum latency. |
|[moondream.](https://github.com/vikhyat/moondream) | a tiny vision language model that kicks ass and runs anywhere|
|[Sentence Embeddings. Introduction to Sentence Embeddings.](https://osanseviero.github.io/hackerllama/blog/posts/sentence_embeddings/) | This series aims to demystify embeddings and show you how to use them in your projects. This first blog post will teach you how to use and scale up open-source embedding models. We’ll look into the criteria for picking an existing model, current evaluation methods, and the state of the ecosystem. |


## Perspectives
|Link|description|
|---|---|
|[Does AI need a “body” to become truly intelligent? Meta researchers think so.](https://www.freethink.com/robots-ai/embodied-ai) |AIs that can generate videos, quickly translate languages, or write new computer code could be world changing, but can they ever be truly intelligent? Not according to the embodiment hypothesis, which argues that human-level intelligence can only emerge if an intelligence is able to sense and navigate a physical environment, the same way babies can.  |
|[Micromanaging AI.](https://tomtunguz.com/micromanaging-ai/) |Currently, AI is classified as micromanage, which requires people to establish tasks, assess work frequently, and lead development at each stage, akin to managing high school interns. Motivation is high but competence level is rather low. |
|[‘Eat the future, pay with your face’: my dystopian trip to an AI burger joint.](https://www.theguardian.com/technology/2024/apr/15/ai-burger-joint-flippy-caliexpress) |If the experience of robot-served fast food dining is any indication, the future of sex robots is going to be very unpleasant |
|[AI now beats humans at basic tasks — new benchmarks are needed, says major report.](https://www.nature.com/articles/d41586-024-01087-4) | Stanford University’s 2024 AI Index charts the meteoric rise of artificial-intelligence tools. Artificial intelligence (AI) systems, such as the chatbot ChatGPT, have become so advanced that they now very nearly match or exceed human performance in tasks including reading comprehension, image classification and competition-level mathematics, according to a new report. |
|[Lethal dust storms blanket Asia every spring — now AI could help predict them.](https://www.nature.com/articles/d41586-024-01076-7) | As the annual phenomenon once again strikes East Asia, scientists are hard at work to better predict how they will affect people.|
|[From boom to burst, the AI bubble is only heading in one direction.](https://www.theguardian.com/commentisfree/2024/apr/13/from-boom-to-burst-the-ai-bubble-is-only-heading-in-one-direction) |No one should be surprised that artificial intelligence is following a well-worn and entirely predictable financial arc |
|[You can't build a moat with AI.](https://generatingconversation.substack.com/p/you-cant-build-a-moat-with-ai) | Differentiating AI is difficult, but the secret is in the unique data that is supplied into these models—not in the AI models themselves, which are becoming commodity-like. Take LLMs, for example. The performance of AI is strongly impacted by effective data engineering, since applications need to integrate customer-specific data in order to respond accurately. Thus, rather than the AI technology itself, gaining a competitive edge in AI applications depends on creative data utilization. |
|[Towards 1-bit Machine Learning Models.](https://mobiusml.github.io/1bit_blog/) |Recent works on extreme low-bit quantization such as BitNet and 1.58 bit have attracted a lot of attention in the machine learning community. The main idea is that matrix multiplication with quantized weights can be implemented without multiplications, which can potentially be a game-changer in terms of compute efficiency of large machine learning models. |
|[From Idea to Integration: Four Steps for Founders Integrating AI.](https://foundationcapital.com/from-idea-to-integration-four-steps-for-founders-integrating-ai/) | There is currently a great deal of push to incorporate AI into current goods. This brief, step-by-step manual will assist you in making the initial move.|
|[Use game theory for climate models that really help reach net zero goals.](https://www.nature.com/articles/d41586-024-01083-8) | Many countries and companies have committed to eliminating their greenhouse-gas emissions by the middle of the century. Yet most of these pledges lack a clear policy pathway.|
|[A step along the path towards AlphaFold — 50 years ago.](https://www.nature.com/articles/d41586-024-01094-5) |Paring down the astronomical complexity of the protein-folding problem |
|[The democratization of global AI governance and the role of tech companies.](https://www.nature.com/articles/s42256-024-00811-z) | Can non-state multinational tech companies counteract the potential democratic deficit in the emerging global governance of AI? We argue that although they may strengthen core values of democracy such as accountability and transparency, they currently lack the right kind of authority to democratize global AI governance.|
|[The new NeuroAI.](https://www.nature.com/articles/s42256-024-00826-6) | After several decades of developments in AI, has the inspiration that can be drawn from neuroscience been exhausted? Recent initiatives make the case for taking a fresh look at the intersection between the two fields.|
|[Connecting molecular properties with plain language.](https://www.nature.com/articles/s42256-024-00812-y) |AI tools such as ChatGPT can provide responses to queries on any topic, but can such large language models accurately ‘write’ molecules as output to our specification? Results now show that models trained on general text can be tweaked with small amounts of chemical data to predict molecular properties, or to design molecules based on a target feature. |
|[MLOps vs. Eng: Misaligned Incentives and Failure to Launch?](https://www.heavybit.com/library/article/machine-learning-engineering-ai-incentives) | An in-depth discussion on the difficulties and solutions associated with implementing AI models in production, as well as how MLOps varies from traditional engineering, with industry experts. They talk about how to focus as a company to truly launch and why so few ML ideas ever reach production.|
|[Is Attention All You Need?](https://www.mackenziemorehead.com/is-attention-all-you-need/) |In order to overcome Transformers' shortcomings in long-context learning, generation, and inference speed, researchers are creating alternative designs that exhibit competitive quality at smaller scales but questionable scalability. Because of the quick development in this area, it is likely that the Pareto frontier will keep growing, opening up more opportunities for lengthier context modeling and higher throughput inference, which will ultimately lead to a bigger variety of AI use cases. |
|[The Shifting Dynamics And Meta-Moats Of AI.](https://www.michaeldempsey.me/blog/2024/04/17/the-meta-moats-of-ai/) |Managing complex short-, mid-, and long-term dynamics while retaining elite speed and execution, owning more of the stack, obtaining unique data, and utilizing synthetic data production are all necessary for building a successful AI business. As the AI sector develops, businesses will need to adjust to changing labor dynamics, comprehend the machine they are creating, and recognize the competitive axes on which they are based in order to forge long-lasting moats and differentiate themselves from the crowd. |
|[Integration of AI in healthcare requires an interoperable digital data ecosystem.](https://www.nature.com/articles/s41591-023-02783-w) |Electronic health information, including from electronic health records, is needed to develop AI tools for health, but the seamless flow of data will require standards and interoperability. |
|[To do no harm — and the most good — with AI in health care.](https://www.nature.com/articles/s41591-024-02853-7) |Drawing from real-life scenarios and insights shared at the RAISE (Responsible AI for Social and Ethical Healthcare) conference, we highlight the critical need for AI in health care (AIH) to primarily benefit patients and address current shortcomings in health care systems such as medical errors and access disparities. |
|[How to support the transition to AI-powered healthcare.](https://www.nature.com/articles/s41591-024-02897-9) | To make health systems more sustainable in the long-term, incentivize artificial intelligence (AI) and digital technologies that are grounded on careful testing and real-world validation.|
|[The increasing potential and challenges of digital twins.](https://www.nature.com/articles/s43588-024-00617-4) |This issue of Nature Computational Science includes a Focus that highlights recent advancements, challenges, and opportunities in the development and use of digital twins across different domains. |
|[The Space Of Possible Minds.](https://www.noemamag.com/ai-could-be-a-bridge-toward-diverse-intelligence/) | Sophisticated AIs are stretching the boundaries of our understanding of what it is to be human and forcing us to consider how we embody agency and true understanding in a spectrum of intelligent beings. Creating mutually beneficial relationships between radically different entities, recognizing the similarities and differences among various forms of intelligence, and developing principled frameworks for scaling our moral concern to the essential qualities of being are all necessary to navigate this new terrain.|
|[CUDA is Still a Giant Moat for NVIDIA.](https://weightythoughts.com/p/cuda-is-still-a-giant-moat-for-nvidia) | NVIDIA's proprietary interconnects and CUDA software environment, in addition to its hardware, continue to solidify the company's leadership in the AI market. The ease of use and performance optimization of CUDA make it superior to alternatives like AMD's ROCM, guaranteeing that NVIDIA's GPUs continue to be the go-to option for AI tasks. NVIDIA's dominance in AI computing is strengthened by its investments in the CUDA ecosystem and community education.|


# ML news: Week 8 - 14 April

## Research
|Link|description|
|---|---|
|[Smartphone app could help detect early-onset dementia cause, study finds.](https://www.theguardian.com/society/2024/apr/01/smartphone-app-could-help-detect-early-onset-dementia-cause-study-finds) |App-based cognitive tests found to be proficient at detecting frontotemporal dementia in those most at risk. Scientists have demonstrated that cognitive tests done via a smartphone app are at least as sensitive at detecting early signs of frontotemporal dementia in people with a genetic predisposition to the condition as medical evaluations performed in clinics.|
|[Unsegment Anything by Simulating Deformation.](https://arxiv.org/abs/2404.02585v1) |A novel strategy called "Anything Unsegmentable" aims to prevent digital photos from being divided into discrete categories by potent AI models, potentially resolving copyright and privacy concerns. |
|[Evaluating LLMs at Detecting Errors in LLM Responses.](https://arxiv.org/abs/2404.03602v1) |A benchmark called ReaLMistake has been introduced by researchers to methodically identify mistakes in lengthy language model answers. |
|[Dynamic Prompt Optimizing for Text-to-Image Generation.](https://arxiv.org/abs/2404.04095v1) | Researchers have created Prompt Auto-Editing (PAE), a technique that uses diffusion models such as Imagen and Stable Diffusion to advance text-to-image generation. With the use of online reinforcement learning, this novel method dynamically modifies the weights and injection timings of particular words to automatically improve text prompts. |
|[No Time to Train: Empowering Non-Parametric Networks for Few-shot 3D Scene Segmentation.](https://arxiv.org/abs/2404.04050v1) |A system called Seg-NN simplifies the 3D segmentation procedure. These models don't have the usual domain gap problems and can quickly adapt to new, unseen classes because they don't require a lot of pre-training. |
|[Foundation Model for Advancing Healthcare: Challenges, Opportunities, and Future Directions.](https://arxiv.org/abs/2404.03264v1) | The potential of Healthcare Foundation Models (HFMs) to transform medical services is examined in this extensive survey. These models are well-suited to adapt to different healthcare activities since they have been pre-trained on a variety of data sets. This could lead to an improvement in intelligent healthcare services in a variety of scenarios.|
|[SwapAnything: Enabling Arbitrary Object Swapping in Personalized Visual Editing.](https://swap-anything.github.io/) |A new algorithm called SwapAnything may swap out objects in an image with other objects of your choosing without affecting the image's overall composition. Compared to other tools, it is superior since it can replace any object, not only the focal point, and it excels at ensuring that the replaced object blends seamlessly into the original image. Pretrained diffusion model, idea vectors, and inversion are employed. |
|[UniFL:Improve Stable Diffusion via Unified Feedback Learning.](https://uni-fl.github.io/) |UniFL is a technique that uses a pretty complex cascade of feedback steps to enhance the output quality of diffusion models. All of these help to raise the image generation models' aesthetics, preference alignment, and visual quality. The methods can be applied to enhance any image generating model, regardless of the underlying model. |
|[Object-Aware Domain Generalization for Object Detection.](https://arxiv.org/abs/2312.12133v1) | In order to tackle the problem of object detection in single-domain generalization (S-DG), the novel OA-DG approach presents two new techniques: OA-Mix for data augmentation and OA-Loss for training.|
|[VAR: a new visual generation method elevates GPT-style models beyond diffusion🚀 & Scaling laws observed.](https://github.com/FoundationVision/VAR) |Code for the latest "next-resolution prediction" project, which presents the process of creating images as a progressive prediction of progressively higher resolution. A demo notebook and inference scripts are included in the repository. Soon, the training code will be made available. |
|[SqueezeAttention: 2D Management of KV-Cache in LLM Inference via Layer-wise Optimal Budget.](https://github.com/hetailang/squeezeattention) | SqueezeAttention is a newly developed technique that optimizes the Key-Value cache of big language models, resulting in a 30% to 70% reduction in memory usage and a doubling of throughput.|
|[Measuring the Persuasiveness of Language Models.](https://www.anthropic.com/news/measuring-model-persuasiveness) |The Claude 3 Opus AI model was shown to closely resemble human persuasiveness in a study that looked at persuasiveness. Statistical tests and multiple comparison adjustments were used to ascertain this. Although not by a statistically significant amount, humans were marginally more convincing, highlighting a trend where larger, more complex models are becoming more credible. The most persuasive model was found to be Claude 3 Opus. The study's methodological reliability was validated by a control condition that demonstrated predictable low persuasiveness for undisputed facts. |
|[DreamView: Injecting View-specific Text Guidance into Text-to-3D Generation.](https://arxiv.org/abs/2404.06119v1) | DreamView presents a novel method for turning text descriptions into 3D objects that may be extensively customized from various angles while maintaining the object's overall consistency. |
|[Hash3D: Training-free Acceleration for 3D Generation.](https://adamdad.github.io/hash3D/) | By adopting a hashing algorithm that takes use of feature-map redundancy across similar camera positions and diffusion time-steps, Hash3D presents a revolutionary way to accelerate 3D generative modeling. |
|[MoCha-Stereo: Motif Channel Attention Network for Stereo Matching.](https://arxiv.org/abs/2404.06842v1) | An innovative method that keeps geometric structures that are sometimes lost in conventional stereo matching techniques is the Motif Channel Attention Stereo Matching Network (MoCha-Stereo).|
|[Efficient and Generic Point Model for Lossless Point Cloud Attribute Compression.](https://arxiv.org/abs/2404.06936v1) |PoLoPCAC is a lossless point cloud attribute compression technique that combines excellent adaptability and great efficiency at different point cloud densities and scales. |
|[Scaling Multi-Camera 3D Object Detection through Weak-to-Strong Eliciting.](https://arxiv.org/abs/2404.06700v1) | In order to boost surround refinement in Multi-Camera 3D Object Detection (MC3D-Det), a field enhanced by bird's-eye view technologies, this study introduces a weak-to-strong eliciting framework.|
|[InstantMesh: Efficient 3D Mesh Generation from a Single Image with Sparse-view Large Reconstruction Models.](https://github.com/tencentarc/instantmesh) | This project introduces InstantMesh, a framework with unparalleled quality and scalability that creates 3D meshes instantaneously from a single image.|
|[Exploring Concept Depth: How Large Language Models Acquire Knowledge at Different Layers?](https://github.com/luckfort/cd) | A recent study examined the ways in which different layers within huge language models understand distinct concepts. It was discovered that while more complicated tasks demand deeper processing, simpler tasks are handled by earlier layers.|
|[SplatPose & Detect: Pose-Agnostic 3D Anomaly Detection.](https://arxiv.org/abs/2404.06832v1) | SplatPose is a revolutionary approach that uses 3D Gaussian splatting to address the problem of anomaly identification in 3D objects from different positions.|

## News
|Link|description|
|---|---|
|[Facebook and Instagram to label digitally altered content ‘made with AI’.](https://www.theguardian.com/technology/2024/apr/05/facebook-instagram-ai-label-digitally-altered-media) |Parent company Meta also to add ‘high-risk’ label to Al-altered content that deceives the public on ‘a matter of importance’ |
|[Google considering charge for internet searches with AI, reports say.](https://www.theguardian.com/technology/2024/apr/04/google-set-to-charge-for-internet-searches-with-ai-reports-say) | Cost of artificial intelligence service could mean leaders in sector turning to subscription models|
|[Apple lays off 600 workers in California after shuttering self-driving car project.](https://www.theguardian.com/technology/2024/apr/05/apple-layoffs-california-self-driving-cars) |Tech company cuts employees from eight offices in Santa Clara in its first big wave of post-pandemic job cuts |
|[AMD to open source Micro Engine Scheduler firmware for Radeon GPUs.](https://www.theregister.com/2024/04/05/amd_mes_open_source/) |AMD plans to document and open source its Micro Engine Scheduler (MES) firmware for GPUs, giving users more control over Radeon graphics cards. |
|[Investors in talks to help Elon Musk's xAI raise $3 billion: report.](https://economictimes.indiatimes.com/tech/technology/investors-in-talks-to-help-elon-musks-xai-raise-3-billion-report/articleshow/109079985.cms) | Investors close to Elon Musk are in talks to help his artificial-intelligence startup xAI raise $3 billion in a round that would value the company at $18 billion, the Wall Street Journal reported on Friday.|
|[Introducing Command R+: A Scalable LLM Built for Business.](https://txt.cohere.com/command-r-plus-microsoft-azure/) | Command R+, a potent, scalable LLM with multilingual coverage in ten important languages and tool use capabilities, has been launched by Cohere. It is intended for use in enterprise use scenarios.|
|[Qwen1.5-32B: Fitting the Capstone of the Qwen1.5 Language Model Series.](https://qwenlm.github.io/blog/qwen1.5-32b/) |A growing consensus within the field now points to a model with approximately 30 billion parameters as the optimal “sweet spot” for achieving both strong performance and manageable resource requirements. In response to this trend, we are proud to unveil the latest additions to our Qwen1.5 language model series: Qwen1.5-32B and Qwen1.5-32B-Chat. |
|[Nvidia Tops Llama 2, Stable Diffusion Speed Trials .](https://spectrum.ieee.org/ai-benchmark-mlperf-llama-stablediffusion) |Now that we’re firmly in the age of massive generative AI, it’s time to add two such behemoths, Llama 2 70B and Stable Diffusion XL, to MLPerf’s inferencing tests. Version 4.0 of the benchmark tests more than 8,500 results from 23 submitting organizations. As has been the case from the beginning, computers with Nvidia GPUs came out on top, particularly those with its H200 processor. But AI accelerators from Intel and Qualcomm were in the mix as well. |
|[Rabbit partners with ElevenLabs to power voice commands on its device.](https://techcrunch.com/2024/03/27/rabbit-partners-with-elevenlabs-to-power-voice-commands-on-its-device/) | Hardware maker Rabbit has tapped a partnership with ElevenLabs to power voice commands on its devices. Rabbit is set to ship the first set of r1 devices next month after getting a ton of attention at the Consumer Electronics Show (CES) at the start of the year.|
|[DALL-E now lets you edit images in ChatGPT.](https://www.theverge.com/2024/4/3/24120181/openai-dall-e-chat-gpt-image-edit) |Tweak your AI creations without leaving the chat. |
|[Jony Ive and OpenAI's Sam Altman Seeking Funding for Personal AI Device.](https://www.macrumors.com/2024/04/05/jony-ive-sam-altman-ai-device/) |OpenAI CEO Sam Altman and former Apple design chief Jony Ive have officially teamed up to design an AI-powered personal device and are seeking funding, reports The Information. |
|[Hugging Face TGI Reverts to Open Source License.](https://github.com/huggingface/text-generation-inference/commit/ff42d33e9944832a19171967d2edd6c292bdb2d6) | Hugging Face temporarily granted a non-commercial license for their well-known and potent inference server in an effort to deter bigger companies from running a rival offering. While community involvement decreased, business outcomes remained unchanged. It is now back to a license that is more liberal.|
|[Securing Canada’s AI advantage.](https://www.pm.gc.ca/en/news/news-releases/2024/04/07/securing-canadas-ai) |To support Canada's AI industry, Prime Minister Justin Trudeau unveiled a $2.4 billion investment package beginning Budget 2024. The package comprises tools to enable ethical AI adoption, support for AI start-ups, and financing for computational skills. These policies are intended to maintain Canada's competitive advantage in AI globally, boost productivity, and hasten the growth of jobs. The money will also be used to fortify the Artificial Intelligence and Data Act's enforcement as well as establish a Canadian AI Safety Institute. |
|[Yahoo is buying Artifact, the AI news app from the Instagram co-founders.](https://www.theverge.com/2024/4/2/24118436/yahoo-news-artifact-acquisition) |Instagram’s co-founders built a powerful and useful tool for recommending news to readers — but could never quite get it to scale. Yahoo has hundreds of millions of readers — but could use a dose of tech-forward cool to separate it from all the internet’s other news aggregators. |
|[Now there’s an AI gas station with robot fry cooks.](https://www.theverge.com/2024/4/2/24119413/robot-fry-cook-re-up-gas-station-florida-ai) |There’s a little-known hack in rural America: you can get the best fried food at the gas station (or in the case of a place I went to on my last road trip, shockingly good tikka masala). Now, one convenience store chain wants to change that with a robotic fry cook that it’s bringing to a place once inhabited by a person who may or may not smell like a recent smoke break and cooks up a mean fried chicken liver. |
|[Elon Musk predicts superhuman AI will be smarter than people next year.](https://www.theguardian.com/technology/2024/apr/09/elon-musk-predicts-superhuman-ai-will-be-smarter-than-people-next-year) |His claims come with a caveat that shortages of training chips and growing demand for power could limit plans in the near term |
|[Gemma Family Expands with Models Tailored for Developers and Researchers.](https://developers.googleblog.com/2024/04/gemma-family-expands.html) | Google announced the first round of additions to the Gemma family, expanding the possibilities for ML developers to innovate responsibly: CodeGemma for code completion and generation tasks as well as instruction following, and RecurrentGemma, an efficiency-optimized architecture for research experimentation.|
|[Meta confirms that its Llama 3 open source LLM is coming in the next month.](https://techcrunch.com/2024/04/09/meta-confirms-that-its-llama-3-open-source-llm-is-coming-in-the-next-month/) |At an event in London on Tuesday, Meta confirmed that it plans an initial release of Llama 3 — the next generation of its large language model used to power generative AI assistants — within the next month. |
|[Intel details Gaudi 3 at Vision 2024 — new AI accelerator sampling to partners now, volume production in Q3.](https://www.tomshardware.com/pc-components/cpus/intel-details-guadi-3-at-vision-2024-new-ai-accelerator-sampling-to-partners-now-volume-production-in-q3) |Intel made a slew of announcements during its Vision 2024 event today, including deep-dive details of its new Gaudi 3 AI processors, which it claims offer up to 1.7X the training performance, 50% better inference, and 40% better efficiency than Nvidia’s market-leading H100 processors, but for significantly less money. |
|[Apple's new AI model could help Siri see how iOS apps work.](https://appleinsider.com/articles/24/04/09/apples-new-ai-model-could-help-siri-see-how-ios-apps-work) |Apple's Ferret LLM could help allow Siri to understand the layout of apps in an iPhone display, potentially increasing the capabilities of Apple's digital assistant. Apple has been working on numerous machine learning and AI projects that it could tease at WWDC 2024. In a just-released paper, it now seems that some of that work has the potential for Siri to understand what apps and iOS itself looks like. |
|[Aerospace AI Hackathon Projects.](http://gonavi.ai/hackathon-apr06.html) | Together, 200 AI and aerospace experts created an amazing array of tools, including AI flight planners, AI air traffic controllers, and Apple Vision Pro flight simulators, as a means of prototyping cutting-edge solutions for the aviation and space industries.|
|[AI race heats up as OpenAI, Google and Mistral release new models.](https://www.theguardian.com/technology/2024/apr/10/ai-race-heats-up-as-openai-google-and-mistral-release-new-models) | Launches within 12 hours of one another, and more activity expected in industry over summer|
|[next-generation Meta Training and Inference Accelerator.](https://ai.meta.com/blog/next-generation-meta-training-inference-accelerator-AI-MTIA/) |The next iteration of Meta's AI accelerator chip has been revealed. Its development was centered on throughput (11 TFLOPs at int8) and chip memory (128GB at 5nm). |
|[Google’s Gemini Pro 1.5 enters public preview on Vertex AI.](https://techcrunch.com/2024/04/09/googles-gemini-pro-1-5-enters-public-preview-on-vertex-ai/) |Gemini 1.5 Pro, Google’s most capable generative AI model, is now available in public preview on Vertex AI, Google’s enterprise-focused AI development platform. The company announced the news during its annual Cloud Next conference, which is taking place in Las Vegas this week. |
|[Microsoft is working on sound recognition AI technologies capable of detecting natural disasters.](https://windowsreport.com/microsoft-is-working-on-sound-recognition-ai-technologies-capable-of-detecting-natural-disasters/) | However, the Redmond-based tech giant is working on performant sound recognition AI technologies that would see Copilot (and any other AI model, such as ChatGPT) capable of detecting upcoming natural disasters, such as earthquakes, and storms.|
|[Amazon scrambles for its place in the AI race.](https://www.theverge.com/2024/3/29/24116056/amazon-ai-race-anthropic-olympus-claude) | With its multibillion-dollar bet on Anthropic and its forthcoming Olympus model, Amazon is pushing hard to be a leader in AI.|
|[Elon Musk's updated Grok AI claims to be better at coding and math.](https://www.engadget.com/elon-musks-updated-grok-ai-claims-to-be-better-at-coding-and-math-120056776.html) |It'll be available to early testers 'in the coming days.' Elon Musk's answer to ChatGPT is getting an update to make it better at math, coding and more. Musk's xAI has launched Grok-1.5 to early testers with "improved capabilities and reasoning" and the ability to process longer contexts. The company claims it now stacks up against GPT-4, Gemini Pro 1.5 and Claude 3 Opus in several areas.|
|[Anthropic's Haiku Beats GPT-4 Turbo in Tool Use - Sometimes.](https://docs.parea.ai/blog/benchmarking-anthropic-beta-tool-use) |Anthropic's beta tool use API is better than GPT-4 Turbo in 50% of cases on the Berkeley Function Calling benchmark. |
|[UK has real concerns about AI risks, says competition regulator.](https://www.theguardian.com/technology/2024/apr/11/uk-has-real-concerns-about-ai-risks-says-competition-regulator) |Concentration of power among just six big tech companies ‘could lead to winner takes all dynamics’ |
|[New bill would force AI companies to reveal use of copyrighted art.](https://www.theguardian.com/technology/2024/apr/09/artificial-intelligence-bill-copyright-art) | Adam Schiff introduces bill amid growing legal battle over whether major AI companies have made illegal use of copyrighted works|
|[Randomness in computation wins computer-science ‘Nobel’.](https://www.nature.com/articles/d41586-024-01055-y) |Computer scientist Avi Wigderson is known for clarifying the role of randomness in algorithms, and for studying their complexity. A leader in the field of computational theory is the latest winner of the A. M. Turing Award, sometimes described as the ‘Nobel Prize’ of computer science.|
|[Introducing Rerank 3: A New Foundation Model for Efficient Enterprise Search & Retrieval.](https://txt.cohere.com/rerank-3/) |Rerank 3, the newest foundation model from Cohere, was developed with enterprise search and Retrieval Augmented Generation (RAG) systems in mind. The model may be integrated into any legacy program with built-in search functionality and is compatible with any database or search index. With a single line of code, Rerank 3 can improve search speed or lower the cost of running RAG applications with minimal effect on latency. |
|[Meta to broaden labeling of AI-made content.](https://www.axios.com/2024/04/05/meta-broader-ai-labeling) |  Meta admits its current labeling policies are "too narrow" and that a stronger system is needed to deal with today's wider range of AI-generated content and other manipulated content, such as a January video which appeared to show President Biden inappropriately touching his granddaughter.|
|[Mistral's New Model.](https://huggingface.co/mistral-community/Mixtral-8x22B-v0.1/discussions/4) |The Mixtral-8x22B Large Language Model (LLM) is a pretrained generative Sparse Mixture of Experts. |
|[Waymo self-driving cars are delivering Uber Eats orders for first time.](https://www.cnbc.com/2024/04/03/waymo-self-driving-cars-are-delivering-uber-eats-orders-for-first-time.html) |Uber Eats customers may now receive orders delivered by one of Waymo’s self-driving cars for the first time in the Phoenix metropolitan area. It is part of a multiyear collaboration between the two companies unveiled last year.|
|[JetMoE: Reaching LLaMA2 Performance with 0.1M Dollars.](https://huggingface.co/jetmoe/jetmoe-8b) |This model of a mixture of experts was trained on a decent amount of CPU power using available datasets. It performs on par with the considerably larger and more costly Meta Llama 2 7B variant. |
|[Google blocking links to California news outlets from search results.](https://www.theguardian.com/technology/2024/apr/12/google-search-blocking-california-news) |Tech giant is protesting proposed law that would require large online platforms to pay ‘journalism usage fee’ |
|[House votes to reapprove law allowing warrantless surveillance of US citizens.](https://www.theguardian.com/us-news/2024/apr/12/fisa-surveillance-act-reauthorized) | Fisa allows for monitoring of foreign communications, as well as collection of citizens’ messages and calls|
|[Tesla settles lawsuit over 2018 fatal Autopilot crash of Apple engineer.](https://www.theguardian.com/technology/2024/apr/08/tesla-crash-lawsuit-apple-engineer) |Walter Huang was killed when his car steered into a highway barrier and Tesla will avoid questions about its technology in a trial |

## Resources
|Link|description|
|---|---|
|[swe agents.](https://swe-agent.com/) |SWE-agent turns LMs (e.g. GPT-4) into software engineering agents that can fix bugs and issues in real GitHub repositories. |
|[Schedule-Free Learning.](https://github.com/facebookresearch/schedule_free) |Faster training without schedules - no need to specify the stopping time/steps in advance! |
|[State-of-the-art Representation Fine-Tuning (ReFT) methods.](https://github.com/stanfordnlp/pyreft) | ReFT is a novel approach to language model fine-tuning that is efficient with parameters. It achieves good performance at a significantly lower cost than even PeFT.|
|[The Top 100 AI for Work – April 2024.](https://www.flexos.work/learn/top-100-ai-for-work) |Following our AI Top 150, we spent the past few weeks analyzing data on the top AI platforms for work. This report shares key insights, including the AI tools you should consider adopting to work smarter, not harder. |
|[LLocalSearch.](https://github.com/nilsherzig/LLocalSearch) | LLocalSearch is a completely locally running search aggregator using LLM Agents. The user can ask a question and the system will use a chain of LLMs to find the answer. The user can see the progress of the agents and the final answer. No OpenAI or Google API keys are needed.|
|[llm.c.](https://github.com/karpathy/llm.c) | LLM training in simple, pure C/CUDA. There is no need for 245MB of PyTorch or 107MB of cPython. For example, training GPT-2 (CPU, fp32) is ~1,000 lines of clean code in a single file. It compiles and runs instantly, and exactly matches the PyTorch reference implementation.|
|[AIOS: LLM Agent Operating System.](https://github.com/agiresearch/AIOS) | AIOS, a Large Language Model (LLM) Agent operating system, embeds large language model into Operating Systems (OS) as the brain of the OS, enabling an operating system "with soul" -- an important step towards AGI. AIOS is designed to optimize resource allocation, facilitate context switch across agents, enable concurrent execution of agents, provide tool service for agents, maintain access control for agents, and provide a rich set of toolkits for LLM Agent developers.|
|[Anthropic Tool use (function calling).](https://docs.anthropic.com/claude/docs/tool-use) | Claude AI may now communicate with customized client-side tools supplied in API requests thanks to the public beta that Anthropic has released. To utilize the feature, developers need to include the 'anthropic-beta: tools-2024-04-04' header. Provided that each tool has a comprehensive JSON structure, Claude's capability can be expanded.|
|[Flyflow.](https://github.com/flyflow-devs/flyflow) | Flyflow is API middleware to optimize LLM applications, same response quality, 5x lower latency, secure, and much higher token limits|
|[ChemBench.](https://github.com/lamalab-org/chem-bench) |LLMs gain importance across domains. To guide improvement, benchmarks have been developed. One of the most popular ones is BIG-bench which currently only included two chemistry-related task. The goal of this project is to add more chemistry benchmark tasks in a BIG-bench compatible way, and develop a pipeline to benchmark frontier and open models. |
|[Longcontext Alpaca Training.](https://colab.research.google.com/drive/1JcWphd5oRxoRzY12s69NCsPEmoWWSCoN) | On an H100, train more than 200k context windows using a new gradient accumulation offloading technique.|
|[attorch.](https://github.com/BobMcDear/attorch) |attorch is a subset of PyTorch's nn module, written purely in Python using OpenAI's Triton. Its goal is to be an easily hackable, self-contained, and readable collection of neural network modules whilst maintaining or improving upon the efficiency of PyTorch. |
|[Policy-Guided Diffusion.](https://github.com/emptyjackson/policy-guided-diffusion) |A novel approach to agent training in offline environments is provided by policy-guided diffusion, which generates synthetic trajectories that closely match target policies and behavior. By producing more realistic training data, this method greatly enhances the performance of offline reinforcement learning models. |
|[Ada-LEval.](https://github.com/open-compass/ada-leval) | Ada-LEval is a pioneering benchmark to assess the long-context capabilities with length-adaptable questions. It comprises two challenging tasks: TSort, which involves arranging text segments into the correct order, and BestAnswer, which requires choosing the best answer of a question among multiple candidates.|

## Perspectives
|Link|description|
|---|---|
|[‘Time is running out’: can a future of undetectable deepfakes be avoided?.](https://www.theguardian.com/technology/2024/apr/08/time-is-running-out-can-a-future-of-undetectable-deepfakes-be-avoided) |Tell-tale signs of generative AI images are disappearing as the technology improves, and experts are scrambling for new methods to counter disinformation |
|[Four Takeaways on the Race to Amass Data for A.I.](https://www.nytimes.com/2024/04/06/technology/ai-data-tech-takeaways.html) | To make artificial intelligence systems more powerful, tech companies need online data to feed the technology. Here’s what to know.|
|[TechScape: Could AI-generated content be dangerous for our health?](https://www.theguardian.com/technology/2024/apr/09/techscape-deepfakes-cognitohazards-science-fiction) | From hyperrealistic deepfakes to videos that not only hijack our attention but also our emotions, tech seems increasingly full of ‘cognitohazards’|
|[AI can help to tailor drugs for Africa — but Africans should lead the way.](https://www.nature.com/articles/d41586-024-01001-y) |Computational models that require very little data could transform biomedical and drug development research in Africa, as long as infrastructure, trained staff and secure databases are available. |
|[Breaking news: Scaling will never get us to AGI.](https://garymarcus.substack.com/p/breaking-news-scaling-will-never) | In order to create artificial general intelligence, additional methods must be used because neural networks' poor capacity to generalize beyond their training data limits their reasoning and trustworthiness.|
|[Americans’ use of ChatGPT is ticking up, but few trust its election information.](https://www.pewresearch.org/short-reads/2024/03/26/americans-use-of-chatgpt-is-ticking-up-but-few-trust-its-election-information/) |It’s been more than a year since ChatGPT’s public debut set the tech world abuzz. And Americans’ use of the chatbot is ticking up: 23% of U.S. adults say they have ever used it, according to a Pew Research Center survey conducted in February, up from 18% in July 2023. |
|[Can Demis Hassabis Save Google?](https://www.bigtechnology.com/p/can-demis-hassabis-save-google) |Demis Hassabis, the founder of DeepMind, is currently in charge of Google's unified AI research division and hopes to keep the tech behemoth ahead of the competition in the field with innovations like AlphaGo and AlphaFold. Notwithstanding the achievements, obstacles nonetheless exist in incorporating AI into physical goods and rivalry from organizations like OpenAI's ChatGPT. Having made a substantial contribution to AI, Hassabis now has to work within Google's product strategy in order to take use of DeepMind's research breakthroughs. |
|[Is ChatGPT corrupting peer review? Telltale words hint at AI use.](https://www.nature.com/articles/d41586-024-01051-2) | A study of review reports identifies dozens of adjectives that could indicate text written with the help of chatbots.|
|[AI-fuelled election campaigns are here — where are the rules?](https://www.nature.com/articles/d41586-024-00995-9) |Political candidates are increasingly using AI-generated ‘softfakes’ to boost their campaigns. This raises deep ethical concerns. |
|[How to break big tech’s stranglehold on AI in academia.](https://www.nature.com/articles/d41586-024-01039-y) |Deep-learning artificial intelligence (AI) models have become an attractive tool for researchers in many areas of science and medicine. But the development of these models is prohibitively expensive, owing mainly to the energy consumed in training them. |
|[Ready or not, AI is coming to science education — and students have opinions.](https://www.nature.com/articles/d41586-024-01002-x) |As educators debate whether it’s even possible to use AI safely in research and education, students are taking a role in shaping its responsible use. |
|[‘Without these tools, I’d be lost’: how generative AI aids in accessibility.](https://www.nature.com/articles/d41586-024-01003-w) |A rush to place barriers around the use of artificial intelligence in academia could disproportionately affect those who stand to benefit most. |

# ML news: Week 1 - 7 April

## Research
|Link|description|
|---|---|
|[TOD3Cap: Towards 3D Dense Captioning in Outdoor Scenes.](https://arxiv.org/abs/2403.19589v1) | Scholars have unveiled a novel methodology for comprehending outside surroundings, surmounting challenges such as variable conditions and insufficient data that had hitherto impeded progress.|
|[Lane-Change in Dense Traffic with Model Predictive Control and Neural Networks.](https://arxiv.org/abs/2403.19633v1) |This work presents a control system that emphasizes collaboration with neighboring drivers to enable safe and seamless lane changes in congested traffic by combining AI and predictive algorithms. |
|[Transformer-Lite: High-efficiency Deployment of Large Language Models on Mobile Phone GPUs.](https://arxiv.org/abs/2403.20041) |It is difficult to run language models on phones because of latency, bandwidth, and power limitations. This study demonstrates how to obtain 30 tokens/second generation for the potent Gemma 2B model using quantization, the removal of the kv cache, and other optimizations. This is about three times quicker than other frameworks. |
|[Unsolvable Problem Detection: Evaluating Trustworthiness of Vision Language Models.](https://arxiv.org/abs/2403.20331) |Sometimes, given an input image, Visual Language Models (VLMs) are unable to provide a response to a question. Even cutting-edge VLMs like GPT-4V have difficulties with this. This paper suggests some possible enhancements and a benchmark for VLMs that encounter intractable problems. |
|[Total-Decom: Decomposed 3D Scene Reconstruction with Minimal Interaction.](https://arxiv.org/abs/2403.19314v1) |With its revolutionary approach to 3D scene reconstruction, Total-Decom makes it simple to edit and manipulate photographs by precisely breaking down objects from several views with little effort on the part of the user. |
|[Mechanism for feature learning in neural networks and backpropagation-free machine learning models.](https://www.science.org/doi/10.1126/science.adi5639) |proposed the deep neural feature ansatz, which states that neural feature learning occurs by up-weighting the features that are most influential on model output, a process that was formulated mathematically in terms of the average gradient outer product and was supported by numerical experiments and theoretical results. The presented mechanism provides a backpropagation-free approach for feature learning in various machine learning models, including those that previously had no such capabilities. |
|[Teaching robots the art of human social synchrony.](https://www.science.org/doi/10.1126/scirobotics.ado5755) | Humanoid robots can now learn the art of social synchrony using neural networks.|
|[Many-shot jailbreaking.](https://www.anthropic.com/research/many-shot-jailbreaking) | Anthropic created a method for breaking into lengthy context models. It has put these discoveries into practice and disseminated them to other organizations. This post describes the method and a few countermeasures that were implemented.|
|[R2-Tuning: Efficient Image-to-Video Transfer Learning for Video Temporal Grounding.](https://arxiv.org/abs/2404.00801) | R2-Tuning is a technique created by researchers to comprehend videos by verbally cueing the system to recognize particular times.|
|[Draw-and-Understand: Leveraging Visual Prompts to Enable MLLMs to Comprehend What You Want.](https://draw-and-understand.github.io/) |SPHINX-V, a multimodal big language model developed as part of the Draw-and-Understand project, aims to improve human-AI interaction through visual cues. |
|[RealKIE: Five Novel Datasets for Enterprise Key Information Extraction.](https://arxiv.org/abs/2403.20101) | Enterprise AI solutions depend on the ability to extract information from datasets. It is possible to gauge general algorithmic performance for RAG applications using these five new benchmark datasets. |
|[DiJiang: Efficient Large Language Models through Compact Kernelization.](https://arxiv.org/abs/2403.19928v2) | Researchers have created a novel method called DiJiang that makes use of current Transformers to create faster, leaner models without requiring a significant amount of retraining.|
|[WcDT: World-centric Diffusion Transformer for Traffic Scene Generation.](https://arxiv.org/abs/2404.02082v1) |This paper presents a novel approach to autonomous vehicle driving path generation that integrates transformers and diffusion models into a system dubbed the "World-Centric Diffusion Transformer" (WcDT). |
|[SeaBird: Segmentation in Bird's View with Dice Loss Improves Monocular 3D Detection of Large Objects.](https://github.com/abhi1kumar/seabird) | In situations when conventional monocular detectors struggle to identify huge objects, a novel 3D detection technique called SeaBird succeeds.|
|[Unsolvable Problem Detection: Evaluating Trustworthiness of Vision Language Models.](https://github.com/atsumiyai/upd) |In order to evaluate if AI is capable of determining when an issue cannot be solved, this study presents the idea of Unsolvable issue Detection (UPD) in Vision Language Models. |
|[ASTRA - 3rd place solution for SoccerNet Action Spotting Challenge 2023.](https://github.com/arturxe2/astra) |ASTRA is a Transformer-based model that may overcome issues like as action localization and data imbalance and recognize important periods in soccer matches. |
|[Multi-Granularity Guided Fusion-in-Decoder.](https://arxiv.org/abs/2404.02581v1) |MGFiD introduces a multi-level evidence discernment strategy that improves the understanding and selection of pertinent information by question-answering systems. |
|[Linear Attention Sequence Parallelism.](https://arxiv.org/abs/2404.02882v1) |With its creative application of linear attention, Linear Attention Sequence Parallel (LASP) presents a novel approach to effectively handling lengthy sequences in language models, outperforming conventional techniques. |
|[Mixture-of-Depths: Dynamically allocating compute in transformer-based language models.](https://arxiv.org/abs/2404.02258) | The fact that every token consumes the same amount of predictive computation is one disadvantage of contemporary transformers. But compared to other tokens, some are far simpler to predict. With this work, DeepMind has paved the way for dynamic compute with a limited maximum by allowing models to depart early in order to spend fewer flops on certain tokens. For the same performance, there are 50% fewer failures at generation time.|
|[InstantStyle: Free Lunch towards Style-Preserving in Text-to-Image Generation.](https://github.com/instantstyle/instantstyle) | With InstantStyle, image personalization takes a new turn by addressing the issue of style consistency without requiring intricate fine-tuning. This framework guarantees precise and consistent visual stylization, merging style intensity with text management with a seamless integration of style-specific sections and a clever division of style and content in images.|
|[T-GATE: Cross-Attention Makes Inference Cumbersome in Text-to-Image Diffusion Models.](https://github.com/haozheliu-st/t-gate) |By splitting the process into parts for planning and revising, TGATE presents an effective method for creating visuals. By correcting some outputs early on, this strategy not only makes the creation process simpler, but it also surprisingly enhances image quality. |

## News
|Link|description|
|---|---|
|[Announcing Grok-1.5.](https://x.ai/blog/grok-1.5) |Grok-1.5 comes with improved reasoning capabilities and a context length of 128,000 tokens. Available on 𝕏 soon. |
|[Microsoft & OpenAI planning $100 billion supercomputer Stargate AI.](https://www.gizmochina.com/2024/03/30/microsoft-openai-plan-100-billion-ai-supercomputer-stargate/) | According to a report by The Information, Microsoft and OpenAI are reportedly planning a joint data center project that could reach $100 billion in cost. The project is said to culminate in the launch of a massive artificial intelligence supercomputer named “Stargate” by 2028.|
|[In One Key A.I. Metric, China Pulls Ahead of the U.S.: Talent.](https://www.nytimes.com/2024/03/22/technology/china-ai-talent.html) |China has produced a huge number of top A.I. engineers in recent years. New research shows that, by some measures, it has already eclipsed the United States. |
|[Qwen1.5-MoE: Matching 7B Model Performance with 1/3 Activated Parameters.](https://qwenlm.github.io/blog/qwen-moe/) | Compared to Qwen1.5-7B, which contains 6.5 billion non-embedding parameters, Qwen1.5-MoE-A2.7B contains only 2.0 billion non-embedding parameters, approximately one-third of Qwen1.5-7B’s size. Notably, it achieves a 75% decrease in training expenses and accelerates inference speed by a factor of 1.74, offering substantial improvements in resource utilization without compromising performance.|
|[“The king is dead”—Claude 3 surpasses GPT-4 on Chatbot Arena for the first time.](https://arstechnica.com/information-technology/2024/03/the-king-is-dead-claude-3-surpasses-gpt-4-on-chatbot-arena-for-the-first-time/) |Anthropic's Claude 3 is first to unseat GPT-4 for #1 since launch of Chatbot Arena in May '23. |
|[Microsoft Copilot AI will soon run locally on PCs.](https://www.engadget.com/microsoft-copilot-ai-will-soon-run-locally-on-pcs-130642514.html) | Microsoft's Copilot AI service is set to run locally on PCs, Intel told Tom's Hardware. The company also said that next-gen AI PCs would require built-in neural processing units (NPUs) with over 40 TOPS (trillion operations per second) of power — beyond the capabilities of any consumer processor on the market.|
|[Navigating the Challenges and Opportunities of Synthetic Voices.](https://openai.com/blog/navigating-the-challenges-and-opportunities-of-synthetic-voices) | Using a 15-second audio sample, OpenAI's Voice Engine model creates speech that sounds like a speaker. Applications for it include support for non-verbal people, translation, and educational aids. Because of the possibility of abuse, OpenAI is deploying its technology cautiously.|
|[Apple AI researchers boast useful on-device model that ‘substantially outperforms’ GPT-4.](https://9to5mac.com/2024/04/01/apple-ai-gpt-4/) |Nevertheless, Apple forges ahead with the promise of AI. In a newly published research paper, Apple’s AI gurus describe a system in which Siri can do much more than try to recognize what’s in an image. The best part? It thinks one of its models for doing this benchmarks better than ChatGPT 4.0. |
|[Introducing Bezi AI.](https://bezi.com/hq/blog/introducing-bezi-ai) |The capacity to ideate at the speed of thought with a limitless asset collection is a major turning point in the field of 3D design. |
|[Robot, can you say ‘Cheese’?](https://www.engineering.columbia.edu/news/robot-can-you-say-cheese) |Columbia engineers build Emo, a silicon-clad robotic face that makes eye contact and uses two AI models to anticipate and replicate a person’s smile before the person actually smiles -- a major advance in robots predicting human facial expressions accurately, improving interactions, and building trust between humans and robots. |
|[Billie Eilish, Nicki Minaj, Stevie Wonder and more musicians demand protection against AI.](https://www.theguardian.com/technology/2024/apr/02/musicians-demand-protection-against-ai) |Letter signed by more than 200 artists makes broad ask that tech firms pledge to not develop AI tools to replace human creatives |
|[US and UK announce formal partnership on artificial intelligence safety.](https://www.theguardian.com/technology/2024/apr/02/us-uk-artificial-intelligence-partnership) | Countries sign memorandum to develop advanced AI model testing amid growing safety concerns|
|[OpenAI deems its voice cloning tool too risky for general release.](https://www.theguardian.com/technology/2024/mar/31/openai-deems-its-voice-cloning-tool-too-risky-for-general-release) |Delaying the Voice Engine technology rollout minimises the potential for misinformation in an important global election year |
|[DrugGPT: new AI tool could help doctors prescribe medicine in England.](https://www.theguardian.com/science/2024/mar/31/druggpt-new-ai-tool-could-help-doctors-prescribe-medicine-in-england) | New tool may offer prescription ‘safety net’ and reduce the 237m medication errors made each year in England|
|[New York City to test AI-enabled gun scanners in subway system.](https://www.theguardian.com/technology/2024/mar/29/new-york-city-subway-ai-gun-scanners) |Mayor Eric Adams announced pilot program as part of effort to deter violence, with plans to evaluate scanners at some stations |
|[Twitter usage in US ‘fallen by a fifth’ since Elon Musk’s takeover.](https://www.theguardian.com/technology/2024/mar/26/twitter-usage-in-us-fallen-by-a-fifth-since-elon-musks-takeover) |App users for social media site, rebranded as X, down by 23% since November 2022 according to Sensor Tower |
|[Scientists turn to AI to make beer taste even better.](https://www.theguardian.com/technology/2024/mar/26/ai-beer-taste-better-belgium-scientists) | Researchers in Belgium use artificial intelligence to improve taste, but say the skill of the brewer remains vital|
|[Google AI could soon use a person’s cough to diagnose disease.](https://www.nature.com/articles/d41586-024-00869-0) |Machine-learning system trained on millions of human audio clips shows promise for detecting COVID-19 and tuberculosis. |
|[Microsoft is working on an Xbox AI chatbot.](https://www.theverge.com/2024/4/2/24118728/microsoft-xbox-ai-chatbot-testing) |Xbox employees have been testing a virtual chatbot that can help with support queries and game refunds. |
|[Sam Altman gives up control of OpenAI Startup Fund, resolving unusual corporate venture structure.](https://techcrunch.com/2024/04/01/sam-altman-gives-up-control-of-openai-startup-fund-resolving-unusual-corporate-venture-structure/) | OpenAI CEO Sam Altman has transferred formal control of the eponymously firm’s named corporate venture fund to Ian Hathaway, OpenAI confirmed to TechCrunch. |
|[You can now use ChatGPT without an account.](https://www.engadget.com/you-can-now-use-chatgpt-without-an-account-184417749.html) | On Monday, OpenAI began opening up ChatGPT to users without an account. It described the move as part of its mission to “make tools like ChatGPT broadly available so that people can experience the benefits of AI.” It also gives the company more training data (for those who don’t opt out) and perhaps nudges more users into creating accounts and subscribing for superior GPT-4 access instead of the older GPT-3.5 model free users get.|
|[GENERATIVE SF: MARKETPLACES IN AI EDITION.](https://lsvp.com/stories/generative-sf-marketplaces-in-ai-edition/) |How Instacart and Faire use AI to boost productivity and better serve their customers. |
|[Replit launches new product in race for AI coding assistants.](https://www.semafor.com/article/04/02/2024/replit-launches-new-product-in-race-for-ai-coding-assistants) |A Silicon Valley AI coding startup is launching a new tool that it hopes will change the way companies develop software. Replit, valued at over $1 billion and backed by venture firms like Andreessen Horowitz and Khosla Ventures, says its new product, called Replit Teams, will allow developers to collaborate in real-time on software projects while an AI agent automatically fixes coding errors.|
|[Samsung might ‘redefine’ Bixby with Galaxy AI after all.](https://9to5google.com/2024/04/02/samsung-bixby-galaxy-ai-report/) | Samsung’s big Galaxy AI push this year skipped over its voice assistant, Bixby, but that might not be forever. Earlier this year when Galaxy AI made its debut, Samsung confirmed that Bixby wasn’t going away, but that it also didn’t really have plans for any new AI features within the voice assistant. Speaking to CNBC more recently, though, Samsung is looking at changing that.|
|[George Carlin’s estate settles lawsuit over comedian’s AI doppelganger.](https://www.theguardian.com/technology/2024/apr/03/george-carlin-dudesy-podcast-ai-lawsuit) |Suit claimed Dudesy podcast violated Carlin’s copyright, calling it ‘a casual theft of a great American artist’s work’ |
|[Opera allows users to download and use LLMs locally.](https://techcrunch.com/2024/04/03/opera-will-now-allow-users-download-and-use-llms-locally/) |Web browser company Opera announced today it will now allow users to download and use large language models (LLMs) locally on their computer. This feature is first rolling out to Opera One users who get developer stream updates and will allow users to select from over 150 models from more than 50 families. |
|[Introducing Stable Audio 2.0.](https://stability.ai/news/stable-audio-2-0) |Stable Audio 2.0 sets a new standard in AI-generated audio, producing high-quality, full tracks with coherent musical structure up to three minutes in length at 44.1kHz stereo. The new model introduces audio-to-audio generation by allowing users to upload and transform samples using natural language prompts. Stable Audio 2.0 was exclusively trained on a licensed dataset from the AudioSparx music library, honoring opt-out requests and ensuring fair compensation for creators.|
|[Scientists create AI models that can talk to each other and pass on skills with limited human input.](https://www.livescience.com/technology/artificial-intelligence/scientists-create-ai-models-that-can-talk-to-each-other-and-pass-on-skills-with-limited-human-input) |Scientists modeled human-like communication skills and the transfer of knowledge between AIs — so they can teach each other to perform tasks without a huge amount of training data. |
|[Worldcoin Foundation open sources core components of the Orb’s software.](https://worldcoin.org/blog/engineering/worldcoin-foundation-open-sources-core-components-orb-software) |For the Worldcoin Orb, Tools for Humanity has created a robust and safe computing environment that makes use of Arm Cortex M4 microcontrollers for real-time operations and NVIDIA Jetson for processing. The Orb does neural network inference using NVIDIA's TensorRT and runs Rust applications. It runs on Orb OS, a customized GNU/Linux distribution with an emphasis on security. For cryptography, the system incorporates a secure element, and for backend authentication, it provides trusted execution environments. |
|[Report: Google might make SGE a paid feature, not working on ad-free Search.](https://9to5google.com/2024/04/03/google-ad-free-search/) | As the Search Generative Experience (SGE) nears its one-year anniversary, Google is reportedly considering making it a paid feature, but is not considering an ad-free offering.|
|[Lambda Announces $500M GPU-Backed Facility to Expand Cloud for AI.](https://www.businesswire.com/news/home/20240402148086/en/Lambda-Announces-500M-GPU-Backed-Facility-to-Expand-Cloud-for-AI) |Lambda, the GPU cloud company founded by AI engineers and powered by NVIDIA GPUs, today announced that it has secured a special purpose GPU financing vehicle of up to $500 million to fund the expansion of its on-demand cloud offering. |
|[OpenAI expands its custom model training program.](https://techcrunch.com/2024/04/04/openai-expands-its-custom-model-training-program/) |OpenAI is expanding a program, Custom Model, to help enterprise customers develop tailored generative AI models using its technology for specific use cases, domains and applications. |
|[Former Snap AI chief launches Higgsfield to take on OpenAI’s Sora video generator.](https://techcrunch.com/2024/04/03/former-snap-ai-chief-launches-higgsfield-to-take-on-openais-sora-video-generator/) | OpenAI captivated the tech world a few months back with a generative AI model, Sora, that turns scene descriptions into original videos — no cameras or film crews required. But Sora has so far been tightly gated, and the firm seems to be aiming it toward well-funded creatives like Hollywood directors — not hobbyists or small-time marketers, necessarily.|
|[Tesla Raising Pay for AI Engineers To Counter Poaching, Musk Says.](https://www.investopedia.com/tesla-raising-pay-for-ai-engineers-to-counter-poaching-musk-says-8624619) | Tesla is raising pay for its artificial intelligence (AI) engineers as it fends off poaching from the likes of OpenAI, Chief Executive Officer (CEO) Elon Musk said in a series of posts on X. The plan to boost the pay of AI staff comes as the talent wars for people well-versed in the technology heats up.|
|[YouTube Says OpenAI Training Sora With Its Videos Would Break Rules.](https://ca.finance.yahoo.com/news/youtube-says-openai-training-sora-185454534.html) |The use of YouTube videos to train OpenAI’s text-to-video generator would be an infraction of the platform's terms of service, YouTube Chief Executive Officer Neal Mohan said. |
|[AI-generated YC Demo Day video.](https://twitter.com/eyc/status/1775636877732663673) |AI was utilized by a team from the latest YC cohort to create their demo day video. This is an unprecedented action taken by a firm. |

## Resources
|Link|description|
|---|---|
|[Your AI Product Needs Evals.](https://hamel.dev/blog/posts/evals/) |How to construct domain-specific LLM evaluation systems. This post outlines my thoughts on building evaluation systems for LLMs-powered AI products.|
|[VoiceCraft: Zero-Shot Speech Editing and Text-to-Speech in the Wild.](https://github.com/jasonppy/VoiceCraft) | VoiceCraft is a token infilling neural codec language model, that achieves state-of-the-art performance on both speech editing and zero-shot text-to-speech (TTS) on in-the-wild data including audiobooks, internet videos, and podcasts.To clone or edit an unseen voice, VoiceCraft needs only a few seconds of reference.|
|[Interrupting Cow.](https://github.com/KhoomeiK/interrupting-cow) |Interruptions make conversations feel natural. Much work has focused on AI voice assistants that can be interrupted by humans, but systems that know much more than us should be able to interrupt us too. |
|[EvoEval: Evolving Coding Benchmarks via LLM.](https://github.com/evo-eval/evoeval) | With the help of a new benchmark suite called EvoEval, Large Language Models' coding prowess is put to the ultimate test.|
|[Optimum-NVIDIA.](https://github.com/huggingface/optimum-nvidia) |Optimum-NVIDIA delivers the best inference performance on the NVIDIA platform through Hugging Face. Run LLaMA 2 at 1,200 tokens/second (up to 28x faster than the framework) by changing just a single line in your existing transformers code. |
|[OpenUI.](https://github.com/wandb/openui) |Building UI components can be a slog. OpenUI aims to make the process fun, fast, and flexible. It's also a tool we're using at W&B to test and prototype our next generation tooling for building powerful applications on top of LLM's. |
|[openchat-3.5-0106-gemma.](https://huggingface.co/openchat/openchat-3.5-0106-gemma) | The highest performing Gemma model in the world. Trained with OpenChat's C-RLFT on openchat-3.5-0106 data. Achieving similar performance to Mistral-based openchat, and much better than Gemma-7b and Gemma-7b-it.|
|[Generative AI for Beginners (Version 2) - A Course.](https://github.com/microsoft/generative-ai-for-beginners) | Microsoft's well-liked course on low-code apps, prompting, vector databases, and LLMs is available on GitHub in version 2. There are eighteen lessons in it. Even though some of the material is aspirational, it's still a useful starting point for the industry.|
|[Industry Documents Library (IDL).](https://huggingface.co/datasets/pixparse/idl-wds) | A huge dataset of 26m pages and 18B tokens of extremely high-quality OCR’d dataset of industrial PDF documents.|
|[SWE-agent.](https://github.com/princeton-nlp/SWE-agent) | SWE-agent turns LMs (e.g. GPT-4) into software engineering agents that can fix bugs and issues in real GitHub repositories.|
|[chug.](https://github.com/huggingface/chug) |A library to help w/ efficient training for multi-modal data. Initially focused on image & document + text tasks. Minimal sharded dataset loaders, decoders, and utils for multi-modal document, image, and text datasets.|
|[Cosmopedia: how to create large-scale synthetic data for pre-training.](https://huggingface.co/blog/cosmopedia) | The HuggingFace group demonstrates how to create synthetic data for language model pre-training by seeding, synthesizing, filtering, and scaling.|
|[AutoQuant.](https://colab.research.google.com/drive/1b6nqC7UZVt8bx4MksX7s656GXPM-eWw4) | HuggingFace models can be exported from this notebook into the following five quantization formats: GGUF, GPTQ, EXL2, AWQ, and HQQ.|
|[AI Infrastructure Explained.](https://salesforceventures.com/perspectives/ai-infrastructure-explained/) |Innovative applications of AI have captured the public’s imagination over the past year and a half. What’s less appreciated or understood is the infrastructure powering these AI-enabled technologies. But as foundational models get more powerful, we’ll need a strong technology stack that balances performance, cost, and security to enable widespread AI adoption and innovation. |
|[Introducing world's largest synthetic open-source Text-to-SQL dataset.](https://gretel.ai/blog/synthetic-text-to-sql-dataset) | HuggingFace currently has 23 million text to SQL tokens ready for use. In order to assist in producing SQL queries based on tasks involving natural language, Gretel has gathered a sizable dataset. This can support the creation of synthetic data as well as RAG applications.|
|[Write OpenAPI with TypeSpec.](https://blog.trl.sn/blog/typespec-for-openapi/) |Compared to JSON or YAML, TypeSpec, an API specification language created at Microsoft, provides a more succinct and understandable format for writing OpenAPI. It solves the verbosity and lack of reusable components in OpenAPI by allowing the specification of API patterns as reusable components, which streamlines code production and governance at scale. This is done by drawing inspiration from TypeScript's syntax. The flexibility and productivity gains of TypeSpec may increase the appeal of developing applications using APIs first. |

## Perspectives
|Link|description|
|---|---|
|[How Autonomous Racing Is Pushing Self-Driving Cars Forward.](https://www.inverse.com/science/self-driving-cars-ai-autonomous-racing) | The gritty reality of racing without drivers teaches us a lot about the future of autonomous cars.|
|[Does AI need a “body” to become truly intelligent? Meta researchers think so.](https://www.freethink.com/robots-ai/embodied-ai) | AIs that can generate videos, quickly translate languages, or write new computer code could be world changing, but can they ever be truly intelligent? Not according to the embodiment hypothesis, which argues that human-level intelligence can only emerge if an intelligence is able to sense and navigate a physical environment, the same way babies can. |
|[Nobody Knows How to Safety-Test AI.](https://time.com/6958868/artificial-intelligence-safety-evaluations-risks/) | In line with government goals, Beth Barnes' NGO METR is working with prominent AI firms like OpenAI and Anthropic to create safety checks for sophisticated AI systems. The emphasis is on evaluating hazards, including AI autonomy and self-replication, with the understanding that safety assessments are still in their infancy and cannot ensure AI safety. Despite worries that the existing testing could not be sufficiently trustworthy to support the rapid progress of AI technologies, METR's work is viewed as pragmatic.|
|[Beyond RPA: How LLMs are ushering in a new era of intelligent process automation.](https://foundationcapital.com/beyond-rpa-how-llms-are-ushering-in-a-new-era-of-intelligent-process-automation/) | RPA failed to achieve the enterprise-wide deployments that were anticipated, notwithstanding a few early triumphs. Only 3% of businesses were able to successfully grow their RPA operations, according to a Deloitte report. Recent developments in AI have the potential to alter this. Because of its innovative features, LLMs are expected to drive at least a tenfold increase in market share for intelligent process automation over the next ten years.|
|[We’re Focusing on the Wrong Kind of AI Apocalypse.](https://time.com/6961559/ethan-mollick-ai-apocalypse-essay/) |When talking about AI's future, people frequently discuss dystopian scenarios rather than the present effects on jobs and misinformation. Instead of bringing about the end of the world, AI has the ability to change work into more fulfilling and productive tasks with careful integration. |
|[How did a small developer of graphics cards for gamers suddenly become the third most valuable firm on the planet?](https://www.theguardian.com/commentisfree/2024/mar/30/nvidia-jensen-huang-ai-gold-rush-computer-chip-maker) |By turning his computer chip-making company Nvidia into a vital component in the AI arms race, Jensen Huang has placed himself at the forefront of the biggest gold rush in tech history |
|[‘It’s very easy to steal someone’s voice’: how AI is affecting video game actors.](https://www.theguardian.com/technology/2024/mar/29/how-ai-is-affecting-video-game-actors) |The increased use of AI to replicate the voice and movements of actors has benefits but some are concerned over how and when it might be used and who might be left short-changed |
|[AI in Africa: Basics Over Buzz.](https://www.science.org/doi/10.1126/science.ado8276) |AI’s transformative power is its utility for virtually every economic sector. But nearly half of the population in sub-Saharan Africa lacks access to electricity, and businesses struggle under the burden of an electricity supply that is among the most expensive and unreliable on earth. |
|[How scientists are making the most of Reddit.](https://www.nature.com/articles/d41586-024-00906-y) |As X wanes, researchers are turning to Reddit for insights and data, and to better connect with the public. |
|[Can lessons from infants solve the problems of data-greedy AI?](https://www.nature.com/articles/d41586-024-00713-5) | Words and images experienced by an infant wearing sensors during their daily life have led to efficient machine learning, pointing to the power of multimodal training signals and to the potentially exploitable statistics of real-life experience.|
|[Full Steam Ahead: The 2024 MAD (Machine Learning, AI & Data) Landscape.](https://mattturck.com/mad2024) |This is our tenth annual landscape and “state of the union” of the data, analytics, machine learning and AI ecosystem. |
|[Building AI Models is faster and cheaper than you probably think.](https://www.ycombinator.com/blog/building-ai-models) |By training or optimizing their own foundation models with YC's assistance, YC companies are dispelling the myth that creating AI models takes enormous resources. In just three months, they have accomplished amazing feats like creating original proteins and producing music of a high caliber. These 25 firms have produced creative AI solutions in a variety of industries by utilizing YC's finance and technical capabilities. They show that smaller teams can achieve major improvements in AI through creativity and strategic insights. |
|[Chinese mourners turn to AI to remember and ‘revive’ loved ones.](https://www.theguardian.com/technology/2024/apr/04/chinese-mourners-turn-to-ai-to-remember-and-revive-loved-ones) |Growing interest in services that create digital clones of the dead as millions visit graves this week for tomb-sweeping festival |
|[When Will the GenAI Bubble Burst?](https://garymarcus.substack.com/p/when-will-the-genai-bubble-burst) |That generative AI might not live up to expectations. The unprofitability of the technology, security flaws, and the innate issue of hallucinations in language models are all causes for concern. The excitement around generative AI may begin to fade unless a ground-breaking model such as GPT-5 is published by the end of 2024, addressing important difficulties and providing a game-changing application. |
|[Inside the shadowy global battle to tame the world's most dangerous technology.](https://www.politico.eu/article/ai-control-kamala-harris-nick-clegg-meta-big-tech-social-media/) |This article explores the intricate global attempts to control artificial intelligence (AI), which is considered to be one of the most powerful and dangerous technologies of our day. |
|[How to win at Vertical AI.](https://platforms.substack.com/p/how-to-win-at-vertical-ai) | Vertical B2B applications, where AI agents and open APIs play a critical role in rebundling and generating new business value, are where artificial intelligence truly shines. Domain-specific models provide vertical AI with an advantage in the near term, but horizontal integration into larger ecosystems is necessary for long-term success. AI agents make it possible to rebundle workflows, which transforms management procedures and gives businesses new competitive advantages across a range of industries.|
|[Where AI Thrives, Religion May Struggle.](https://www.chicagobooth.edu/review/where-ai-thrives-religion-may-struggle) |According to a study headed by Adam Waytz and Joshua Conrad Jackson, there may be a correlation between a drop in religious beliefs and growing exposure to robotics and AI. Higher robotization countries have higher declines in religiosity. According to the study, those whose occupations involved a lot of AI had a much lower likelihood of believing in God. These associations suggest that automation technologies could have an impact on the loss of religion. |




