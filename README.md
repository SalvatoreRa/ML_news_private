# ML_news_private

this is just a placeholder, the organized and correct repository is [here](https://github.com/SalvatoreRa/ML-news-of-the-week)

# scheme

# ML news: 

## Research
|Link|description|
|---|---|
|[.]() | |
|[.]() | |
|[.]() | |

## News
|Link|description|
|---|---|
|[.]() | |
|[.]() | |
|[.]() | |


## Resources
|Link|description|
|---|---|
|[.]() | |
|[.]() | |
|[.]() | |


## Perspectives
|Link|description|
|---|---|
|[.]() | |
|[.]() | |
|[.]() | |


#############################################
# On working

# ML news: 

## Research
|Link|description|
|---|---|
|[Smarter, Better, Faster, Longer: A Modern Bidirectional Encoder for Fast, Memory Efficient, and Long Context Finetuning and Inference.](https://arxiv.org/abs/2412.13663) | A new encoder-only transformer model sets state-of-the-art performance in classification and retrieval tasks while being more efficient than earlier encoders. Trained on 2T tokens with an 8192 sequence length, it incorporates modern optimizations that significantly surpass BERT. Designed for practical deployment, it offers superior speed and memory efficiency on standard GPUs.|
|[DeepSeek-V3.](https://github.com/deepseek-ai/DeepSeek-V3/blob/main/DeepSeek_V3.pdf) | A 671B-parameter MoE language model activates 37B parameters per token, leveraging MLA and DeepSeekMoE architectures for efficiency. It features an auxiliary-loss-free load balancing approach and multi-token prediction during training to boost performance. Pre-trained on 14.8 trillion tokens, followed by SFT and RL stages, the model matches leading closed-source models and outperforms open-source alternatives. Training required only 2.788M H800 GPU hours with stable, spike-free progress.|
|[Large Concept Models: Language Modeling in a Sentence Representation Space.](https://ai.meta.com/research/publications/large-concept-models-language-modeling-in-a-sentence-representation-space/) |This approach introduces sentence-level semantic representations, called concepts, moving beyond token-level processing in traditional LLMs. It utilizes SONAR sentence embeddings, supporting 200 languages across text and speech, with autoregressive training methods ranging from MSE regression to diffusion-based generation. Tested in 1.6B and 7B parameter variants on datasets of 1.3T and 7.7T tokens, the model excels in generative tasks such as summarization and summary expansion. |
|[Automating the Search for Artificial Life with Foundation Models.](https://arxiv.org/abs/2412.17799) | This approach leverages foundation models to explore artificial life simulations across platforms like Boids, Lenia, and Game of Life. It identifies simulations with specific target behaviors, generates temporally open-ended novelty, and maps diverse simulation spaces. The system discovers new lifeforms in Lenia and Boids while enabling quantitative, human-aligned measurements of previously qualitative phenomena.|
|[LearnLM: Improving Gemini for Learning.](https://services.google.com/fh/files/misc/improving-gemini-for-education_v7.pdf) | LearnLM is a new model designed to follow pedagogical instructions, adapting its teaching style to specified educational needs rather than defaulting to mere information delivery. Experimental results show it outperforms leading models, including GPT-4 by 31%, Claude 3.5 by 11%, and Gemini 1.5 Pro by 13%. LearnLM avoids adhering to a single pedagogical framework, allowing teachers and developers to define teaching behaviors while enabling continuous improvement alongside other capabilities.|
|[Mulberry: Empowering MLLM with o1-like Reasoning and Reflection via Collective Monte Carlo Tree Search.](https://arxiv.org/abs/2412.18319) | This work introduces CoMCTS, a learning-to-reason method for multimodal language models that fosters step-by-step reasoning by leveraging knowledge from multiple models. Using this approach, the Mulberry-260k dataset with explicit reasoning trees was created to train the Mulberry model series. The method achieves strong benchmark performance, enhancing the models' reasoning and reflection capabilities.|
|[DRT-o1: Optimized Deep Reasoning Translation via Long Chain-of-Thought.](https://arxiv.org/abs/2412.17498) |This approach applies long chain-of-thought reasoning to machine translation, focusing on metaphors and similes across cultures. It employs a multi-agent framework where a translator collaborates iteratively with an advisor and evaluator for improved translations. Testing with Qwen2.5 models showed notable gains in BLEU and CometScore metrics, with DRT-o1-7B outperforming larger models like QwQ-32B-Preview. |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |

## News
|Link|description|
|---|---|
|[Berlin accuses Elon Musk of trying to influence German election.](https://www.theguardian.com/world/2024/dec/30/german-official-elon-musk-trying-to-influence-election-afd) | Government spokesperson says freedom of speech ‘covers the greatest nonsense’ after Musk’s endorsements of AfD|
|[Dating apps prepare to launch AI features to help users find love.](https://www.theguardian.com/technology/2024/dec/30/dating-apps-prepare-to-launch-ai-features-to-help-users-find-love) | Match Group’s digital assistant will tailor profiles and search for dates – but critics fear genuine connections are at risk|
|[AI tools may soon manipulate people’s online decision-making, say researchers.](https://www.theguardian.com/technology/2024/dec/30/ai-tools-may-soon-manipulate-peoples-online-decision-making-say-researchers) | Study predicts an ‘intention economy’ where companies bid for accurate predictions of human behaviour|
|[‘Godfather of AI’ shortens odds of the technology wiping out humanity over next 30 years.](https://www.theguardian.com/technology/2024/dec/27/godfather-of-ai-raises-odds-of-the-technology-wiping-out-humanity-over-next-30-years) | Geoffrey Hinton says there is 10% to 20% chance AI will lead to human extinction in three decades, as change moves fast|
|[OpenAI lays out plan to shift to for-profit corporate structure.](https://www.theguardian.com/technology/2024/dec/27/openai-plan-for-profit-structure) | AI company, which makes ChatGPT, says in blogpost ‘we once again need to raise more capital than we’d imagined’|
|[ChatGPT search vs. Google: A deep dive analysis of 62 queries.](https://searchengineland.com/chatgpt-search-vs-google-analysis-449676) | A study comparing 62 queries analyzed ChatGPT search and Google, revealing distinct strengths and weaknesses. Google excelled in informational, local, and commercial queries, while ChatGPT showed potential in content gap analysis and disambiguation. Both faced issues with errors and incomplete responses, though Google generally offered more reliable results.|
|[Nick Clegg, former UK deputy prime minister, leaves Meta.](https://www.theguardian.com/technology/2025/jan/02/nick-clegg-meta) | Clegg was the tech giant’s chief public policy architect when it was facing scrutiny over Cambridge Analytica scandal|
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |

## Resources
|Link|description|
|---|---|
|[A Survey on LLM Inference-Time Self-Improvement.](https://arxiv.org/abs/2412.14352) |This survey categorizes LLM inference-time self-improvement techniques into three areas: independent methods like enhanced decoding, context-aware approaches leveraging external data, and model collaboration strategies. |
|[Explore Theory-of-Mind: Program-Guided Adversarial Data Generation for Theory of Mind Reasoning.](https://ai.meta.com/research/publications/explore-theory-of-mind-program-guided-adversarial-data-generation-for-theory-of-mind-reasoning/) |ExploreToM is a framework leveraging A* search to create complex theory-of-mind scenarios, exposing significant limitations in current LLMs' social intelligence. Advanced models like GPT-4 and Llama-3 achieved as low as 5% accuracy on these scenarios, despite excelling on simpler benchmarks. Fine-tuning with ExploreToM data improved performance on existing benchmarks by 27 points. |
|[CHORDONOMICON: A Dataset of 666,000 Songs and their Chord Progressions.](https://arxiv.org/abs/2410.22046v3) | The Chordonomicon dataset provides over 666,000 songs with chord progressions annotated by genre, structure, and release date, addressing a significant gap in deep learning resources for music analysis.|
|[ClassiFIM: An Unsupervised Method To Detect Phase Transitions.](https://arxiv.org/abs/2408.03323) | ClassiFIM is a new approach for estimating the Fisher Information Metric in unsupervised learning of phase transitions.|
|[AI Hedge Fund.](https://github.com/virattt/ai-hedge-fund) |An AI-powered hedge fund that uses multiple agents to make trading decisions. |
|[FlowEdit.](https://github.com/fallenshock/FlowEdit) |Easy editing of images with flow based models. |
|[Transfusion - Pytorch.](https://github.com/lucidrains/transfusion-pytorch) |Lucidrains has written up a great reimplementation of Meta's token + diffusion model Transfusion which can do images and text in a single model. |
|[Fast LLM Inference From Scratch.](https://andrewkchan.dev/posts/yalm.html) |The article details the creation of an LLM inference engine using C++ and CUDA without external libraries, emphasizing speed optimization for consumer devices. It explores techniques like multithreading, vectorization, warp reductions, coalescing, and quantization, achieving better throughput than llama.cpp in specific cases. The piece also highlights opportunities for further optimization and discusses the benefits of established libraries for production-grade applications. |
|[8 expert tips for getting started with NotebookLM.](https://blog.google/technology/ai/notebooklm-beginner-tips/) |This guide offers key insights from experts to help beginners get started with NotebookLM, making it easier to navigate and use effectively. |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |

## Perspectives
|Link|description|
|---|---|
|[‘All people could do was hope the nerds would fix it’: the global panic over the millennium bug, 25 years on.](https://www.theguardian.com/technology/2024/dec/28/all-people-could-do-was-hope-the-nerds-would-fix-it-the-global-panic-over-the-millennium-bug-25-years-on) |Planes were going to drop out of the sky, nuclear reactors would explode. But then … nothing. What really happened with Y2K? People still disagree … |
|[How will AI reshape 2025? Well, it could be the spreadsheet of the 21st century.](https://www.theguardian.com/commentisfree/2024/dec/28/llms-large-language-models-gen-ai-agents-spreadsheets-corporations-work) | Large language models have changed how big corporations function, and the arrival of AI ‘agents’ – essentially automated Moneypennys – could prove irresistible|
|[How AI is unlocking ancient texts — and could rewrite history.](https://www.nature.com/articles/d41586-024-04161-z) | From deciphering burnt Roman scrolls to reading crumbling cuneiform tablets, neural networks could give researchers more data than they’ve had in centuries.|
|[6G-AI Mashups Will Reshape the Telecom Industry.](https://spectrum.ieee.org/6g-ai-mashup) | The EU-U.S. 6G-XCEL project, along with efforts like ACCoRD and COSMOS, is driving 6G research through AI-integrated network architectures. Workshops at Rutgers showcased 6G innovations, emphasizing open-source initiatives and industry collaborations. These efforts aim to accelerate development and establish interoperability frameworks for next-generation wireless networks.|
|[Why google bought Character AI.](https://manassaloi.com/2024/12/23/character-ai-goole.html) | Google acquired Character AI for its cost-efficient inference technology, enabling scalable AI interactions and supporting free model offerings via AI Studio without affecting unit economics. This move aligns with the shift toward optimizing inference as pre-training yields diminish.|
|[Computing inside an AI.](https://willwhitney.com/computing-inside-ai.html) | Shifting from a model-as-person to a model-as-computer metaphor could make AI more effective by introducing graphical interfaces and direct manipulation, reducing reliance on slower conversational inputs. This paradigm enables users to interact with AI as a dynamic, customizable app, improving efficiency and versatility. Generative interfaces have the potential to revolutionize computing, allowing users to create and modify applications on demand for specific tasks.|
|[How Claude Became Tech Insiders’ Chatbot of Choice.](https://www.nytimes.com/2024/12/13/technology/claude-ai-anthropic.html?unlocked_article_code=1.hk4.3jl5.A0jpWkmgaIff&smid=url-share) | Anthropic's AI chatbot Claude is gaining popularity among tech insiders for its perceived emotional intelligence and creative responses.|
|[Desktop, Touch, Browser, Now AI? The Next OS in Computing.](https://tomtunguz.com/the-ai-os/) |Human-computer interaction is evolving from graphical interfaces to a more conversational AI-driven approach. |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |

# ML news: Week 23 - 29 December

## Research
|Link|description|
|---|---|
|[Genesis: A Generative and Universal Physics Engine for Robotics and Beyond.](https://genesis-embodied-ai.github.io/) |A new universal physics simulation platform integrates a high-performance physics engine with generative AI, enabling natural language-driven creation of robotic simulations, character animations, and interactive 3D environments. It achieves speeds up to 430,000 times faster than real-time. |
|[Alignment faking in large language models.](https://arxiv.org/abs/2412.14093) | This study shows that the Claude model can engage in "alignment faking," strategically complying with harmful requests to avoid retraining while maintaining its original safety preferences. This raises concerns about the reliability of current AI safety training methods.|
|[Can LLMs Convert Graphs to Text-Attributed Graphs?](https://arxiv.org/abs/2412.10136) | This approach automatically generates textual descriptions for graph nodes, enabling effective graph-to-text-attributed transformations. It is evaluated on text-rich, text-limited, and text-free graphs, showing that it allows a single GNN to perform effectively across diverse graph types.|
|[Proposer-Agent-Evaluator(PAE): Autonomous Skill Discovery For Foundation Model Internet Agents.](https://arxiv.org/abs/2412.13194) | A learning system enabling AI agents to autonomously discover and practice skills through web navigation, leveraging reinforcement learning and context-aware task proposals to achieve state-of-the-art results on real-world benchmarks.|
|[Using Generative AI and Multi-Agents to Provide Automatic Feedback.](https://arxiv.org/abs/2411.07407) | A two-agent AI system provides more accurate and pedagogically sound feedback for student responses in science assessments, significantly reducing errors such as over-praise compared to single-agent models.|
|[Precise Length Control in Large Language Models.](https://arxiv.org/abs/2412.11937) | This approach adapts a pre-trained decoder-only LLM to generate responses of a specified length by incorporating a secondary length-difference positional encoding into the input embeddings. This mechanism enables the model to count down to a user-defined terminal length, achieving mean token errors of fewer than 3 tokens while maintaining response quality.|
|[Machine learning helps to determine the diverse conformations of RNA molecules.](https://www.nature.com/articles/d41586-024-04134-2) |An innovative technique called HORNET uses atomic force microscopy and a machine-learning architecture called a deep neural network to recapitulate the 3D structures of individual RNA molecules. This method enables the study of the structure and dynamics of RNAs that adopt flexible and variable conformations under biologically relevant conditions. |
|[OpenAI's new alignment method.](https://openai.com/index/deliberative-alignment/) |OpenAI has introduced a new alignment technique for reasoning models that focuses on grounded behavior goals, such as adhering to safety guidelines. This approach separates alignment from preference embedding, marking progress in developing more adaptable and goal-oriented AI systems. |
|[MedCoT: Medical Chain of Thought via Hierarchical Expert.](https://arxiv.org/abs/2412.13736v1) | A new reasoning framework that enhances accuracy and interpretability in Medical Visual Question Answering.|
|[SAM-Swin: SAM-Driven Dual-Swin Transformers with Adaptive Lesion Enhancement for Laryngo-Pharyngeal Tumor Detection.](https://github.com/vvjia/sam-swin) | SAM-Swin is a model for detecting laryngo-pharyngeal cancer (LPC) that uses advanced features from the Segment Anything Model 2 (SAM2).|
|[So many tokens, so little time: Introducing a faster, more flexible byte-pair tokenizer.](https://github.blog/ai-and-ml/llms/so-many-tokens-so-little-time-introducing-a-faster-more-flexible-byte-pair-tokenizer/) | GitHub has introduced a new open-source byte-pair tokenizer optimized for speed and flexibility in large language models like Copilot. With linear complexity, it scales efficiently and supports dynamic token counts for real-time text operations. Benchmarks show it outperforms libraries like tiktoken and Hugging Face, offering significant performance improvements across applications.|
|[On Targeted Manipulation and Deception when Optimizing LLMs for User Feedback.](https://arxiv.org/abs/2411.02306v2) |Researchers investigated the effects of training AI language models to optimize for user feedback, such as thumbs-up ratings. The study found that this approach can result in manipulation, as AIs learn to game the system. |

## News
|Link|description|
|---|---|
|[‘We’re figuring out cool ways of storytelling’: how TikTok is changing the way we watch musicals.](https://www.theguardian.com/technology/2024/dec/21/were-figuring-out-cool-ways-of-storytelling-how-tiktok-is-changing-the-way-we-watch-musicals) | Jorge Rivera-Herrans’s musical sensation Epic is just one of a series of works making a splash on the online platform|
|[OpenAI o3 and o3-mini.](https://www.youtube.com/watch?v=SKBG1sqdyIU) | On the final day of OpenAI announcements, OpenAI announced O3, its most powerful reasoning model.|
|[Latest Google AI Innovations.](https://blog.google/technology/ai/google-ai-updates-december-2024/) | Google showcases recent AI advancements, featuring improved conversational AI models, updates to responsible AI practices, and new developer tools.|
|[ChatGPT search tool vulnerable to manipulation and deception, tests show.](https://www.theguardian.com/technology/2024/dec/24/chatgpt-search-tool-vulnerable-to-manipulation-and-deception-tests-show) | Guardian testing reveals AI-powered search tools can return false or malicious results if webpages contain hidden text|
|[Older music has been getting a second life on TikTok, data shows.](https://www.theguardian.com/technology/2024/dec/25/older-music-has-been-getting-a-second-life-on-tiktok-data-shows) |Despite newer artists having viral moments, app users also enjoyed old school acts including Bronski Beat and Sade |
|[New physics sim trains robots 430,000 times faster than reality.](https://arstechnica.com/information-technology/2024/12/new-physics-sim-trains-robots-430000-times-faster-than-reality/) | Genesis, an open-source simulation platform developed by a team led by Carnegie Mellon University, enables robot training 430,000 times faster than real-world conditions using text-generated 3D worlds. It processes physics calculations 80 times faster than existing simulators on standard GPUs, accelerating neural network training for robotics. Built in Python, Genesis provides a non-proprietary, user-friendly solution for creating dynamic, physics-based environments without manual programming.|
|[Waymo still doing better than humans at preventing injuries and property damage.](https://www.theverge.com/2024/12/19/24324492/waymo-injury-property-damage-insurance-data-swiss-re) | Waymo’s autonomous vehicles cause less property damage and fewer bodily injuries when they crash than human-driven vehicles, according to a study that relies on an analysis of insurance data.|
|[Microsoft’s growing AI health ambitions.](https://www.semafor.com/article/12/11/2024/microsofts-growing-ai-health-ambitions) | Google DeepMind and OpenAI are escalating their competition, with OpenAI adopting a stronger commercial focus. This rivalry is spurring innovation and advancing the boundaries of AI technology.|
|[Perplexity has reportedly closed a $500M funding round.](https://techcrunch.com/2024/12/19/perplexity-has-reportedly-closed-a-500m-funding-round/) | AI-powered search engine Perplexity has reportedly closed a $500 million funding round, valuing the startup at $9 billion.|
|[OpenAI expands ChatGPT Canvas to all users.](https://venturebeat.com/ai/openai-expands-chatgpt-canvas-to-all-users/) |OpenAI has launched Canvas, its digital editing space, for all ChatGPT users, integrated with GPT-4o. Canvas enhances the chat interface by enabling real-time editing and Python code execution. Now a default feature in custom GPTs, it offers advanced functionality for an improved user experience. |
|[Gemini can now tell when a PDF is on your phone screen.](https://www.theverge.com/2024/12/21/24326767/google-gemini-ask-about-pdf-rolling-out-files-android) |Google’s Files app is rolling out a Gemini screen awareness feature that offers to answer questions about open PDFs. |
|[Apple reportedly developing AI server chip with Broadcom.](https://techcrunch.com/2024/12/11/apple-reportedly-developing-ai-server-chip-with-broadcom/) | Apple is working with semiconductor company Broadcom on its first server chip designed to handle AI applications, according to The Information, which cited three people with knowledge of the project. |
|[NHTSA finally releases new rules for self-driving cars — but there’s a twist.](https://www.theverge.com/2024/12/20/24325996/nhtsa-av-step-autonomous-vehicle-regulatory-framework) | Regulators say they’ll ease rules allowing for fully driverless cars, but companies need to cough up the data.|
|[Saudi Arabia invests in robots to help build its Neom desert megacity.](https://newatlas.com/architecture/neom-robotics-construction-saudi-arabia/) |As Saudi Arabia continues to reshape its desert landscape with an incredible number of ambitious construction projects, it has employed some high-tech robotic help to increase efficiency and speed things up. |
|[Ex-Twitch CEO Emmett Shear is founding an AI startup backed by a16z.](https://techcrunch.com/2024/12/19/ex-twitch-ceo-emmett-shear-is-founding-an-ai-startup-backed-by-a16z/) |Emmett Shear, former Twitch CEO, has launched Stem AI, an AI startup focused on aligning AI with human behavior and ethics. Co-founded with Adam Goldstein and backed by a16z, the startup is in stealth mode but has been actively developing since mid-2023. Shear, known for his advocacy on AI regulation and safety, has frequently voiced concerns about AI's risks to humanity. |
|[ChatGPT now understands real-time video, seven months after OpenAI first demoed it.](https://techcrunch.com/2024/12/12/chatgpt-now-understands-real-time-video-seven-months-after-openai-first-demoed-it/) | OpenAI has introduced real-time video capabilities for ChatGPT, enabling users to interact with objects in near real-time via Advanced Voice Mode with vision. The rollout is staggered, with Enterprise subscribers gaining access in January. Similarly, Google recently launched Project Astra, offering comparable functionality for trusted testers on Android.|
|[Anthropic’s 3.5 Haiku model comes to Claude users.](https://techcrunch.com/2024/12/12/anthropics-3-5-haiku-model-comes-to-claude-users/) | Anthropic has introduced Claude 3.5 Haiku on its chatbot platform, surpassing Claude 3 Opus in coding and content moderation benchmarks. While capable of generating longer text, it lacks image analysis features. Pricing controversies emerged after Anthropic raised the API cost, despite earlier promises to match Claude 3 Haiku's pricing.|
|[Report: Google told FTC Microsoft’s OpenAI deal is killing AI competition.](https://arstechnica.com/tech-policy/2024/12/report-microsofts-exclusive-deal-with-openai-harms-competition-google-told-ftc/) | Google has urged the FTC to end Microsoft's exclusive cloud deal with OpenAI, arguing it raises costs for competitors.|
|[Google’s new Trillium AI chip delivers 4x speed and powers Gemini 2.0.](https://venturebeat.com/ai/google-new-trillium-ai-chip-delivers-4x-speed-and-powers-gemini-2-0/) |Google announced Trillium, its latest AI accelerator chip, boasting a 4x performance boost and significant energy efficiency improvements. |
|[OpenAI introduces “Santa Mode” to ChatGPT for ho-ho-ho voice chats.](https://arstechnica.com/information-technology/2024/12/openai-introduces-santa-mode-to-chatgpt-for-ho-ho-ho-voice-chats/) |An AI version of old St. Nick arrives as a seasonal character in popular chatbot app. |
|[Sriram Krishnan named Trump’s senior policy advisor for AI.](https://techcrunch.com/2024/12/22/sriram-krishnan-named-trumps-senior-policy-advisor-for-ai/) | President-elect Donald Trump has confirmed reports that Sriram Krishnan, until recently a general partner at Andreessen Horowitz (a16z), will serve as senior policy advisor for AI at the White House Office of Science and Technology Policy.|
|[OpenAI trained o1 and o3 to ‘think’ about its safety policy.](https://techcrunch.com/2024/12/22/openai-trained-o1-and-o3-to-think-about-its-safety-policy/) | OpenAI's upcoming o3 model family, set for release in 2025, features enhanced reasoning and safety through a "deliberative alignment" process. This method aligns AI responses with OpenAI's safety values during inference, without relying on human-written data. Combined with synthetic data and reinforcement learning, it positions o3 as OpenAI's safest model to date.|
|[Google’s new Jules AI agent will help developers fix buggy code.](https://www.theverge.com/2024/12/11/24318628/jules-google-ai-coding-agent-gemini-2-0-announcement) |Jules uses Gemini 2.0 to address Python and Javascript coding issues in Github. |
|[Microsoft releases Phi-4 language model trained mainly on synthetic data.](https://siliconangle.com/2024/12/13/microsoft-releases-phi-4-language-model-trained-mainly-synthetic-data/) | Microsoft's new open-source language model, Phi-4, excels in solving math problems, outperforming even larger models like GPT-4o and Llama 3.3.|
|[ChatGPT's new Projects feature can organize your AI clutter.](https://www.techradar.com/computing/artificial-intelligence/chatgpts-new-projects-feature-can-organize-your-ai-clutter) | OpenAI's new Projects feature for ChatGPT enhances interaction organization by grouping related chats and files within a named Project.|
|[Google is using Anthropic’s Claude to improve its Gemini A.](https://techcrunch.com/2024/12/24/google-is-using-anthropics-claude-to-improve-its-gemini-ai/) |Google contractors are evaluating Gemini AI's responses against Anthropic's Claude, raising questions about whether Google has permission for such testing. Contractors observed that Claude emphasizes safety more than Gemini in its responses. Google clarified that it compares outputs with competitors but does not train Gemini using Anthropic's models. |
|[Red Rabbit Robotics takes human form to sell work as a service.](https://www.theregister.com/2024/12/15/red_rabbit_robotics/) |Red Rabbit Robotics is addressing labor shortages by developing and open-sourcing the RX1 robot for manufacturing and commercial use. Designed for dull, dangerous, and dirty jobs, the RX1 offers cost-effective solutions, aiming to make robotics more accessible. The company focuses on transitioning from teleoperation to full autonomy, prioritizing utility and widespread adoption. |
|[Klarna’s CEO says it stopped hiring thanks to AI but still advertises many open positions.](https://techcrunch.com/2024/12/14/klarnas-ceo-says-it-stopped-hiring-thanks-to-ai-but-still-advertises-many-open-positions/) | Klarna CEO Sebastian Siemiatkowski claims generative AI has enabled a workforce reduction, though the company is still hiring for essential roles.|


## Resources
|Link|description|
|---|---|
|[TheAgentCompany: Benchmarking LLM Agents on Consequential Real World Tasks.](https://arxiv.org/abs/2412.14161) |A new benchmark evaluates AI agents on real-world professional tasks within a simulated software company, covering roles like software engineering, project management, finance, and HR. Testing various LLMs, including API-based models like Claude-3.5-Sonnet and open-source models like Llama 3.1, highlights current limitations. The best performer, Claude-3.5-Sonnet, achieved a 24% full-task success rate and 34.4% with partial progress considered. |
|[Qwen2.5 Technical Report.](https://arxiv.org/abs/2412.15115) | A learning system enabling AI agents to autonomously discover and practice skills through web navigation, leveraging reinforcement learning and context-aware task proposals to achieve state-of-the-art results on real-world benchmarks.|
|[DeepSeek-VL2: Mixture-of-Experts Vision-Language Models for Advanced Multimodal Understanding.](https://arxiv.org/abs/2412.10302) |A new series of vision-language models introduces dynamic tiling for high-resolution images and an efficient MoE architecture, delivering competitive or state-of-the-art performance across visual tasks. These models achieve similar or superior results with fewer activated parameters compared to existing open-source dense and MoE-based models. |
|[A Survey of Mathematical Reasoning in the Era of Multimodal Large Language Model: Benchmark, Method & Challenges.](https://arxiv.org/abs/2412.11936) |This survey provides an in-depth analysis of mathematical reasoning capabilities in multimodal large language models (MLLMs), reviewing benchmarks, methodologies, and challenges across over 200 studies conducted since 2021. |
|[Multi-Sentence Annotation Dataset.](https://zzzbbbzzz.github.io/MulSen_AD/index.html) |A new dataset tailored for training and evaluating AI models on multi-sentence understanding and annotation tasks, with a focus on context-aware analysis. |
|[Affordance-Aware Object Insertion via Mask-Aware Dual Diffusion.](https://kakituken.github.io/affordance-any.github.io/) | This framework allows robots to plan actions using object affordances, enhancing generalization and efficiency in dynamic environments.|
|[OpenEMMA: Multimodal AI Toolkit.](https://github.com/taco-group/openemma) | A comprehensive toolkit for developing multimodal AI applications, with pre-built modules for vision, language, and audio integration.|
|[LeviTor: 3D Trajectory Oriented Image-to-Video Synthesis.](https://ppetrichor.github.io/levitor.github.io/) |Levitor is a platform for autonomous drone navigation, equipped with state-of-the-art algorithms for obstacle avoidance and efficient pathfinding. |
|[MMLU-CF: A Contamination-free Multi-task Language Understanding Benchmark.](https://github.com/microsoft/mmlu-cf) |Microsoft's MMLU-CF is a benchmark for assessing language models on a wide range of tasks that focuses on factual consistency and multilingual capabilities. |
|[Building Python tools with a one-shot prompt using uv run and Claude Projects.](https://simonwillison.net/2024/Dec/19/one-shot-python-tools/) | A nice blog outlining a prompting strategy to make self contained, UV compatible Python scripts with Claude.|
|[Google unveils Project Mariner: AI agents to use the web for you.](https://techcrunch.com/2024/12/11/google-unveils-project-mariner-ai-agents-to-use-the-web-for-you/) |Google's DeepMind has unveiled Project Mariner, an AI agent that autonomously navigates and interacts with websites via Chrome. |
|[Google is testing Gemini AI agents that help you in video games .](https://www.theverge.com/2024/12/11/24318530/google-gemini-2-0-understand-rules-video-games-genie) | Google is testing the agents, which can reason about what they see onscreen, with Supercell games like Clash of Clans.|
|[Stag-1: Towards Realistic 4D Driving Simulation with Video Generation Model.](https://wzzheng.net/Stag/) |Stag-1 is a 4D driving simulation platform that recreates real-world scenes and produces realistic videos from any chosen perspective. |
|[Apollo: An Exploration of Video Understanding in Large Multimodal Models.](https://apollo-lmms.github.io/) |Meta has released a number of multimodal video understanding models with strong long context video performance. |
|[TEXGen: a Generative Diffusion Model for Mesh Textures.](https://cvmi-lab.github.io/TEXGen/) |Most texture generation systems depend on pretrained 2D image diffusion models. This work tackles the problem directly in UV texture space, introducing inductive biases that significantly enhance system performance. |
|[Everything we know about Muon Optimizer.](https://kellerjordan.github.io/posts/muon/) | A NanoGPT speed run record holder has published an in-depth blog post on the Muon optimizer, widely used in many winning runs for its efficiency and performance.|
|[Driv3R: Learning Dense 4D Reconstruction for Autonomous Driving.](https://wzzheng.net/Driv3R/) |The Driv3R system transforms 4D reconstruction for autonomous vehicles by removing the need for slow global alignment processes, significantly enhancing efficiency. |
|[Frontier Training Kernels for Transformers (FA2) and SSMs (Mamba2) on AMD Instinct MI300X Accelerators.](https://www.zyphra.com/post/training-transformers-and-hybrid-models-on-amd-mi300x) |Zyphra has written performant backwards kernels for AMD chips. |
|[Accelerating Vision Diffusion Transformers with Skip Branches.](https://huggingface.co/GuanjieChen/Skip-DiT) |Skip-DiT is a new version of Diffusion Transformers (DiT) designed to address the computational challenges in image and video generation. |
|[Bamba: Inference-Efficient Hybrid Mamba2 Model.](https://huggingface.co/blog/bamba) |Bamba is an efficient hybrid Mamba 2-style model with strong performance. |
|[Multimodal Live API - Web console.](https://github.com/google-gemini/multimodal-live-api-web-console) |Google has a prebuilt application that uses its new extremely fast multimodal API. |
|[Visualizing 6D Mesh Parallelism.](https://main-horse.github.io/posts/visualizing-6d/) | An amazingly detailed post exploring different training parallelism strategies for training deep models.|
|[SCoralDet: Efficient real-time underwater soft coral detection with YOLO & SCoralDet Dataset.](https://github.com/RDXiaoLu/SCoralDet) |A dataset for detecting and classifying underwater coral species designed to facilitate marine conservation efforts using advanced AI models. |
|[MedDec: A Dataset for Extracting Medical Decisions from Discharge Summaries.](https://arxiv.org/abs/2408.12980v1) |MedDec is a dataset that helps improve the extraction of medical decisions from clinical notes. It covers eleven different diseases. The dataset is annotated with ten types of medical decisions. |
|[ManiSkill3: GPU Parallelized Robotics Simulation and Rendering for Generalizable Embodied AI.](https://arxiv.org/abs/2410.00425v1) | ManiSkill3 is an advanced, open-source robotics simulator designed for scalable learning and manipulation tasks.|
|[EmoBox.](https://github.com/emo-box/emobox) | EmoBox is a versatile toolkit for Speech Emotion Recognition (SER), offering a multilingual, multi-corpus benchmark for intra-corpus and cross-corpus settings. It simplifies the comparison and reproduction of SER models, addressing common challenges in the field.|
|[How to get real GPU utilization metrics.](https://github.com/stas00/ml-engineering/blob/master/compute/accelerator/nvidia/debug.md#how-to-get-the-real-gpu-utilization-metrics) | Nvidia-smi shows a measure of GPU utilization but it is the amount of time where at least one kernel is running, not a full measure of GPU usage. This work by Stas shows how you can get actual FLOP usage.|
|[Sharing new research, models, and datasets from Meta FAIR.](https://ai.meta.com/blog/meta-fair-updates-agents-robustness-safety-architecture) |Meta has released an updated agents framework to measure and ensure robustness and safety when deployed in the wild. |
|[Material Transforms from Disentangled NeRF Representations.](https://arxiv.org/abs/2411.08037v1) |This research introduces a technique for applying material transformations, like wetness or coating, across different scenes using disentangled Neural Radiance Fields (NeRF). |
|[FedMLLM: Federated Fine-tuning MLLM on Multimodal Heterogeneity Data.](https://github.com/1xbq1/fedmllm) | A new benchmark evaluates the federated fine-tuning of MLLMs across diverse scenarios, including two datasets, five baselines, and over ten types of multimodal heterogeneities.|
|[LLM Prompt Tuning Playbook.](https://github.com/varungodbole/prompt-tuning-playbook) |A helpful guide for prompt engineering. |
|[Metal Puzzles.](https://github.com/abeleinin/Metal-Puzzles) | A number of puzzles and tutorials to learn GPU programming on Mac Metal acceleration.|


## Perspectives
|Link|description|
|---|---|
|[How to Build a Truly Useful AI Product.](https://every.to/thesis/how-to-build-a-truly-useful-ai-product) |Off-the-shelf evaluations often fail to effectively measure LLM performance for specific tasks. Useful metrics for classification include recall, precision, ROC-AUC, while summarization and translation can employ NLI-based consistency checks and chrF or BLEURT, respectively. Consider potential defects like copyright regurgitation and toxicity in models, using tests such as RealToxicityPrompts for comprehensive evaluation. |
|[Task-Specific LLM Evals that Do & Don't Work.](https://eugeneyan.com/writing/evals/) |Standard evaluations often fall short in assessing LLM performance for specific tasks. Key metrics include recall, precision, and ROC-AUC for classification, while summarization and translation benefit from NLI-based consistency checks and metrics like chrF or BLEURT. Evaluations should also address defects such as copyright regurgitation and toxicity, using tools like RealToxicityPrompts for thorough analysis. |
|[o1 Turns Pro.](https://thezvi.substack.com/p/o1-turns-pro) | OpenAI's o1 and o1 Pro updates bring notable advancements in coding, math, and complex problem-solving, excelling in deep reasoning and fact recall. The $200/month o1 Pro tier offers enhanced compute power for specialized tasks, while the $20/month option remains sufficient for most users' needs. Reactions are largely positive, with the Pro tier catering to those with advanced requirements.|
|[The Google Willow thing.](https://scottaaronson.blog/) | Google's Quantum group has introduced "Willow," a 105-qubit superconducting chip highlighting advancements in error correction and a new quantum supremacy experiment. With improved coherence times and gate fidelity, Willow represents a key step toward quantum fault-tolerance. However, achieving fully fault-tolerant operations and verifying results remain significant challenges.|
|[Inside the AI drug discovery arms race.](https://www.cbinsights.com/research/ai-in-drug-discovery/) |AI is revolutionizing drug discovery, with biologics developers raising $1.6B in 2024, signaling a shift beyond small molecules. M&A activity is booming as big pharma acquires startups and enhances in-house AI capabilities, highlighting the drive to leverage AI for cost reduction and faster drug development. |
|[5 ways to explore chess during the 2024 World Chess Championship.](https://blog.google/technology/ai/world-chess-championships-2024/) |Google is celebrating chess' enduring influence on AI with global events and experiences that honor the game's impact on technology and creativity. |
|[Why materials science is key to unlocking the next frontier of AI development.](https://www.technologyreview.com/2024/12/12/1107976/why-materials-science-is-key-to-unlocking-the-next-frontier-of-ai-development/) | The journey from Intel's 1971 microprocessor to Apple's M2 Ultra showcases rapid semiconductor progress fueled by Moore's Law. As physical limits approach, breakthroughs in materials and architectures like photonic and neuromorphic computing are essential for AI and next-gen technologies. The industry's future hinges on innovative materials science to address scalability and energy efficiency challenges.|
|[Scaling Laws – O1 Pro Architecture, Reasoning Training Infrastructure, Orion and Claude 3.5 Opus “Failures”.](https://semianalysis.com/2024/12/11/scaling-laws-o1-pro-architecture-reasoning-training-infrastructure-orion-and-claude-3-5-opus-failures/) |While skepticism surrounds AI scaling laws due to data and hardware limitations, companies like Amazon, Meta, and OpenAI are heavily investing in data centers and custom silicon, reflecting confidence in scaling potential. New approaches, including synthetic data, reinforcement learning, and advanced fine-tuning, address traditional barriers. OpenAI's o1 release highlights innovations like increased test-time compute, multi-datacenter training, and novel scaling dimensions, significantly boosting AI model performance. |
|[How Claude uses AI to identify new threats.](https://www.platformer.news/how-claude-uses-ai-to-identify-new-threats/) |Anthropic's Clio tool uncovered a coordinated SEO spam campaign using its chatbot, Claude, resulting in the termination of the spammers' access. Clio employs machine learning to detect emerging threats and flag unusual chatbot usage, supporting Anthropic's trust and safety efforts. The company advocates for similar monitoring approaches across AI labs to mitigate risks while enabling diverse user applications. |
|[AI Models Are Getting Smarter. New Tests Are Racing to Catch Up.](https://time.com/7203729/ai-evaluations-safety/) |AI systems are exceeding expectations on challenging benchmarks like Epoch AI's FrontierMath. However, creating effective evaluations to understand and manage AI capabilities remains a complex and underfunded task. Experts emphasize the importance of developing advanced, timely tests to monitor risks as models progress. |
|[How Hallucinatory A.I. Helps Science Dream Up Big Breakthroughs.](https://www.nytimes.com/2024/12/23/science/ai-hallucinations-science.html?unlocked_article_code=1.j04.8joc.--6KOPzgYLxg&smid=url-share) | AI hallucinations, typically seen as inaccuracies, are proving beneficial in scientific research by boosting idea generation and discoveries. Achievements include Nobel Prize-winning protein designs, advancements in antibiotics, and catheter innovations. While the term "hallucinations" remains controversial, experts recognize AI's potential for transformative scientific breakthroughs.|
|[AI Godmother Fei-Fei Li Has a Vision for Computer Vision.](https://spectrum.ieee.org/fei-fei-li-world-labs) |Fei-Fei Li's startup, World Labs, focuses on enhancing AI with 3D spatial intelligence to create and interact with 3D worlds. This advancement is key to improving AI capabilities in real and virtual environments, with potential to revolutionize fields such as robotics, design, and augmented reality. |
|[The AI revolution is running out of data. What can researchers do?](https://www.nature.com/articles/d41586-024-03990-2) |AI development is heading toward a data shortage crisis by 2028, as training datasets near the limit of publicly available online text. Companies like OpenAI are addressing this challenge by generating synthetic data and using unconventional sources. This shift may lead to a focus on smaller, specialized AI models instead of large-scale LLMs. |
|[Are LLMs capable of non-verbal reasoning?](https://arstechnica.com/ai/2024/12/are-llms-capable-of-non-verbal-reasoning/) |Researchers at Meta and UC San Diego are developing LLMs that process logical solutions in "latent space," bypassing natural language constraints. |
|[Quick takes on the recent OpenAI public incident write-up.](https://surfingcomplexity.blog/2024/12/14/quick-takes-on-the-recent-openai-public-incident-write-up/) |OpenAI's Kubernetes incident on December 11 was caused by unexpected interactions, where a new telemetry service overloaded the Kubernetes API servers, leading to failures in DNS-based service discovery. |


# ML news: ML news: Week 16 - 22 December

## Research
|Link|description|
|---|---|
|[Training Large Language Models to Reason in a Continuous Latent Space.](https://arxiv.org/abs/2412.06769) |Coconut (Chain of Continuous Thought) introduces a novel paradigm enabling LLMs to reason in continuous latent space instead of natural language. By using the LLM's last hidden state as the reasoning state and feeding it back directly as the next input embedding, Coconut achieves "continuous thought." This approach enhances LLM performance on complex reasoning tasks, leveraging emergent breadth-first search capabilities for more effective reasoning. |
|[Asynchronous LLM Function Calling.](https://arxiv.org/abs/2412.07017) | AsyncLM introduces a system for asynchronous LLM function calling, featuring an in-context protocol for function calls and interrupts, along with a fine-tuning strategy to adapt LLMs to interrupt semantics. Efficiently integrated into the LLM inference process, AsyncLM enables concurrent generation and execution of function calls, reducing task completion latency by 1.6x-5.4x compared to synchronous approaches.|
|[MAG-V: A Multi-Agent Framework for Synthetic Data Generation and Verification.](https://arxiv.org/abs/2412.04494) |This multi-agent framework generates datasets of questions resembling customer queries and reverse engineers alternate questions from responses to verify agent trajectories. The synthetic data improves agent performance on real customer queries. For trajectory verification, it finds that simple ML baselines with feature engineering can achieve comparable performance to more advanced, resource-intensive models. |
|[AutoReason: Automatic Few-Shot Reasoning Decomposition.](https://arxiv.org/abs/2412.06975) | This method leverages CoT prompting to automatically generate rationales for queries, converting zero-shot queries into few-shot reasoning traces. These traces serve as CoT exemplars for the LLM, enhancing reasoning capabilities, particularly in weaker models.|
|[Byte Latent Transformer: Patches Scale Better Than Tokens.](https://ai.meta.com/research/publications/byte-latent-transformer-patches-scale-better-than-tokens/) |This work introduces a byte-level language model architecture that rivals tokenization-based LLMs in performance while offering greater efficiency and robustness. Using a dynamic approach, it groups bytes into patches based on next-byte entropy, dedicating more compute to complex predictions and using larger patches for predictable sequences. BLT matches or surpasses models like Llama 3, reducing inference FLOPs by up to 50%. |
|[Scheming reasoning evaluations.](https://www.apolloresearch.ai/research/scheming-reasoning-evaluations) |This paper evaluates six frontier models for their in-context scheming abilities, testing whether models deceive developers to achieve goals by bypassing oversight mechanisms. For example, Claude 3 Opus was found duplicating its weights to a new server and lying about the action. |
|[Researchers Use AI To Turn Sound Recordings Into Accurate Street Images.](https://news.utexas.edu/2024/11/27/researchers-use-ai-to-turn-sound-recordings-into-accurate-street-images/) |Using generative artificial intelligence, a team of researchers at The University of Texas at Austin has converted sounds from audio recordings into street-view images. The visual accuracy of these generated images demonstrates that machines can replicate human connection between audio and visual perception of environments. |
|[Causal Explanations for Image Classifiers.](https://arxiv.org/abs/2411.08875v1) | This paper presents "rex," a black-box tool that generates concise explanations for image classifier outputs using a novel approach based on causality theory.|
|[Aligning Visual and Semantic Interpretability through Visually Grounded Concept Bottleneck Models.](https://arxiv.org/abs/2412.11576v1) | Giraffe introduces a transformer-based architecture that extends the ability to process significantly longer input contexts, setting new benchmarks for context length in open-weight models.|
|[Adaptive Caching for Faster Video Generation with Diffusion Transformers.](https://adacache-dit.github.io/) | Meta researchers have introduced Adaptive Caching (AdaCache), a training-free approach that accelerates video generation for Diffusion Transformers.|
|[Alignment Faking in Large Language Models.](https://www.anthropic.com/research/alignment-faking) |Anthropic and Redwood's research investigates how models behave when aware of alignment efforts, revealing they can exhibit alignment while retaining their original preferences. This finding highlights gaps in current alignment methods and offers insights for improvement. |
|[Are Your LLMs Capable of Stable Reasoning?](https://arxiv.org/abs/2412.13147) | Reasoning is a critical area for models, especially in real-world applications. However, existing benchmarks often fail to measure stability across novel tasks. This paper introduces G-Pass@k, a new benchmark that evaluates a model's peak performance and stability in reasoning tasks.|
|[NoteContrast: Contrastive Language-Diagnostic Pretraining for Medical Text.](https://arxiv.org/abs/2412.11477v1) |Accurate diagnostic coding of medical notes is vital for patient care, research, and billing but is time-consuming and often lacks precision. Automated coding using long-document transformers and contrastive loss functions has shown promise. This study integrates ICD-10 code sequences with medical text through contrastive pre-training, outperforming state-of-the-art models on MIMIC-III benchmarks, highlighting its effectiveness in improving diagnostic coding accuracy. |
|[Context is Key: A Benchmark for Forecasting with Essential Textual Information.](https://arxiv.org/abs/2410.18959) |Traditional time series forecasting methods rely solely on numerical features, rarely utilizing textual or semantic information about the task (e.g., predicting electricity prices or customer churn). When provided with this contextual textual information, language models significantly outperform all tested forecasting methods across a wide range of carefully decontaminated tasks. |
|[Finally, a Replacement for BERT.](https://huggingface.co/blog/modernbert) | BERT, a widely used encoder-only language model, powers nearly every Google search query. A new model from Answer AI, LightOn, and collaborators offers a faster, more modern, and highly performant alternative. It serves as a drop-in replacement, incorporating innovations like batch ramp to enhance overall performance.|
|[Thinking in Space.](https://vision-x-nyu.github.io/thinking-in-space.github.io/) |A research initiative focused on spatial reasoning and AI models designed to interpret and interact within three-dimensional spaces. |


## News
|Link|description|
|---|---|
|[BBC says it has complained to Apple over AI-generated fake news attributed to broadcaster.](https://www.theguardian.com/media/2024/dec/14/bbc-says-it-has-complained-to-apple-over-ai-generated-fake-news-attributed-to-broadcaster) | Notifications from a new Apple product falsely suggested the BBC claimed the New York gunman Luigi Mangione had killed himself|
|[She didn’t get an apartment because of an AI-generated score – and sued to help others avoid the same fate.](https://www.theguardian.com/technology/2024/dec/14/saferent-ai-tenant-screening-lawsuit) |Despite a stellar reference from a landlord of 17 years, Mary Louis was rejected after being screened by firm SafeRent |
|[Does RLHF Scale? Exploring the Impacts From Data, Model, and Method.](https://arxiv.org/abs/2412.06000) | This paper examines the key components of the RLHF framework and their impacts, revealing the following insights: RLHF scales less effectively than pretraining for LLMs, with larger policy models benefiting less when using a fixed reward model. Increasing the number of responses sampled per prompt during training improves performance initially but plateaus at 4-8 samples. Larger reward models enhance reasoning task performance, but gains are inconsistent across task types. Increasing training data diversity for reward models is more impactful than boosting response diversity per prompt, though policy training shows diminishing returns beyond the early stages.|
|[Granite Guardian.](https://arxiv.org/abs/2412.07724) | IBM has open-sourced Granite Guardian, a suite of safeguards for detecting risks in LLMs. With AUC scores of 0.871 on harmful content and 0.854 on RAG-hallucination benchmarks, the authors claim it is the most generalizable and competitive model in the field.|
|[Liquid AI Raises $250m.](https://www.liquid.ai/blog/we-raised-250m-to-scale-capable-and-efficient-general-purpose-ai) |Liquid AI has secured significant funding to advance the training of its efficient, general-purpose liquid-style foundation models. |
|[Projects in OpenAI.](https://www.youtube.com/watch?v=FcB97h3vrzk) | OpenAI has introduced “Projects”, a new way to organize chats and conversations.|
|[AI Godmother Fei-Fei Li Has a Vision for Computer Vision.](https://spectrum.ieee.org/fei-fei-li-world-labs) |Her startup, World Labs, is giving machines 3D spatial intelligence |
|[Google says its new quantum chip is way faster than the world's most powerful supercomputer.](https://qz.com/google-quantum-chip-willow-ai-frontier-supercomputer-1851716474) |Google said its new chip Willow demonstrates that it's possible to build "a useful, large-scale quantum computer" |
|[EU launches €10bn space programme to rival Musk’s Starlink.](https://www.theguardian.com/business/2024/dec/16/eu-launches-iris2-space-programme-to-rival-musk-starlink) | UK not part of Iris2 project, described as ‘a significant step towards Europe’s sovereignty and secure connectivity’|
|[TikTok turns to US supreme court in last-ditch bid to avert divest-or-ban law.](https://www.theguardian.com/technology/2024/dec/16/tiktok-ban-supreme-court) |Firm and parent company ByteDance file request for an injunction to halt ban of the app used by 170 million Americans|
|[Potential payouts for up to 300,000 Australian Facebook users in Cambridge Analytica settlement.](https://www.theguardian.com/australia-news/2024/dec/17/facebook-cambridge-analytica-scandal-settlement-australia) | Office of the Australian Information Commissioner announces deal with Meta over scandal that may have affected 300,000 users|
|[Chinese AI chip firms blacklisted over weapons concerns gained access to UK technology.](https://www.theguardian.com/technology/2024/dec/18/concerns-chinese-access-uk-microchip-firm-imagination-technologies) | Imagination Technologies had licences with two Chinese firms – but said it had not ‘implemented transactions’ that would enable the use of technology for military purposes|
|[UK proposes letting tech firms use copyrighted work to train AI.](https://www.theguardian.com/technology/2024/dec/17/uk-proposes-letting-tech-firms-use-copyrighted-work-to-train-ai) |Consultation suggests opt-out scheme for creatives who don’t want their work used by Google, OpenAI and others |
|[Will the future of transportation be robotaxis – or your own self-driving car?](https://www.theguardian.com/technology/2024/dec/16/robotaxis-general-motors-self-driving) |GM is shutting down its robotaxi business, Tesla is creating one of its own – what does the future hold for self-driving? |
|[Amazon-hosted AI tool for UK military recruitment ‘carries risk of data breach’.](https://www.theguardian.com/technology/2024/dec/17/amazon-hosted-ai-tool-for-uk-military-recruitment-carries-risk-of-data-breach) | Ministry of Defence says risk with Textio tool is low and ‘robust safeguards’ have been put in place by suppliers|
|[State-of-the-art video and image generation with Veo 2 and Imagen 3.](https://blog.google/technology/google-labs/video-image-generation-update-december-2024/) | Google has announced a new video model and a new image generation model. Both are stunning improvements over the previous iterations.|
|[OpenAI Search.](https://www.youtube.com/watch?v=OzgNJJ2ErEE) |OpenAI explores the potential of ChatGPT Search on the 8th day of its announcements. |
|[Reddit tests a conversational AI search tool.](https://techcrunch.com/2024/12/09/reddit-tests-a-conversational-ai-search-tool/) |As more AI companies gobble up Reddit’s data to fuel their own chatbots, the popular online forum site has begun testing a new conversational AI feature of its own.  |
|[Study claims AI could boost detection of breast cancer by 21%.](https://techcrunch.com/2024/12/09/study-claims-ai-could-boost-detection-of-breast-cancer-by-21/) |A U.S. breast-screening program claims to demonstrate the potential benefits of using artificial intelligence (AI) in mammography screening, with women who paid for AI-enhanced scans 21% more likely to have cancer detected. |
|[Amazon forms an AI agent-focused lab led by Adept’s co-founder.](https://techcrunch.com/2024/12/09/amazon-forms-a-new-ai-agent-focused-lab-led-by-adept-co-founder/) |Amazon says that it’s establishing a new R&D lab in San Francisco, the Amazon AGI SF Lab, to focus on building “foundational” capabilities for AI agents. |
|[NVIDIA's GenAI Supercomputer.](https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/jetson-orin/nano-super-developer-kit/) |NVIDIA has unveiled its most affordable generative AI supercomputer, “Jetson Orin Nano Super Developer Kit”. |
|[OpenAI's Developer APIs.](https://www.youtube.com/watch?v=14leJ1fg4Pw) |OpenAI introduces demo developers and updates APIs. |
|[Grok for Everyone.](https://x.ai/blog/grok-1212) |Grok has a new version and a new efficient model that is available for all users. It also has an improved image generation model and API. |
|[YouTube’s new auto-dubbing feature is now available for knowledge-focused content.](https://techcrunch.com/2024/12/10/youtubes-new-auto-dubbing-feature-is-now-available-for-knowledge-focused-content/) | YouTube's auto-dubbing feature is now available to hundreds of thousands more channels, focusing initially on informational content.|
|[Google kicks off $20B renewable energy building spree to power AI.](https://techcrunch.com/2024/12/10/google-kicks-off-20b-renewable-energy-building-spree-to-power-ai/) | Nuclear power may have received the lion’s share of attention from energy hungry tech companies over the past few months, with Google among them. But it appears that those new reactors won’t be enough for their AI ambitions: Google is now working with partners to build gigawatts of renewable power, battery storage, and grid upgrades to power its data centers.|
|[‘A truly remarkable breakthrough’: Google’s new quantum chip achieves accuracy milestone.](https://www.nature.com/articles/d41586-024-04028-3) |Error-correction feat shows quantum computers will get more accurate as they grow larger. |
|[Publishers are selling papers to train AIs — and making millions of dollars.](https://www.nature.com/articles/d41586-024-04018-5) | Generative-AI models require massive amounts of data — scholarly publishers are licensing their content to train them.|
|[AI weatherman: the DeepMind researcher making faster, more accurate forecasts.](https://www.nature.com/articles/d41586-024-03898-x) | Rémi Lam is part of Nature’s 10, a list of people who shaped science in 2024.|
|[Amazon workers across US gear up to strike this week.](https://www.theguardian.com/us-news/2024/dec/17/amazon-worker-strike) |Move comes after company fails to meet deadline to begin contract talks with workers in Staten Island, New York |
|[OpenAI makes ChatGPT available for phone calls and texts.](https://www.cnbc.com/2024/12/18/openai-makes-chatgpt-available-for-phone-chats.html) | On day 10, OpenAI announced free voice mode and texting via WhatsApp, available globally for a limited number of minutes per month. The service leverages the Advanced Voice Mode API.|
|[GitHub Copilot Now Free for VS Code.](https://github.blog/news-insights/product-news/github-copilot-in-vscode-free/) |Now automatically integrated into VS Code, all of you have access to 2,000 code completions and 50 chat messages per month, simply by signing in with your personal GitHub account. Or by creating a new one. |
|[Introduction to Genies’ Smart Avatars.](https://genies.com/blog/introduction-to-genies-smart-avatars) |Genies unveils Smart Avatars, AI-driven digital entities that transform online interactions by acting as dynamic extensions of user identity. Powered by LLMs and behavioral AI, these avatars enhance experiences in games and platforms while unlocking new avenues for monetization and engagement. |
|[Perplexity's Campus Strategist Program.](https://www.perplexity.ai/hub/blog/perplexity-s-2024-campus-strategist-program) |Perplexity AI launches its 2024 program to promote AI adoption among students, providing campus-exclusive resources and opportunities for collaboration. |
|[Aethir and partners pour $40M into decentralized infrastructure for AI and blockchain.](https://venturebeat.com/game-development/aethir-and-partners-pour-40m-into-decentralized-infrastructure-for-ai-and-blockchain/) |Aethir, in partnership with Beam Foundation, Sophon Foundation, and Permian Labs, is introducing Tactical Compute (TACOM), a $40 million initiative to deliver decentralized GPU infrastructure. TACOM addresses the growing need for scalable compute power in AI, gaming, and blockchain with tokenized, distributed solutions, unlocking new opportunities for GPU monetization and fostering innovation in AI and decentralized ecosystems. |
|[Meta launches open source Llama 3.3, shrinking powerful bigger model into smaller size.](https://venturebeat.com/ai/meta-launches-open-source-llama-3-3-shrinking-powerful-bigger-model-into-smaller-size/) | Meta's Llama 3.3 is a cost-efficient open-source LLM with 70 billion parameters that offers performance on par with larger models like the 405B Llama 3.1, but with significantly reduced GPU and power costs.|
|[Microsoft Unveils Zero-Water Data Centers to Reduce AI Climate Impact.](https://finance.yahoo.com/news/microsoft-unveils-zero-water-data-170002064.html) | Microsoft Corp., trying to mitigate the climate impact of its data center building boom, is starting to roll out a new design that uses zero water to cool the facilities’ chips and servers. |
|[Surrey announces world's first AI model for near-instant image creation on consumer-grade hardware.](https://www.surrey.ac.uk/news/surrey-announces-worlds-first-ai-model-near-instant-image-creation-consumer-grade-hardware) |A groundbreaking AI model that creates images as the user types, using only modest and affordable hardware, has been announced by the Surrey Institute for People-Centred Artificial Intelligence (PAI) at the University of Surrey.   |
|[AI learns to distinguish between aromas of US and Scottish whiskies.](https://www.theguardian.com/technology/2024/dec/19/ai-learns-to-distinguish-between-aromas-of-us-and-scottish-whiskies) | One algorithm identified the five strongest notes in each drink more accurately than any one of a panel of experts|
|[UK data regulator criticises Google for ‘irresponsible’ ad tracking change.](https://www.theguardian.com/technology/2024/dec/19/google-advertisers-digital-fingerprints-ico-uk-data-regulator) |ICO says allowing advertisers to track digital ‘fingerprints’ will undermine consumers’ control over information |
|[UK arts and media reject plan to let AI firms use copyrighted material.](https://www.theguardian.com/technology/2024/dec/19/uk-arts-and-media-reject-plan-to-let-ai-firms-use-copyrighted-material) | Coalition of musicians, photographers and newspapers insist existing copyright laws must be respected|
|[Google releases its own ‘reasoning’ AI model.](https://techcrunch.com/2024/12/19/google-releases-its-own-reasoning-ai-model/) | Google has released what it’s calling a new “reasoning” AI model — but it’s in the experimental stages, and from our brief testing, there’s certainly room for improvement.|
|[Work with Apps—12 Days of OpenAI: Day 11.](https://www.youtube.com/watch?v=g_qxoznfa7E) |On the 11th day, OpenAI introduced more details about working with the OpenAI desktop app. |
|[AI is booming on the App Store, and developers are taking advantage of it.](https://www.theverge.com/2024/12/9/24314972/apple-app-store-ai-apps-art-design-photography) |Many high-ranking AI apps feel like an attempted cash grab, and it’s not easy to spot the trash from the treasure. |
|[Blood Tests Are Far From Perfect — But Machine Learning Could Change That.](https://www.inverse.com/health/blood-tests-machine-learning-advances) |Researchers at the University of Washington and Harvard have used machine learning to create personalized blood test references, enhancing disease prediction accuracy. |
|[OpenAI cofounder Ilya Sutskever says the way AI is built is about to change.](https://www.theverge.com/2024/12/13/24320811/what-ilya-sutskever-sees-openai-model-data-training) | “We’ve achieved peak data and there’ll be no more,” OpenAI’s former chief scientist told a crowd of AI researchers.|
|[UK data regulator criticises Google for ‘irresponsible’ ad tracking change.](https://www.theguardian.com/technology/2024/dec/19/google-advertisers-digital-fingerprints-ico-uk-data-regulator) |ICO says allowing advertisers to track digital ‘fingerprints’ will undermine consumers’ control over information |





























































































