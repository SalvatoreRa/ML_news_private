# ML_news_private

this is just a placeholder, the organized and correct repository is [here](https://github.com/SalvatoreRa/ML-news-of-the-week)

# scheme

# ML news: 

## Research
|Link|description|
|---|---|
|[.]() | |
|[.]() | |
|[.]() | |

## News
|Link|description|
|---|---|
|[.]() | |
|[.]() | |
|[.]() | |

## Resources
|Link|description|
|---|---|
|[.]() | |
|[.]() | |
|[.]() | |

## Perspectives
|Link|description|
|---|---|
|[.]() | |
|[.]() | |
|[.]() | |

# ON WORKING

# ML news: 

## Research
|Link|description|
|---|---|
|[Yi: Open Foundation Models by 01.AI.](https://arxiv.org/abs/2403.04652) |One of the most potent open language models for a long time has been the Yi model. The group has published a document that offers significant new information about how they gather data and train employees. |
|[From One to Many: Expanding the Scope of Toxicity Mitigation in Language Models.](https://arxiv.org/abs/2403.03893v1) | This research uses translation to enhance safety measures in situations when direct data is not available, so taking on the task of minimizing dangerous material in AI across many languages.|
|[Plum: Prompt Learning using Metaheuristic.](https://arxiv.org/abs/2311.08364v1) |In this research, a broad class of more than 100 discrete optimization techniques known as metaheuristics is presented as a potent tool for enhancing rapid learning in big language models. |
|[ViewFusion: Towards Multi-View Consistency via Interpolated Denoising.](https://wi-sc.github.io/ViewFusion.github.io/) | A new technique called ViewFusion aims to enhance the way diffusion models produce images from fresh angles while maintaining the consistency of the images from one view to another.|
|[Functional Benchmarks for Robust Evaluation of Reasoning Performance, and the Reasoning Gap.](https://arxiv.org/abs/2402.19450) | reveals that there is a reasoning gap between the current models and the proposed functional benchmarks for evaluating the reasoning abilities of LLMs, ranging from 58.35% to 80.31%. However, the authors also note that these gaps can be closed with more advanced prompting techniques.|
|[Can Large Language Models Reason and Plan?](https://arxiv.org/abs/2403.04121) |The subject of thinking and planning for LLMs is covered in a recent position paper. The following is an overview of the author's findings: In summary, I don't have any strong evidence from anything I've read, checked, or done to suggest that LLMs engage in typical reasoning or planning. Instead, they use web-scale training to perform a type of universal approximate retrieval, which is sometimes confused for reasoning abilities, as I have explained." |
|[KnowAgent: Knowledge-Augmented Planning for LLM-Based Agents.](https://arxiv.org/abs/2403.03101) | we introduce KnowAgent, a novel approach designed to enhance the planning capabilities of LLMs by incorporating explicit action knowledge. Specifically, KnowAgent employs an action knowledge base and a knowledgeable self-learning strategy to constrain the action path during planning, enabling more reasonable trajectory synthesis, and thereby enhancing the planning performance of language agents.  |
|[Stealing Stable Diffusion Prior for Robust Monocular Depth Estimation.](https://arxiv.org/abs/2403.05056v1) | The new Stealing Stable Diffusion (SSD) method improves monocular depth estimate performance in challenging settings such as low light or wet ones.|
|[VideoElevator : Elevating Video Generation Quality with Versatile Text-to-Image Diffusion Models.](https://videoelevator.github.io/) |Using the advantages of text-to-image models, VideoElevator presents a unique method that improves text-to-video diffusion models. Videos with better frame quality and text alignment are produced by dividing the improvement process into two parts: fine-tuning temporal motion and improving spatial quality. This is known as the plug-and-play approach. |
|[Face2Diffusion for Fast and Editable Face Personalization.](https://mapooon.github.io/Face2DiffusionPage/) | Gaussian Splatting is combined with 3D mesh geometry in SplattingAvatar to create vibrant virtual humans, introducing a novel method for producing lifelike virtual humans. |
|[Stealing Part of a Production Language Model.](https://arxiv.org/abs/2403.06634) |By leveraging their public APIs, you may obtain parts of closed language models—like the embeddings layer—for free. A simple budget of less than $2,000 may do this. |
|[Caduceus: Bi-Directional Equivariant Long-Range DNA Sequence Modeling.](https://caduceus-dna.github.io/) |DNA sequence prediction model developed on the Transformer rival Mamba platform. For a little model, it is incredibly powerful and efficient. |
|[V3D: Video Diffusion Models are Effective 3D Generators.](https://heheyas.github.io/V3D/) |In order to improve 3D object production, this research presents a revolutionary method that creates detailed, high-quality objects from a single photograph. |
|[A generalist AI agent for 3D virtual environments.](https://deepmind.google/discover/blog/sima-generalist-ai-agent-for-3d-virtual-environments/) |We present new research on a Scalable Instructable Multiworld Agent (SIMA) that can follow natural-language instructions to carry out tasks in a variety of video game settings |
|[SSM Meets Video Diffusion Models: Efficient Video Generation with Structured State Spaces.](https://arxiv.org/abs/2403.07711v1) |By concentrating on linear memory consumption, this study overcomes the memory limitations of conventional attention-based diffusion models and presents a novel method for producing videos using state-space models (SSMs). As tested with the UCF101 and MineRL Navigate datasets, SSMs allow the generation of lengthier video sequences with competitive quality. |
|[SemCity: Semantic Scene Generation with Triplane Diffusion.](https://sglab.kaist.ac.kr/SemCity/) | SemCity transforms 3D scene production by emphasizing real-world outdoor environments—a problem that is sometimes disregarded because of how difficult and sparse outdoor data may be.|
|[Branch-Train-MiX: Mixing Expert LLMs into a Mixture-of-Experts LLM.](https://arxiv.org/abs/2403.07816) |This study demonstrates how to train several models and combine them into a single Mixture-of-Experts model. |
|[LiveCodeBench: Holistic and Contamination Free Evaluation of Large Language Models for Code.](https://arxiv.org/abs/2403.07974) |It is difficult to evaluate language models that have been taught to code. The majority of people utilize OpenAI's HumanEval. Some open models, nevertheless, appear to overfit to this standard. Coding performance may be measured while reducing contamination issues with LiveCodeBench. |
|[Evil Geniuses: Delving into the Safety of LLM-based Agents.](https://arxiv.org/abs/2311.11855v1) |'Evil Geniuses' is a virtual squad that researchers utilized in a recent study to examine the safety of LLMs. They discovered that these AI agents are less resistant to malevolent attacks, give more nuanced answers, and make it more difficult to identify improper responses. |
|[ViT-CoMer: Vision Transformer with Convolutional Multi-scale Feature Interaction for Dense Predictions.](https://github.com/Traffic-X/ViT-CoMer) | In this work, a novel backbone architecture called ViT-CoMer is presented, which improves on Vision Transformers (ViT) for dense prediction tasks without requiring pre-training.|
|[From Wait Times to Real-Time: Assort Health Secures $3.5 Million to Scale First Generative AI for Healthcare Call Centers.](https://www.assorthealth.com/blog-posts/assort-health-secures-3-5-million-to-scale-first-generative-ai-for-healthcare-call-centers) |Solution Erases Long Phone Holds for Patients, Supports Overwhelmed Medical Front Desk Workers and Improves Patient Access to Physicians |
|[MM1: Methods, Analysis & Insights from Multimodal LLM Pre-training.](https://arxiv.org/abs/2403.09611) | Apple just released a multimodal model and discussed how they trained in detail.|
|[.]() | |
|[.]() | |

## News
|Link|description|
|---|---|
|[OpenAI announces new members to board of directors.](https://openai.com/blog/openai-announces-new-members-to-board-of-directors) |Dr. Sue Desmond-Hellmann, Nicole Seligman, Fidji Simo join; Sam Altman rejoins board |
|[So long and thanks for all the pixels: Nvidia reportedly retiring the GTX brand for good.](https://www.pcgamer.com/hardware/graphics-cards/so-long-and-thanks-for-all-the-pixels-nvidia-reportedly-retiring-the-gtx-brand-for-good/) | Nvidia has stopped producing GPUs based on its Turing architecture. The last of them included the likes of the GTX 1660, 1650 and 1630 series of GPUs. Once remaining stocks sell, they'll be gone and with them the "GTX" brand itself, leaving all Nvidia gaming graphics cards as "RTX" models.|
|[Google’s upcoming Tensor G4 Chip set to rival Snapdragon 8 Gen 4 and Apple A18 Pro.](https://www.gizmochina.com/2024/03/07/google-tensor-g4-chip-performance/) | Let’s say you’re a smartphone manufacturer aiming to develop a new model. You have two options: partner with an established chipmaker like Qualcomm or MediaTek, or follow the path of Apple by designing your own custom chipset.Google has taken a similar approach, developing its in house Tensor processors. Recent information suggests the Pixel 9 will feature the Tensor G4 chipset, promising improved heat and power management for an enhanced user experience. |
|[Microsoft may debut its first 'AI PCs' later this month.](https://www.engadget.com/microsoft-may-debut-its-first-ai-pcs-later-this-month-204522580.html) |A report suggests an OLED Surface Pro 10 and Surface Laptop 6 are imminent. |
|[Looks like we may now know which OpenAI execs flagged concerns about Sam Altman before his ouster.](https://www.businessinsider.com/openai-cto-mira-murati-concerns-sam-altman-ouster-nyt-2024-3) | Two OpenAI execs raised concerns about Sam Altman before his ouster, The New York Times reported. The outlet reported that the company's chief technology officer, Mira Murati, played a key role. Altman returned as CEO in days, leaving many unanswered questions about what happened.|
|[Cloudflare announces Firewall for AI.](https://blog.cloudflare.com/firewall-for-ai/) |Today, Cloudflare is announcing the development of Firewall for AI, a protection layer that can be deployed in front of Large Language Models (LLMs) to identify abuses before they reach the models. |
|[Google announces they are tackling spammy, low-quality content on Search.]() |We’re making algorithmic enhancements to our core ranking systems to ensure we surface the most helpful information on the web and reduce unoriginal content in search results. We’re updating our spam policies to keep the lowest-quality content out of Search, like expired websites repurposed as spam repositories by new owners and obituary spam. |
|[This week, xAI will open source Grok.](https://twitter.com/elonmusk/status/1767108624038449405) | Official tweet of Elon Musk |
|[Covariant is building ChatGPT for robots.](https://techcrunch.com/2024/03/11/covariant-is-building-chatgpt-for-robots/) | The UC Berkeley spinout says its new AI platform can help robots think more like people. Covariant this week announced the launch of RFM-1 (Robotics Foundation Model 1).|
|[AI solves huge problem holding back fusion power.](https://www.freethink.com/energy/nuclear-fusion-reactions) | Princeton researchers have trained an AI to predict and prevent a common problem arising during nuclear fusion reactions — and they think it might be able to solve other problems, too.|
|[Midjourney bans all Stability AI employees over alleged data scraping.](https://www.theverge.com/2024/3/11/24097495/midjourney-bans-stability-ai-employees-data-theft-outage) |Midjourney blamed a near 24-hour service outage on ‘botnet-like activity’ from two accounts linked to the Stable Diffusion creator. |
|[Microsoft compares The New York Times’ claims against OpenAI to Hollywood’s early fight against VCR.](/www.cnbc.com/2024/03/05/microsoft-seeks-dismissal-parts-of-new-york-times-suit-against-openai.html) |Microsoft is helping OpenAI fight back against claims of copyright infringement by The New York Times. The news outlet’s lawsuit, filed in December, seeks to hold Microsoft and OpenAI accountable for billions of dollars in damages. In a court filing on Monday, Microsoft accuses the publisher of “unsubstantiated” claims that use of OpenAI’s technology is harming its business.|
|[Introducing Devin, the first AI software engineer.](https://www.cognition-labs.com/blog) | Devin, a new system from Cognition, receives a 14% on the difficult SWE-Bench benchmark, which evaluates AI's capacity for writing code. GPT-4 received a 1.7% score. This model demonstrates excellent contextual learning skills.|
|[Building Meta’s GenAI Infrastructure.](https://engineering.fb.com/2024/03/12/data-center-engineering/building-metas-genai-infrastructure/) |The Llama 3 training infrastructure is described in this Meta blog article. It covers networking, storage, Pytorch, NCCL, and many enhancements. This will prepare the way for Meta's H100s to go online throughout the course of the remaining months of this year. |
|[Physical Intelligence Raises $70M to Build AI-Powered Robots for Any Application.](https://www.maginative.com/article/physical-intelligence-raises-70m-to-build-ai-powered-robots-for-any-application/) |Pi differentiates itself by aiming to create software that can be applied across a wide range of robotics hardware. |
|[Researchers create AI worms that can spread from one system to another.](https://arstechnica.com/ai/2024/03/researchers-create-ai-worms-that-can-spread-from-one-system-to-another/) |Worms could potentially steal data and deploy malware. Now, in a demonstration of the risks of connected, autonomous AI ecosystems, a group of researchers has created one of what they claim are the first generative AI worms—which can spread from one system to another, potentially stealing data or deploying malware in the process.|
|[Perplexity brings Yelp data to its chatbot.](https://www.theverge.com/2024/3/12/24098728/perplexity-chatbot-yelp-suggestions-data-ai) |Perplexity’s responses can source multiple Yelp reviews for that cafe you were considering, along with location data and other information. |
|[Gemini now lets you tune and modify responses with a prompt.](https://9to5google.com/2024/03/06/gemini-modify-tune-response/) |Google is launching “a more precise way for you to tune Gemini’s responses” on the web app. When selecting (by highlighting) a part of Gemini’s response to your prompt, a pencil/sparkle icon appears to “Modify selected text.” This opens a box with Regenerate, Shorter, Longer, and Remove options, as well as an open text field. |
|[Microsoft’s neural voice tool for people with speech disabilities arrives later this year.](https://www.engadget.com/microsofts-neural-voice-tool-for-people-with-speech-disabilities-arrives-later-this-year-161550277.html) |At the Microsoft Ability summit today, the company is continuing to raise awareness about inclusive design. |
|[Together AI $106M round of funding.](https://www.together.ai/blog/series-a2) | we’ve raised $106M in a new round of financing led by Salesforce Ventures with participation from Coatue, and existing investors.|
|[Autonomous Vehicle Startup Applied Intuition Hits $6B Valuation After $250M Series E.](https://news.crunchbase.com/transportation/applied-intuition-valuation-autonomous-vehicle-startup-funding) |Autonomous vehicle software developer Applied Intuition locked up a $250 million Series E valuing the company at a $6 billion — a 67% uptick in value from its previous round. The deal comes even as venture funding for autonomous vehicle-related startups has been in decline in recent years. |
|[OpenAI CTO Says It’s Releasing Sora This Year.](https://futurism.com/the-byte/openai-cto-releasing-sora-this-year) | But now, OpenAI chief technology officer Mira Murati told the Wall Street Journal that the company will publicly release Sora "later this year."|
|[Google now wants to limit the AI-powered search spam it helped create.](https://arstechnica.com/gadgets/2024/03/google-wants-to-close-pandoras-box-fight-ai-powered-search-spam/) | Ranking update targets sites "created for search engines instead of people."|
|[OpenAI Partners With Le Monde And Prisa Media.](https://openai.com/blog/global-news-partnerships-le-monde-and-prisa-media) | We have partnered with international news organizations Le Monde and Prisa Media to bring French and Spanish news content to ChatGPT.|
|[World’s first major act to regulate AI passed by European lawmakers.](https://www.cnbc.com/2024/03/13/european-lawmakers-endorse-worlds-first-major-act-to-regulate-ai.html) | The European Union’s parliament on Wednesday approved the world’s first major set of regulatory ground rules to govern the mediatized artificial intelligence at the forefront of tech investment.|
|[Figure 01 can now have full conversations with people.](https://twitter.com/figure_robot/status/1767913661253984474) | Figure's robots can now hold in-depth discussions with humans thanks to the integration of OpenAI's technology. While Figure's neural networks provide quick, low-level dexterous robot operations, OpenAI's models offer high-level visual and linguistic intelligence. This X article includes a video of a human conversing with a Figure robot, teaching it how to complete tasks, explaining the rationale behind the tasks, and providing a self-evaluation of the activities' effectiveness.|
|[Claude 3 Is The Most Human AI Yet.](https://every.to/napkin-math/claude-3-is-the-most-human-ai-yet) | Claude 3, Anthropic's latest AI model, is distinguished by its "warmth," which makes it a reliable collaborator on creative writing assignments. More human-feeling and lifelike, Claude 3 is said to straddle the line between delightful deep contemplation and good thought. Though this subtlety has not been fully captured by technological benchmarks, Claude 3 is set to transform our relationship with AI in creative processes.|
|[Enhancing RAG-based application accuracy by constructing and leveraging knowledge graphs.](https://blog.langchain.dev/enhancing-rag-based-applications-accuracy-by-constructing-and-leveraging-knowledge-graphs/) |A practical guide to constructing and retrieving information from knowledge graphs in RAG applications with Neo4j and LangChain |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |

## Resources
|Link|description|
|---|---|
|[DeepSpeed-FP6: The Power of FP6-Centric Serving for Large Language Models.](https://github.com/microsoft/DeepSpeed/tree/master/blogs/deepspeed-fp6/03-05-2024) | A recent upgrade to Microsoft's robust DeepSpeed training package lets models use up to six bits per parameter. This can expedite inference by a factor of more than two.|
|[You can now train a 70b language model at home.](https://www.answer.ai/posts/2024-03-06-fsdp-qlora.html) |a fully open source system that, for the first time, can efficiently train a 70b large language model on a regular desktop computer with two or more standard gaming GPUs (RTX 3090 or 4090). This system, which combines FSDP and QLoRA, is the result of a collaboration between Answer.AI, Tim Dettmers (U Washington), and Hugging Face’s Titus von Koeller and Sourab Mangrulkar. |
|[Retrieval-Augmented Generation for AI-Generated Content: A Survey.](https://arxiv.org/abs/2402.19473v1) | gives a summary of RAG's application in several generating contexts, such as code, images, and audio, and includes a taxonomy of RAG upgrades along with citations to important works. |
|[Sora: A Review on Background, Technology, Limitations, and Opportunities of Large Vision Models.](https://arxiv.org/abs/2402.17177v2) | Based on public technical reports and reverse engineering, this paper presents a comprehensive review of the model's background, related technologies, applications, remaining challenges, and future directions of text-to-video AI models. |
|[SaulLM-7B: A pioneering Large Language Model for Law.](https://arxiv.org/abs/2403.03883) | With 7 billion parameters, SaulLM-7B is the first LLM designed explicitly for legal text comprehension and generation. Leveraging the Mistral 7B architecture as its foundation, SaulLM-7B is trained on an English legal corpus of over 30 billion tokens. |
|[A Practical Guide to RAG Pipeline Evaluation (Part 1: Retrieval).](https://medium.com/relari/a-practical-guide-to-rag-pipeline-evaluation-part-1-27a472b09893) | Retrieval is a critical and complex subsystem of the RAG pipelines. After all, the LLM output is only as good as the information you provide it, unless your App relies solely on the training data of the LLM. The core is measuring retrieval is assessing whether each of the retrieved results is relevant for a given query. |
|[C4AI Command-R.](https://huggingface.co/CohereForAI/c4ai-command-r-v01) |C4AI Command-R is a research release of a 35 billion parameter highly performant generative model. Command-R is a large language model with open weights optimized for a variety of use cases including reasoning, summarization, and question answering. Command-R has the capability for multilingual generation evaluated in 10 languages and highly performant RAG capabilities. |
|[Artificial Intelligence Controller Interface (AICI).](https://github.com/microsoft/aici) |The Artificial Intelligence Controller Interface (AICI) lets you build Controllers that constrain and direct output of a Large Language Model (LLM) in real time. Controllers are flexible programs capable of implementing constrained decoding, dynamic editing of prompts and generated text, and coordinating execution across multiple, parallel generations.  |
|[US Public Domain Books (English).](https://huggingface.co/datasets/storytracer/US-PD-Books) | This dataset contains more than 650,000 English books (~ 61 billion words) presumed to be in the public domain in the US which were digitised by the Internet Archive and catalogued as part of the Open Library project. |
|[transformer-debugger.](https://github.com/openai/transformer-debugger) | Transformer Debugger (TDB) is a tool developed by OpenAI's Superalignment team with the goal of supporting investigations into specific behaviors of small language models. The tool combines automated interpretability techniques with sparse autoencoders.|
|[VideoMamba.](https://github.com/opengvlab/videomamba) |VideoMamba is a technology that effectively manages global dependencies and local redundancy to tackle the challenges of video interpretation. |
|[FastV.](https://github.com/pkunlp-icler/fastv) |FastV is a plug-and-play inference acceleration method for large vision language models relying on visual tokens. It could reach 45% theoretical FLOPs reduction without harming the performance through pruning redundant visual tokens in deep layers. |
|[Maximizing training throughput using PyTorch FSDP.](https://pytorch.org/blog/maximizing-training/) | Together, teams from IBM and Meta have achieved 57% MFU by rapidly training potent models in parallel on huge A100 and H100 clusters.|
|[MoAI.](https://github.com/ByungKwanLee/MoAI) |MoAI is a new large language and vision model that integrates auxiliary visual data from specific computer vision tasks to improve upon existing models. |
|[superopenai: logging and caching superpowers for the openai sdk.](https://github.com/villagecomputing/superopenai) |superopenai is a minimal convenience library for logging and caching LLM requests and responses for visibility and rapid iteration during development. |
|[TripoSR.](https://github.com/vast-ai-research/triposr) | TripoSR, a state-of-the-art open-source model for fast feedforward 3D reconstruction from a single image, collaboratively developed by Tripo AI and Stability AI.|
|[Exploring Alternative UX Patterns for GenAI Interfaces.](https://medium.com/@danlittlewood/exploring-alternative-ux-patterns-for-genai-interfaces-a5c0d3ad4e01) | In the rapidly evolving landscape of GenAI interfaces, it is crucial to venture beyond the established norms. The current dominance of Quick Actions and Multi-Turn engagement patterns in these interfaces, while effective in many cases, should not limit our imagination or hinder the potential for innovation.|
|[rerankers.](https://github.com/AnswerDotAI/rerankers/) |Rerankers are an important part of any retrieval architecture, but they're also often more obscure than other parts of the pipeline. rerankers seeks to address this problem by providing a simple API for all popular rerankers, no matter the architecture.|
|[skyvern.](https://github.com/Skyvern-AI/skyvern) |Skyvern automates browser-based workflows using LLMs and computer vision. It provides a simple API endpoint to fully automate manual workflows, replacing brittle or unreliable automation solutions.|
|[Licensing AI Means Licensing the Whole Economy.](https://www.fromthenew.world/p/licensing-ai-means-licensing-the) |Because artificial intelligence is a process that is essential to many different economic uses, it is not possible to regulate it like a physical thing. |
|[.]() | |
|[.]() | |

## Perspectives
|Link|description|
|---|---|
|[Winning Strategies for Applied AI Companies.](https://medium.com/point-nine-news/winning-strategies-for-applied-ai-companies-f02cac0a6ad8) | Key Success Factors after reviewing over 70 companies that have raised at least $7M|
|[AI startups require new strategies: This time it’s actually different.](https://longform.asmartbear.com/ai-startups/) | The typical dynamics between startups and incumbents do not apply in AI as they did in previous technology revolutions like mobile and the Internet. Ignore this at your peril.|
|[The GPT-4 barrier has finally been broken.]() | Four weeks ago, GPT-4 remained the undisputed champion: consistently at the top of every key benchmark, but more importantly the clear winner in terms of “vibes”. Today that barrier has finally been smashed. We have four new models, all released to the public in the last four weeks, that are benchmarking near or even above GPT-4. |
|[Embrace AI to break down barriers in publishing for people who aren’t fluent in English.](https://www.nature.com/articles/d41586-024-00761-x) |E. M. Wolkovich describes having a paper rejected because of an unfounded accusation that ChatGPT was used to write it.We think that both the rejection and the bias against the use of artificial intelligence (AI) in scientific writing are misguided. |
|[Why scientists trust AI too much — and what to do about it.](https://www.nature.com/articles/d41586-024-00639-y) | Some researchers see superhuman qualities in artificial intelligence. All scientists need to be alert to the risks this creates.|
|[The Future of Poetry.](https://medium.com/@sierraelman/the-future-of-poetry-26dabfc2f50a) |Questions about whether poems were authored by humans or artificial intelligence (AI) were given to 38 AI experts and 39 English experts. First prize went to The Human, followed by Bard, ChatGPT-4, and Claude in that order, for both writing quality and the ability to deceive respondents into thinking that the poetry were written by a human. The fact that English specialists were far better at identifying which poems were composed by AI suggests that they should be involved more in the development of upcoming AI systems. |
|[Barack Obama on AI, free speech, and the future of the internet.](https://www.theverge.com/23948871/barack-obama-ai-regulation-free-speech-first-amendment-decoder-interview) | The former president joined me on Decoder to discuss AI regulation, the First Amendment, and of course, what apps he has on his homescreen.|
|[AI startups require new strategies: This time it’s actually different.](https://longform.asmartbear.com/ai-startups/) |The typical dynamics between startups and incumbents do not apply in AI as they did in previous technology revolutions like mobile and the Internet. Ignore this at your peril. |
|[Top AIs still fail IQ tests - When asked to read image-based questions.](https://www.maximumtruth.org/p/top-ais-still-fail-iq-tests) |According to recent testing, sophisticated AI models such as ChatGPT-4 and Google's "Gemini Advanced" do poorly on visual IQ tests, receiving lower than average scores. Although ChatGPT-4 exhibits mediocre pattern recognition abilities, it misidentifies objects visually and makes logical mistakes, indicating a considerable difference in comparison to human intellect. These results suggest that the development of universally intelligent AI systems may still be some way off. |
|[The Top 100 Gen AI Consumer Apps.](https://a16z.com/100-gen-ai-apps/) | Over 40% of the top web products are new, having entered the top 50 in the last six months, according to Andreessen Horowitz's most recent consumer analysis on the top 100 Gen AI consumer apps.|
|[This Nvidia Cofounder Could Have Been Worth $70 Billion. Instead He Lives Off The Grid.](https://www.forbes.com/sites/phoebeliu/2023/11/26/this-nvidia-cofounder-could-have-been-worth-70-billion-instead-he-lives-off-the-grid/) |If Curtis Priem, Nvidia’s first CTO, had held onto all his stock, he’d be the 16th richest person in America. Instead, he sold out years ago and gave most of his fortune to his alma mater Rensselaer Polytechnic Institute. |
|[How to thrive in a crowded enterprise AI market.](https://lsvp.com/stories/generative-sf-how-to-thrive-in-a-crowded-enterprise-ai-market/) |At a Lightspeed event, Arvind Jain, CEO of Glean, spoke on the difficulties and solutions facing corporate AI startups. He emphasized the need of providing genuine business value, being tenacious in hiring, and placing a higher priority on product quality than speed and cost. Jain also emphasized how privacy and security issues have slowed down the deployment of generative AI tools in businesses. Glean wants to become a widely used workplace AI platform that completely transforms how people work by becoming firmly integrated into organizational operations. |
|[As AI tools get smarter, they’re growing more covertly racist, experts find.](https://www.theguardian.com/technology/2024/mar/16/ai-racism-chatgpt-gemini-bias) | ChatGPT and Gemini discriminate against those who speak African American Vernacular English, report shows|
|[.]() | |
|[.]() | |

# ML news: Week 4 - 10 March

## Research
|Link|description|
|---|---|
|[HyperAttention: Long-context Attention in Near-Linear Time.](https://arxiv.org/abs/2310.05869) | It's well accepted—and informally verified—that HyperAttention is the key to Gemini's incredible 1 million+ token context window's success.|
|[Why do Learning Rates Transfer? Reconciling Optimization and Scaling Limits for Deep Learning.](https://arxiv.org/abs/2402.17457) | An attempt is made to explain the success of MuP hyperparameter transfer theoretically in this study. The greatest eigenvalue of the training loss Hessian, according to its creators, is unaffected by the network's depth or breadth.|
|[WebArena: A Realistic Web Environment for Building Autonomous Agents.](https://arxiv.org/abs/2307.13854) | The possibility for Agents to handle a range of digital responsibilities has the community enthused. But even the most advanced general-purpose models find it difficult to accomplish jobs where people achieve more than 70% of the time. It is becoming evident that these activities could require models that have been carefully trained.|
|[Smooth Diffusion: Crafting Smooth Latent Spaces in Diffusion Models.](https://shi-labs.github.io/Smooth-Diffusion/) |Latent space smoothness in text-to-image diffusion models is a problem that is addressed by a novel method called Smooth Diffusion. With this technique, even little changes in input will result in a steady and progressive alteration of the visuals. |
|[Rethinking Inductive Biases for Surface Normal Estimation.](https://baegwangbin.github.io/DSINE/) |A technique called DSNIE significantly enhances monocular surface normal estimation, which finds use in various computer graphics fields. |
|[CricaVPR: Cross-image Correlation-aware Representation Learning for Visual Place Recognition.](https://arxiv.org/abs/2402.19231v1) | CricaVPR presents a revolutionary method that focuses on the relationships between many photos, even when they are taken in various situations, in order to improve visual place identification.|
|[Empowering Large Language Model Agents through Action Learning.](https://arxiv.org/abs/2402.15809) | investigates open-action learning for language agents using an iterative learning strategy that uses Python functions to create and improve actions; on each iteration, the proposed framework (LearnAct) modifies and updates available actions based on execution feedback, expanding the action space and improving action effectiveness; the LearnAct framework was tested on Robotic planning and AlfWorld environments, showing 32% improvement in agent performance in AlfWorld when compared to ReAct+Reflexion.|
|[PlanGPT: Enhancing Urban Planning with Tailored Language Model and Efficient Retrieval.](https://arxiv.org/abs/2402.19273) |demonstrates how to use LLMs to integrate several approaches, such as retrieval augmentation, fine-tuning, tool utilization, and more; while the suggested framework is used in the context of urban and spatial planning, many of the insights and useful advice are applicable to other fields as well. |
|[Evo: Long-context modeling from molecular to genome scale.](https://www.together.ai/blog/evo) | Introducing Evo, a long-context biological foundation model based on the StripedHyena architecture that generalizes across the fundamental languages of biology: DNA, RNA, and proteins. Evo is capable of both prediction tasks and generative design, from molecular to whole genome scale (over 650k tokens in length). Evo is trained at a nucleotide (byte) resolution, on a large corpus of prokaryotic genomic sequences covering 2.7 million whole genomes.|
|[Resonance RoPE: Improving Context Length Generalization of Large Language Models.](https://arxiv.org/abs/2403.00071) | To assist LLMs comprehend and produce text in longer sequences than they were first trained on, researchers have created a new method dubbed Resonance RoPE. By using less processing power, our approach outperforms the current Rotary Position Embedding (RoPE) technique and improves model performance on lengthy texts.|
|[The All-Seeing Project V2: Towards General Relation Comprehension of the Open World.](https://arxiv.org/abs/2402.19474v1) | The All-Seeing Project V2 introduces the ASMv2 model, which blends text generation, object localization, and understanding the connections between objects in images.|
|[GPQA: A Graduate-Level Google-Proof Q&A Benchmark.](https://arxiv.org/abs/2311.12022v1) | A formidable task is offered by a new dataset named GPQA, which has 448 difficult multiple-choice questions covering physics, chemistry, and biology. Even domain specialists have difficulty—they only score about 65% accuracy—while non-experts only get 34%. Only 39% of advanced AI systems, such as GPT-4, are accurate. The goal of this dataset is to provide techniques for monitoring AI results in challenging scientific problems.|
|[SURE: SUrvey REcipes for building reliable and robust deep networks.](https://yutingli0606.github.io/SURE/) |SURE is a revolutionary strategy that integrates multiple approaches to increase the accuracy of deep neural network uncertainty predictions, particularly for image classification applications. |
|[Stable Diffusion 3: Research Paper.](https://stability.ai/news/stable-diffusion-3-research-paper) |Stable Diffusion 3 outperforms state-of-the-art text-to-image generation systems such as DALL·E 3, Midjourney v6, and Ideogram v1 in typography and prompt adherence, based on human preference evaluations. Our new Multimodal Diffusion Transformer (MMDiT) architecture uses separate sets of weights for image and language representations, which improves text understanding and spelling capabilities compared to previous versions of SD3.  |
|[Researchy Questions: A Dataset of Multi-Perspective, Decompositional Questions for LLM Web Agents.](https://arxiv.org/abs/2402.17896) |These days, language models are quite good at responding to queries. As a result, the majority of benchmarks in use today are saturated. 'Researchy' questions are a new breed of open-ended questions that call for several steps to complete. The source of this specific dataset is search engine queries. It includes instances where GPT-4 had trouble responding to questions. |
|[UniCtrl: Improving the Spatiotemporal Consistency of Text-to-Video Diffusion Models via Training-Free Unified Attention Control.](https://unified-attention-control.github.io/) |A novel method for improving motion quality and semantic coherence in films produced by text-to-video models is presented by UniCtrl. By employing motion injection and cross-frame self-attention approaches, it enhances video coherence and realism without requiring further training. |
|[VTG-GPT: Tuning-Free Zero-Shot Video Temporal Grounding with GPT.](https://github.com/YoucanBaby/VTG-GPT) |With natural language queries, VTG-GPT provides a revolutionary GPT-based technique that can precisely identify particular video segments without the need for fine-tuning or training. |
|[MobileCLIP: Fast Image-Text Models through Multi-Modal Reinforced Training.](https://github.com/apple/ml-mobileclip) |With the same performance as OpenAI's original CLIP model, MobileClip operates seven times quicker. It may be utilized for a variety of language and visual activities on-device. |
|[Vision-RWKV: Efficient and Scalable Visual Perception with RWKV-Like Architectures.](https://arxiv.org/abs/2403.02308v1) | Vision-RWKV provides an effective solution for high-resolution image processing by modifying the RWKV architecture from NLP for use in vision challenges.|
|[Design2Code: How Far Are We From Automating Front-End Engineering?](https://arxiv.org/abs/2403.03163) | It's hard to take pictures of a design and turn them into code. This study suggests an 18B model as a baseline and assessments imply that we are about there for performing this on basic designs. GPT-4V-generated code is sometimes preferred to human-synthesized code.|
|[MathScale: Scaling Instruction Tuning for Mathematical Reasoning.](https://arxiv.org/abs/2403.02884) |Researchers created two million route issues using fake data. After training a 7B model, they discovered that it performed well when compared to the most advanced big language models. |
|[Why Not Use Your Textbook? Knowledge-Enhanced Procedure Planning of Instructional Videos.](https://arxiv.org/abs/2403.02782v1) | The KEPP system offers a fresh method for organizing and carrying out difficult jobs. The approach, which makes use of a probabilistic knowledge network, enables the model to arrange activities in a logical way in order to accomplish a goal.|
|[KnowAgent: Knowledge-Augmented Planning for LLM-Based Agents.](https://www.zjukg.org/project/KnowAgent/) | KnowAgent presents an innovative method for enhancing the planning abilities of big language models through the incorporation of explicit action information. The method leads LLMs through more rational planning trajectories, which improves their performance on challenging tasks. |
|[tinyBenchmarks: evaluating LLMs with fewer examples.](https://arxiv.org/abs/2402.14992) | In this paper, we investigate strategies to reduce the number of evaluations needed to assess the performance of an LLM on several key benchmarks. This work shows that you can reliably evaluate language model performance with as few as 100 examples from popular benchmarks.|
|[3D Diffusion Policy.](https://3d-diffusion-policy.github.io/) | DP3 presents a novel method for imitation learning that effectively teaches robots difficult abilities by fusing diffusion strategies with 3D visual data.|
|[Co-LLM: Learning to Decode Collaboratively with Multiple Language Models.](https://github.com/clinicalml/co-llm) |Using an innovative approach, multiple huge language models can collaborate by alternately producing text token by token. With the use of this tactic, models are better able to apply their distinct advantages and areas of competence to a variety of activities, including following instructions, answering questions related to a given domain, and solving reasoning-based problems. |

## News
|Link|description|
|---|---|
|[AI-generated images of Trump with Black voters being spread by supporters.](https://www.theguardian.com/us-news/2024/mar/04/trump-ai-generated-images-black-voters) |No evidence to tie fake images, including one created by Florida radio host, to Trump campaign, BBC Panorama investigation finds |
|[Elon Musk sues OpenAI over AI threat.](https://www.courthousenews.com/elon-musk-sues-openai-over-ai-threat/) |OpenAI is not so open now, Musk claims, following the closed-source release of the company's artificial general intelligence technology under Microsoft. |
|[OpenAI wants to make a walking, talking humanoid robot smarter.](https://www.popsci.com/technology/openai-wants-to-make-a-walking-talking-humanoid-robot-smarter/) | Figure’s founder Brett Adcock says a new partnership with OpenAI could help its robots hold conversation and learn from its mistakes over time.|
|[MagicLab’s humanoid can toast marshmallows, fold clothes and dance.](https://interestingengineering.com/innovation/magiclabs-humanoid-can-toast-marshmallows-fold-clothes-and-dance) |Miniature high-torque servo actuators combined with sensitive multi-dimensional pressure sensors enabled the team to create an exceptionally dexterous hand–MagicBot. |
|[Amazon to spend $1 billion on startups that combine AI with robots.](https://arstechnica.com/ai/2024/02/amazon-to-spend-1-billion-on-startups-that-combine-ai-with-robots/) | Amazon’s $1 billion industrial innovation fund is to step up investments in companies that combine artificial intelligence and robotics, as the ecommerce giant seeks to drive efficiencies across its logistics network.|
|[Claude 3 released.](https://www.anthropic.com/news/claude-3-family) |Three new Claude 3 family models have been trained by Anthropic, the best of which achieves benchmark scores that GPT4 has publicly disclosed. It excels at visual tasks and is a multimodal model as well. Claude's coding skills have significantly improved with this version, which is significant. |
|[ChatGPT can read its answers out loud.](https://www.theverge.com/2024/3/4/24090500/chatgpt-openai-voice-ios-android) |OpenAI’s new Read Aloud feature for ChatGPT could come in handy when users are on the go by reading its responses in one of five voice options out loud to users. It is now available on both the web version of ChatGPT and the iOS and Android ChatGPT apps. |
|[Adobe reveals a GenAI tool for music.](https://techcrunch.com/2024/02/28/adobe-reveals-a-genai-tool-for-music/) |  Adobe unveiled Project Music GenAI Control, a platform that can generate audio from text descriptions (e.g. “happy dance,” “sad jazz”) or a reference melody and let users customize the results within the same workflow.|
|[OpenAI fires back at Elon Musk in legal fight over breach of contract claims.](https://www.theguardian.com/technology/2024/mar/06/openai-elon-musk-emails-chatgpt) | ChatGPT maker releases emails in support of claim businessman backed plan to create for-profit unit|
|[OpenAI and Elon Musk.](https://openai.com/blog/openai-elon-musk) | In response to Elon Musk's complaint, OpenAI provided screenshots of emails between Elon Musk, Greg Brockman, Sam Altman, and Ilya Sutskever, as well as their version of events. According to the receipts, Musk thought there was little hope for OpenAI to succeed and agreed that some models should be closed source.|
|[Perplexity AI Reportedly Raising Additional Money At Significantly Higher Valuation Cap Than $520M.](https://www.benzinga.com/news/24/02/37412558/watch-out-google-openai-perplexity-ai-reportedly-raising-additional-money-at-significantly-higher-va) | Perplexity AI, a rising star in the field of artificial intelligence, is reportedly in discussions to secure additional funding at a valuation significantly higher than its previous round.|
|[Le Chat.](https://mistral.ai/news/le-chat-mistral/) | Using its Mistral models, Mistral AI has introduced 'le Chat Mistral,' a new multilingual conversational assistant with an enterprise edition for companies.|
|[Neuralink brain chip: advance sparks safety and secrecy concerns.](https://www.nature.com/articles/d41586-024-00550-6) | Elon Musk announced this week that his company’s brain implant has allowed a person to move a computer mouse with their mind.|
|[Ex-Google engineer arrested for alleged theft of AI secrets for Chinese firms.](https://www.theguardian.com/technology/2024/mar/06/chinese-google-engineer-arrested-stealing-ai-trade-secrets) | Linwei Ding, facing four counts of theft of trade secrets, accused of transferring confidential information to his personal account|
|[Mistral x Snowflake.](https://www.snowflake.com/news/snowflake-partners-with-mistral-ai-to-bring-industry-leading-language-models-to-enterprises-through-snowflake-cortex/) | Snowflake, the Data Cloud company, and Mistral AI, one of Europe’s leading providers of AI solutions, today announced a global partnership to bring Mistral AI’s most powerful language models directly to Snowflake customers in the Data Cloud.|
|[Moondream 2 small vision language model.](https://moondream.ai/) | Moondream is a tiny language model built on SigLIP and Phi-2. The benchmark performance has been much enhanced in this second edition, which is licensed for commercial use. It is perfect for describing visuals and operating on low-end computing hardware.|
|[Driverless startup Waymo to test self-driving vehicles with no human driver in Austin.](https://eu.statesman.com/story/business/technology/2024/03/05/waymo-to-test-self-driving-vehicles-without-human-driver-in-austin/72855110007/) |Autonomous vehicle company Waymo will begin testing driverless cars, with no human behind the wheel, in Austin, starting Wednesday. |
|[Google brings Stack Overflow’s knowledge base to Gemini for Google Cloud.](https://techcrunch.com/2024/02/29/google-brings-stack-overflows-knowledge-base-to-gemini/) |Developer Q&A site Stack Overflow is launching a new program today that will give AI companies access to its knowledge base through a new API, aptly named OverflowAPI. |
|[Brave’s Leo AI assistant is now available to Android users.](https://techcrunch.com/2024/02/29/braves-leo-ai-assistant-is-now-available-to-android-users/) |Brave is launching its AI-powered assistant, Leo, to all Android users. The assistant allows users to ask questions, translate pages, summarize pages, create content and more. The Android launch comes a few months after Brave first launched Leo on desktop. Brave says Leo will be available on iOS devices in the coming weeks. |
|[Inflection-2.5.](https://inflection.ai/inflection-2-5) |A new model has been introduced by Inflection to power Pi, its personal assistant. The model achieves remarkable reasoning scores on benchmarks and performs within 94% of the GPT-4. In comparison to GPT-4, Inflection claims that training only required 40% of the compute. This post offers an intriguing discovery: a typical conversation with Pi lasts 33 minutes. |
|[Cohere and Accenture Collaborate to Accelerate Enterprise AI Adoption.](https://txt.cohere.com/cohere-accenture-collaborate/) | Cohere and Accenture are working together to provide over 9,000 enterprise clients with cohere embedding technology.|
|[Microsoft’s Mistral deal beefs up Azure without spurning OpenAI.](https://www.theverge.com/24087008/microsoft-mistral-openai-azure-europe) | Microsoft investing in Mistral puts the focus on its Azure model offerings.|


## Resources
|Link|description|
|---|---|
|[2.4x faster Gemma + 58% less VRAM.](https://unsloth.ai/blog/gemma) |You can now finetune Gemma 7b 2.43x faster than HF + Flash Attention 2 with 57.5% less VRAM use. When compared to vanilla HF, Unsloth is 2.53x faster and uses 70% less VRAM. |
|[DUSt3R.](https://github.com/naver/dust3r/tree/main) |With the help of this project, you may create 3D representations in GLB form by taking a few photos of a site and reconstructing it for usage in 3D applications. |
|[Datasets for Large Language Models: A Comprehensive Survey.](https://arxiv.org/abs/2402.18041) |an extensive (more than 180 pages) review and analysis of LLM datasets. |
|[Large Language Models(LLMs) on Tabular Data: Prediction, Generation, and Understanding -- A Survey.](https://arxiv.org/abs/2402.17944) |an overview of LLMs for tabular data jobs that includes important methods, measurements, datasets, models, and optimization strategies; it also discusses unmet issues and offers suggestions for future lines of inquiry. |
|[Using Claude 3 Opus for video summarization.](https://github.com/hundredblocks/transcription_demo) | Andrej Karpathy challenged me to write a blog article based on one of his latest videos in a lengthy context. This job was completed by Claude 3 with assistance from some pre-processing data. The end product is an excellent and captivating blog post.|
|[Dual-domain strip attention for image restoration.](https://github.com/c-yn/DSANet) |A new technique that greatly enhances image restoration tasks is dual-domain strip attention mechanism. |
|[Open-Sora-Plan.](https://github.com/PKU-YuanGroup/Open-Sora-Plan) |This project aim to reproducing Sora (Open AI T2V model), but we only have limited resource. We deeply wish the all open source community can contribute to this project. |
|[ML system design: 300 case studies to learn from.](https://www.evidentlyai.com/ml-system-design) | We put together a database of 300 case studies from 80+ companies that share practical ML use cases and learnings from designing ML systems. |
|[orca-math-word-problems-200k .](https://huggingface.co/datasets/microsoft/orca-math-word-problems-200k) |This dataset contains ~200K grade school math word problems. All the answers in this dataset is generated using Azure GPT4-Turbo. Please refer to Orca-Math: Unlocking the potential of SLMs in Grade School Math for details about the dataset construction. |
|[mlx-swift-examples.](https://github.com/ml-explore/mlx-swift-examples) | Apple created the MLX framework, which is used to train AI models on Macs. This repository demonstrates how to use Swift for model training on mobile devices. An MNIST classifier model can be trained with just one on an iPhone.|
|[Text Clustering.](https://github.com/huggingface/text-clustering) |A free and open source text clustering tool that makes it simple and rapid to embed, cluster, and semantically label clusters. On 100k samples, the full pipeline runs in 10 minutes. |
|[EasyLM.](https://github.com/young-geng/EasyLM) | Large language models (LLMs) made easy, EasyLM is a one stop solution for pre-training, finetuning, evaluating and serving LLMs in JAX/Flax. EasyLM can scale up LLM training to hundreds of TPU/GPU accelerators by leveraging JAX's pjit functionality.|
|[You can now train a 70b language model at home.](https://www.answer.ai/posts/2024-03-06-fsdp-qlora.html) |Today, we’re releasing Answer.AI’s first project: a fully open source system that, for the first time, can efficiently train a 70b large language model on a regular desktop computer with two or more standard gaming GPUs (RTX 3090 or 4090). This system, which combines FSDP and QLoRA, is the result of a collaboration between Answer.AI, Tim Dettmers (U Washington), and Hugging Face’s Titus von Koeller and Sourab Mangrulkar. |
|[Training Models at Scale.](https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/scaling/JAX/overview.html?utm_source=tldrai) |The goal of this tutorial is to provide a comprehensive overview of techniques and strategies used for scaling deep learning models, and to provide a hands-on guide to implement these strategies from scratch in JAX with Flax using shard_map.  |
|[Genstruct 7B.](https://huggingface.co/NousResearch/Genstruct-7B) |Genstruct 7B is an instruction-generation model, designed to create valid instructions given a raw text corpus. This enables the creation of new, partially synthetic instruction finetuning datasets from any raw-text corpus. |
|[Fructose.](https://github.com/bananaml/fructose) |Fructose is a python package to create a dependable, strongly-typed interface around an LLM call. |
|[Efficient Multi-Head Attention Implementations.](https://github.com/rasbt/LLMs-from-scratch/blob/main/ch03/02_bonus_efficient-multihead-attention/mha-implementations.ipynb) |Different implementations of the widely used multi-headed attention module in contemporary LLMs varied in speed by over ten times. This notebook lists a handful and compares how well they perform. |
|[US regulators investigate whether OpenAI investors were misled, say reports.](https://www.theguardian.com/business/2024/feb/29/us-regulators-investigate-whether-openai-investors-were-misled) | Internal communications from CEO Sam Altman reportedly under scrutiny in SEC inquiry|
|[Microsoft introduces Copilot AI chatbot for finance workers in Excel and Outlook.](https://www.cnbc.com/2024/02/29/microsoft-introduces-copilot-ai-chatbot-for-finance-workers.html) | Microsoft is launching a Copilot for Finance, which it said will be able to perform a handful of common role-specific actions in Excel and Outlook.|

## Perspectives
|Link|description|
|---|---|
|[On the Societal Impact of Open Foundation Models.](https://crfm.stanford.edu/open-fms/) |a position paper that centers on open foundation models and discusses their advantages, disadvantages, and effects; it also suggests a framework for risk analysis and clarifies why, in certain situations, the marginal risk of these models is low. Finally, it provides a more sober evaluation of the open foundation models' effects on society. |
|[Towards Long Context RAG.](https://www.llamaindex.ai/blog/towards-long-context-rag) |The amazing one-million-word context window that Google's Gemini 1.5 Pro has brought to the AI community has sparked a debate regarding the future viability of retrieval-augmented generation (RAG).  |
|[Aggregator’s AI Risk.](https://stratechery.com/2024/aggregators-ai-risk/) |The impact of the Internet, especially through Aggregators like Google and Meta, is comparable to that of the printing press on the spread of knowledge and the establishment of nation-states. But the rise of generative AI puts the Aggregator model to the test by offering unique solutions that represent ingrained worldviews. This could undermine the Aggregator economics's universal appeal and point to the need for a move toward personalized AI in order to preserve its dominance. |
|[Is Synthetic Data the Key to AGI?.](https://digitalspirits.substack.com/p/is-synthetic-data-the-key-to-agi) |The caliber of training data has a major impact on how effective large language models are. By 2027, projections indicate that there will be a shortage of high-quality data. A possible answer to this problem is synthetic data generation, which could change internet business models and emphasize the significance of fair data access and antitrust laws.|
|[AI Research Internship Search as a CS PhD Student.](https://newsletter.yongzx.io/p/ai-research-internship-search-as) | Tips and thoughts from my relatively successful summer research internship hunt during third-year Computer Science PhD study.|
|[How AI Could Disrupt Hollywood.](https://www.vanityfair.com/news/ai-hollywood-letter-from-la) |New platforms and tools may allow a person to create a feature-length film from their living room. But can they really compete with the studios? |
|[Training great LLMs entirely from ground zero in the wilderness as a startup.](https://www.yitay.net/blog/training-great-llms-entirely-from-ground-zero-in-the-wilderness) |Reka's creator and well-known GPU critic Yi Tay detailed their experience building very powerful language models outside of Google in a blog post. The primary obstacles stem from hardware instability and cluster issues. They also had difficulties with software maturity. |
|[Claude 3 Is The Most Human AI Yet.](https://every.to/napkin-math/claude-3-is-the-most-human-ai-yet) | Anthropic's Claude 3, a large language model similar to GPT-4, is notable not so much for its cost-effectiveness or benchmark test results as for its distinctly human-like, creative, and naturalistic interaction quality. This represents a major breakthrough in AI's capacity to collaborate imaginatively with writers.|
|[Licensing AI Means Licensing the Whole Economy.](https://www.fromthenew.world/p/licensing-ai-means-licensing-the) | AI is a vast process employing statistical approaches, and it would be impractical to control its use across all organizations. Therefore, regulating AI like a tangible commodity is incorrect. Given AI's imminent economic ubiquity, targeted regulation for particular misuses—akin to current strategies for programming or email abuses—is more successful.|
|[Is ChatGPT making scientists hyper-productive? The highs and lows of using AI.](https://www.nature.com/articles/d41586-024-00592-w) |Large language models are transforming scientific writing and publishing. But the productivity boost that these tools bring could have a downside. |
|[Artificial intelligence and illusions of understanding in scientific research.](https://www.nature.com/articles/s41586-024-07146-0) |Why are AI tools so attractive and what are the risks of implementing them across the research pipeline? Here we develop a taxonomy of scientists’ visions for AI, observing that their appeal comes from promises to improve productivity and objectivity by overcoming human shortcomings. |
|[AI will likely increase energy use and accelerate climate misinformation – report.](https://www.theguardian.com/technology/2024/mar/07/ai-climate-change-energy-disinformation-report) | Claims that artificial intelligence will help solve the climate crisis are misguided, warns a coalition of environmental groups|
|[We Need Self-Driving Cars.](https://www.newcomer.co/p/we-need-self-driving-cars) | Anyone rooting against self-driving cars is cheering for tens of thousands of deaths, year after year. We shouldn’t be burning self-driving cars in the streets. We should be celebrating…|
|[Subprime Intelligence.](https://www.wheresyoured.at/sam-altman-fried/) |Significant problems in OpenAI's Sora demonstrate the limitations of generative AI's comprehension. The technology presents both practical obstacles and revolutionary possibilities, as seen by its high computing needs and potential impact on the creative industry. |
|[Sora, Groq, and Virtual Reality.](https://stratechery.com/2024/sora-groq-and-virtual-reality/) |A few years ago, Facebook's drive into the metaverse looked misguided, and the idea of the metaverse appeared like fiction from Ernest Cline's novel. Things feel different now. Groq's deterministic circuits streamline machine-learning algorithms for quicker processing, while Sora creates intricate video situations. The combination of these developments brings us one step closer to real-time video simulation and full-fledged virtual reality. |
|[AI Is Like Water.](https://www.nfx.com/post/ai-like-water) | For GenAI companies to have a competitive advantage, technology alone is no longer sufficient. This means that since the basic product is virtually the same, GenAI and bottled water are comparable. The primary differentiators need to originate from elements like distribution, user experience, perceived customer value, branding, and marketing.|


# ML news: Week 26 February - 3 March

## Research
|Link|description|
|---|---|
|[Back to Basics: Revisiting REINFORCE Style Optimization for Learning from Human Feedback in LLMs.](https://arxiv.org/abs/2402.14740) | The RL approach REINFORCE is straightforward, well-known, and simple to comprehend. In simulators, training steadily is a challenge. In general, PPO is far more reliable and performant. REINFORCE is used by Gemini, and PPO is presumably used by GPT-4.|
|[AlphaFold Meets Flow Matching for Generating Protein Ensembles.](https://arxiv.org/abs/2402.04845) |The protein's post-folding state can be predicted using AlphaFold. Adding invertible flow matching allows you to significantly increase modeling capability throughout the whole protein landscape. |
|[Not All Experts are Equal: Efficient Expert Pruning and Skipping for Mixture-of-Experts Large Language Models.](https://github.com/lucky-lance/expert_sparsity) | Researchers have created a new technique that focuses on "expert-level sparsification," which minimizes model size without sacrificing performance, to make LLMs more effective and user-friendly. For Mixture-of-Experts LLMs, which are strong but typically too large to manage simply, this is very helpful.|
|[Towards Generalizable Hand-Object Interaction Denoising via Denoising Diffusion.](https://meowuu7.github.io/GeneOH-Diffusion/) |A novel method called GeneOH Diffusion enhances models' comprehension of and ability to manipulate objects with their hands. The goal of this technique is to improve the naturalness of these interactions by fixing mistakes in hand gestures and object relationships. |
|[Snap Video: Scaled Spatiotemporal Transformers for Text-to-Video Synthesis.](https://snap-research.github.io/snapvideo/index.html) |With the exception of Sora, Snap Research has developed a video creation model that is 3 times faster to run than the prior state of the art. |
|[OpenCodeInterpreter.](https://opencodeinterpreter.github.io/) |By training on a synthetic multi-turn dataset and utilizing human feedback, a model built on CodeLlama and DeepSeek Coder was able to achieve 85%+ on the HumanEval programming benchmark. |
|[INSTRUCTIR: A Benchmark for Instruction Following of Information Retrieval Models.](https://arxiv.org/abs/2402.14334v1) | A new benchmark called INSTRUCTIR aims to improve search engines' ability to infer users' intentions. INSTRUCTIR assesses how well search engines can obey user instructions and adjust to different and evolving search needs, in contrast to existing approaches that primarily concentrate on the query itself.|
|[MobileLLM: Optimizing Sub-billion Parameter Language Models for On-Device Use Cases.](https://arxiv.org/abs/2402.14905) | In terms of accuracy in jobs involving contacting API functions, Meta's 350m parameter language model has high reasoning performance, even coming close to Llama 7B. Although the model is not yet available, it is worthwhile to investigate the novelty in fixed parameter models. |
|[ConceptMath: A Bilingual Concept-wise Benchmark for Measuring Mathematical Reasoning of Large Language Models.](https://arxiv.org/abs/2402.14660v1) | A new multilingual benchmark called ConceptMath is used to assess LLMs' arithmetic proficiency in both Chinese and English. It's special because it deconstructs arithmetic problems into discrete ideas, enabling a more thorough evaluation of an AI's mathematical prowess and shortcomings. |
|[Generate What You Prefer: Reshaping Sequential Recommendation via Guided Diffusion.](https://arxiv.org/abs/2310.20453v1) | DreamRec proposed a revolutionary 'learning-to-generate' technique to sequential recommendation, whereby it generates a 'oracle' item representing the optimal next option for the user, as opposed to the conventional way of identifying user preferences from a mixture of positive and negative things.|
|[FlowMDM: Seamless Human Motion Composition with Blended Positional Encodings.](https://barquerogerman.github.io/FlowMDM/) | A novel model called FlowMDM uses text descriptions to create lengthy, continuous sequences of human movements. This groundbreaking diffusion-based model excels in accuracy and realism on important datasets by using Blended Positional Encodings to create realistic motion without the need for additional denoising stages.|
|[VSP-LLM (Visual Speech Processing incorporated with LLMs).](https://github.com/sally-sh/vsp-llm) | We propose a novel framework, namely Visual Speech Processing incorporated with LLMs (VSP-LLM), to maximize the context modeling ability by bringing the overwhelming power of LLMs. Specifically, VSP-LLM is designed to perform multi-tasks of visual speech recognition and translation, where the given instructions control the type of task. |
|[Repetition Improves Language Model Embeddings.](https://github.com/jakespringer/echo-embeddings) |We present echo embeddings, an embedding strategy designed to address an architectural limitation of autoregressive models: that token embeddings cannot contain information from tokens that appear later in the input. Echo embeddings resolve this issue by repeating the input twice in the input to the embedding model. Our method has strong performance on MTEB and is compatible with many other methods for improving embedding models. |
|[Range-Agnostic Multi-View Depth Estimation With Keyframe Selection.](https://andreaconti.github.io/projects/range_agnostic_multi_view_depth/) |Multi-View 3D reconstruction techniques process a set of source views and a reference view to yield an estimated depth map for the latter. |
|[ChatMusician: Understanding and Generating Music Intrinsically with LLM.](https://arxiv.org/abs/2402.16153) | Adding a modality-specific encoder to a language model is usually necessary for comprehending music. This is unstable and costly. This study demonstrated that tokenizing music into ABC notation significantly boosted music knowledge without affecting basic language proficiency. |
|[MegaScale: Scaling Large Language Model Training to More Than 10,000 GPUs.](https://arxiv.org/abs/2402.15627) | Bytedance has produced a system called MegaScale that can be used to train massively parallel large language models. It succeeded in training a 175B LLM on 12,288 GPUs with 55.2% Model FLOPs Utilization (MFU), which is extremely impressive. Bytedance plans to open source some aspects of the codebase. |
|[ListT5: Listwise Reranking with Fusion-in-Decoder Improves Zero-shot Retrieval.](https://arxiv.org/abs/2402.15838v1) |ListT5 presents a novel reranking technique that not only increases information retrieval precision but also provides a workable solution to the issues that earlier listwise rerankers encountered. |
|[MobiLlama: Towards Accurate and Lightweight Fully Transparent GPT.](https://github.com/mbzuai-oryx/MobiLlama) |  Our primary contribution is the introduction of an accurate and fully transparent open-source 0.5 billion (0.5B) parameter SLM, named MobiLlama, catering to the specific needs of resource-constrained computing with an emphasis on enhanced performance with reduced resource demands.  |
|[Accurate LoRA-Finetuning Quantization of LLMs via Information Retention.](https://arxiv.org/abs/2402.05445v1) |A novel method called IR-QLoRA improves quantized big language model accuracy, which makes them more appropriate for usage on low-resource devices. |
|[Video as the New Language for Real-World Decision Making.](https://arxiv.org/abs/2402.17139) |An incredible research that presents video as a possible improvement over current methods for AI to communicate with humans. It demonstrates the usage of video models as environment simulators, planners, agents, and computation engines. |
|[The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits.](https://arxiv.org/abs/2402.17764) |A parameter in the majority of language models is represented by 16 bits or more. This produces strong models that may be costly to operate. This study suggests a technique where each parameter is in {-1, 0, 1} and requires 1.58 bits. Performance is precisely matched by this approach up to 3B parameters. Models and code are not yet available. |
|[Q-Instruct: Improving Low-level Visual Abilities for Multi-modality Foundation Models.](https://arxiv.org/abs/2311.06783v1) |Enhancing multi-modality foundation models such as GPT-4V in low-level visual perception tasks is the main goal of this research. The extensive study collected comments on 18,973 photos from 58,000 people and produced the Q-Pathway dataset for brightness, color, and clarity analysis. |
|[Graph Diffusion Policy Optimization.](https://github.com/sail-sg/gdpo) | The primary objective of this work is to improve multi-modality foundation models, like GPT-4V, in low-level visual perception tasks. The comprehensive study created the Q-Pathway dataset for brightness, color, and clarity analysis by gathering feedback on 18,973 photographs from 58,000 users.|
|[HiGPT: Heterogeneous Graph Language Model.](https://higpt-hku.github.io/) |A method for learning across many heterogeneous graphs without requiring fine-tuning is called HiGPT. It excels at adapting to different data distributions thanks to its integration with a unique graph tokenizer and a large corpus of graph commands. |
|[PromptMM: Multi-Modal Knowledge Distillation for Recommendation with Prompt-Tuning.](https://arxiv.org/abs/2402.17188v1) |PromptMM uses Multi-modal Knowledge Distillation to enhance recommendation systems on sites like Amazon and TikTok. In order to avoid overfitting, it eliminates errors in user preferences and streamlines systems by extracting key characteristics from different kinds of content (textual, audio, or visual). |
|[Genie: Generative Interactive Environments.](https://sites.google.com/view/genie-2024/home) |We introduce Genie, a foundation world model trained from Internet videos that can generate an endless variety of playable (action-controllable) worlds from synthetic images, photographs, and even sketches. |
|[UniVS: Unified and Universal Video Segmentation with Prompts as Queries.](https://arxiv.org/abs/2402.18115) | With a unique prompt-based methodology, UniVS is a unified architecture for video segmentation that addresses the difficulties of diverse segmentation jobs. UniVS removes the requirement for heuristic inter-frame matching by utilizing prompt characteristics as queries and providing a target-wise prompt cross-attention layer. This allows UniVS to adapt to various video segmentation settings with ease.|
|[Coarse-to-Fine Latent Diffusion for Pose-Guided Person Image Synthesis.](https://arxiv.org/abs/2402.18078v1) | With a deep semantic knowledge of pictures, the Coarse-to-Fine Latent Diffusion (CFLD) method avoids overfitting and offers a novel Pose-Guided Person Image Synthesis technique that overcomes the drawbacks of previous models.|
|[Evaluating Quantized Large Language Models.](https://arxiv.org/abs/2402.18158v1) |Large language models like OPT and LLaMA2 can be rendered more compute- and memory-efficient through the use of post-training quantization. |
|[Representing 3D sparse map points and lines for camera relocalization.](https://thpjp.github.io/pl2map/) | With minimal memory and processing power, this study presents a novel method for 3D mapping and localization that processes both point and line information using a lightweight neural network, greatly improving pose accuracy.|
|[Driving into the Future: Multiview Visual Forecasting and Planning with World Model for Autonomous Driving.](https://drive-wm.github.io/) | Drive-WM can produce high-quality multiview films to forecast future events, allowing self-driving cars to make more intelligent and safe driving choices.|
|[Do Large Language Models Latently Perform Multi-Hop Reasoning?.](https://arxiv.org/abs/2402.16837) | |


## News
|Link|description|
|---|---|
|[Microsoft reportedly makes AI server gear to cut Nvidia dependence.](https://breakingthenews.net/Article/Microsoft-reportedly-makes-AI-server-gear-to-cut-Nvidia-dependence/61524303) | Microsoft is creating its own AI server hardware to intensify actions to decrease its dependency on Nvidia, according to a source familiar with the matter speaking to The Information.|
|[‘Embarrassing and wrong’: Google admits it lost control of image-generating AI.](https://techcrunch.com/2024/02/23/embarrassing-and-wrong-google-admits-it-lost-control-of-image-generating-ai/) | Google has apologized (or come very close to apologizing) for another embarrassing AI blunder this week, an image-generating model that injected diversity into pictures with a farcical disregard for historical context. While the underlying issue is perfectly understandable, Google blames the model for “becoming” oversensitive. |
|[Is OpenAI the next challenger trying to take on Google Search?](https://www.theverge.com/2024/2/14/24073320/is-openai-the-next-challenger-trying-to-take-on-google-search) | The Information says OpenAI is working on web search (partially powered by Bing) that would more directly compete with Google. It’s unclear if it would be standalone, or a part of ChatGPT.|
|[Transformer Circuits Thread - Updates - February 2024.](https://transformer-circuits.pub/2024/feb-update/index.html) | The research experts at Anthropic have been developing a Circuit-based approach to comprehend deep neural networks. These circuits seek to pinpoint model components that are employed in particular applications. Every month, the research team publishes an update on the trials they conducted and the 
|[A new tool targets voter fraud in Georgia – but is it skirting the law?.](https://www.theguardian.com/us-news/2024/feb/26/eagleai-georgia-voter-registration-election) |A tech company supported by Trump’s former lawyer is injecting chaos into the state’s vote-counting process |
|[Democratic political operative admits he commissioned robocall of AI Biden.](https://www.theguardian.com/us-news/2024/feb/26/steve-kramer-admits-he-commissioned-robocall-ai-biden-new-hampshire) |Steve Kramer said ‘easy-to-use technology’ enabled him to send automated call while New Orleans magician says he was paid $150 to make it |
|[Mistral Large.](https://mistral.ai/news/mistral-large/) |Mistral Large is our new cutting-edge text generation model. It reaches top-tier reasoning capabilities. It can be used for complex multilingual reasoning tasks, including text understanding, transformation, and code generation. Mistral Large achieves strong results on commonly used benchmarks, making it the world's second-ranked model generally available through an API (next to GPT-4) |
|[Scale AI to set the Pentagon’s path for testing and evaluating large language models .](https://defensescoop.com/2024/02/20/scale-ai-pentagon-testing-evaluating-large-language-models/) | The company will create a comprehensive T&E framework for generative AI within the Defense Department.|
|[DatologyAI is building tech to automatically curate AI training datasets.](https://techcrunch.com/2024/02/22/datologyai-is-building-tech-to-automatically-curate-ai-training-data-sets/) |Morcos’ company, DatologyAI, builds tooling to automatically curate datasets like those used to train OpenAI’s ChatGPT, Google’s Gemini and other like GenAI models. The platform can identify which data is most important depending on a model’s application (e.g. writing emails), Morcos claims, in addition to ways the dataset can be augmented with additional data and how it should be batched, or divided into more manageable chunks, during model training. |
|[Bay Bridge: A supercomputer built for startups.](https://sfcompute.com/blog/worlds-cheapest-supercomputer) | With flexible short-term renting options, San Francisco Compute Company is now providing the lowest-cost H100 training clusters in the world to customers who require intensive compute for AI model training but do not want to commit to long-term agreements. Its first cluster, Angel Island, is operational at the moment, and Bay Bridge will follow shortly. The unique business strategy of SF Compute places a premium on cost and accessibility for AI entrepreneurs without requiring long-term commitments.|
|[mlabonne/AlphaMonarch-7B.](https://huggingface.co/mlabonne/AlphaMonarch-7B) |AlphaMonarch-7B is a new DPO merge that retains all the reasoning abilities of the very best merges and significantly improves its conversational abilities. Kind of the best of both worlds in a 7B model. |
|[LazyAxolotl.](https://colab.research.google.com/drive/1TsDKNo2riwVmU55gjuBgB1AXVtRRfRHW) | This notebook allows you to fine-tune your LLMs using Axolotl and Runpod|
|[Apple’s electric car project is dead.](https://www.theverge.com/2024/2/27/24084907/apple-electric-car-project-titan-shuts-down) |After a decade of work, the company is reportedly giving up on its ambitious effort to create an autonomous electric car. |
|[Expressive Whole-Body Control for Humanoid Robots.](https://expressive-humanoid.github.io/) |UCSD researchers trained robust, socially-inclined, expressive policies for humanoid robots. Their unchoreographed dancing on grass videos are quite amazing. |
|[Meta plans launch of new AI language model Llama 3 in July, The Information reports.](https://www.reuters.com/technology/meta-plans-launch-new-ai-language-model-llama-3-july-information-reports-2024-02-28/) |Meta Platforms (META.O), opens new tab is planning to release the newest version of its artificial-intelligence large language model Llama 3 in July which would give better responses to contentious questions posed by users, The Information reported on Wednesday. |
|[Tim Cook Says Apple Will 'Break New Ground' in Generative AI.](https://www.macrumors.com/2024/02/28/tim-cook-apple-generative-ai-break-new-ground/) | Cook said that the company will "break new ground" in generative AI in 2024. "We believe it will unlock transformative opportunities for our users," said Cook.|
|[Elon Musk sues OpenAI accusing it of putting profit before humanity.](https://www.theguardian.com/technology/2024/mar/01/elon-musk-sues-open-ai-profit-power-microsoft-sam-altman) |Lawsuit says chief executive Sam Altman’s deal with Microsoft has broken organisation’s mission |
|[Figure raises $675M at $2.6B valuation.](https://twitter.com/Figure_robot/status/1763202496959521036?t=dkT4cm1ds_PCRErc8liWww&s=19) | In order to continue developing humanoid robots, Figure, a robotics startup, has secured $675 million from a number of significant investors, including OpenAI.|


## Resources
|Link|description|
|---|---|
|[Pearl - A Production-ready Reinforcement Learning AI Agent Library.](https://github.com/facebookresearch/pearl) | Pearl is a new production-ready Reinforcement Learning AI agent library open-sourced by the Applied Reinforcement Learning team at Meta. Pearl enables to develop Reinforcement Learning AI agents. |
|[Large Language Models for Data Annotation: A Survey.](https://github.com/zhen-tan-dmml/llm4annotation) | This is a curated list of papers about LLM for Annotation|
|[Automotive Object Detection with Spiking Neural Networks (SNNs).](https://github.com/aitor-martinez-seras/snn-automotive-object-detection) |One novel and effective model for autonomous cars is Spiking Neural Networks. High performance is attained using up to 85% less energy. |
|[Berkeley function calling leaderboard.](https://gorilla.cs.berkeley.edu/blogs/8_berkeley_function_calling_leaderboard.html) | When a language model can access resources through synthesized functions to carry out commands, this is known as function calling. To pass to such functions, the parameters must be properly synthesized. The purpose of this leaderboard is to evaluate the model's performance on function calling tasks.|
|[FuseChat.](https://github.com/fanqiwan/fusellm) |FuseChat is a novel approach to combine the advantages of many huge language models into a single, more potent model without having to pay expensive training fees again. |
|[ShieldLM .](https://github.com/thu-coai/ShieldLM) | ShieldLM is a bilingual (Chinese and English) safety detector that mainly aims to help to detect safety issues in LLMs' generations. It aligns with general human safety standards, supports fine-grained customizable detection rules, and provides explanations for its decisions.|
|[Enable decision making based on LLM-based simulations.](https://github.com/simulatrex/simulatrex-engine) | An open-source project called Simulatrex is dedicated to GABM, or generative agent-based modeling. Large language models are used to provide more accurate simulations.|
|[Training-Free Long-Context Scaling of Large Language Models.](https://github.com/hkunlp/chunkllama) |Dual chunk attention is a training-free and effective method for extending the context window of large language models (LLMs) to more than 8x times their original pre-training length. We refer to the Llama-based model with dual chunk attention as ChunkLlama. |
|[DPO to encourage descriptiveness.](A minimal code set up with TRL to tune a model to be more descriptive.) | https://gist.github.com/vwxyzjn/64d91ce0b66b0548f1d2c33e855d168c|
|[Shape suffixes for ML coding.](https://medium.com/@NoamShazeer/shape-suffixes-good-coding-style-f836e72e24fd) | The readable nature of shapes in tensors is significantly enhanced by a coding style at Character AI.|
|[Getting started with MAX Developer Edition.](https://www.modular.com/blog/getting-started-with-max-developer-edition) |To drastically reduce complexity and accelerate AI implementations, Modular developed the MAX toolset. It is currently accessible. |
|[Bonito.](https://github.com/batsresearch/bonito) |Bonito is an open-source model for conditional task generation: the task of converting unannotated text into task-specific training datasets for instruction tuning. This repo is a lightweight library for Bonito to easily create synthetic datasets built on top of the Hugging Face transformers and vllm libraries. |
|[Awesome-LLMs-for-Video-Understanding.](https://github.com/yunlong10/Awesome-LLMs-for-Video-Understanding) |A selection of helpful resources for comprehending videos with huge language models can be found in this repository. |
|[Mist text to speech.](https://rime.ai/blog/introducing-mist) |A new text-to-speech technology called Rime has strong conversational capabilities. This model may incorporate "ums" and realistic pauses, in contrast to earlier ones. |
|[Add your own Ollama models.](https://github.com/ollama/ollama/blob/main/docs/import.md) |guidelines for contributing your own models to the Ollama repository for public usage. |
|[2x speed up HF inference with static KV Cache.](https://gist.github.com/ArthurZucker/af34221def212259b43d55a2811d2dbb) | Increased inference speed can lead to new use cases. This code proposes a method to accelerate Hugging Face inference using Llama models.|


## Perspectives
|Link|description|
|---|---|
|[Sam Altman Wants $7 Trillion.](https://www.astralcodexten.com/p/sam-altman-wants-7-trillion) |In order to meet the fast rising costs of developing generative AI models such as GPT, Sam Altman has proposed a $7 trillion budget, indicating an exponential increase in resources required for further iterations. This goal highlights a critical juncture in the development of AI, striking a balance between the quickening pace of scientific improvement and its wider effects on safety and societal preparedness. |
|[Ten AI Insights from Databricks, Anyscale, and Microsoft.](https://foundationcapital.com/ten-ai-insights-from-databricks-anyscale-and-microsoft/) |This article features interviews with founders of AI-forward firms, including their perspectives on the emergence of artificial intelligence (AGI), how to approach LLMs, and basic strategies for entrepreneurs integrating AI into their products. |
|[What the EU’s tough AI law means for research and ChatGPT.](https://www.nature.com/articles/d41586-024-00497-8) |The EU AI Act is the world’s first major legislation on artificial intelligence and strictly regulates general-purpose models. |
|[Online images amplify gender bias.](https://www.nature.com/articles/s41586-024-07068-x) |We find that gender bias is consistently more prevalent in images than text for both female- and male-typed categories. We also show that the documented underrepresentation of women online is substantially worse in images than in text, public opinion and US census data. |
|[ChunkLlama.](https://github.com/hkunlp/chunkllama) |Dual chunk attention is a training-free and effective method for extending the context window of large language models (LLMs) to more than 8x times their original pre-training length. We refer to the Llama-based model with dual chunk attention as ChunkLlama.  |
|[distilabel.](https://github.com/argilla-io/distilabel) | AI Feedback (AIF) framework for building datasets with and for LLMs.|
|[StarCoder2.](https://huggingface.co/bigcode/starcoder2-15b) |StarCoder2-15B model is a 15B parameter model trained on 600+ programming languages from The Stack v2, with opt-out requests excluded. |
|[The paradox of diffusion distillation.](https://sander.ai/2024/02/28/paradox.html) |Diffusion models decompose complex issues, such as image production, into numerous smaller issues, such as minimizing a little amount of noise in an image. Single step diffusion generation has received a lot of attention, however it appears to miss the mark. This article examines the diffusion distillation conundrum and lists the various avenues of inquiry that might be pursued. |

# ML news: Week 19 - 25 February

## Research
|Link|description|
|---|---|
|[Long Is More for Alignment: A Simple but Tough-to-Beat Baseline for Instruction Fine-Tuning.](https://arxiv.org/abs/2402.04833) | Deciding which examples to employ when aligning language models with preference data is frequently difficult. This paper proposes an unexpectedly strong baseline: pick the 1,000 longest cases.|
|[Extreme Video Compression with Pre-trained Diffusion Models.](https://arxiv.org/abs/2402.08934v1) |As diffusion models get more adept in synthesizing pictures and videos, they may be used for other purposes due to their extensive "knowledge" of the world. This study discovered an astounding 0.02 bits per pixel reduction. The secret here was to track perceptual similarities along the route and deliver a new frame of the original movie as necessary. |
|[OpenMathInstruct-1: A 1.8 Million Math Instruction Tuning Dataset.](https://arxiv.org/abs/2402.10176v1) |In order to train open-source Large Language Models in math that equal the performance of closed-source models, researchers have developed a new dataset called OpenMathInstruct-1. With 1.8 million problem-solution pairings, this innovation paves the way for more competitive and approachable AI systems for math teaching. |
|[KVQuant: Towards 10 Million Context Length LLM Inference with KV Cache Quantization.](https://arxiv.org/abs/2401.18079) | A feature of the Transformer design that allows it to consume less memory at inference time is the quantization of the KV cache. The process of decreasing floating point accuracy with the least amount of quality loss is called quantization. |
|[Pushing the Limits of Zero-shot End-to-End Speech Translation.](https://arxiv.org/abs/2402.10422v1) | ZeroSwot is a novel approach to voice Translation (ST) that addresses the data scarcity and distinctions between text and voice. It may operate with a multilingual translation model by using special strategies to train a voice encoder using only speech recognition data.|
|[Interpreting CLIP with Sparse Linear Concept Embeddings (SpLiCE).](https://arxiv.org/abs/2402.10376v1) |A novel technique called SpLiCE simplifies the complicated visual data in CLIP. |
|[TDViT: Temporal Dilated Video Transformer for Dense Video Tasks.](https://arxiv.org/abs/2402.09257v1) | A novel Temporal Dilated Video Transformer (TDViT) has been created to enhance the analysis of tasks involving dense videos, like object detection in videos frame by frame.|
|[Generative Representational Instruction Tuning.](https://arxiv.org/abs/2402.09906) | A model that creates embeddings and text has been trained and released by the Contextual team. It performs noticeably better than a single specialized model. With an embedding as the output modality, the model offers an intriguing interpretation of the multi-modal trend. |
|[LoRA+: Efficient Low Rank Adaptation of Large Models.](https://arxiv.org/abs/2402.12354v1) | In order to improve on the current Low-Rank Adaptation (LoRA) technique for fine-tuning big models, this work introduces LoRA+. By applying multiple learning rates for important process components, LoRA+ achieves improved performance and faster fine-tuning without raising processing loads.|
|[GaussianObject: Just Taking Four Images to Get A High-Quality 3D Object with Gaussian Splatting.](https://github.com/GaussianObject/GaussianObject) |We propose GaussianObject, a framework to represent and render the 3D object with Gaussian splatting, that achieves high rendering quality with only 4 input images. |
|[MVDiffusion++: A Dense High-resolution Multi-view Diffusion Model for Single to Sparse-view 3D Object Reconstruction.](https://mvdiffusion-plusplus.github.io/) |This paper presents a neural architecture MVDiffusion++ for 3D object reconstruction that synthesizes dense and high-resolution views of an object given one or a few images without camera poses.  |
|[ChatterBox: Multi-round Multimodal Referring and Grounding.](https://github.com/sunsmarterjie/chatterbox) |A vision-language model called ChatterBox performs exceptionally well in multimodal dialogues, particularly in the recently defined job of multimodal multi-round referring and grounding. |
|[Large language models streamline automated machine learning for clinical studies.](https://www.nature.com/articles/s41467-024-45879-8) |A knowledge gap persists between machine learning developers and clinicians. Here, the authors show that the Advanced Data Analysis extension of ChatGPT could bridge this gap and simplify complex data analyses, making them more accessible to clinicians.|
|[Extracting accurate materials data from research papers with conversational language models and prompt engineering.](https://www.nature.com/articles/s41467-024-45914-8) | Efficient data extraction from research papers accelerates science and engineering. Here, the authors develop an automated approach which uses conversational large language models to achieve high precision and recall in extracting materials data.|
|[GradSafe: Detecting Unsafe Prompts for LLMs via Safety-Critical Gradient Analysis.](https://arxiv.org/abs/2402.13494v1) | GradSafe is a novel technique that can identify dangerous prompts in big language models without requiring a lot of training. Compared to existing approaches, it can identify dangerous prompts more accurately by examining the gradients of certain parameters.|
|[Class-Aware Mask-Guided Feature Refinement for Scene Text Recognition.](https://arxiv.org/abs/2402.13643v1) |A novel technique called Class-Aware Mask-guided (CAM) feature refinement improves text recognition in challenging environments. |
|[Object Recognition as Next Token Prediction.](https://github.com/kaiyuyue/nxtp) |an innovative approach to object recognition that makes use of a language decoder. With this approach, text tokens are predicted from picture embeddings by using a customized non-causal attention mask. It makes it possible to sample many labels in parallel effectively. |
|[TIER: Text and Image Encoder-based Regression for AIGC Image Quality Assessment.](https://arxiv.org/abs/2401.03854v1) | To evaluate the quality of the generated images, TIER makes use of both written prompts and the images that result from them. |


## News
|Link|description|
|---|---|
|[Anthropic takes steps to prevent election misinformation.](https://techcrunch.com/2024/02/16/anthropic-takes-steps-to-prevent-election-misinformation/) | Called Prompt Shield, the technology, which relies on a combination of AI detection models and rules, shows a pop-up if a U.S.-based user of Claude, Anthropic’s chatbot, asks for voting information. The pop-up offers to redirect the user to TurboVote, a resource from the nonpartisan organization Democracy Works, where they can find up-to-date, accurate voting information.|
|[OpenAI's next AI product could be after your job (again).](https://www.androidauthority.com/openai-ai-agent-coming-soon-3412336/) | OpenAI is said to be developing AI agents that automate even more complex tasks, though their launch timeline remains unknown. One AI agent is said to take over the customer’s device to perform tasks like transferring data from a document to a spreadsheet, filling out expense reports, and entering them into accounting software. The other AI agent is said to perform more research-oriented, web-based tasks, such as creating itineraries and booking flight tickets.|
|[Our next-generation model: Gemini 1.5.](https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/) |  In fact, we’re ready to introduce the next generation: Gemini 1.5. It shows dramatic improvements across a number of dimensions and 1.5 Pro achieves comparable quality to 1.0 Ultra, while using less compute.|
|[OpenAI on track to hit $2bn revenue milestone as growth rockets.](https://www.ft.com/content/81ac0e78-5b9b-43c2-b135-d11c47480119) | Thanks in large part to ChatGPT's enormous success, OpenAI has reached an annual revenue run rate of over $2 billion, making it one of the fastest-growing tech companies.|
|[Sam Altman wants Washington's backing for his $7 trillion AI chip venture.](https://www.businessinsider.com/sam-altman-wants-government-backing-7-trillion-ai-chip-venture-2024-2) |The OpenAI CEO is working to secure US government approval for the project as it risks raising national security and antitrust concerns, Bloomberg reported. |
|[‘Gemini Business’ and ‘Gemini Enterprise’ plans for Google Workspace are coming.](https://9to5google.com/2024/02/19/gemini-business-enterprise/) | The upcoming changelog — as spotted by Testing Catalog and Dylan Roussel on X/Twitter today — reveals the existence of “Gemini Business” and “Gemini Enterprise” plans. This will give “Google Workspace customers access to one of Google’s most capable Al models, 1.0 Ultra in Gemini and enterprise-grade data protections.”|
|[OpenAI Reaches $80 Billion Valuation In Venture Firm Deal, Report Says.](https://www.forbes.com/sites/antoniopequenoiv/2024/02/16/openai-reaches-80-billion-valuation-in-venture-firm-deal-report-says) |OpenAI inked a deal with venture capital firm Thrive Capital that boosted its valuation to $80 billion or more, the New York Times reported, a nearly threefold increase in value from just nine months ago.|
|[Magic raises $117m to continue code generation models.](https://x.com/magicailabs/status/1758140204446323188?s=20) |We've raised $117M  to build an AI software engineer. |
|[SoftBank Founder Masayoshi Son Aims to Raise $100 Billion for New Chip Venture, "Izanagi".](https://www.msn.com/en-us/money/companies/softbank-founder-masayoshi-son-aims-to-raise-100-billion-for-new-chip-venture-izanagi/ar-BB1iq42h) |Masayoshi Son, the visionary founder of SoftBank Group Corp., has set his sights on revolutionizing the semiconductor industry with the launch of Izanagi, a groundbreaking chip venture backed by a staggering $100 billion investment. |
|[Scribe $25M Series B.](https://scribehow.com/library/series-b-announcement) | To further its AI-driven platform, Scribe has secured a Series B fundraising round headed by Redpoint Ventures. This round aims to speed up the generation of visual step-by-step tutorials and enable knowledge exchange between enterprises.  |
|[Amazon AGI Team Say Their AI Is Showing “Emergent Abilities”.](https://futurism.com/the-byte/amazon-researchers-ai-emergent) | "Big Adaptive Streamable TTS with Emergent Abilities" (BASE TTS), a language model created by Amazon AGI researchers, exhibits "state-of-the-art naturalness" in conversational text and demonstrates language skills that it wasn't particularly trained on.|
|[Gemma: Introducing new state-of-the-art open models.](https://blog.google/technology/developers/gemma-open-models/) | We’re releasing model weights in two sizes: Gemma 2B and Gemma 7B. Each size is released with pre-trained and instruction-tuned variants. Ready-to-use Colab and Kaggle notebooks, alongside integration with popular tools such as Hugging Face, MaxText, NVIDIA NeMo and TensorRT-LLM, make it easy to get started with Gemma.|
|[Reddit has a new AI training deal to sell user content.](https://www.theverge.com/2024/2/17/24075670/reddit-ai-training-license-deal-user-content) |Over a decade of valuable user content is now for sale as Reddit preps to go public. |
|[Apple Developing AI Tool to Help Developers Write Code for Apps.](https://www.macrumors.com/2024/02/15/apple-xcode-ai-tool-for-coding/) | Apple is working on an updated version of Xcode that will include an AI tool for generating code, reports Bloomberg. The AI tool will be similar to GitHub Copilot from Microsoft, which can generate code based on natural language requests and convert code from one programming language to another.|
|[Stable Diffusion 3.](https://stability.ai/news/stable-diffusion-3) |Announcing Stable Diffusion 3 in early preview, our most capable text-to-image model with greatly improved performance in multi-subject prompts, image quality, and spelling abilities. |
|[How Bret Taylor’s new company is rethinking customer experience in the age of AI.](https://techcrunch.com/2024/02/19/sierra-ai-agents-customer-service/) |he two founders fundamentally see AI agents as a new technology category, providing an entirely new way for customers to interact with brands to improve their overall experience. |
|[Introducing Phind-70B – closing the code quality gap with GPT-4 Turbo while running 4x faster.](https://www.phind.com/blog/introducing-phind-70b) | We're excited to announce Phind-70B, our largest and most performant model to date. Running at up to 80 tokens per second, Phind-70B gives high-quality answers for technical topics without making users make a cup of coffee while they wait. Phind-70B scores 82.3% on HumanEval, beating the latest GPT-4 Turbo (gpt-4-0125-preview) score of 81.1% in our evaluation.  |
|[Marqo Raises $12.5 Million to Help Businesses Build Generative AI Applications.](https://www.pymnts.com/news/investment-tracker/2024/marqo-raises-12-5-million-to-help-businesses-build-generative-ai-applications/) |Marqo has raised $12.5 million in a Series A funding round to advance the adoption of its search platform that helps businesses build generative artificial intelligence (AI) applications that are more relevant and up to date. |

## Resources
|Link|description|
|---|---|
|[minbpe.](https://github.com/karpathy/minbpe) |Minimal, clean code for the (byte-level) Byte Pair Encoding (BPE) algorithm commonly used in LLM tokenization. The BPE algorithm is "byte-level" because it runs on UTF-8 encoded strings. |
|[GPTScript.](https://github.com/gptscript-ai/gptscript) |GPTScript is a new scripting language to automate your interaction with a Large Language Model (LLM), namely OpenAI. The ultimate goal is to create a fully natural language based programming experience. The syntax of GPTScript is largely natural language, making it very easy to learn and use. |
|[QWEN.](https://github.com/QwenLM/Qwen) | We opensource our Qwen series, now including Qwen, the base language models, namely Qwen-1.8B, Qwen-7B, Qwen-14B, and Qwen-72B, as well as Qwen-Chat, the chat models, namely Qwen-1.8B-Chat, Qwen-7B-Chat, Qwen-14B-Chat, and Qwen-72B-Chat. |
|[Sora Reference Papers.](https://huggingface.co/collections/fffiloni/sora-reference-papers-65d0c8d4891646a27b84c4a8) |A collection of all papers referenced in OpenAI's "Video generation models as world simulators" |
|[repeng.](https://github.com/vgel/repeng/) |Control vectors are a low-cost means of controlling the output of semantic generation. Compared to LoRA, they are less expensive to train yet may still be fairly powerful. It's made simpler with this library. |
|[OpenRLHF.](https://github.com/OpenLLMAI/OpenRLHF) | This is a Ray-based implementation of RLHF for Mistral and other Llama-style models. Several PPO stabilizing techniques are included to enhance performance. |
|[3D Diffuser Actor: Policy Diffusion with 3D Scene Representations.](https://github.com/nickgkan/3d_diffuser_actor) |To enhance robot manipulation, the 3D Diffuser Actor blends 3D scene representations with diffusion strategies. Robots are better able to comprehend and engage with their surroundings thanks to this AI-driven method. |
|[How to jointly tune learning rate and weight decay for AdamW.](https://fabian-sp.github.io/posts/2024/02/decoupling/) |AdamW is often considered a method that decouples weight decay and learning rate. In this blog post, we show that this is not true for the specific way AdamW is implemented in Pytorch. We also show how to adapt the tuning strategy in order to fix this: when doubling the learning rate, the weight decay should be halved. |
|[OpenLLMetry-JS.](https://github.com/traceloop/openllmetry-js) | OpenLLMetry-JS is a set of extensions built on top of OpenTelemetry that gives you complete observability over your LLM application. Because it uses OpenTelemetry under the hood, it can be connected to your existing observability solutions - Datadog, Honeycomb, and others.|
|[List of GPU clusters for rent.](https://gpulist.ai/) |a list of entire clusters that can be rented on an hourly basis. |
|[Mamba: The Hard Way.](https://srush.github.io/annotated-mamba/hard.html) | A detailed description of how Mamba works |
|[new benchmark for large language models.](https://nicholas.carlini.com/writing/2024/my-benchmark-for-large-language-models.html) |It's a collection of nearly 100 tests I've extracted from my actual conversation history with various LLMs. |
|[BoCoEL.](https://github.com/rentruewang/bocoel) |Bayesian Optimization as a Coverage Tool for Evaluating LLMs. Accurate evaluation (benchmarking) that's 10 times faster with just a few lines of modular code. |
|[FiT: Flexible Vision Transformer for Diffusion Model.](https://github.com/whlzy/fit) | This repo contains PyTorch model definitions, pre-trained weights and sampling code for our flexible vision transformer (FiT). FiT is a diffusion transformer based model which can generate images at unrestricted resolutions and aspect ratios.|
|[RobustVLM.](https://github.com/chs20/robustvlm) | In order to defend multi-modal models like OpenFlamingo and LLaVA against visual adversarial assaults, a novel technique is presented in this study. The authors successfully defend these models against manipulative picture assaults by fine-tuning the CLIP visual encoder in an unsupervised way, increasing the models' dependability and security in practical applications without requiring a complete model retraining.|
|[HELM Instruct: A Multidimensional Instruction Following Evaluation Framework with Absolute Ratings.](https://crfm.stanford.edu/2024/02/18/helm-instruct.html) | A popular benchmark called Holistic Evaluation of Language Models (HELM) was issued by the Stanford language modeling group. Additionally, they created HELM-Instruct, a version for instruction following. It is absolute, open-ended, and multifaceted.|
|[LoRA Land: Fine-Tuned Open-Source LLMs that Outperform GPT-4.](https://predibase.com/blog/lora-land-fine-tuned-open-source-llms-that-outperform-gpt-4) | We’re excited to release LoRA Land, a collection of 25 fine-tuned Mistral-7b models that consistently outperform base models by 70% and GPT-4 by 4-15%, depending on the task. This collection of specialized fine-tuned models–all trained with the same base model–offers a blueprint for teams seeking to efficiently and cost-effectively deploy highly performant AI systems.|
|[Multimodal LLM’s Ability to Understand Visual Data.](https://github.com/unimodal4reasoning/chartvlm) | A new tool called ChartX is designed to assess how well multi-modal large language models (MLLMs) can understand and make sense of visual charts.|
|[A Critical Evaluation of AI Feedback for Aligning Language Models.](https://github.com/architsharma97/dpo-rlaif) |The efficacy of integrating reinforcement learning with supervised fine-tuning in training is questioned in this repository. The more involved two-step technique can be outperformed by first training with a more sophisticated model, such as GPT-4. |
|[MMCSG Dataset.](https://ai.meta.com/datasets/mmcsg-dataset/) | The MMCSG (Multi-Modal Conversations in Smart Glasses) dataset comprises two-sided conversations recorded using Aria glasses, featuring multi-modal data such as multi-channel audio, video, accelerometer, and gyroscope measurements. This dataset is suitable for research in areas like automatic speech recognition, activity detection, and speaker diarization.|
|[MultiLora inference server.](https://github.com/predibase/lorax) |One base model can have many LoRAs hot-swapped onto it using the Lorax inference server. This allows a large variety of model tunes to be supported with a significant reduction in RAM use. |
|[GTBench: Uncovering the Strategic Reasoning Limitations of LLMs via Game-Theoretic Evaluations.](https://github.com/jinhaoduan/gtbench) | GTBench is a language-driven environment, evaluating the strategic reasoning limitations of LLMs through game-theoretic tasks. GTBench is built on top of OpenSpiel, supporting 10 widely-recognized games|
|[CrewAI.](https://blog.replit.com/crew-ai) |A library called CrewAI is available for creating and managing AI agents that make use of Replit and LangChain. It offers an easy-to-integrate modular setup comprising tasks, agents, crews, and tools for a variety of applications. LangSmith improves performance insights into non-deterministic LLM calls while streamlining the debugging process. |
|[gemma.cpp.](https://github.com/google/gemma.cpp) | gemma.cpp is a lightweight, standalone C++ inference engine for the Gemma foundation models from Google.|
|[MMedLM.](https://github.com/magic-ai4med/mmedlm) | The official codes for "Towards Building Multilingual Language Model for Medicine".|
|[LLM Evaluation Metrics for Labeled Data.](https://docs.parea.ai/blog/llm-eval-metrics-for-labeled-data) |How to measure the performance of LLM applications with ground truth data. |


## Perspectives
|Link|description|
|---|---|
|[The data revolution in venture capital.](https://www.signatureblock.co/articles/the-data-revolution-in-venture-capital) |Investors, data scientists, and tool builders leading the data-driven future of venture capital. |
|[The Three C's: Creativity, Collaboration, and Communication.](https://www.digitalnative.tech/p/the-three-cs-creativity-collaboration) | The way we communicate, work together, and complete creative projects has changed significantly since the invention of computing. With AI, we're beginning to witness the commencement of another significant change. We undervalue how significant this change will be. Businesses that integrate artificial intelligence (AI) into their products from the start will have a significant edge over those who add it later to already-existing goods.|
|[Inside OpenAI Logan Kilpatrick (head of developer relations).](https://www.lennyspodcast.com/inside-openai-logan-kilpatrick-head-of-developer-relations/) | Have you ever wondered how OpenAI develops and innovates so quickly? The head of developer relations at OpenAI, Logan Kilpatrick, talks about the company's decision-making structure for product launches, high agency and urgency, and OpenAI's distinct culture in this podcast.|
|[Mind-reading devices are revealing the brain’s secrets.](https://www.nature.com/articles/d41586-024-00481-2) |Implants and other technologies that decode neural activity can restore people’s abilities to move and speak — and help researchers to understand how the brain works. |
|[Generative AI’s environmental costs are soaring — and mostly secret.](https://www.nature.com/articles/d41586-024-00478-x) | First-of-its-kind US bill would address the environmental costs of the technology, but there’s a long way to go.|
|[Strategies for an Accelerating Future.](https://www.oneusefulthing.org/p/strategies-for-an-accelerating-future) | With Google's Gemini providing a context window of over a million tokens and Groq's hardware enabling almost instantaneous responses from GPT-3.5 models, among other recent advancements in AI, these represent a significant advancement in practical AI applications and highlight the pressing need for leaders to comprehend and adjust to the rapidly changing AI landscape.|
|[How to lose at Generative AI!](https://medium.com/@sanguit/how-to-lose-at-generative-ai-2e6e6c20fecf) |Despite its excitement, generative AI is likely to let most startups down since it benefits established players with data advantages, established workflows, and the capacity to integrate AI without requiring significant system changes. A difficult road lies ahead for startups hoping to make a significant impact in the Generative AI space, even in spite of venture capital flooding the space. These startups are essentially preparing the market for incumbents who can readily adopt and integrate AI innovations into their dominant platforms by concentrating on expeditious engineering and UX improvements at the workflow layer. |
|[Stockholm declaration on AI ethics: why others should sign.](https://www.nature.com/articles/d41586-024-00517-7) |The use of artificial intelligence (AI) in science has potential to do both harm and good. As a step towards preventing the harms, we have prepared the Stockholm Declaration on AI for Science.  |
|[This is why the idea that AI will just augment jobs, never replace them, is a lie!.](https://donaldclarkplanb.blogspot.com/2024/02/this-is-why-idea-that-ai-will-just.html) |AI will automate labor in certain areas. The response thus far has been divided: would increased efficiency allow for more human workers to accomplish the same duties, or will fewer workers be needed? This article compares and contrasts the effects of technology on manufacturing, agriculture, and the contemporary knowledge worker. |
|[LLM evaluation at scale with the NeurIPS Large Language Model Efficiency Challenge.](https://blog.mozilla.ai/exploring-llm-evaluation-at-scale-with-the-neurips-large-language-model-efficiency-challenge/) |‍After a year of breakneck innovation and hype in the AI space, we have now moved sufficiently beyond the peak of the hype cycle to start asking a critical question: are LLMs good enough yet to solve all of the business and societal challenges we are setting them up for? |

# ML news: Week 12 - 18 February

## Research
|Link|description|
|---|---|
|[Skill Set Optimization: Reinforcing Language Model Behavior via Transferable Skills.](https://allenai.github.io/sso/) |It has so far proven difficult to transfer expertise amongst RL agents. An environment-neutral skill set is optimized for in this work. Its generalization performance is encouraging. |
|[Self-Play Fine-Tuning (SPIN).](https://github.com/uclaml/SPIN) |We propose a new fine-tuning method called Self-Play fIne-tuNing (SPIN), which starts from a supervised fine-tuned model. At the heart of SPIN lies a self-play mechanism, where the LLM refines its capability by playing against instances of itself. More specifically, the LLM generates its own training data from its previous iterations, refining its policy by discerning these self-generated responses from those obtained from human-annotated data. |
|[Real-World Fluid Directed Rigid Body Control via Deep Reinforcement Learning.](https://arxiv.org/abs/2402.06102) |"Box o Flows" addresses the difficulty of replicating complicated fluid dynamics for reinforcement learning (RL) applications by introducing a unique experimental system for testing RL algorithms in dynamic real-world environments. It demonstrates how model-free reinforcement learning algorithms may produce complex behaviors from simple rewards, improve data efficiency through offline reinforcement learning, and open the door to more widespread RL use in complex systems. |
|[WebLINX.](https://mcgill-nlp.github.io/weblinx/) |A collection of 100,000 web-based conversations in conversational format is called Weblinx. It was made available to advance research on web-based navigation guided by language models. |
|[ImplicitDeepfake: Plausible Face-Swapping through Implicit Deepfake Generation using NeRF and Gaussian Splatting.](https://arxiv.org/abs/2402.06390v1) | In order to produce incredibly lifelike 3D avatars, this work presents ImplicitDeepfake1, a novel method that blends deepfake technology with Gaussian Splatting (GS) and Neural Radiance Fields (NeRFs).|
|[AutoMathText: Autonomous Data Selection with Language Models for Mathematical Texts.](https://arxiv.org/abs/2402.07625v1) | Researchers have created a novel method to improve language models' mathematical proficiency by letting base models choose excellent mathematical information on their own.|
|[Complete Instances Mining for Weakly Supervised Instance Segmentation.](https://arxiv.org/abs/2402.07633v1) | A novel method for image segmentation has been presented by researchers that uses just simple image labels to identify particular portions of a picture, such as a dog. They overcame the difficulty of a network identifying many occurrences of the same object by presenting an innovative technique that improves efficiency and lowers mistake rates.|
|[Whispers in the Machine: Confidentiality in LLM-integrated Systems.](https://arxiv.org/abs/2402.06922v1) | The increased pairing of huge language models with external technologies has given rise to new vulnerabilities associated with data breaches. This research offers a methodical way to assess various AI systems' privacy protection efficacy.|
|[This AI learnt language by seeing the world through a baby’s eyes.](https://www.nature.com/articles/d41586-024-00288-1) | An artificial intelligence (AI) model has learnt to recognize words such as ‘crib’ and ‘ball’, by studying headcam recordings of a tiny fraction of a single baby’s life. [original article.](https://www.science.org/doi/10.1126/science.adi1374)|
|[World Model on Million-Length Video and Language with RingAttention.](https://largeworldmodel.github.io/) |This model can correctly respond to queries with a million token video duration using ring attention and an optimized 7B parameter model. It performs exceptionally accurately on retrieval benchmarks and beats commercial VLMs. |
|[LUMIERE - A Space-Time Diffusion Model for Video Generation.](https://lumiere-video.github.io/) | A new text-to-video model from Google can assist in accepting input in the form of images and styles. It diffuses everything simultaneously via a brand-new "space-time UNet." |
|[SEINE: Short-to-Long Video Diffusion Model for Generative Transition and Prediction.](https://vchitect.github.io/SEINE-project/) | With the help of textual descriptions, SEINE is a novel video diffusion model that can expand short AI-generated video clips into larger, narrative-level segments with smooth and creative scene transitions.|
|[Text-Driven Image Editing via Learnable Regions.](https://yuanze-lin.me/LearnableRegions_page/) |Given an input image and a language description for editing, our method can generate realistic and relevant images without the need for user-specified regions for editing. It performs local image editing while preserving the image context. Our method can also handle multiple-object and long-paragraph scenarios. |
|[Video annotator.](https://github.com/netflix/videoannotator) |The annotation process directly incorporates subject experts thanks to the Video Annotator framework. This novel method increases the accuracy and efficiency of the model by combining human expertise with zero-shot and active learning techniques. |
|[Automated Unit Test Improvement using Large Language Models at Meta.](https://arxiv.org/abs/2402.09171) |Meta created tests for its code base using massive language models. It discovered significant gains in overall code quality and test coverage. |
|[Meta’s V-JEPA model.](https://ai.meta.com/blog/v-jepa-yann-lecun-ai-model-video-joint-embedding-predictive-architecture/?) |According to Yann LeCun, VP and Chief AI Scientist at Meta, more data-efficient self-supervised models are required for general intelligence. This approach, which uses models trained on video to comprehend parts of the world, is a first step in that direction. The models can be accessed by the general public. |
|[Extreme Video Compression with Pre-trained Diffusion Models.](https://arxiv.org/abs/2402.08934v1) |Diffusion models have been used by researchers to create a novel video compression technique that produces high-quality video frames at low data rates. |


## News
|Link|description|
|---|---|
|[Laion releases assistant BUD-E.](https://laion.ai/blog/bud-e/) | An open assistant that runs on a gaming laptop and utilizes highly optimized language models and natural voice has been made available by the Laion research group. The project's goal is to offer a capable, low-resource personal assistant that is simple to deploy.|
|[OpenAI Hits $2 Billion Revenue Milestone.](https://money.usnews.com/investing/news/articles/2024-02-09/openai-hits-2-billion-revenue-milestone-ft) |Microsoft-backed OpenAI hit the $2 billion revenue milestone in December. The company's annualized revenue topped $1.6 billion in December based on strong growth from its ChatGPT product, up from $1.3 billion as of mid-October, the Information had reported previously. |
|[AI PCs will make up nearly 60% of total PC shipments by 2027.](https://www.techspot.com/news/101818-ai-capable-pcs-make-up-nearly-60-total.html) |Demand for AI PCs to start ramping up this year |
|[The first human received an implant from 
@Neuralink
 yesterday and is recovering well.](https://twitter.com/elonmusk/status/1752098683024220632) |Initial results show promising neuron spike detection. |
|[Reka Flash: An Efficient and Capable Multimodal Language Model.](https://reka.ai/reka-flash-an-efficient-and-capable-multimodal-language-model/?) |Reka Flash is a state-of-the-art 21B model trained entirely from scratch and pushed to its absolute limits. It serves as the “turbo-class” offering in our lineup of models. Reka Flash rivals the performance of many significantly larger models, making it an excellent choice for fast workloads that require high quality. On a myriad of language and vision benchmarks, it is competitive with Gemini Pro and GPT-3.5. |
|[Apple releases ‘MGIE’, a revolutionary AI model for instruction-based image editing.](https://venturebeat.com/ai/apple-releases-mgie-a-revolutionary-ai-model-for-instruction-based-image-editing/) | Apple has released a new open-source AI model, called “MGIE,” that can edit images based on natural language instructions. MGIE, which stands for MLLM-Guided Image Editing, leverages multimodal large language models (MLLMs) to interpret user commands and perform pixel-level manipulations. The model can handle various editing aspects, such as Photoshop-style modification, global photo optimization, and local editing.|
|[DeepMind framework offers breakthrough in LLMs’ reasoning.](https://www.artificialintelligence-news.com/2024/02/08/deepmind-framework-offers-breakthrough-llm-reasoning) | A breakthrough approach in enhancing the reasoning abilities of large language models (LLMs) has been unveiled by researchers from Google DeepMind and the University of Southern California. Their new ‘SELF-DISCOVER’ prompting framework – published this week on arXiV and Hugging Face – represents a significant leap beyond existing techniques, potentially revolutionising the performance of leading models such as OpenAI’s GPT-4 and Google’s PaLM 2.|
|[Meta will start detecting and labeling AI-generated images from other companies.](https://www.techspot.com/news/101779-meta-start-detecting-labeling-ai-generated-images-other.html) | The feature will arrive on Facebook, Instagram, and Threads in the coming months|
|[Stability and Wurstchen release new text to image model.](https://stability.ai/news/introducing-stable-cascade) |a new text to image model building upon the Würstchen architecture. Stable Cascade is exceptionally easy to train and finetune on consumer hardware thanks to its three-stage approach. In addition to providing checkpoints and inference scripts, we are releasing scripts for finetuning, ControlNet, and LoRA training to enable users further to experiment with this new architecture that can be found on [the Stability GitHub page](https://github.com/Stability-AI/StableCascade).|
|[Memory and new controls for ChatGPT.](https://openai.com/blog/memory-and-new-controls-for-chatgpt) |OpenAI is testing a new feature that allows ChatGPT to remember facts across conversations. This can be switched off if desired. It will allow for a higher measure of personalization when interacting with the chat system. |
|[Report: Sam Altman seeking trillions for AI chip fabrication from UAE, others.](https://arstechnica.com/information-technology/2024/02/report-sam-altman-seeking-trillions-for-ai-chip-fabrication-from-uae-others) | On Thursday, The Wall Street Journal reported that OpenAI CEO Sam Altman is in talks with investors to raise as much as $5 trillion to $7 trillion for AI chip manufacturing, according to people familiar with the matter. The funding seeks to address the scarcity of graphics processing units (GPUs) crucial for training and running large language models like those that power ChatGPT, Microsoft Copilot, and Google Gemini.|
|[Meta to deploy in-house custom chips this year to power AI drive.](https://finance.yahoo.com/news/exclusive-meta-deploy-house-custom-161945182.html) | acebook owner Meta Platforms plans to deploy into its data centers this year a new version of a custom chip aimed at supporting its artificial intelligence (AI) push, according to an internal company document seen by Reuters on Thursday.|
|[Google Launches €25 Million AI Opportunity Initiative for Skills Training Across Europe.](https://www.maginative.com/article/google-launches-eu25-million-ai-opportunity-initiative-for-skills-training-across-europe/) | |
|[The brain area that lights up in prickly people.](https://www.nature.com/articles/d41586-024-00318-y) |Those who are quick to take offence show similar levels of activity in a region of the brain that’s crucial for decision-making. |
|[Disrupting malicious uses of AI by state-affiliated threat actors.](https://openai.com/blog/disrupting-malicious-uses-of-ai-by-state-affiliated-threat-actors) |OpenAI discovered and terminated accounts affiliated with nation-states using GPT models for malicious cases. |
|[Andrej Karpathy is leaving OpenAI again — but he says there was no drama.](https://techcrunch.com/2024/02/13/andrej-karpathy-is-leaving-openai-again-but-he-says-there-was-no-drama/) |Andrej Karpathy, a widely respected research scientist, announced today that he has left OpenAI. This is the second time Karpathy has left the top AI firm and his departure is not because of any event, issue or drama, he said. |
|[NVIDIA’s new AI chatbot runs locally on your PC.](https://www.engadget.com/nvidias-new-ai-chatbot-runs-locally-on-your-pc-163406121.html) |NVIDIA just released a free demo version of a chatbot that runs locally on your PC. This is pretty neat, as it gives the chatbot access to your files and documents. You can feed Chat with RTX a selection of personal data and have it create summaries based on that information. You can also ask it questions, just like any chatbot, and dives into your data for answers. |
|[MAGNeT: Masked Audio Generation using a Single Non-Autoregressive Transformer.](https://github.com/facebookresearch/audiocraft/blob/main/docs/MAGNET.md) | Facebook unveiled an advanced open-source audio model that is 7 times quicker than competing models without compromising on quality. It is able to produce sound effects and music. The manuscript is now accessible.|
|[MIMIR.](https://github.com/iamgroot42/mimir) |Python package for measuring memorization in LLMs. |
|[Nvidia is now worth as much as the whole Chinese stock market.](https://finance.yahoo.com/news/nvidia-now-worth-much-whole-010315545.html) |Nvidia is now worth the same as the whole Chinese stock market as defined by Hong Kong-listed H-shares, Bank of America chief investment strategist Michael Hartnett pointed out in a new note. The company's market cap has hit $1.7 trillion, the same as all Chinese companies listed on the Hong Kong Stock Exchange. Nvidia's stock soared 239% in 2023 and is up 41% in 2024, through Thursday.|
|[OpenAI Sora.](https://openai.com/sora) |A new video generating model with amazing quality was revealed by OpenAI. Red teamers are allowed to test it right now. |
|[Lambda Raises $320M To Build A GPU Cloud For AI.](https://lambdalabs.com/blog/lambda-raises-320m-to-build-a-gpu-cloud-for-ai) | Lambda’s mission is to build the #1 AI compute platform in the world. To accomplish this, we’ll need lots of NVIDIA GPUs, ultra-fast networking, lots of data center space, and lots of great new software to delight you and your AI engineering team.|
|[USPTO says AI models can’t hold patents.](https://arstechnica.com/information-technology/2024/02/us-says-ai-models-cant-hold-patents/) | the United States Patent and Trademark Office (USPTO) published guidance on inventorship for AI-assisted inventions, clarifying that while AI systems can play a role in the creative process, only natural persons (human beings) who make significant contributions to the conception of an invention can be named as inventors. It also rules out using AI models to churn out patent ideas without significant human input.|

## Resources
|Link|description|
|---|---|
|[RLX: Reinforcement Learning with MLX.](https://github.com/noahfarr/rlx) |RLX is a collection of Reinforcement Learning algorithms implemented based on the implementations from CleanRL in MLX, Apple's new Machine Learning framework.  |
|[llmware.](https://github.com/llmware-ai/llmware) | llmware is a unified framework for developing LLM-based application patterns including Retrieval Augmented Generation (RAG). This project provides an integrated set of tools that anyone can use - from a beginner to the most sophisticated AI developer - to rapidly build industrial-grade, knowledge-based enterprise LLM applications with specific focus on making it easy to integrate open source small specialized models and connecting enterprise knowledge safely and securely.|
|[Point Transformer V3.](https://github.com/pointcept/pointtransformerv3) | For processing 3D point clouds, the Point Transformer V3 (PTv3) model is an effective and straightforward paradigm. By putting more of an emphasis on efficiency and scaling up than on fine-grained design details, it is able to attain quicker processing speeds and improved memory economy.|
|[phidata.](https://github.com/phidatahq/phidata) |Phidata is a toolkit for building AI Assistants using function calling. Function calling enables LLMs to achieve tasks by calling functions and intelligently choosing their next step based on the response, just like how humans solve problems. |
|[ml-mgie.](https://github.com/apple/ml-mgie) |Apple released code that uses multimodal language models to improve human-provided natural language edits to images. |
|[Lag-Llama: Towards Foundation Models for Probabilistic Time Series Forecasting.](https://github.com/time-series-foundation-models/lag-llama) | Lag-Llama is the first open-source foundation model for time series forecasting!|
|[Learning to Fly in Seconds.](https://github.com/arplaboratory/learning-to-fly) |This repository contains the code for the paper Learning to Fly in Seconds. It allows to train end-to-end control policies using deep reinforcement learning. The training is done in simulation and is finished within seconds on a consumer-grade laptop. The trained policies generalize and can be deployed on real quadrotors |
|[Packing Inputs Without Cross-Contamination Attention.](https://github.com/MeetKai/functionary/tree/main/functionary/train/packing) |By concatenating instances, packing in training models can enhance training effectiveness. When examples are handled carelessly, contamination might happen since the focus isn't sure where to end. Although the community has discovered that EOS is frequently enough, issues can nevertheless arise. This repository offers a Hugging Face implementation for popular models to correctly compress input data. |
|[ZLUDA.](https://github.com/vosen/ZLUDA) | ZLUDA lets you run unmodified CUDA applications with near-native performance on  AMD GPUs.|
|[GenTranslate.](https://github.com/yuchen005/gentranslate) |A novel method called GenTranslate leverages massive language models to enhance translation quality. The best translations produced by foundational models are the main focus. Tests have shown that the approach performs better than the state-of-the-art translation models. |
|[Design2Code.](https://github.com/mostafasadeghi97/design2code) |Design2Code is an open-source project that converts various web design formats, including sketches, wireframes, Figma, XD, etc., into clean and responsive HTML/CSS/JS code. Just upload your design image, and Design2Code will automatically generate the code for you. It's that simple! |
|[SGLang.](https://github.com/sgl-project/sglang) |SGLang is a structured generation language designed for large language models (LLMs). It makes your interaction with LLMs faster and more controllable by co-designing the frontend language and the runtime system. |
|[DALI.](https://github.com/AAAI-DISIM-UnivAQ/DALI) |This study presents cutting-edge techniques to guarantee that autonomous intelligent agents—which are essential in applications that depend on life—remain morally and ethically sound even as they develop. |
|[Reor Project.](https://github.com/reorproject/reor) | Reor is an AI-powered desktop note-taking app: it automatically links related ideas, answers questions on your notes and provides semantic search. Everything is stored locally and you can edit your notes with an Obsidian-like markdown editor.|
|[Dinosaur: differentiable dynamics for global atmospheric modeling.](https://github.com/google-research/dinosaur) | The Google group has made code available to support atmospheric modeling. DeepMind's latest weather modeling tools are built around this code.|
|[Neural Flow.](https://github.com/valine/NeuralFlow) | This is a Python script for plotting the intermediate layer outputs of Mistral 7B. When you run the script, it produces a 512x256 image representing the output at every layer of the model. The concept is straightforward: collect the output tensors from each layer, normalize them between zero and one, and plot these values as a heatmap. The resulting image reveals a surprising amount of structure. I have found this enormously helpful for visually inspecting outputs when fine-tuning models.|
|[Tabula Rasa: not enough data? Generate them!.](https://levelup.gitconnected.com/tabula-rasa-not-enough-data-generate-them-e1c160acb9c9) |How you can apply generative AI to tabular data |
|[A practical guide to neighborhood image processing.](https://ai.plainenglish.io/a-practical-guide-to-neighborhood-image-processing-cd3cc7f264a7) |Love thy neighbors: How the neighbors are influencing a pixel |

## Perspectives
|Link|description|
|---|---|
|[AI agents as a new distribution channel.](https://kojo.blog/agent-driven-commerce/) |By making judgments about what to buy on behalf of customers, AI agents are starting to emerge as a new route of distribution that might level the playing field between startups and established players. Businesses will need to adjust their goods to cater to AI tastes instead of human ones as this trend develops, which will alter the conventional dynamics of product appraisal, purchase, and discovery. The development of AI portends a time when agent-driven commerce may completely change the way goods are advertised and bought. |
|[Thinking about High-Quality Human Data.](https://lilianweng.github.io/posts/2024-02-05-human-data-quality/) |The topic of this piece is how people generate data. It also covers labeling, annotating, and gathering preference data, among other topics. |
|[AI Aesthetics.](https://www.usv.com/writing/2024/02/ai-aesthetics/) | Artificial Intelligence will radically transform the way we create, appreciate, and produce art. This article delves deeper into this topic and identifies the businesses spearheading the shift.|
|[NYC: Brain2Music.](https://www.youtube.com/watch?v=cD6Y1K1xgwk) | Research talk from Google about reading music from a person’s brain.|
|[Massed Muddler Intelligence.](https://studio.ribbonfarm.com/p/massed-muddler-intelligence) | A move away from conventional monolithic AI scaling and toward a paradigm based on distributed, agent-based systems that learn and adapt in real time is represented by the idea of massed muddler intelligence, or MMI. MMI promotes AI development that stresses scalable, interactive agents with a degree of autonomy and mutual governance, moving away from the current focus on accumulating larger datasets and computational resources. This approach is based on the principles of embodiment, boundary intelligence, temporality, and personhood.|
|[AI Could Actually Help Rebuild The Middle Class.](https://www.noemamag.com/how-ai-could-help-rebuild-the-middle-class/) |AI doesn’t have to be a job destroyer. It offers us the opportunity to extend expertise to a larger set of workers. |
|[Letter from the YouTube CEO: 4 Big bets for 2024.](https://blog.youtube/inside-youtube/2024-letter-from-neal/) | YouTube is investing in diverse revenue streams for creators. The platform witnessed a 50% increase in the use of channel memberships. It is creating creator support networks through programs like the Creator Collective. Efforts are undertaken to help politicians appreciate and respect the economic and entertainment worth of artists.|
|[Meta’s AI Chief Yann LeCun on AGI, Open-Source, and AI Risk.](https://time.com/6694432/yann-lecun-meta-ai-interview/) | Ahead of the award ceremony in Dubai, LeCun sat down with TIME to discuss the barriers to achieving “artificial general intelligence” (AGI), the merits of Meta’s open-source approach, and what he sees as the “preposterous” claim that AI could pose an existential risk to the human race.|
|[Deepfakes, trolls and cybertroopers: how social media could sway elections in 2024.](https://www.nature.com/articles/d41586-024-00274-7) | Faced with data restrictions and harassment, researchers are mapping out fresh approaches to studying social media’s political reach.|
|[Why "Chat over Your Data" Is Harder Than You Think.](https://www.arcus.co/blog/chat) |Contrary to popular belief, developing chat-based, domain-specific LLM applications and copilots is challenging. Achieving strong performance, managing intricate queries and data, and providing robust data retrieval for LLM-based chat apps are a few of the difficulties. |


# ML news: Week 5 - 11 February

## Research
|Link|description|
|---|---|
|[Bad Actor, Good Advisor: Exploring the Role of Large Language Models in Fake News Detection.](https://arxiv.org/abs/2309.12247) |When it comes to detecting bogus news, a refined BERT model performs better than an off-the-shelf LLM like GPT-3.5-turbo. |
|[PAP-REC: Personalized Automatic Prompt for Recommendation Language Model.](https://arxiv.org/abs/2402.00284v1) |In order to improve the efficacy and efficiency of Recommendation Language Models, PAP-REC has developed a technique that automatically generates tailored prompts. |
|[PAM: Prompting Audio-Language Models for Audio Quality Assessment.](https://arxiv.org/abs/2402.00282v1) | PAM is a tool that evaluates audio quality without reference tracks or specific training by using Audio-Language Models.|
|[AnimateLCM: Accelerating the Animation of Personalized Diffusion Models and Adapters with Decoupled Consistency Learning.](https://animatelcm.github.io/) |AnimateLCM is a novel method that divides the learning process into two halves in order to rapidly produce high-quality films and enhance current video diffusion models. |
|[Boximator: Generating Rich and Controllable Motions for Video Synthesis.](https://arxiv.org/abs/2402.01566) |Controlling video synthesis is a well-known challenge. This paper suggests guiding the generation using boxes and arrows over time, which enhances human preference judgment but still leaves the user with imperfect guidance. |
|[KTO: Model Alignment as Prospect Theoretic Optimization.](https://arxiv.org/abs/2402.01306v1) |Kahneman-Tversky Optimization (KTO) is a novel method for conditioning AI models to more closely resemble human thought processes. Utilizing ideas from prospect theory developed by Kahneman & Tversky, KTO prioritizes utility above preference likelihood. |
|[A simple method to reduce hallucination in Large Vision-Language Models.](https://arxiv.org/abs/2402.01345v1) | This study clarifies the reasons for multimodal hallucination, a condition in which large vision-language models (LVLMs) occasionally represent visuals erroneously. One important factor is semantic shift bias, especially at paragraph breaks.|
|[CapHuman: Capture Your Moments in Parallel Universes.](https://caphuman.github.io/) | Given only one reference facial photograph, our CapHuman can generate photo-realistic specific individual portraits with content-rich representations and diverse head positions, poses, facial expressions, and illuminations in different contexts.|
|[Nomic Embed: Training a Reproducible Long Context Text Embedder.](https://arxiv.org/abs/2402.01613v1) | Nomic-Embed-Text-V1 is an open-source, completely reproducible text embedding model that raises the bar. It does well on activities with both short and lengthy contexts. Nomic-Embed-Text-V1, which is transparent to the extreme, provides full access to its model weights, training code, and a large dataset consisting of 235 million text pairs.|
|[SynthCLIP: Are We Ready for a Fully Synthetic CLIP Training?](https://arxiv.org/abs/2402.01832) | Training large-scale picture models is difficult due to legitimate copyright concerns and the disappearance of large-scale datasets like LAION. This work demonstrates that 30 million artificially created pictures may be used to train a strong CLIP model.|
|[Rethinking Optimization and Architecture for Tiny Language Models.](https://arxiv.org/abs/2402.02791v2) | This work investigates how to focus on small models with fewer parameters in order to develop strong language models better suited for mobile devices. |
|[Unified Hallucination Detection for Multimodal Large Language Models.](https://arxiv.org/abs/2402.03190v1) |In order to address the important problem of hallucinations in Multimodal Large Language Models (MLLMs), researchers have created a new benchmark called MHaluBench, which is used to assess different hallucination detection techniques. |
|[InteractiveVideo: User-Centric Controllable Video Generation with Synergistic Multimodal Instructions.](https://invictus717.github.io/InteractiveVideo/) | With InteractiveVideo, users may now create videos in a new style that allows for dynamic user interaction. This intuitive framework, in contrast to conventional techniques, enables real-time adjustments utilizing text, graphics, painting, and even drag-and-drop.|
|[DeepSeekMath.](https://github.com/deepseek-ai/deepseek-math) |DeepSeekMath 7B has achieved an impressive score of 51.7% on the competition-level MATH benchmark without relying on external toolkits and voting techniques, approaching the performance level of Gemini-Ultra and GPT-4.  |
|[Natural language guidance of high-fidelity text-to-speech models with synthetic annotations.](https://www.text-description-to-speech.com/) | These Stability AI-trained text-to-speech algorithms can follow exact natural language commands. Its developers artificially annotated a sizable corpus of speech for training as there isn't a sizable dataset with appropriate textual descriptions of audio for creation. This is a further illustration of the larger trend of generative modeling training, up-captioning, and annotating.|
|[MusicRL: Aligning Music Generation to Human Preferences.](https://arxiv.org/abs/2402.04229) |The Google MusicLM team used an RL approach on their music generating models using 300k feedback pieces and other incentive signals. They discovered that in human preference experiments, it performs better than the base model; nonetheless, it is not evident whether RL technique produces the greatest quality output. |
|[A Hard-to-Beat Baseline for Training-free CLIP-based Adaptation.](https://arxiv.org/abs/2402.04087v1) |In order to increase CLIP's performance in picture classification tasks without the need for more training or resources, this article revisits the traditional Gaussian Discriminant Analysis (GDA) approach. |
|[MobileVLM V2: Faster and Stronger Baseline for Vision Language Model.](https://arxiv.org/abs/2402.03766v1) | The line of sophisticated vision-language models for mobile devices known as MobileVLM V2 offers appreciable performance gains thanks to creative architecture.|
|[The Instinctive Bias: Spurious Images lead to Hallucination in MLLMs.](https://arxiv.org/abs/2402.03757v1) |According to a recent study, multi-modal large language models (MLLMs) like GPT-4V have a flaw in that they make mistakes when dealing with particular kinds of image-text inputs. A benchmark called CorrelationQA was created to assess how well MLLMs performed in situations where text could be contradicted or misled by visuals. |
|[Read to Play (R2-Play): Decision Transformer with Multimodal Game Instruction.](https://arxiv.org/abs/2402.04154v2) | The creation of a generalist AI agent that can comprehend and adhere to gaming instructions is examined in this research as a first step toward "read-to-play" capabilities. The researchers incorporate multimodal game instructions into a decision transformer to improve the agent's multitasking and generalization abilities.|
|[MetaTree: Learning a Decision Tree Algorithm with Transformers.](https://github.com/evanzhuang/metatree) |MetaTree is a transformer-based decision tree algorithm. It learns from classical decision tree algorithms for better generalization capabilities. |


## News
|Link|description|
|---|---|
|[Sakana Awarded Japanese Government Supercomputing Grant.](https://sakana.ai/nedo-grant/) |Sakana AI is one of seven institutions in Japan chosen by the Japanese government to receive a supercomputing grant, for encouraging development of foundation AI models to strengthen the capabilities of Japan’s generative AI ecosystem. |
|[Hugging Face launches open source AI assistant maker to rival OpenAI’s custom GPTs.](https://venturebeat.com/ai/hugging-face-launches-open-source-ai-assistant-maker-to-rival-openais-custom-gpts/) | Hugging Face, the New York City-based startup that offers a popular, developer-focused repository for open source AI code and frameworks (and hosted last year’s “Woodstock of AI”), today announced the launch of third-party, customizable Hugging Chat Assistants.|
|[Arc is building an AI agent that browses on your behalf.](https://techcrunch.com/2024/02/01/arc-is-building-an-ai-agent-that-browses-on-your-behalf/) | The Browser Company, which makes the Arc Browser, is on a quest to change that by building an AI that surfs the web for you and gets you the results while bypassing search engines. |
|[Introducing Qwen1.5.](https://qwenlm.github.io/blog/qwen1.5/) | 0.5B to 72B range of parameters. This collection of multilingual models is outstanding. It's interesting to note that the first significant sub-1B parameter language model is the smallest model.|
|[Inside OpenAI’s Plan to Make AI More ‘Democratic’.](https://time.com/6684266/openai-democracy-artificial-intelligence/) |Colin Megill met with Wojciech Zaremba, co-founder of OpenAI, in May 2023 to talk about integrating Polis, an AI-powered public debating platform that promotes democratic involvement. The cooperation sought to use public feedback to match AI with human ideals. It started the "Democratic Inputs to AI" project at OpenAI, which aims to investigate AI governance through a $1 million award program. |
|[Roblox releases real-time AI chat translator.](https://www.theverge.com/2024/2/5/24061495/roblox-generative-ai-chat-translator) | Roblox built an AI model that it says translates text chats so quickly users may not even notice it’s translating the messages of other players at first. It works with 16 languages, including English, French, Japanese, Thai, Polish, and Vietnamese. |
|[OpenAI is adding new watermarks to DALL-E 3.](https://www.theverge.com/2024/2/6/24063954/ai-watermarks-dalle3-openai-content-credentials) |OpenAI says watermarks in image metadata are not perfect, but they help build trust of digital information. |
|[Microsoft Copilot for Sales and Copilot for Service are now generally available.](https://cloudblogs.microsoft.com/dynamics365/bdm/2024/02/01/microsoft-copilot-for-sales-and-copilot-for-service-are-now-generally-available/) |The AI-powered Copilot for Sales and Service from Microsoft is now widely accessible. It increases the efficiency of sales and support staff by integrating with CRM platforms like Salesforce. The solutions promise to improve customer interactions and expedite company operations by automating repetitive tasks and providing insights directly within Microsoft 365 apps. Early users of these AI capabilities, such as Avanade, report considerable time savings and improved client engagement. |
|[First passages of rolled-up Herculaneum scroll revealed.](https://www.nature.com/articles/d41586-024-00346-8) |Researchers used artificial intelligence to decipher the text of 2,000-year-old charred papyrus scripts, unveiling musings on music and capers. |
|[IBM wants to build a 100,000-qubit quantum computer.](https://www.technologyreview.com/2023/05/25/1073606/ibm-wants-to-build-a-100000-qubit-quantum-computer/) | The company wants to make large-scale quantum computers a reality within just 10 years.|
|[Microsoft brings new AI image functionality to Copilot, adds new model Deucalion.](https://venturebeat.com/ai/microsoft-brings-ai-image-generation-to-copilot-adds-new-model-deucalion/) |In a startling move, Microsoft today announced a redesigned look for its Copilot AI search and chatbot experience on the web (formerly known as Bing Chat), new built-in AI image creation and editing functionality, and a new AI model, Deucalion, that is powering one version of Copilot. |
|[Meet ‘Smaug-72B’: The new king of open-source AI.](https://venturebeat.com/ai/meet-smaug-72b-the-new-king-of-open-source-ai/) | A new open-source language model has claimed the throne of the best in the world, according to the latest rankings from Hugging Face, one of the leading platforms for natural language processing (NLP) research and applications.|
|[EU’s AI Act passes last big hurdle on the way to adoption.](https://techcrunch.com/2024/02/02/eu-ai-act-coreper-vote/) |The European Union’s AI Act, a risk-based plan for regulating applications of artificial intelligence, has passed what looks to be the final big hurdle standing in the way of adoption after Member State representatives today voted to confirm the final text of the draft law. |
|[OpenAI forms a new team to study child safety.](https://techcrunch.com/2024/02/07/openai-forms-a-new-team-to-study-child-safety/) |Under scrutiny from activists — and parents — OpenAI has formed a new team to study ways to prevent its AI tools from being misused or abused by kids. |
|[Human brain cells hooked up to a chip can do speech recognition.](https://www.technologyreview.com/2023/12/11/1084926/human-brain-cells-chip-organoid-speech-recognition/) |Clusters of brain cells grown in the lab have shown potential as a new type of hybrid bio-computer. |
|[Bard becomes Gemini: Try Ultra 1.0 and a new mobile app today.](https://blog.google/products/gemini/bard-gemini-advanced-app/) |You may now finally interact with Gemini Ultra 1.0 thanks to a new service that Google established. However, access to the model will need a monthly subscription fee. Additionally, a companion smartphone app exists. |
|[1X robotics demonstration.](https://www.1x.tech/discover/all-neural-networks-all-autonomous-all-1x-speed) | One robotics startup, 1X, has achieved significant advancements in video-to-control models. The robot, which is powered by neural networks that generate 10 Hz control impulses from visual input, has been demonstrated by the business executing a variety of tasks.|
|[AR glasses with multimodal AI nets funding from Pokémon GO creator.](https://techcrunch.com/2024/02/08/ar-glasses-with-multimodal-ai-attracts-funding-from-pokemon-go-founder/) | Today, Singapore-based Brilliant Labs announced its new product, Frame, a pair of lightweight AR glasses powered by a multimodal AI assistant called Noa. The glasses have captured the attention and investment of John Hanke, CEO of Niantic, the augmented reality platform behind games like Pokémon GO.|

## Resources
|Link|description|
|---|---|
|[aphrodite-engine.](https://github.com/PygmalionAI/aphrodite-engine) | For AI inference workloads, the Aphrodite engine can increase throughput while lowering VRAM needs.|
|[chatllm-vscode.](https://marketplace.visualstudio.com/items?itemName=locuslab.chatllm-vscode) | ChatLLM is a VSCode extension for interacting with LLM APIs in a flexible and long-form manner. It leverages the VSCode notebook support to do so, creating a new type of notebook (.chatllm) files where you can interact with an (API-based) LLM system over a long document. |
|[diffusers v0.26.0.](https://github.com/huggingface/diffusers/releases/tag/v0.26.0) |This new release comes with two new video pipelines, a more unified and consistent experience for single-file checkpoint loading, support for multiple IP-Adapters’ inference with multiple reference images, and more. |
|[Ollama vision models.](https://ollama.ai/blog/vision-models) |Recently, support for vision models was introduced by Ollama. Llava 1.6 comes with both Python and JavaScript packages that offer enhanced support and vision functionality. |
|[Image to Music v2.](https://huggingface.co/posts/fffiloni/484223631728087) |Images to text, text to prompt, and prompt to music can all be translated into a visually appealing pipeline. |
|[3DTopia.](https://github.com/3DTopia/3DTopia) |A two-stage text-to-3D generation model. The first stage uses diffusion model to quickly generate candidates. The second stage refines the assets chosen from the first stage. |
|[Open Source Alternative to Rabbit.](https://github.com/KillianLucas/01) |An open-source version of the Rabbit hardware, complete with language modeling, is being developed by a team. |
|[NaturalSQL by ChatDB.](https://github.com/cfahlgren1/natural-sql) | NaturalSQL by ChatDB is a series of models with state-of-the-art performance on Text to SQL instructions.|
|[contextual_bandits_tutorial.](https://github.com/facebookresearch/Pearl/blob/main/pearl/tutorials/contextual_bandits/contextual_bandits_tutorial.ipynb) |Meta maintains the RL framework called Pearls. This tutorial uses the program to walk through a bandit-based learning problem. |
|[BRIA Background Removal v1.4 Model Card.](https://huggingface.co/briaai/RMBG-1.4) |RMBG v1.4 is our state-of-the-art background removal model, designed to effectively separate foreground from background in a range of categories and image types. This model has been trained on a carefully selected dataset, which includes: general stock images, e-commerce, gaming, and advertising content, making it suitable for commercial use cases powering enterprise content creation at scale. |
|[MetaVoice-1B.](https://huggingface.co/metavoiceio/metavoice-1B-v0.1) | a small and powerful text-to-speech model that supports generation and voice cloning.|
|[Latxa.](https://huggingface.co/collections/HiTZ/latxa-65a697e6838b3acc53677304) |Latxa is a collection of foundation models specifically tuned for Basque. |
|[fabric.](https://github.com/danielmiessler/fabric) | An open-source framework for augmenting humans using AI.|
|[YOLO-World.](https://github.com/AILab-CVC/YOLO-World) |The process of locating objects and their bounding boxes is called object detection. Usually, only a predetermined selection of items selected during training may be used for this. This study presents a real-time approach capable of Open Vocabulary object identification, i.e., detecting bounding boxes for any combination of objects supplied at run-time. |
|[SELF-DISCOVER.](https://github.com/catid/self-discover) | the implementation of SELF-DISCOVER: Large Language Models Self-Compose Reasoning Structures. a novel prompting technique that allows language models to use a set of reasoning primitives to discover a larger framework for problem-specific reasoning.|
|[AI Filter.](https://github.com/thomasj02/AiFilter) |AI Filter is a Chrome extension that uses a local language model to filter your social media feeds (currently, only Twitter / X) according to your instructions. |
|[Fully Local RAG using Ollama & PgVector.](https://github.com/phidatahq/phidata/tree/main/cookbook/local_rag) |Using Ollama, pgvector, and local data, you can create a complex and potent RAG system that operates on your hardware. |
|[LightEval .](https://github.com/huggingface/lighteval) | LightEval is a lightweight LLM evaluation suite that Hugging Face has been using internally with the recently released LLM data processing library datatrove and LLM training library nanotron.|
|[CogCoM.](https://github.com/thudm/cogcom) | CogCoM is a general vision-language model (VLM) endowed with Chain of Manipulations (CoM) mechanism, that enables VLMs to perform multi-turns evidential visual reasoning by actively manipulating the input image. We now release CogCoM-base-17b, a model with 10 billion visual parameters and 7 billion language parameters, trained on a data fusion of 4 types capabilities (instruction-following, OCR, detailed-captioning, and CoM).|
|[How we got fine-tuning Mistral-7B to not suck: Helix Project Report, Feb 2024.](https://helixml.substack.com/p/how-we-got-fine-tuning-mistral-7b) |By using a set of qapair questions that gathered material from a variety of viewpoints and produced a content-addressed hash for every document, HelixML was able to improve Mistral-7B. |
|[VatsaDev/animebench-alpha.](https://huggingface.co/datasets/VatsaDev/animebench-alpha) | a benchmark dataset with quotes and information about different anime characters to evaluate language model performance.|
|[NextBrain: a next-generation, histological atlas of the human brain for high-resolution neuroimaging studies.](https://github-pages.ucl.ac.uk/NextBrain/#/home) |We present a next-generation probabilistic atlas of the human brain using histological sections of five full human hemispheres with manual annotations for 333 regions of interest. This website enables the interactive inspection of these five cases using a  3D navigation interface  and search functionality. |
|[Efficient Linear Model Merging for LLMs.](https://lightning.ai/lightning-ai/studios/efficient-linear-model-merging-for-llms) |Model merging is a technique for combining multiple pretrained or finetuned LLMs into a single, more powerful model. This approach is particularly useful when individual models excel in different domains or tasks, and merging them can create a model with a broader range of capabilities and improved overall performance. |

## Perspectives
|Link|description|
|---|---|
|[MIT Paper: AI’s Labor Market Impacts Are Slower Than Expected.](https://aisupremacy.substack.com/p/mit-paper-ais-labor-market-impacts) |The economic feasibility of automating vision-based operations is examined in the working paper "Beyond AI Exposure: Which Tasks are Cost-Effective to Automate with Computer Vision?" authored by researchers from IBM and MIT. Just 23% of them are profitable to automate, it was discovered. In contrast with more disruptive expectations, the report projects a gradual impact on the job market over several years. |
|[How AI Is Helping Us Learn About Birds.](https://themarkup.org/hello-world/2024/02/03/how-ai-is-helping-us-learn-about-birds) |Machine learning is powering new insights into how birds migrate—and forecasts about where they’ll go next |
|[The Techno-Industrial Revolution.](https://www.notboring.co/p/the-techno-industrial-revolution) | |The increasing sophistication of AI tooling and corporate use cases will lead to an increasing number of practical uses of the technology. The potential here can be viewed through the lens of how AI will increase margins significantly while lowering costs and improving process efficiency. This could open the door to entirely new approaches that weren't previously viable due to extremely narrow profit margins. A couple of these examples are examined in this article.
|[The path to profitability for AI in 2024.](https://sidstage.substack.com/p/the-path-to-profitability-for-ai) | The emphasis of AI research has recently shifted from accuracy and breadth to efficiency and depth. AI's increasing energy consumption and NVIDIA's H100 sales demonstrate the industry's size. Research is now focused on smaller, more efficient models, such as Phi 2, and emphasizes sustainable economics from model architecture to deployment, all because investments expect profitability. AI's computational efficiency and energy efficiency are expected to increase with advancements in training, fine-tuning, and design. On-device features are a reflection of a larger movement towards more useful and sustainable AI applications.|
|[How design drove $10M in preorders for Rabbit R1 AI hardware.](https://www.fastcompany.com/91013196/how-design-drove-10m-in-pre-orders-for-rabbit-r1-ai-hardware) |In an expansive interview, Rabbit CEO Jesse Lyu shares how he collaborates with Teenage Engineering, why he didn’t want to make a phone, and how the R1’s retro-future design is key to the company’s strategy. |
|[What’s next for robotaxis in 2024.](https://www.technologyreview.com/2024/01/23/1086936/whats-next-for-robotaxis-2024/) |In addition to restoring public trust, robotaxi companies need to prove that their business models can compete with Uber and taxis. |
|[Google's Gemini Advanced: Tasting Notes and Implications.](https://www.oneusefulthing.org/p/google-gemini-advanced-tasting-notes) | Similar to OpenAI's GPT-4, Google's recently released GPT-4 class AI model, Gemini Advanced, exhibits comparable characteristics. It excels at providing explanations and fusing search with images.|
|[Thesis on value accumulation in AI.](https://lethain.com/value-accumulation-in-ai/) |This investor's perspective breaks down the layers of value that exist in AI today into three categories: AI-enhanced products (like all of you that use AI to improve your products), modeling and core (like OpenAI and Anthropic), and infrastructure layer (like cloud providers and chip makers). |

# ML news: Week 29 January - 4 February

## Research
|Link|description|
|---|---|
|[Matryoshka Representation Learning.](https://arxiv.org/abs/2205.13147) |The new embeddings from OpenAI are scalable to meet your demands. This is thought to be caused by the learning strategy known as the nesting doll approach, which learns characteristics at different granularities. |
|[Vivim: a Video Vision Mamba for Medical Video Object Segmentation.](https://arxiv.org/abs/2401.14168v1) | A new framework called Vivim efficiently processes lengthy video sequences for medical video object segmentation. In comparison to conventional techniques, Vivim provides faster and more accurate segmentation results by effectively compressing spatiotemporal data using the state space model methodology.|
|[Multimodal Pathway: Improve Transformers with Irrelevant Data from Other Modalities.](https://ailab-cvc.github.io/M2PT/) | This study presents a unique way to improve transformers by utilizing disparate input from many modalities, e.g., audio data to improve an image model. By connecting the transformers of two distinct modalities in a unique way, Multimodal Pathway enables a target modality to profit from the advantages of another.|
|[pix2gestalt: Amodal Segmentation by Synthesizing Wholes.](https://gestalt.cs.columbia.edu/) | A framework called Pix2Gestalt is intended for zero-shot amodal segmentation. When an item is partially occluded, it can rebuild its entire shape and look with great skill. Pix2Gestalt, which makes use of large-scale diffusion models, performs exceptionally well in difficult situations, such as producing artistic images that break convention.|
|[Large-Vocabulary 3D Diffusion Model with Transformer.](https://ziangcao0312.github.io/difftf_pages/) |The variety of objects that may be generated in 3D poses a significant difficulty. This study builds up the system to operate with a considerably bigger range of items in each 3D category and employs a changed architecture to enhance sampling efficiency. |
|[SliceGPT: Compress Large Language Models by Deleting Rows and Columns.](https://arxiv.org/abs/2401.15024) |Another potential distillation work. Importantly, this one can work on models as small as Phi-2. This means you can remove 90% of the rows and columns of weight matrices with minimal reduction to quality at almost all scales. |
|[Learning Universal Predictors.](https://arxiv.org/abs/2401.14953) |The process of teaching systems to learn from experience and swiftly adjust to new tasks is known as meta-learning. With artificial data produced by a Universal Turing Machine, this Google project enhances Meta Learning and conducts both theoretical and experimental analysis of the outcomes. |
|[CreativeSynth: Creative Blending and Synthesis of Visual Arts based on Multimodal Diffusion.](https://arxiv.org/abs/2401.14066v1) | CreativeSynth is an artistic picture editing technique that combines text and image inputs in a seamless manner. Its diffusion approach, which has specialized attention processes built in, allows for fine alteration of both style and content while maintaining the essential elements of the original artwork.|
|[Annotated Hands for Generative Models.](https://arxiv.org/abs/2401.15075v1) |By adding three more channels to training photos for hand annotations, researchers have increased the capacity of generative models, such as GANs and diffusion models, to produce realistic hand images. |
|[Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling.](https://arxiv.org/abs/2401.16380) | Many AI systems employ the concept of "up captioning" to enhance labels during training. This work from Apple rephrases C4 as instructions, Q&A pairs, and more in order to apply it to pre-training. The rephrasing step increased convergence by 10x, according to the study, making the model significantly more sample-efficient, albeit at the expense of the rephrasing step itself.|
|[Continual Learning with Pre-Trained Models: A Survey.](https://arxiv.org/abs/2401.16386v1) |This work provides an extensive overview of the most recent developments in continuous learning, which is centered on continually adjusting to new information while preserving prior understanding. |
|[MacGNN.](https://github.com/yuanchenbei/macgnn) |The MAcro Recommendation Graph (MAG) and Macro Graph Neural Networks (MacGNN) are introduced in this research. These methods greatly reduce the number of nodes by assembling similar behavior patterns into macro nodes, which addresses the computational difficulty of Graph Neural Networks. |
|[Machine learning predicts which rivers, streams, and wetlands the Clean Water Act regulates.](https://www.science.org/doi/10.1126/science.adi3794) | Our framework can support permitting, policy design, and use of machine learning in regulatory implementation problems. |
|[Weaver: Foundation Models for Creative Writing.](https://arxiv.org/abs/2401.17268) | A group of models called Weaver have been trained especially to narrate stories. On a benchmark for storytelling, the biggest model (34B params) performs better than GPT-4.|
|[Text Image Inpainting via Global Structure-Guided Diffusion Models.](https://arxiv.org/abs/2401.14832v1) |In this study, two datasets for handwritten words and scenes are introduced, along with a benchmark. With original, damaged, and assistant photos, the new Global Structure-guided Diffusion Model (GSDM) effectively recovers clean texts by taking use of text structure. Both picture quality and identification accuracy demonstrate notable gains. |
|[Multi-granularity Correspondence Learning from Long-term Noisy Videos.](https://lin-yijie.github.io/projects/Norton/) | With Norton, the multi-granularity noisy correspondence problem in video-language studies is addressed, offering a novel strategy for enhancing long-term video comprehension. |
|[GPAvatar: Generalizable and Precise Head Avatar from Image(s).](https://xg-chu.github.io/project_gpavatar/) | With the use of a Multi Tri-planes Attention module and a dynamic point-based expression field, GPAvatar presents a novel technique for generating 3D head avatars from photos.|
|[MobileDiffusion: Rapid text-to-image generation on-device.](https://blog.research.google/2024/01/mobilediffusion-rapid-text-to-image.html) |With certain architectural modifications, Google has demonstrated a latent consistency diffusion model that it trained for sub-second generation times on mobile devices. |
|[SNP-S3: Shared Network Pre-training and Significant Semantic Strengthening for Various Video-Text Tasks.](https://arxiv.org/abs/2401.17773v1) | Shared Network Pre-training (SNP) enhances the joint learning of text and video. Compared to earlier models, this approach is more effective and adaptable and incorporates a novel technique called Significant Semantic Strengthening (S3) to improve comprehension of important terms in sentences.|
|[Hi-SAM: Marrying Segment Anything Model for Hierarchical Text Segmentation.](https://github.com/ymy-k/hi-sam) | An improved version of the Segment Anything Model (SAM) with a focus on hierarchical text segmentation is called Hi-SAM. Hi-SAM is an excellent text segmenter at several levels, ranging from strokes to paragraphs, and it can even analyze layouts.|


## News
|Link|description|
|---|---|
|[Voltron Data acquires Claypot to unlock real-time AI with modular data systems.](https://venturebeat.com/data-infrastructure/exclusive-voltron-data-acquires-claypot-to-unlock-real-time-ai-with-modular-data-systems/) |Today, San Francisco-based Voltron Data, a startup providing enterprises with a modular and composable approach to building systems for data analytics, confirmed to VentureBeat that is acquiring real-time AI platform Claypot. The terms of the deal were not disclosed. |
|[FTC investigating Microsoft, Amazon, and Google investments into OpenAI and Anthropic.](https://www.theverge.com/2024/1/25/24050693/ftc-investigating-microsoft-amazon-google-investments-openai-anthropic) | The commission wants to understand the tangled web of investments between cloud providers and AI startups.|
|[Google’s New AI Is Learning to Diagnose Patients.](https://spectrum.ieee.org/ai-doctor) | The DeepMind team turns to medicine with an AI model named AMIE|
|[1/100th of the cost: CPU startup Tachyum claims that one of its processing units can rival dozens of Nvidia H200 GPUs — with a 99% saving that could turn the AI market on its head if true.](https://www.techradar.com/pro/1100th-of-the-cost-cpu-startup-tachyum-claims-that-one-of-its-processing-units-can-rival-dozens-of-nvidia-h200-gpus-with-a-99-saving-that-could-turn-the-ai-market-on-its-head-if-true) |The 5nm Prodigy processor can dynamically switch between AI, HPC, and cloud workloads and costs $23,000 |
|[ChatGPT is violating Europe’s privacy laws, Italian DPA tells OpenAI.](https://techcrunch.com/2024/01/29/chatgpt-italy-gdpr-notification/) |https://techcrunch.com/2024/01/29/chatgpt-italy-gdpr-notification/ |
|[This whimsical clock is the playful gadget AI needs right now.](https://www.fastcompany.com/91015583/this-whimsical-clock-is-the-playful-gadget-ai-needs-right-now) |The Poem/1 clock dreams up a new poem every minute to tell you the time. Do you need it? No. But you might want it. |
|[iOS 17.4: Apple continues work on AI-powered Siri and Messages features, with help from ChatGPT.](https://9to5mac.com/2024/01/26/apple-siri-chatgpt-ios-18-development/) | Apple is widely expected to unveil major new artificial intelligence features with iOS 18 in June. Code found by 9to5Mac in the first beta of iOS 17.4 shows that Apple is continuing to work on a new version of Siri powered by large language model technology, with a little help from other sources.|
|[Opera to launch new AI-powered browser for iOS in Europe following Apple’s DMA changes.](https://techcrunch.com/2024/01/26/opera-to-launch-new-ai-powered-browser-for-ios-in-europe-following-apples-dma-changes/) |Opera revealed today that it will launch a new AI-powered browser built on its own engine for iOS in Europe. The Norway-based company announced the change following the news that Apple is going to allow alternative browser engines to run on iOS as a result of the requirements of the European Digital Markets Act (DMA).  |
|[Mistral CEO confirms ‘leak’ of new open source AI model nearing GPT-4 performance.](https://venturebeat.com/ai/mistral-ceo-confirms-leak-of-new-open-source-ai-model-nearing-gpt-4-performance/) | The past few days have been a wild ride for the growing open source AI community — even by its fast-moving and freewheeling standards.|
|[Microsoft LASERs away LLM inaccuracies.](https://www.theverge.com/2024/1/31/24057362/microsoft-llm-accuracy-laser-research-ai) | Microsoft’s LASER method seems counterintuitive, but it makes models trained on large amounts of data smaller and more accurate.|
|[LLaVA-1.6: Improved reasoning, OCR, and world knowledge.](https://llava-vl.github.io/blog/2024-01-30-llava-1-6/) | The most recent iteration of the visual language model Llava features enhanced reasoning, global knowledge, and OCR. It complements Gemini in some duties. The model, code, and data will be made available by the Llava team.|
|[ServiceNow’s statement on AI.](https://www.linkedin.com/posts/tomasztunguz_servicenow-a-150b-market-cap-company-made-activity-7156752212608618496-R7Yy/) | The $150 billion market capitalization business ServiceNow revealed last week that, among all of its new product family launches, including its initial Pro SKU, its generation AI solutions generated the biggest net new ACV contribution for the first full quarter. It's exciting to see that enterprise-level AI applications are already contributing to significant revenue growth.|
|[Bard’s latest updates: Access Gemini Pro globally and generate images.](https://blog.google/products/bard/google-bard-gemini-pro-image-generation/amp/) |you can now generate images in Bard in English in most countries around the world, at no cost. This new capability is powered by our updated Imagen 2 model |
|[Amazon debuts ‘Rufus,’ an AI shopping assistant in its mobile app.](https://techcrunch.com/2024/02/01/amazon-debuts-rufus-an-ai-shopping-assistant-in-its-mobile-app/) |Amazon announced today the launch of an AI-powered shopping assistant it’s calling Rufus that’s been trained on the e-commerce giant’s product catalog as well as information from around the web. |

## Resources
|Link|description|
|---|---|
|[imp-v1-3b .](https://huggingface.co/MILVLG/imp-v1-3b) |An additional multimodal model trained using SigLIP and Phi-2. This one is tiny enough to run on-device and provides very promising performance. |
|[WebDataset.](https://huggingface.co/docs/hub/datasets-webdataset) |WebDataset is a library for writing I/O pipelines for large datasets. Its sequential I/O and sharding features make it especially useful for streaming large-scale datasets to a DataLoader. |
|[LLMs-from-scratch.](https://github.com/rasbt/LLMs-from-scratch) | An unfinished yet intriguing series of exercises to teach language model building from beginning.|
|[Exploring ColBERT with RAGatouille.](https://til.simonwillison.net/llms/colbert-ragatouille) | For RAG applications, ColBERT is a great paradigm to embed queries and index data. This article runs some benchmarks and examines the method's underlying intuition.|
|[mamba.rs.](https://github.com/LaurentMazare/mamba.rs) | Inspired by efforts on the Llama models, this project uses pure Rust to run inference for Mamba on the CPU.|
|[🦙 Code Llama.](https://huggingface.co/codellama) |Code Llama is a code-specialized version of Llama 2 that was created by further training Llama 2 on its code-specific datasets, sampling more data from that same dataset for longer. |
|[Eagle 7B : Soaring past Transformers with 1 Trillion Tokens Across 100+ Languages (RWKV-v5).](https://blog.rwkv.com/p/eagle-7b-soaring-past-transformers) |A brand new era for the RWKV-v5 architecture and linear transformer's has arrived - with the strongest multi-lingual model in open source today |
|[InconsistencyMasks.](https://github.com/michaelvorndran/inconsistencymasks) | A novel technique for picture segmentation called Inconsistency Masks (IM) functions even with sparse data. Tested on the ISIC 2018 dataset, our method performs better than conventional methods and even surpasses models trained on fully labeled datasets.|
|[distortion-generator.](https://github.com/zamdimon/distortion-generator) |A novel technique for picture distortion strikes a compromise between privacy and accuracy in biometric systems, rendering facial photos incomprehensible to humans but yet identifiable to AI. |
|[TaskingAI.](https://github.com/TaskingAI/TaskingAI) | TaskingAI brings Firebase's simplicity to AI-native app development. The platform enables the creation of GPTs-like multi-tenant applications using a wide range of LLMs from various providers. It features distinct, modular functions such as Inference, Retrieval, Assistant, and Tool, seamlessly integrated to enhance the development process.|
|[100x Faster Clustering with Lilac Garden.](https://docs.lilacml.com/blog/introducing-garden.html) | A difficulty in language model training is locating a sufficiently varied dataset. It is considerably more difficult to visualize this data. This useful tool facilitates data exploration to enhance filtering and overall quality through topic modeling and quick clustering.|
|[float8_experimental.](https://github.com/pytorch-labs/float8_experimental) |Although less precise model training is quicker and less expensive, it is less reliable. Quantized training has been the subject of several excellent contemporary studies. Building on those foundations, this repository offers float8 teaching through readable and hackable code. |
|[Enchanted.](https://github.com/AugustDev/enchanted) | Enchanted is open source, Ollama compatible, elegant iOS/iPad mobile app for chatting with privately hosted models such as Llama 2, Mistral, Vicuna, Starling and more. It's essentially ChatGPT app UI that connects to your private Ollama models. You can download Enchanted from the App Store or build yourself from scratch.|
|[Introduction to point processing.](https://medium.com/ai-in-plain-english/introduction-to-point-processing-b9d022ad8cf8) | Whether you are doing medical image analysis or you use Photoshop, you are using point preprocessing|
|[MF-MOS: A Motion-Focused Model for Moving Object Segmentation.](https://github.com/scnu-rislab/mf-mos) |A new model called MF-MOS makes use of LiDAR technology to more effectively identify moving objects during autonomous driving. Using residual maps for motion capture and range pictures for semantic guiding, it distinguishes motion from semantic information in a unique way. |
|[Mctx: MCTS-in-JAX.](https://github.com/google-deepmind/mctx) |Mctx is a library with a JAX-native implementation of Monte Carlo tree search (MCTS) algorithms such as AlphaZero, MuZero, and Gumbel MuZero. For computation speed up, the implementation fully supports JIT-compilation. |
|[FireLLaVA: the first commercially permissive OSS LLaVA model.](https://fireworks.ai/blog/firellava-the-first-commercially-permissive-oss-llava-model) |A new open vision model called FireLlava can be used for commercial applications after it was trained on data. It performs similarly to the first Llava, however not quite as well as Llava 1.5. |
|[uAgents: AI Agent Framework.](https://github.com/fetchai/uAgents) |uAgents is a library developed by Fetch.ai that allows for creating autonomous AI agents in Python. With simple and expressive decorators, you can have an agent that performs various tasks on a schedule or takes action on various events. |
|[teknium/OpenHermes-2.5.](https://huggingface.co/datasets/teknium/OpenHermes-2.5) | Some of the top open models available have been trained using data from OpenHermes-2.5. More than one million high-quality data points are included in the collection. It's now available for purchase.|
|[OLMo: Open Language Model.](https://blog.allenai.org/olmo-open-language-model-87ccfc95f580) |A State-Of-The-Art, Truly Open LLM and Framework |
|[BAAI/bge-m3.](https://huggingface.co/BAAI/bge-m3) |A flexible embedding model that performs very well in multi-functionality (dense, multi-vector, and sparse retrieval), multi-linguistic (supporting more than 100 languages), and multi-granularity (managing inputs ranging from brief phrases to documents with up to 8192 tokens) is presented by the BGE-M3 project. It makes use of a hybrid retrieval pipeline, which leverages its simultaneous embedding and sparse retrieval capabilities, to combine several techniques and re-ranking for increased accuracy and generalization. |
|[RAGs.](https://github.com/run-llama/rags) |Using natural language, users can develop RAG pipelines from data sources with the help of the Streamlit app RAGs. All users need to do is specify the parameters and tasks they require from their RAG systems. You can query the RAG, and it will respond to inquiries about the information.|
|[GPT Newspaper.](https://github.com/assafelovic/gpt-newspaper) | GPT Newspaper project, an innovative autonomous agent designed to create personalized newspapers tailored to user preferences. GPT Newspaper revolutionizes the way we consume news by leveraging the power of AI to curate, write, design, and edit content based on individual tastes and interests. |


## Perspectives
|Link|description|
|---|---|
|[Many AI Safety Orgs Have Tried to Criminalize Currently-Existing Open-Source AI.](https://1a3orn.com/sub/machine-learning-bans.html) | Numerous teams are attempting to address the difficulties posed by the quickly developing field of artificial intelligence. |
|[AlphaFold found thousands of possible psychedelics. Will its predictions help drug discovery?](https://www.nature.com/articles/d41586-024-00130-8) | Researchers have doubted how useful the AI protein-structure tool will be in discovering medicines — now they are learning how to deploy it effectively. |
|[Reaching carbon neutrality requires energy-efficient training of AI.](https://www.nature.com/articles/d41586-024-00200-x) |Artificial intelligence (AI) models have achieved remarkable success, but their training requires a huge amount of energy.  |
|[What will robots think of us?](https://www.science.org/doi/10.1126/scirobotics.adn6096) | Two recent science fiction novels humorously illustrate the importance of correct robot mental models.|
|[What Can be Done in 59 Seconds: An Opportunity (and a Crisis).](https://www.oneusefulthing.org/p/what-can-be-done-in-59-seconds-an) |AI is already capable of completing several jobs in less than a minute, thus businesses and staff will need to stress the need of utilizing AI for good rather than evil. |
|[The American Dynamism 50: AI.](https://a16z.com/american-dynamism-50-ai/) |This list of 50 companies, compiled by a16z, addresses some of the most important issues facing the US in the areas of manufacturing, transportation, energy, and military. They're all utilizing AI to speed up their work in one way or another. This is an excellent insight if you're interested in practical uses of artificial intelligence. |



# ML news: Week 22 - 28 January

## Research
|Link|description|
|---|---|
|[OMG-Seg: Is One Model Good Enough For All Segmentation?.](https://lxtgh.github.io/project/omg_seg/) |OMG-Seg can handle over ten different segmentation tasks in one framework, including image-level and video-level segmentation tasks, interactive segmentation, and open-vocabulary segmentation. To our knowledge, this is the first model to unify these four directions. |
|[Instance Brownian Bridge as Texts for Open-vocabulary Video Instance Segmentation.](https://arxiv.org/abs/2401.09732v1) |BriVIS, an approach that enhances open-vocabulary Video Instance Segmentation (VIS), was created by researchers. BriVIS achieves a more precise alignment between text and video by preserving the context of object motions across video frames through the use of a method known as Brownian Bridges. |
|[Encoder-minimal and Decoder-minimal Framework for Remote Sensing Image Dehazing.](https://arxiv.org/abs/2312.07849v1) |A novel framework called RSHazeNet was created to eliminate haze from remote sensing photos. The tool makes use of cutting-edge modules to enhance image comprehension and detail preservation, improving clarity and analytical use. |
|[Supervised Fine-tuning in turn Improves Visual Foundation Models.](https://github.com/tencentarc/visft) |Drawing inspiration from supervised fine-tuning (SFT) in natural language processing such as instruction tuning, we explore the potential of fine-grained SFT in enhancing the generation of vision foundation models after their pretraining. Thus a two-stage method ViSFT (Vision SFT) is proposed to unleash the fine-grained knowledge of vision foundation models. |
|[Group Anything with Radiance Fields.](https://www.garfield.studio/) |Hierarchical grouping in 3D by training a scale-conditioned affinity field from multi-level masks |
|[DiverseEvol.](https://github.com/ofa-sys/diverseevol) | We introduce DiverseEvol, an efficient instruction-tuning method that allows the model itself to iteratively sample training subsets to improve its own performance, without any external supervision from humans or more advanced LLMs.|
|[Unleashing the Power of Large-Scale Unlabeled Data.](https://depth-anything.github.io/) |Depth Anything is trained on 1.5M labeled images and 62M+ unlabeled images jointly, providing the most capable Monocular Depth Estimation (MDE) |
|[Prompt Highlighter: Interactive Control for Multi-Modal LLMs.](https://julianjuaner.github.io/projects/PromptHighlighter/) | By enabling users to highlight specific portions of prompts, researchers present the "Prompt Highlighter," a technique that transforms text production in multi-modal language models.|
|[MM-Interleaved: Interleaved Image-Text Generative Modeling via Multi-modal Feature Synchronizer.](https://github.com/opengvlab/mm-interleaved) | A novel generative model called MM-Interleaved is very good at handling and producing interleaved image-text data.|
|[Contrastive Preference Optimization: Pushing the Boundaries of LLM Performance in Machine Translation.](https://arxiv.org/abs/2401.08417) | A different preference optimization method is now being used in machine translation. For this job, it is more data-efficient than DPO. Crucially, the goal prevented the model from suggesting correct but inadequate translations, allowing it to perform competitively on WMT.|
|[WARM: On the Benefits of Weight Averaged Reward Models.](https://arxiv.org/abs/2401.12187) |In RLHF, reward models are employed to simulate human desire; nevertheless, the model that is being aligned frequently "hacks the reward" and performs poorly. The resultant aligned model is favored 79% of the time over one aligned with a single reward model. This is achieved by combining numerous reward models that maintain a linear mode connection. Although model merging may be merely regularization, it has shown to be an effective training phase for the general language model pipeline and has performed fairly well in general models. |
|[Benchmarking Large Multimodal Models against Common Corruptions.](https://arxiv.org/abs/2401.11943) | This technical study introduces MMCBench, a new benchmark created to evaluate large multimodal models' (LMMs) consistency and dependability on a variety of tasks, including text-to-image and speech-to-text. It covers more than 100 well-known models with the goal of helping readers better comprehend how various AI systems function in practical situations.|
|[Predicting multiple conformations via sequence clustering and AlphaFold2.](https://www.nature.com/articles/s41586-023-06832-9) |AlphaFold2  has revolutionized structural biology by accurately predicting single structures of proteins. However, a protein’s biological function often depends on multiple conformational substates, and disease-causing point mutations often cause population changes within these substates |
|[HEDNet: A Hierarchical Encoder-Decoder Network for 3D Object Detection in Point Clouds.](https://arxiv.org/abs/2310.20234v1) |HEDNet is a novel encoder-decoder network that aims to improve autonomous cars' ability to recognize 3D objects by tackling the problem of sparse point distribution in 3D situations. |
|[Prompt Pool based Class-Incremental Continual Learning for Dialog State Tracking.](https://github.com/thu-spmi/ppt2dst) | This project proposes a novel prompt pool approach to recording the status of dialogs that does not need task IDs during testing, allowing it to adjust to changing user requirements.|
|[DittoGym: Learning to Control Soft Shape-Shifting Robots.](https://dittogym.github.io/) |A major problem with soft robotics is the wide control space. In this study, a simulator with a variety of tasks for handling soft objects that resemble "dittos" is introduced. It includes several powerful baselines, visualization, and utilities. |
|[SGTR+: End-to-end Scene Graph Generation with Transformer.](https://arxiv.org/abs/2401.12835v1) | A novel technique that researchers have created speeds up and improves the efficiency of the scene graph creation process. Their transformer-based approach aims to enhance the model's comprehension and interconnection of many parts in a picture, resulting in enhanced performance on complex tasks.|
|[DreamSim: Learning New Dimensions of Human Visual Similarity using Synthetic Data.](https://dreamsim-nights.github.io/) | Based on how similar two photographs are to one another, image similarity systems provide a score. This study builds upon earlier approaches, mainly by using artificial intelligence and human preferences.|
|[SegMamba: Long-range Sequential Modeling Mamba For 3D Medical Image Segmentation.](https://arxiv.org/abs/2401.13560v2) | A model called SegMamba is intended for 3D medical image segmentation. In comparison to the Transformer architecture, it provides a more effective option. |
|[SFC: Shared Feature Calibration in Weakly Supervised Semantic Segmentation.](https://github.com/barrett-python/sfc) |To improve semantic segmentation, researchers have created the Shared Feature Calibration (SFC) technique. |


## News
|Link|description|
|---|---|
|[OpenAI’s Sam Altman Is Raising Money to Set Up AI Chip Factories.](https://beebom.com/openai-sam-altman-raising-money-ai-chip-factories/) |A new report reveals that OpenAI CEO Sam Altman is gearing up to raise money to set up his own network of AI chip factories. |
|[Google DeepMind scientists in talks to leave and form AI startup.](https://finance.yahoo.com/news/google-deepmind-scientists-talks-leave-193114887.html) |A pair of scientists at Google's artificial intelligence subsidiary DeepMind is in talks with investors to form an AI startup in Paris, Bloomberg News reported on Friday, citing people familiar with the conversations. |
|[The AI phones are coming.](https://www.theverge.com/2024/1/16/24040562/samsung-unpacked-galaxy-ai-s24) |We’re tired of tapping through apps on our phones all day. Can Samsung show us an AI tool to save us? |
|[How Microsoft found a potential new battery material using AI.](https://www.theverge.com/24027031/microsoft-new-solid-state-battery-material-ai) |Advances in AI and high-performance computing are changing the way scientists look for new battery materials. |
|[Google will pitch Bard Advanced as providing ‘complex, better responses’.](https://9to5google.com/2024/01/19/bard-advanced-better-responses/) |At the start of December, Google said Gemini Ultra would launch in early 2024 and be available in “Bard Advanced.” When it launches, Google will position Bard Advanced as providing “complex, better responses.” |
|[Stability AI unveils smaller, more efficient 1.6B language model as part of ongoing innovation.](https://venturebeat.com/ai/stability-ai-unveils-smaller-more-efficient-1-6b-language-model-as-part-of-ongoing-innovation/) |Stability AI, the vendor that is perhaps best known for its stable diffusion text to image generative AI technology, today released one of its smallest models yet, with the debut of  Stable LM 2 1.6B. |
|[Tesla finally releases FSD v12, its last hope for self-driving.](https://electrek.co/2024/01/22/tesla-releases-fsd-v12-last-hope-self-driving/) |Tesla has finally started releasing its FSD Beta v12 update to customers, which is sort of its last hope to deliver on its self-driving promises. |
|[Code LoRA From Scratch.](https://lightning.ai/lightning-ai/studios/code-lora-from-scratch) | LoRA, which stands for Low-Rank Adaptation, is a popular technique to finetune LLMs more efficiently. Instead of adjusting all the parameters of a deep neural network, LoRA focuses on updating only a small set of low-rank matrices. This Studio explains how LoRA works by coding it from scratch, which is an excellent exercise for looking under the hood of an algorithm.|
|[Microsoft’s Nadella Wants Stability at OpenAI, Not Control.](https://www.bloomberg.com/news/articles/2024-01-16/microsoft-s-nadella-wants-stability-at-openai-not-more-control) |In the midst of regulatory reviews in the EU and the UK, Microsoft CEO Satya Nadella is happy with the current condition of Microsoft's cooperation with OpenAI, emphasizing stability above control. He highlights both Microsoft's substantial funding in OpenAI and their own autonomous AI research. |
|[ElevenLabs Releases New Voice AI Products and Raises $80M Series B.](https://elevenlabs.io/blog/series-b/) | To strengthen its position in voice AI research and product development|
|[Google Chrome gains AI features, including a writing helper, theme creator, and tab organizer.](https://techcrunch.com/2024/01/23/google-chrome-gains-ai-features-including-a-writing-helper-theme-creator-and-tab-organizer/) | Google’s Chrome web browser is getting an infusion of AI technology in the latest release. The company announced today it’s soon adding a trio of new AI-powered features to Chrome for Mac and Windows, including a way to smartly organize your tabs, customize your theme, and get help when writing things on the web — like forum posts, online reviews, and more.|
|[Anthropic researchers find that AI models can be trained to deceive.](https://techcrunch.com/2024/01/13/anthropic-researchers-find-that-ai-models-can-be-trained-to-deceive/) | Most humans learn the skill of deceiving other humans. So can AI models learn the same? Yes, the answer seems — and terrifyingly, they’re exceptionally good at it.|
|[Google shows off Lumiere, a space-time diffusion model for realistic AI videos .](https://venturebeat.com/ai/google-shows-off-lumiere-a-space-time-diffusion-model-for-realistic-ai-videos/) |Lumiere, a space-time diffusion model proposed by researchers from Google, Weizmann Institute of Science and Tel Aviv University to help with realistic video generation. |
|[Adept Fuyu-Heavy: A new multimodal model.](https://www.adept.ai/blog/adept-fuyu-heavy) |Adept Fuyu-Heavy is a new multimodal model designed specifically for digital agents. In particular, Fuyu-Heavy scores higher on the MMMU benchmark than even Gemini Pro.|
|[Report: Apple Making ‘Significant’ Push to Bring AI to iPhones.](https://www.pymnts.com/apple/2024/report-apple-making-significant-push-to-bring-ai-to-iphones/) |Apple is reportedly making a major push to bring artificial intelligence (AI) to the iPhone. |
|[Hugging Face and Google partner for open AI collaboration.](https://huggingface.co/blog/gcp-partnership) |Today, we are thrilled to announce our strategic partnership with Google Cloud to democratize good machine learning. We will collaborate with Google across open science, open source, cloud, and hardware to enable companies to build their own AI with the latest open models from Hugging Face and the latest cloud and hardware features from Google Cloud. |
|[OpenAI's New embedding models and API updates.](https://openai.com/blog/new-embedding-models-and-api-updates) | We are launching a new generation of embedding models, new GPT-4 Turbo and moderation models, new API usage management tools, and soon, lower pricing on GPT-3.5 Turbo.|
|[Announcing Qdrant's $28M Series A Funding Round.](https://qdrant.tech/blog/series-a-funding-round/) | The firm behind the vector database, which powers some of ChatGPT and X's "More like this," has secured funds to enhance its corporate solutions and extend its Rust-based vector store.|


## Resources
|Link|description|
|---|---|
|[nanotron.](https://github.com/huggingface/nanotron) |The objective of this library is to provide easy distributed primitives in order to train a variety of models efficiently using 3D parallelism. |
|[DataTrove.](https://github.com/huggingface/datatrove) |DataTrove is a library to process, filter and deduplicate text data at a very large scale. It provides a set of prebuilt commonly used processing blocks with a framework to easily add custom functionality. |
|[CaptionIMG.](https://github.com/ANTONIOPSD/CaptionIMG) |Simple program written in python to manually caption your images (or any other file types) so you can use them for AI training. I use it for Dreambooth training (StableDiffusion). |
|[AI Toolkit.](https://github.com/linkdd/aitoolkit) | AI Toolkit is a header-only C++ library which provides tools for building the brain of your game's NPCs.|
|[Face Mixer Diffusion.](https://www.justinpinkney.com/blog/2024/face-mixer-diffusion/?utm_source=tldrai) | This piece demonstrates how to clone faces in photos using diffusion. Although there are other methods for creating deep fakes, diffusion is intriguing since it allows for the necessary inpainting of other image elements.|
|[Self-Rewarding Language Model.](https://github.com/lucidrains/self-rewarding-lm-pytorch) |Implementation of the training framework proposed in the Self-Rewarding Language Model, from MetaAI |
|[snorkelai/Snorkel-Mistral-PairRM-DPO.](https://huggingface.co/snorkelai/Snorkel-Mistral-PairRM-DPO) | A powerful new Mistral tune that creates a DPO-compatible dataset by cleverly using poor supervision and synthetic data. Numerous iterations of the described procedure can be used for a broad range of corporate use cases.|
|[nanoColBERT.](https://github.com/Hannibal046/nanoColBERT) | ColBERT is a powerful late-interaction model that can perform both retrieval and reranking.|
|[RPG-DiffusionMaster.](https://github.com/yangling0818/rpg-diffusionmaster) | RPG is a powerful training-free paradigm that can utilize proprietary MLLMs (e.g., GPT-4, Gemini-Pro) or open-source local MLLMs (e.g., miniGPT-4) as the prompt recaptioner and region planner with our complementary regional diffusion to achieve SOTA text-to-image generation and editing. Our framework is very flexible and can generalize to arbitrary MLLM architectures and diffusion backbones. |
|[Matrix Multiplication: Optimizing the code from 6 hours to 1 sec.](https://vaibhaw-vipul.medium.com/matrix-multiplication-optimizing-the-code-from-6-hours-to-1-sec-70889d33dcfa) | A brief read about matrix multiplication optimizations particular to certain hardware and a generic procedure to accelerate AI programs.|
|[SyncTalk: Mastering Realism in Talking Head Videos.](https://ziqiaopeng.github.io/synctalk/) |A significant advancement in realistic talking head videos is SyncTalk. It solves earlier problems with lip motions, expressions, and facial identity synchronization. |
|[Hallucination Leaderboard.](https://github.com/vectara/hallucination-leaderboard) |Public LLM leaderboard computed using Vectara's Hallucination Evaluation Model. This evaluates how often an LLM introduces hallucinations when summarizing a document. We plan to update this regularly as our model and the LLMs get updated over time. |
|[Embedding English Wikipedia in under 15 minutes.](https://modal.com/blog/embedding-wikipedia) | Modal provides a serverless solution for organizations grappling with scaling workloads. Modal’s technology enables rapid scaling across many GPUs, which we can use to run large-scale workloads, such as generating embeddings for a massive text dataset, at lightning speed.|
|[Concrete Steps to Get Started in Transformer Mechanistic Interpretability.](https://www.neelnanda.io/mechanistic-interpretability/getting-started) | Among the founders of Mechanistic Interpretability (MI) is Neel Nanda. This serves as his entry guide into the industry. It has two hundred specific open-ended questions. The research of language models' quantitative values, or MI, involves actually examining neurons. Even though there hasn't been much progress in this area of study yet, it is accessible because it doesn't demand a lot of processing power.|
|[The Song Describer Dataset: a Corpus of Audio Captions for Music-and-Language Evaluation.](https://github.com/mulab-mir/song-describer-dataset) | SDD contains ~1.1k captions for 706 permissively licensed music recordings. It is designed for use in evaluation of models that address music-and-language (M&L) tasks such as music captioning, text-to-music generation and music-language retrieval.|
|[DiffMoog: A Modular Differentiable Commercial-like Synthesizer.](https://github.com/aisynth/diffmoog) | This repo contains the implementation of DiffMoog, a differential, subtractive, modular synthesizer, incorporating standard architecture and sound modules commonly found in commercial synthesizers.|
|[TensorDict.](https://github.com/pytorch/tensordict) |TensorDict is a dictionary-like class that inherits properties from tensors, such as indexing, shape operations, casting to device or point-to-point communication in distributed settings. The main purpose of TensorDict is to make code-bases more readable and modular by abstracting away tailored operations |
|[Evaluation Metrics for LLM Applications In Production.](https://docs.parea.ai/blog/eval-metrics-for-llm-apps-in-prod) |How to measure the performance of LLM applications without ground truth data. |
|[Asynchronous Local-SGD Training for Language Modeling.](https://github.com/google-deepmind/asyncdiloco) |This repository contains a Colab notebook that presents a minimal toy example replicating the observed optimization challenge in asynchronous Local-SGD. The task is to perform classification on a mixture of mixtures of Gaussian data. |
|[SpeechGPT: Speech Large Language Models.](https://github.com/0nutation/speechgpt) |A novel speech synthesis model called SpeechGPT-Gen effectively manages the intricacies of language and voice traits. |
|[LLM Steer.](https://github.com/Mihaiii/llm_steer) |A Python module to steer LLM responses towards a certain topic/subject and to enhance capabilities (e.g., making it provide correct responses to tricky logical puzzles more often). A practical tool for using activation engineering by adding steer vectors to different layers of a Large Language Model (LLM). It should be used along with the transformers library. |
|[RoMa: A lightweight library to deal with 3D rotations in PyTorch..](https://github.com/naver/roma) |RoMa (which stands for Rotation Manipulation) provides differentiable mappings between 3D rotation representations, mappings from Euclidean to rotation space, and various utilities related to rotations. It is implemented in PyTorch and aims to be an easy-to-use and reasonably efficient toolbox for Machine Learning and gradient-based optimization.|
|[AgentBoard: An Analytical Evaluation Board of
Multi-Turn LLM Agent.](https://hkust-nlp.github.io/agentboard/) | AgentBoard is a benchmark designed for multi-turn LLM agents, complemented by an analytical evaluation board for detailed model assessment beyond final success rates. Main Performance of different LLMs across various environments are shown below, please check our Result for more details.|
|[makeMoE: Implement a Sparse Mixture of Experts Language Model from Scratch.](https://huggingface.co/blog/AviSoori1x/makemoe-from-scratch) | This blog walks through implementing a sparse mixture of experts language model from scratch. This is inspired by and largely based on Andrej Karpathy's project 'makemore' and borrows a number of re-usable components from that implementation. |


## Perspectives
|Link|description|
|---|---|
|[Text-to-Video: The Task, Challenges and the Current State.](https://huggingface.co/blog/text-to-video) |Text-to-video is next in line in the long list of incredible advances in generative models. How do these models work, how do they differ from text-to-image models, and what kind of performance can we expect from them?|
|[My AI Timelines Have Sped Up (Again).](https://www.alexirpan.com/2024/01/10/ai-timelines-2024.html) |In light of developments in scaling up models, the author updated their forecasts for the AI timetable. As of right now, they predict that artificial general intelligence will be achieved with a 10% probability by 2028 and a 50% likelihood by 2045. The efficacy of massive language models and the knowledge that numerous intelligent capabilities may arise at scale are credited with these changes. |
|[Should The Future Be Human?.](https://www.astralcodexten.com/p/should-the-future-be-human) | Elon Musk and Larry Page have a deep disagreement over the possible risks associated with artificial intelligence. Page has called Musk a "speciesist" for favoring humans over digital life forms, which has caused a gap in their friendship. This demonstrates the necessity for careful and deliberate development of AI technology and reflects the larger discussion on the influence of AI, which includes worries about consciousness, individuation, art, science, philosophy, and the potential for mergers between humans and AI.|
|[Computers make mistakes and AI will make things worse — the law must recognize that.](https://www.nature.com/articles/d41586-024-00168-8) | A tragic scandal at the UK Post Office highlights the need for legal change, especially as organizations embrace artificial intelligence to enhance decision-making.|
|[Google AI has better bedside manner than human doctors — and makes better diagnoses.](https://www.nature.com/articles/d41586-024-00099-4) | Researchers say their artificial-intelligence system could help to democratize medicine.|
|[Tech developers must respect equitable AI access.](https://www.nature.com/articles/d41586-024-00185-7) | We argue for a legal framework to ensure equitable access to artificial intelligence (AI) tools, such as ChatGPT, to avoid limiting their benefits to a privileged few|
|[Seven technologies to watch in 2024.](https://www.nature.com/articles/d41586-024-00173-x) | Advances in artificial intelligence are at the heart of many of this year’s most exciting areas of technological innovation|
|[If AI Were Conscious, How Would We Know?.](https://suzitravis.substack.com/p/if-ai-were-conscious-how-would-we) | When discussing AI consciousness, references to Searle's Chinese Room Thought Experiment and the Turing Test are frequently made. The former examines whether an AI's conduct can be distinguished from that of a human, while the latter contends that exterior behavior is insufficient to demonstrate consciousness. Given that our knowledge of consciousness in AI is mostly derived on functionalist theories and human experiences, this argument emphasizes how difficult it is to define and identify consciousness in AI.|
|[AI today and trends for an AI future.](https://davidtsong.substack.com/p/ai-today-and-trends-for-an-ai-future) | A survey of experts on: How are early adopters using AI today? Where is AI going in 2024?|




# ML news: Week 15 - 21 January

## Research
|Link|description|
|---|---|
|[I am a Strange Dataset: Metalinguistic Tests for Language Models.](https://arxiv.org/abs/2401.05300) |An example of a self-referential challenge phrase is "the last word in this sentence is is." This kind of phrase is extremely difficult for language models to handle. This work presents a dataset and some assessments aimed at enhancing the metalinguistic capabilities of language models. |
|[PIXART-δ: Fast and Controllable Image Generation with Latent Consistency Models.](https://arxiv.org/abs/2401.05252) | A complementary line of inquiry to the well-known Stable Diffusion collection of picture generating models has been PixArt. With the use of ControlNet-style prompting and latent consistency models, this work improves control and speeds up creation.|
|[Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training.](https://arxiv.org/abs/2401.05566) |Anthropic has published some really intriguing research in which a sleeper phrase designed to induce a particular response is used to deliberately poison a language model. It discovered that this kind of model could not be "aligned" with the robust system that it utilized for its production models. In other words, once the model was poisoned, negative behavior could not be undone with the resources available today. |
|[PALP: Prompt Aligned Personalization of Text-to-Image Models.](https://prompt-aligned.github.io/) | Right now, Dreambooth is the most effective way to customize an image model. Prompt alignment is composable and significantly increases adherence to the prompt.|
|[INTERS: Unlocking the Power of Large Language Models in Search with Instruction Tuning.](https://arxiv.org/abs/2401.06532v1) |We introduce a novel instruction tuning dataset, INTERS, encompassing 21 tasks across three fundamental IR categories: query understanding, document understanding, and query-document relationship understanding. The data are derived from 43 distinct datasets with manually written templates |
|[Transforming Image Super-Resolution: A ConvFormer-based Efficient Approach.](https://arxiv.org/abs/2401.05633v1) |A new dataset called INTERS has been created by researchers with the goal of enhancing the performance of big language models such as Mistral and LLaMA in information retrieval tasks. |
|[HiCMAE.](https://github.com/sunlicai/hicmae) | A revolutionary self-supervised learning framework called HiCMAE was created to improve AVER, or Audio-Visual Emotion Recognition. This method leverages large-scale pre-training on unlabeled audio-visual data to get over data scarcity issues.|
|[Language Enhanced Multi-modal Grounding Model.](https://lzw-lzw.github.io/LEGO.github.io/) | A novel end-to-end multimodal grounding model called LEGO exhibits sophisticated comprehension and grounding skills across several modalities, including pictures, sounds, and videos.|
|[The Unreasonable Effectiveness of Easy Training Data for Hard Tasks.](https://arxiv.org/abs/2401.06751) | Challenging data has long been assumed to be necessary to solve challenging issues, yet this data is noisy and difficult to identify. This work demonstrates that models may be made far more capable of generating solutions to difficult situations by fine-tuning them on related but easy data. A further piece of evidence to back up fine-tuning is that it elicits information rather than imparts it.|
|[Mutual Distillation Learning For Person Re-Identification.](https://arxiv.org/abs/2401.06430v1) | By merging two distinct approaches, researchers have created a revolutionary method called Mutual Distillation Learning For Person Re-identification (MDPR) that improves person re-identification.|
|[Large language models help computer programs to evolve.](https://www.nature.com/articles/s41586-023-06924-6) | A branch of computer science known as genetic programming has been given a boost with the application of large language models that are trained on the combined intuition of the world’s programmers. [comment here.](https://www.nature.com/articles/d41586-023-03998-0)|
|[Solving olympiad geometry without human demonstrations.](https://www.nature.com/articles/s41586-023-06747-5) |Proving mathematical theorems at the olympiad level represents a notable milestone in human-level automated reasoning [Blog post from DeepMind.](https://deepmind.google/discover/blog/alphageometry-an-olympiad-level-ai-system-for-geometry/) |
|[Fast and Expressive LLM Inference with RadixAttention and SGLang.](https://lmsys.org/blog/2024-01-17-sglang) |Two new advances for language model inference have been provided by LMSYS. The first is a backend tweak that raises the performance of tokens per second overall. Prompting parallelism is possible with the second prompting approach, which is an embedded language tailored to a particular domain. |
|[Forging Vision Foundation Models for Autonomous Driving: Challenges, Methodologies, and Opportunities.](https://arxiv.org/abs/2401.08045) | The difficulty of creating Vision Foundation Models (VFMs) especially for autonomous driving is examined in this research. It offers insights into pre-training, task adaptability, and data preparation in AI by examining more than 250 research articles, showcasing state-of-the-art methods such as 3D Gaussian Splatting and NeRF.|
|[DoraemonGPT: Toward Understanding Dynamic Scenes with Large Language Models.](https://arxiv.org/abs/2401.08392v1) | By concentrating on video tasks, DoraemonGPT, a novel artificial intelligence system built on huge language models, advances our comprehension of dynamic real-world events. For effective spatial-temporal querying, it transforms films into a symbolic memory. It also includes specialized tools and an innovative planner for handling challenging tasks.|
|[Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering.](https://github.com/codium-ai/alphacodium) | AlphaCodium presents a new method to improve LLMs' code creation. As evidenced by the CodeContests dataset, this multi-stage, test-based iterative procedure greatly increases the accuracy of models such as GPT-4 in tackling complicated programming tasks.|
|[Foundations of Vector Retrieval.](https://arxiv.org/abs/2401.09350) |Almost all of the information one may want to know about the current status of the vector retrieval area is covered in this enormous document. It will take some time to go through this important resource. |
|[Learning to Follow Object-Centric Image Editing Instructions Faithfully.](https://arxiv.org/abs/2310.19145v1) |This study addresses issues such as ambiguous instructions and selectively selecting regions of the image to modify, hence enhancing the quality of photographs modified with natural language instructions. |


## News
|Link|description|
|---|---|
|[OpenAI changes policy to allow military applications.](https://techcrunch.com/2024/01/12/openai-changes-policy-to-allow-military-applications/) |In an unannounced update to its usage policy, OpenAI has opened the door to military applications of its technologies. |
|[Using AI, MIT researchers identify a new class of antibiotic candidates.](https://www.freethink.com/health/ai-antibiotics) |These compounds can kill methicillin-resistant Staphylococcus aureus (MRSA), a bacterium that causes deadly infections. |
|[Microsoft wants to automatically launch its Copilot AI on some Windows 11 devices.](https://www.theverge.com/2024/1/12/24035637/microsoft-windows-11-copilot-ai-chatbot-automatically-open-boot-startup) | You might see Copilot start automatically opening on Windows 11 soon, but only with certain display situations.|
|[Microsoft launches Copilot Pro for $20 per month per user.](https://searchengineland.com/microsoft-launches-copilot-pro-for-20-per-month-per-user-436526) | Copilot Pro gives you the latest features and best models that Microsoft AI has to offer.|
|[How OpenAI is approaching 2024 worldwide elections.](https://openai.com/blog/how-openai-is-approaching-2024-worldwide-elections) | We’re working to prevent abuse, provide transparency on AI-generated content, and improve access to accurate voting information.|
|[Sakana AI raises $30m seed.](https://sakana.ai/seed-round/) |In Tokyo, Sakana.ai is constructing a state-of-the-art research facility to create foundation models that are more compact and effective. David Ha and Llion Jones, two former Google researchers who are credited with innovations including Transformers, World Models, and LoRA, formed the business. To lead this initiative and establish Tokyo as a leader in AI, it has received a $30 million seed round from Jon Chu at Khosla Ventures and Brandon Reeves at Lux Capital. |
|[Stable Code 3B: Coding on the Edge.](https://stability.ai/news/stable-code-2024-llm-code-completion-release) |Stable Code 3B is a 3 billion parameter Large Language Model (LLM), allowing accurate and responsive code completion at a level on par with models such as CodeLLaMA 7b that are 2.5x larger. |
|[OpenAI announces team to build ‘crowdsourced’ governance ideas into its models.](https://techcrunch.com/2024/01/16/openai-announces-team-to-build-crowdsourced-governance-ideas-into-its-models/) | OpenAI says it wants to implement ideas from the public about how to ensure its future AI models “align to the values of humanity.”|
|[OpenAI must defend ChatGPT fabrications after failing to defeat libel suit.](https://arstechnica.com/tech-policy/2024/01/openai-must-defend-chatgpt-fabrications-after-failing-to-defeat-libel-suit) | ChatGPT users may soon learn whether false outputs will be allowed to ruin lives.|
|[Samsung’s S24 and S24 Plus put new AI smarts in a polished package.](https://www.theverge.com/2024/1/17/24040372/samsung-galaxy-s24-plus-price-release-date-specs-features-ai-artificial-intelligence) |The two smaller siblings of the Galaxy S24 Ultra are very similar-looking phones to last year’s devices, but they include new AI-powered features and a promise of seven years of software and security updates. |
|[OpenAI announces first partnership with a university.](https://www.cnbc.com/2024/01/18/openai-announces-first-partnership-with-a-university.html) | OpenAI on Thursday announced its first partnership with a higher education institution.|
|[Mark Zuckerberg’s new goal is creating artificial general intelligence.](https://www.theverge.com/2024/1/18/24042354/mark-zuckerberg-meta-agi-reorg-interview) | And he wants Meta to open source it. Eventually. Maybe.|
|[8bit HippoAttention: Up to 3X Faster Compared to FlashAttentionV2.](https://blog.hippoml.com/8bit-hippoattention-up-to-3x-faster-compared-to-flashattentionv2-8f9def90b482) | 8bit in neural networks is not a new concept. However, shipping 8bit models in the real world on a large scale is challenging.|
|[Microsoft makes its AI-powered reading tutor free.](https://techcrunch.com/2024/01/18/microsoft-makes-its-ai-powered-reading-tutor-free/) | Microsoft today made Reading Coach, its AI-powered tool that provides learners with personalized reading practice, available at no cost to anyone with a Microsoft account.|
|[Ousted Twitter CEO Parag Agrawal is back with an AI startup; gets $30 mn in funding led by Khosla Ventures.](https://www.msn.com/en-in/money/news/ousted-twitter-ceo-parag-agrawal-is-back-with-an-ai-startup-gets-30-mn-in-funding-led-by-khosla-ventures/ar-AA1mQq92) |  Agrawal is back with an artificial intelligence (AI) startup that has already raised $30 million in funding that is led by Khosla Ventures.|

## Resources
|Link|description|
|---|---|
|[Moore-AnimateAnyone.](https://github.com/MooreThreads/Moore-AnimateAnyone) |AnimateAnyone is a fantastic video control model that animates the person in the control image by using skeletal motion and an image as input. This code replicates that work in an open manner. |
|[surya.](https://github.com/VikParuchuri/surya) | Surya is a multilingual document OCR toolkit|
|[David Attenborough narrates your life.](https://github.com/cbh123/narrator) |Using a combination of GPT4-V, top-of-the-line text-to-speech, and some computer capture software, you can have someone like David Attenborough narrate everything that is happening in your life. |
|[Create translations that follow your speech style.](https://seamless.metademolab.com/expressive) |Meta has a new demo for seamless voice cloning and translation between languages. SeamlessExpressive is an AI model that aims to maintain expressive speech style elements in the translation|
|[Vanna.](https://github.com/vanna-ai/vanna) | Vanna is an MIT-licensed open-source Python RAG (Retrieval-Augmented Generation) framework for SQL generation and related functionality.|
|[GRDBIS.](https://github.com/liuxy1103/grdbis) |Graph Relation Distillation for Efficient Biomedical Instance Segmentation |
|[AQLM.](https://github.com/vahe1994/aqlm) | Official PyTorch implementation for Extreme Compression of Large Language Models via Additive Quantization|
|[RotationDrag.](https://github.com/tony-lowe/rotationdrag) |RotationDrag: Point-based Image Editing with Rotated Diffusion Features |
|[AutoGGUF.](https://colab.research.google.com/drive/1P646NEg33BZy4BfLDNpTz0V0lwIU3CHu) |GGUF is a format that allows many quantization methods and is used to run models with llama cpp. The quantization is automated by this notebook; it may not be effective for all models, but it is for the majority. |
|[Listening with LLM.](https://paul.mou.dev/posts/2023-12-31-listening-with-llm/) |consolidate learnings on how to finetune Large Language Models (LLMs) to process audio, with the eventual goal of being able to build and host a LLM able to describe human voices. |
|[PhotoMaker: Customizing Realistic Human Photos via Stacked ID Embedding.](https://github.com/TencentARC/PhotoMaker) |Generating customized, styled images is one of the most popular applications of generative picture models. Previously, DreamBooth or LoRA training were needed for this. Now, with just one picture and ID embeddings, you may significantly increase quality while lowering computing costs. |
|[Content Consistent Super-Resolution.](https://github.com/csslc/CCSR) |Improving the Stability of Diffusion Models for Content Consistent Super-Resolution |
|[FilCo.](https://github.com/zorazrw/filco) | This repository contains the code and data about the project: Learning to Filter Context for Retrieval-Augmented Generation|
|[haiku_dpo .](https://huggingface.co/datasets/davanstrien/haiku_dpo) |Dataset to help align models to write correct Haiku’s. |
|[sanity-checks-revisited.](https://github.com/annahedstroem/sanity-checks-revisited) |This repository contains the code and experiments for the paper Sanity Checks Revisited: An Exploration to Repair the Model Parameter Randomisation Test |
|[MAGNeT.](https://huggingface.co/collections/facebook/magnet-659ef0ceb62804e6f41d1466) | Masked Audio Generation using a Single Non-Autoregressive Transformer|
|[Tiny Narrations.](https://github.com/sfcompute/tinynarrations) |A text-to-speech read variant of the well-known (and compact) Tiny Stories dataset is called Tiny Narrations. On the SF Compute H100 cluster, it makes use of XTTS2. |
|[Interconnects Tools for Multimodal Blogging!.](https://github.com/natolambert/interconnects-tools) | Python tools for easily translating your blog content to podcasts & YouTube|
|[ALMA: Advanced Language Model-based translator.](https://github.com/fe1ixxu/alma) |ALMA (Advanced Language Model-based TrAnslator) is a many-to-many LLM-based translation model, which adopts a new translation model paradigm: it begins with fine-tuning on monolingual data and is further optimized using high-quality parallel data. This two-step fine-tuning process ensures strong translation performance. |
|[Privy.](https://github.com/srikanth235/privy) |A privacy-first coding assistant. |
|[UV-SAM: Adapting Segment Anything Model for Urban Village Identification.](https://github.com/tsinghua-fib-lab/uv-sam) |This work presents UV-SAM, a modified version of the Segment Anything Model and the Vision Foundation Model that may be used to precisely locate urban village borders on satellite imagery. UV-SAM provides an effective substitute for conventional field surveys by integrating various image representations to achieve accurate detection. |
|[ml-aim.](https://github.com/apple/ml-aim) | We introduce AIM a collection of vision models pre-trained with an autoregressive generative objective. |
|[compose-and-conquer.]() |Official implementation of Compose and Conquer: Diffusion-Based 3D Depth Aware Composable Image Synthesis. Excell for placing objects in three-dimensional space |
|[Vlogger.](https://github.com/zhuangshaobin/vlogger) |we present Vlogger, a generic AI system for generating a minute-level video blog (i.e., vlog) of user descriptions. Different from short videos with a few seconds, vlog often contains a complex storyline with diversified scenes, which is challenging for most existing video generation approaches.  |
|[trapped-in-texture-bias.](https://github.com/johannestheo/trapped-in-texture-bias) |This is the official code release for the paper Trapped in texture bias? A large scale comparison of deep instance segmentation |
|[MegaDolphin-120b.](https://huggingface.co/cognitivecomputations/MegaDolphin-120b) |MegaDolphin-2.2-120b is a transformation of Dolphin-2.2-70b |
|[TACO(Topics in Algorithmic COde generation dataset).](https://github.com/FlagOpen/TACO) |TACO (Topics in Algorithmic COde generation dataset) is a dataset focused on algorithmic code generation, designed to provide a more challenging training dataset and evaluation benchmark for the code generation model field.  |


## Perspectives
|Link|description|
|---|---|
|[The Case for Cyborgs.](https://every.to/p/the-case-for-cyborgs) |Augmenting human intelligence beyond AI will take us much further than creating something new |
|[Past, Present, and Future of AI with Vijay Pande.](https://a16z.com/podcast/past-present-and-future-of-ai-with-vijay-pande/) |A forty-minute contemplation about AI featuring an outlook for the future. |
|[AI Will Transform the Global Economy. Let’s Make Sure It Benefits Humanity.](https://www.imf.org/en/Blogs/Articles/2024/01/14/ai-will-transform-the-global-economy-lets-make-sure-it-benefits-humanity) |AI will affect almost 40 percent of jobs around the world, replacing some and complementing others. We need a careful balance of policies to tap its potential |
|[AI is Not the Solution to All Our Educational Challenges.](https://nickpotkalitsky.substack.com/p/ai-is-not-the-solution-to-all-our) |Empowering Students with an Immersive Mindset for Navigating an Unpredictable World |
|[The Lazy Tyranny of the Wait Calculation.](https://www.oneusefulthing.org/p/the-lazy-tyranny-of-the-wait-calculation) |The "Wait Calculation" idea suggests holding off on undertaking certain tasks or going on a space mission to Barnard's Star until technology has advanced enough to save a considerable amount of time and effort. This strategy must be weighed against the unpredictable nature of technology advancement and the possibility of learning losses. |
|[What counts as plagiarism? Harvard president’s resignation sparks debate.](https://www.nature.com/articles/d41586-024-00035-6) |Allegations against Claudine Gay have left researchers arguing over academic standards and practices. |
|[‘Set it and forget it’: automated lab uses AI and robotics to improve proteins.](https://www.nature.com/articles/d41586-024-00093-w) |A self-driving lab system spent half a year engineering enzymes to work at higher temperatures. |
|[The consciousness wars: can scientists ever agree on how the mind works?.](https://www.nature.com/articles/d41586-024-00107-7) | There are dozens of theories of how the brain produces conscious experience, and a new type of study is testing some of them head-to-head.|
|[Centres of Excellence in AI for global health equity — a strategic vision for LMICs.](https://www.nature.com/articles/d41586-024-00113-9) |We propose that Centres of Excellence should be established in low- and middle-income countries (LMICs) to enable artificial intelligence (AI) to deliver equity in health care. |
|[Does generative AI help academics to do more or less?.](https://www.nature.com/articles/d41586-024-00115-7) |UK academics use generative artificial intelligence (AI) in their work mainly because it improves task efficiency, saves time and labour, and boosts competitiveness  |
|[Evaluations Are All We Need.](https://www.strangeloopcanon.com/p/evaluations-are-all-we-need) |This essay examines the difficulties in assessing LLMs and contrasts them with assessments of employees conducted by humans. It addresses the challenge of gauging the practicality and intelligence of LLMs, emphasizing the shortcomings of existing assessment techniques and the demand for more efficient ones. |
|[The Road To Honest AI.](https://www.astralcodexten.com/p/the-road-to-honest-ai) |Identifying and modifying honesty-related vectors within the AI or employing unrelated questions to discover lying tendencies based on the AI's response consistency are two strategies suggested by recent studies to regulate AI honesty. |


# ML news: 8 - 14 January

## Research
|Link|description|
|---|---|
|[GUESS:GradUally Enriching SyntheSis for Text-Driven Human Motion Generation.]() |A human motion from text framework named GUESS has been introduced. It reduces intricate human stances to more abstract forms on several levels, resulting in a more steady and condensed synthesis of motion from text. |
|[Learning to Prompt with Text Only Supervision for Vision-Language Models.](https://muzairkhattak.github.io/ProText/) | This project presents a technique to keep the generalization capabilities of CLIP-like vision-language models while adapting them for different tasks. Prompts are learned from LLM data, so labeled images are not necessary.|
|[LLaVA-ϕ: Efficient Multi-Modal Assistant with Small Language Model.](https://arxiv.org/abs/2401.02330v1) |In this paper, we introduce LLaVA-ϕ (LLaVA-Phi), an efficient multi-modal assistant that harnesses the power of the recently advanced small language model, Phi-2, to facilitate multi-modal dialogues. |
|[V*: Guided Visual Search as a Core Mechanism in Multimodal LLMs.](https://vstar-seal.github.io/) |We introduce V*, an LLM-guided visual search mechanism that employs the world knowledge in LLMs for efficient visual querying. When combined with an MLLM, this mechanism enhances collaborative reasoning, contextual understanding, and precise targeting of specific visual elements. |
|[DeepSeek LLM: Scaling Open-Source Language Models with Longtermism.](https://arxiv.org/abs/2401.02954) |The DeepSeek LLM was one of the greatest coding models available last year. In several benchmarks, it achieved closeness to GPT-3.5 (despite being probably three times larger). A technical study has been made public with details on model training, token counts, model architecture, and other topics. |
|[Denoising Vision Transformers.](https://arxiv.org/abs/2401.02957) |The vision community has been overtaken by Vision Transformers (ViT). They occasionally still exhibit artifacts in their embeddings that resemble grids. The community is reluctant to use them for jobs that come after because of this. This study suggests a positional embeddings update that fixes this problem and provides a 25%+ performance gain for downstream vision tasks. |
|[FED-NeRF: Achieve High 3D Consistency and Temporal Coherence for Face Video Editing on Dynamic NeRF.](https://arxiv.org/abs/2401.02616v1) | A new stabilizer for smooth temporal coherence and GAN-NeRF technology for 3D consistency have been used by researchers to create a facial video editing architecture. This technique works well for editing videos since it keeps viewpoints constant and makes frame transitions smooth.|
|[A Minimaximalist Approach to Reinforcement Learning from Human Feedback.](https://arxiv.org/abs/2401.04056) |Self-Play Preference Optimization (SPO), a less complex alignment method than conventional RLHF, has been presented by Google researchers. Using game theory, the researchers were able to develop single-player self-play dynamics that provide good performance and are resilient to noisy preferences. |
|[Mixtral of Experts.](https://arxiv.org/abs/2401.04088) | We introduce Mixtral 8x7B, a Sparse Mixture of Experts (SMoE) language model. Mixtral has the same architecture as Mistral 7B, with the difference that each layer is composed of 8 feedforward blocks (i.e. experts). |
|[GPT-4V(ision) is a Human-Aligned Evaluator for Text-to-3D Generation.](https://arxiv.org/abs/2401.04092v1) |The constraints of existing single-criterion measures have been addressed by researchers with the development of a new assessment metric for text-to-3D generative models. This sophisticated technique compares 3D objects and generates prompts using GPT-4V. It is very compatible with human tastes and provides flexibility by adjusting to different user-specified requirements. |
|[Self-emerging Token Labeling.](https://github.com/NVlabs/STL) | Using a novel self-emerging token labeling (STL) framework, researchers have made a substantial development for Vision Transformers (ViTs) by improving the resilience of the Fully Attentional Network (FAN) models. Using this method, a FAN student model is trained after a FAN token labeler has been trained to produce relevant patch token labels.|
|[MedAgents: Large Language Models as Collaborators for Zero-shot Medical Reasoning.](https://github.com/gersteinlab/medagents) |We propose a Multi-disciplinary Collaboration (MC) framework. The framework works in five stages: (i) expert gathering: gather experts from distinct disciplines according to the clinical question; (ii) analysis proposition: domain experts put forward their own analysis with their expertise; (iii) report summarization: compose a summarized report on the basis of a previous series of analyses; (iv) collaborative consultation: engage the experts in discussions over the summarized report. The report will be revised iteratively until an agreement from all the experts is reached; (v) decision making: derive a final decision from the unanimous report. |
|[DiffBody: Diffusion-based Pose and Shape Editing of Human Images.](https://www.cgg.cs.tsukuba.ac.jp/~okuyama/pub/diffbody/index.html) | This study presents a one-shot approach to human image editing that allows for substantial body form and position modifications without compromising the subject's identification.|
|[LLaMA Beyond English: An Empirical Study on Language Capability Transfer.](https://huggingface.co/papers/2401.01055) |  Our evaluation results demonstrate that comparable performance to state-of-the-art transfer models can be achieved with less than 1% of the pretraining data, both in terms of knowledge alignment and response quality.|
|[Masked Audio Generation using a Single Non-Autoregressive Transformer.](https://pages.cs.huji.ac.il/adiyoss-lab/MAGNeT/) |The majority of audio creation methods produce sounds by diffusion or an auto-regressive model. This study does not employ a complex Transformer or several stages. Rather, it employs an obscured language model on top of audio tokens. |
|[TechGPT-2.0: A large language model project to solve the task of knowledge graph construction.](https://arxiv.org/abs/2401.04507v1) |TechGPT-2.0 improves on big language models for particular applications, such as building knowledge graphs. With its emphasis on relationship triple extraction and named entity identification, the project also represents a major advancement for the Chinese open-source AI community. |
|[Long-Context Retrieval Models with Monarch Mixer.](https://hazyresearch.stanford.edu/blog/2024-01-11-m2-bert-retrieval) |Compute has been investigating a variety of substitutes for Transformers. It has published a retrieval model for retrieval tasks that performs better than a lot of closed embedding models. |
|[Quantifying Language Models' Sensitivity to Spurious Features in Prompt Design or: How I learned to start worrying about prompt formatting.](https://arxiv.org/abs/2310.11324) | It is shown that, depending on the prompt, prompting models for a small set of shot benchmarks can provide task accuracy ranging from 4 to 88%. This study demonstrates how to enhance your prompts in a scientific way.|
|[Application of Deep Learning in Blind Motion Deblurring: Current Status and Future Prospects.](https://arxiv.org/abs/2401.05055v1) | An extensive review of deep learning's application to blind motion deblurring—a crucial field in computer vision—is provided in this work. It covers everything from fundamental ideas and the drawbacks of conventional approaches to a thorough analysis of contemporary strategies including CNNs, GANs, RNNs, and Transformers.|
|[Singer Identity Representation Learning using Self-Supervised Techniques.](https://arxiv.org/abs/2401.05064v1) | A new framework has been created by researchers to examine and comprehend singing voices more thoroughly. By applying self-supervised learning on isolated vocal records and focusing on out-of-domain generalization, they achieved progress in tasks like singing voice similarity and synthesis, improving upon current technology.|
|[Towards the Law of Capacity Gap in Distilling Language Models.](https://github.com/genezc/minima) | Language model (LM) distillation is a trending area that aims to distil the knowledge resided in a large teacher LM to a small student one. he law later guides us to distil a 3B student LM (termed MiniMA) from a 7B teacher LM (adapted LLaMA2-7B). |


## News
|Link|description|
|---|---|
|[Nabla raises another $24 million for its AI assistant for doctors that automatically writes clinical notes.](https://techcrunch.com/2024/01/05/nabla-raises-another-24-million-for-its-ai-assistant-for-doctors/) | Paris-based startup Nabla just announced that it has raised a $24 million Series B funding round led by Cathay Innovation|
|[OpenInterpreter gets an OS mode.](https://changes.openinterpreter.com/log/the-new-computer-update) |An excellent effort that mimics OpenAI's interpreter is called Open Interpreter. It can now operate your computer using a language model by pressing buttons and seeing the screen since it has both an OS mode and a visual mode. |
|[Wave of Apple Generative AI Tools on Track for WWDC Debut.](https://www.macrumors.com/2024/01/07/wave-of-apple-ai-tools-at-wwdc/) |Apple is on schedule to announce a series of generative AI-based tools at its Worldwide Developers Conference (WWDC) in June, Bloomberg's Mark Gurman reports.|
|[A survey of 2,778 researchers shows how fragmented the AI science community is.](https://the-decoder.com/a-survey-of-2778-researchers-shows-how-fragmented-the-ai-science-community-is/) |The "2023 Expert Survey on Progress in AI" shows that the scientific community has no consensus on the risks and opportunities of AI, but everything is moving faster than once thought. |
|[Microsoft’s observer has reportedly joined the OpenAI board.]() |Now Bloomberg reports that person is Microsoft vp Dee Templeton, who has been there for 25 years and leads a team responsible for managing its relationship with OpenAI.|
|[Microsoft, OpenAI sued for copyright infringement by nonfiction book authors in class action claim.](https://www.cnbc.com/2024/01/05/microsoft-openai-sued-over-copyright-infringement-by-authors.html) |Two nonfiction book authors sued Microsoft and OpenAI in a putative class action complaint alleging that the defendants “simply stole” the writers’ copyrighted works to help build a billion-dollar artificial intelligence system. |
|[OpenAI and journalism.](https://openai.com/blog/openai-and-journalism) |In response to The New York Times lawsuit, OpenAI emphasized working with news organizations, asserted that using public content for AI training is fair use, pledged to stop using rare content repeatedly in their models, and expressed surprise at the lawsuit considering their continuous efforts to address issues. |
|[Getty and Nvidia bring generative AI to stock photos.](https://www.theverge.com/2024/1/8/24027259/getty-images-nvidia-generative-ai-stock-photos) | Generative AI by iStock lets users make their own stock photos from text prompts.|
|[Microsoft’s new Copilot key is the first big change to Windows keyboards in 30 years.](https://www.theverge.com/2024/1/4/24023809/microsoft-copilot-key-keyboard-windows-laptops-pcs) | Microsoft wants 2024 to be the year of the AI PC as it lines up bigger changes to Windows.|
|[Rabbit foundation model and computer.](https://www.rabbit.tech/keynote) |Large action model (LAM) developed by Rabbit was designed to work with the R1 pocket companion computer. Almost fully driven by its LAM, the company's R1 gadget is a reimagining of the computer and smartphone. |
|[OpenAI’s news publisher deals reportedly top out at $5 million a year.](https://www.theverge.com/2024/1/4/24025409/openai-training-data-lowball-nyt-ai-copyright) | The ChatGPT company has been trying to get more news organizations to sign licensing deals to train AI models.|
|[Intel: ‘We are bringing the AI PC to the car’.](https://www.theverge.com/2024/1/9/24026990/intel-auto-car-ai-pc-soc-sdv-zeekr-ces) | The chip company is doubling down on its auto business, introducing a new AI-enhanced system-on-a-chip for cars. The first company to install it will be Zeekr.|
|[AlphaFold’s Latest Strides: Improved Accuracy for Antibody-Antigen Complex Modeling.](https://cbirt.net/alphafolds-latest-strides-improved-accuracy-for-antibody-antigen-complex-modeling/) | A new study from the University of Maryland evaluates its accuracy and provides new insights into the factors influencing protein modeling.|
|[Introducing the GPT Store.](https://openai.com/blog/introducing-the-gpt-store) | OpenAI has launched the GPT store, which allows developers to get paid by building these agents. The company plans to feature GPTs every week.|
|[Regulators aren’t convinced that Microsoft and OpenAI operate independently.](https://arstechnica.com/tech-policy/2024/01/regulators-arent-convinced-that-microsoft-and-openai-operate-independently/) | EU is fielding comments on potential market harms of Microsoft's investments.|
|[Your private AI can have eyes. Ollama with the LLaVA model.](https://benyoung.blog/your-private-ai-can-have-eyes-ollama-with-the-llava-model) | Vision models are now supported by Ollama. With Llava, you may enjoy cutting-edge language and vision performance on your MacBook Pro.|
|[OpenAI debuts ChatGPT subscription aimed at small teams.](https://techcrunch.com/2024/01/10/openai-launches-chatgpt-subscription-aimed-at-small-teams/) |OpenAI is launching a new subscription plan for ChatGPT, its viral AI-powered chatbot, aimed at smaller, self-service-oriented teams. |
|[Valve now allows the “vast majority” of AI-powered games on Steam.](https://arstechnica.com/gaming/2024/01/valve-most-games-made-with-ai-tools-are-now-welcome-on-steam/) |New reporting system will enforce "guardrails" for "live-generated" AI content. |
|[marc newson designs swarovski's world-first AI binoculars that identify species on their own.](https://www.designboom.com/technology/marc-newson-swarovski-optik-world-first-ai-binoculars-ax-visio-ces-2024-01-11-2024/) | the dubbed world’s first AI-supported binoculars that using their high-performance analog long-range optics and digital intelligence, they can detect and identify more than 9,000 birds and other wildlife at a touch of a button.|
|[Google Cloud launches new generative AI tools for retailers.](https://www.cnbc.com/2024/01/11/google-cloud-launches-new-generative-ai-tools-for-retailers.html) |Google launched several new AI tools for retailers to improve online shopping experiences and other retail operations. |
|[Amazon’s Alexa gets new generative AI-powered experiences.](https://techcrunch.com/2024/01/09/amazons-alexa-gets-new-generative-ai-powered-experiences/) |Today, the company revealed three developers delivering new generative AI-powered Alexa experiences, including AI chatbot platform Character.AI, AI music company Splash and Voice AI game developer Volley. All three experiences are available in the Amazon Alexa Skill Store. |


## Resources
|Link|description|
|---|---|
|[Steering Llama-2 with contrastive activation additions.](https://www.alignmentforum.org/posts/v7f8ayBxLhmMFRzpa/steering-llama-2-with-contrastive-activation-additions) | By just adding e.g. a "sycophancy vector" to one bias term, we outperform supervised finetuning and few-shot prompting at steering completions to be more or less sycophantic. Furthermore, these techniques are complementary: we show evidence that we can get all three benefits at once!|
|[DiffusionEdge.](https://github.com/guhuangai/diffusionedge) | DiffusionEdge is an innovative edge detection model that works better than current techniques. Through the integration of a diffusion probabilistic model, DiffusionEdge produces resource-efficient edge maps that are more precise and clean.|
|[Transformers From Scratch.](https://blog.matdmiller.com/posts/2023-06-10_transformers/notebook.html) | In this blog we’re going to walk through creating and training a transformer from scratch. We’ll go through each foundational element step by step and explain what is happening along the way.|
|[Merge Large Language Models with mergekit.](https://towardsdatascience.com/merge-large-language-models-with-mergekit-2118fb392b54) | Model merging is a technique that combines two or more LLMs into a single model. It’s a relatively new and experimental method to create new models for cheap (no GPU required). Model merging works surprisingly well and produced many state-of-the-art models on the Open LLM Leaderboard. In this tutorial, we will implement it using the mergekit library. |
|[Mathematical Introduction to Deep Learning: Methods, Implementations, and Theory.](https://arxiv.org/abs/2310.20360) | This book aims to provide an introduction to the topic of deep learning algorithms. We review essential components of deep learning algorithms in full mathematical detail including different artificial neural network (ANN) architectures and different optimization algorithms|
|[Portkey's AI Gateway.](https://github.com/Portkey-AI/gateway) | is the interface between your app and hosted LLMs. It streamlines API requests to OpenAI, Anthropic, Mistral, LLama2, Anyscale, Google Gemini and more with a unified API.|
|[act-plus-plus.](https://github.com/MarkFzp/act-plus-plus) | Imitation Learning algorithms and Co-training for Mobile ALOHA|
|[crewAI.](https://github.com/joaomdmoura/crewAI) |  Cutting-edge framework for orchestrating role-playing, autonomous AI agents. By fostering collaborative intelligence, CrewAI empowers agents to work together seamlessly, tackling complex tasks.|
|[Integrating CLIP and SAM for Enhanced Image Segmentation.](https://www.mmlab-ntu.com/project/ovsam/) |In order to enhance picture segmentation and identification, this research presents the Open-Vocabulary SAM, a framework that combines the advantages of CLIP and SAM models. |
|[Diffusion Models for Reinforcement Learning: A Survey.](https://github.com/apexrl/diff4rlsurvey) | Diffusion models' contribution to RL. Their applications are categorized in this repository, which also provides links to upcoming interdisciplinary research opportunities.|
|[tinygrad.](https://github.com/tinygrad/tinygrad) | A very simple implementation of inference of the new Mistral MoE model using the Tinygrad library.|
|[YouTube Transcripts → Knowledge Graphs for RAG Applications.](https://medium.com/@a-gilmore/youtube-transcripts-knowledge-graphs-for-rag-applications-2cc790543d4b) | how to scrape YouTube video transcripts into a knowledge graph for Retrieval Augmented Generation (RAG) applications. |
|[AI Toolkit.](https://github.com/linkdd/aitoolkit) | AI Toolkit is a header-only C++ library which provides tools for building the brain of your game's NPCs.|
|[SpeechAgents.](https://0nutation.github.io/SpeechAgents.github.io/) |SpeechAgents is a multi-modal artificial intelligence system that can very realistically mimic human speech. With the use of a multi-modal LLM, this system can manage up to 25 agents. Its ability to imitate human language, complete with constant substance, realistic rhythms, and emotive emotions, suggests that it has promise for use in plays and audio books. |
|[Model Card for Switch Transformers C - 2048 experts (1.6T parameters for 3.1 TB).](https://huggingface.co/google/switch-c-2048) |Google's switch transformer was among the first Mixture-of-Experts models to achieve success. It can now be found on the HuggingFace platform with code. |
|[Make LLM Fine-tuning 2x faster with Unsloth and 🤗 TRL.](https://huggingface.co/blog/unsloth-trl) | Pulling your hair out because LLM fine-tuning is taking forever? In this post, we introduce a lightweight tool developed by the community to make LLM fine-tuning go super fast!|
|[distilabel Orca Pairs for DPO.](https://huggingface.co/datasets/argilla/distilabel-intel-orca-dpo-pairs) | a novel technique that makes it possible to filter excellent pair preferences for alignment. It significantly raises the performance of the baseline model.|
|[Chatbot UI.](https://github.com/mckaywrigley/chatbot-ui) |The open-source AI chat app for everyone. |
|[explain-then-translate.](https://github.com/pootiet/explain-then-translate) |We propose 2-stage Chain-of-Thought (CoT) like prompting technique for program translation: we ask models to explain the source programs first before translating. |
|[WhiteRabbitNeo-33B-v1 .](https://huggingface.co/whiterabbitneo/WhiteRabbitNeo-33B-v1) | Both offensive and defensive security training have been given to this model. This general-purpose coding paradigm can help with activities related to cyber security. This implies that you may use it to learn how to defend against various attacks and vulnerabilities as well as to safeguard your networks.|


## Perspectives
|Link|description|
|---|---|
|[How to Build a Thinking AI.](https://aithought.com/) |This article provides an analytical framework for how to simulate human-like thought processes within a computer. It describes how attention and memory should be structured, updated, and utilized to search for associative additions to the stream of thought. |
|[The New York Times’ AI Opportunity.](https://stratechery.com/2024/the-new-york-times-ai-opportunity) | In its case against OpenAI and Microsoft, the New York Times alleges that the companies' AI technologies—ChatGPT among them—were trained on millions of copyrighted articles from the newspaper, resulting in outputs that are directly competitive with the Times' services. The lawsuit challenges the legality of AI training practices and the effects of AI on traditional content creators, claiming that this amounts to copyright infringement and jeopardizes the newspaper's investment in journalism. It also demands the destruction of AI models and data that used Times content, along with billions of dollars in damages.|
|[Does AI risk “other” the AIs?.](https://joecarlsmith.com/2024/01/09/does-ai-risk-other-the-ais) |The idea of "othering" AIs and the moral ramifications of regulating or changing AI in the future as well as human values are the main topics of this essay's analysis of Robin Hanson's critique of the AI risk discourse. Fearing AI as a "other" is biased, according to Hanson. It's possible that Hanson's opinions undervalue the dangers of unchecked AI growth and the difficulties of bringing future AI ideals into line with human ethics. |
|[Part One: One-Year Anniversary of ChatGPT. Has AI Become the New Tech Platform?.](https://twang.substack.com/p/part-one-one-year-anniversary-of) | The "Anatomy Framework", a tool for evaluating the disruptive potential of any breakthrough, including artificial intelligence, is introduced in this article. It examines innovation from five perspectives: apps, tools, core platform, underlying infrastructure, and ecosystem facilitators. It also covers the role of innovators, both new and established, and the innovation medium (hardware vs. software).|
|[There are holes in Europe’s AI Act — and researchers can help to fill them.](https://www.nature.com/articles/d41586-024-00029-4) |Scientists have been promised a front-row seat for the formulation of the EU’s proposed AI regulatory structures. They should seize this opportunity to bridge some big gaps. |
|[The science events to watch for in 2024.](https://www.nature.com/articles/d41586-023-04044-9) |Advanced AI tools, Moon missions and ultrafast supercomputers are among the developments set to shape research in the coming year. |
|[Will superintelligent AI sneak up on us? New study offers reassurance.](https://www.nature.com/articles/d41586-023-04094-z) |Improvements in the performance of large language models such as ChatGPT are more predictable than they seem. |
|[AI consciousness: scientists say we urgently need answers.](https://www.nature.com/articles/d41586-023-04047-6) |Researchers call for more funding to study the boundary between conscious and unconscious systems. |
|[AI could transform metal recycling globally.](https://www.nature.com/articles/d41586-024-00022-x) |Metal recycling needs to become more cost-efficient because it is a crucial contributor to the global circular economy and the transition to renewable energy.  |
|[Can AI make genuine theoretical discoveries?.]() | When Nature included ChatGPT alongside its list of ten people who helped to shape science in 2023, it seemed deliberately provocative|
|[AI and the Future of SaaS.](https://thebootstrappedfounder.com/ai-and-the-future-of-saas/) |Today, let’s look into the crystal ball and see a few opportunities, challenges, and threats that AI systems may pose for software entrepreneurs and creators. |
|[Benchmarking GPT-4 Turbo - A Cautionary Tale.](https://blog.mentat.ai/benchmarking-gpt-4-turbo-a-cautionary-tale) |GPT-4 Turbo came up slightly behind at 68.8%, while GPT-4 successfully finished 70% of the programming tasks. It's interesting to note that GPT-4 Turbo needed more tries than GPT-4, which may indicate that it lacks GPT-4's memory power. An further test supported this. |
|[Unraveling spectral properties of kernel matrices.](https://francisbach.com/spectrum-kernel-matrices-i/) | This article examines the implications for learning properties of the way that eigenvalues vary for various Kernel Matrices.|
|[NVIDIA’s CEO on Leading Through the A.I. Revolution.](https://hbr.org/podcast/2023/12/nvidias-ceo-on-leading-through-the-a-i-revolution) |In this podcast, NVIDIA CEO and co-founder Jensen Huang shares his thoughts on how he steers his company through rapidly changing times and offers advice to other entrepreneurs on how to stay competitive by incorporating AI into their operations. |
|[It’s Humans All the Way Down.](https://blog.jim-nielsen.com/2024/humans-all-the-way-down/) |Because everyone believes that everyone else's work is simple, people believe that AI will replace a lot of employment. Ignorance is the foundation for the desire to exclude humans from the equation. It is impossible to ignore the fact that people matter, even in the craziest of ideas. Humans want to be seen and understood by other humans. |

# ML news: Week 1 - 7 January

## Research
|Link|description|
|---|---|
|[MosaicBERT: A Bidirectional Encoder Optimized for Fast Pretraining.](https://mosaicbert.github.io/) |MosaicBERT is a custom BERT architecture optimized for fast pretraining. This study motivated many of the architecture choices around MosaicML's MPT-7B and MPT-30B models. the main architectural modifications used: FlashAttention, ALiBi,  Gated Linear Units, Low Precision LayerNorm.|
|[Improving Text Embeddings with Large Language Models.](https://arxiv.org/abs/2401.00368) | Microsoft researchers trained a decoder-only transformer based on Mistral for embeddings using synthetic data. In the class, it is the best. Remarkably, they create the synthetic retrieval training data using GPT-4 and a two-step prompting technique.|
|[Images altered to trick machine vision can influence humans too.](https://deepmind.google/discover/blog/images-altered-to-trick-machine-vision-can-influence-humans-too/) |New research shows that even subtle changes to digital images, designed to confuse computer vision systems, can also affect human perception |
|[Self-Play Fine-Tuning Converts Weak Language Models to Strong Language Models.](https://arxiv.org/abs/2401.01335) | The fact that existing language models require very expensive human preference data to function properly is one of their main disadvantages. Determining if it is possible to have language models self-play develop without gathering this data has emerged as a major area of current study. With only SFT data, a new technique called SPIN makes significant progress in that direction by significantly enhancing a basic model's performance on a variety of tasks.|
|[Boundary Attention: Learning to Find Faint Boundaries at Any Resolution.](https://arxiv.org/abs/2401.00935) |Identifying edges and curves in pictures is a traditional computer vision challenge. Nevertheless, many existing approaches perform poorly when noise, quality changes, or out-of-distribution instances are introduced. With just 207k parameters, this newly discovered approach works very well on sensor readings. It significantly advances state of the art and employs a two-stage training procedure. |
|[Bracketing is All You Need: Unifying Image Restoration and Enhancement Tasks with Multi-Exposure Images.](https://arxiv.org/abs/2401.00766) | This work uses a unique temporally modulated recurrent network (TMRNet) with bracketing photography to achieve a considerable improvement in low-light photo quality. This method surpasses current multi-image processing techniques by training with synthetic data and adapting to real-world pictures.|
|[Auffusion: Leveraging the Power of Diffusion and Large Language Models for Text-to-Audio Generation.](https://auffusion.github.io/) | The Auffusion system presents a breakthrough in Text-to-Audio (TTA) creation, inspired by Text-to-Image diffusion models. It is quite good at turning text into high-quality audio, especially with complicated inputs.|
|[Context-Aware Interaction Network for RGB-T Semantic Segmentation.](https://arxiv.org/abs/2401.01624v1) |CAINet is an innovative technique that researchers have developed to improve RGB-T semantic segmentation, which is important for autonomous driving. This system mixes many data kinds in a unique way, emphasizing the complementary qualities and global context of each form of data. |
|[3D-Aware Visual Question Answering about Parts, Poses and Occlusions.](https://arxiv.org/abs/2310.17914v1) |Although there has been progress in Visual Question Answering (VQA), most models focus primarily on 2D reasoning and ignore the intricacy of 3D visual settings. This study introduces 3D-aware VQA. |
|[DocLLM.](https://arxiv.org/abs/2401.00908) | We present DocLLM, a lightweight extension to traditional large language models (LLMs) for reasoning over visual documents, taking into account both textual semantics and spatial layout |
|[GPT-4V(ision) is a Generalist Web Agent.](https://arxiv.org/abs/2401.01614) | In this work, we explore the potential of LMMs like GPT-4V as a generalist web agent that can follow natural language instructions to complete tasks on any given website. |
|[Fast Inference of Mixture-of-Experts Language Models with Offloading.]() |With the widespread adoption of Large Language Models (LLMs), many deep learning practitioners are looking for strategies for running these models more efficiently. One such strategy is to use a sparse mixture of experts (MoE). In this work, we study the problem of running large MoE language models on consumer hardware with limited accelerator memory. |
|[LLM Augmented LLMs: Expanding Capabilities through Composition.](https://arxiv.org/abs/2401.02412) |investigate combining specialized models with preexisting foundation models to increase capabilities; introduce cross-attention between models to combine representations that allow for new capabilities. For instance, a PaLM2-S model was enhanced with a smaller model trained on low-resource languages to enhance English translation and arithmetic reasoning for low-resource languages; this was also accomplished with a code-specific model that produced a 40% improvement in code generation and explanation tasks compared to the base code model. |
|[LLaMA Pro.](https://arxiv.org/abs/2401.02415) |provides a post-pretraining technique to enhance an LLM's knowledge without causing catastrophic forgetting; it does this by freezing the inherited blocks and tuning expanded identity blocks using only new corpus; trains an LLaMA Pro-8.3B initialized from Llama2-7B using code and math data; these models outperform base models on a variety of benchmarks while maintaining the original general capabilities. |
|[Self-Play Fine-Tuning Converts Weak Language Models to Strong Language Models.](https://arxiv.org/abs/2401.01335) | demonstrates that a supervised fine-tuned LLM can be made better without needing to obtain more human-annotated data. Drawing inspiration from self-play, it uses the LLM to create its training data from prior iterations, then refines its policy by separating the responses it generated from the human-annotated data. This shows that the method can make the LLM perform better and outperform models trained via DPO with GPT-4 preference data.|

## News
|Link|description|
|---|---|
|[Microsoft’s Copilot app is now available on iOS.](https://www.theverge.com/2023/12/29/24019288/microsoft-copilot-app-available-iphone-ipad-ai) | The Microsoft Copilot app lets you ask questions, draft text, and generate images using AI. |
|[Stuff we figured out about AI in 2023.](https://simonwillison.net/2023/Dec/31/ai-in-2023/) | This piece aims to summarize the major advancements in AI research throughout the course of 2023. It addresses a number of topics, including LLM applications, the issue of gullibility, model tweaking, and how to execute LLMs on personal devices. When used appropriately, LLMs can significantly improve the quality of life for those who use them. Although they are really rather simple to construct, many applications still find them to be unstable and there is still plenty to learn about them.|
|[Gemini in Reasoning: Unveiling Commonsense in Multimodal Large Language Models.](https://github.com/eternityyw/gemini-commonsense-evaluation) |This study conducts a thorough evaluation of Gemini Pro's efficacy in commonsense reasoning tasks, employing a diverse array of datasets that span both language-based and multimodal scenarios. |
|[Noise-free Optimization in Early Training Steps for Image Super-Resolution.](https://arxiv.org/abs/2312.17526v1) | By concentrating on two crucial elements—the ideal centroid of possible high-resolution images and the intrinsic noise that degrades image quality—researchers have created a novel technique that enhances single image super-resolution.|
|[AI-created “virtual influencers” are stealing business from humans.](https://arstechnica.com/ai/2023/12/ai-created-virtual-influencers-are-stealing-business-from-humans/) |Brands are turning to hyper-realistic, AI-generated influencers for promotions. |
|[DeepMind AI outdoes human mathematicians on unsolved problem.](https://www.nature.com/articles/d41586-023-04043-w) |Large language model improves on efforts to solve combinatorics problems inspired by the card game Set. |
|[Nikon, Sony, and Canon fight AI fakes with new camera tech.](https://asia.nikkei.com/Business/Technology/Nikon-Sony-and-Canon-fight-AI-fakes-with-new-camera-tech) |Digital signatures to provide a way to tell real photos from deep fakes |
|[Intel to spin out AI software firm with outside investment.](https://finance.yahoo.com/news/intel-spins-ai-software-firm-133626026.html) | Intel on Wednesday said it was forming a new independent company around its artificial intelligence software efforts with backing from digital-focused asset manager DigitalBridge Group and other investors.|
|[Search startup Perplexity AI valued at $520 mln in funding from Bezos, Nvidia.](https://www.reuters.com/technology/perplexity-ai-valued-520-mln-funding-bezos-nvidia-2024-01-04/) |Search startup Perplexity AI has raised $73.6 million from a group of investors including Nvidia |
|[OpenAI’s app store for GPTs will launch next week.](https://techcrunch.com/2024/01/04/openais-app-store-for-gpts-will-launch-next-week/) | OpenAI plans to launch a store for GPTs, custom apps based on its text-generating AI models (e.g. GPT-4), sometime in the coming week.|
|[Google appears to be working on an ‘advanced’ version of Bard that you have to pay for.](https://www.theverge.com/2024/1/4/24025270/google-bard-advanced-paid-subscription) | Google might be on track to release a Gemini Ultra-powered Bard Advanced.|
|[LLM Training and Inference with Intel Gaudi 2 AI Accelerators.](https://www.databricks.com/blog/llm-training-and-inference-intel-gaudi2-ai-accelerators) | Excellent training throughput, flops, and decoding bandwidth are features of the new Intel processor, which is accessible for on-premise deployment across many platforms.|
|[GitHub makes Copilot Chat generally available, letting devs ask questions about code.](https://techcrunch.com/2023/12/29/github-makes-copilot-chat-generally-available-letting-devs-ask-questions-about-code/) |GitHub’s launching Chat in general availability for all users. |


## Resources
|Link|description|
|---|---|
|[llm-course.](https://github.com/mlabonne/llm-course) |Course to get into Large Language Models (LLMs) with roadmaps and Colab notebooks. |
|[Bash One-Liners for LLMs.](https://justine.lol/oneliners/) |A project called Llamafile combines the inference and model code into a single portable executable. In order to handle command line output further, this blog post explains how to do so. |
|[pykoi: RLHF/RLAIF in one unified interface.](https://github.com/CambioML/pykoi) |pykoi is an open-source Python library for improving LLMs with RLHF. We provide a unified interface including RLHF/RLAIF data and feedback collection, finetuning with reinforcement learning and reward modeling, and LLM comparisons. |
|[gpt-fast.](https://github.com/pytorch-labs/gpt-fast) |Simple and efficient pytorch-native transformer text generation. |
|[TinyGPT-V.](https://github.com/DLYuanGod/TinyGPT-V) |TinyGPT-V: Efficient Multimodal Large Language Model via Small Backbones |
|[sbs-generator.](https://github.com/TheWiselyBearded/sbs-generator?utm_source=tldrai) |This repository contains a framework for converting monocular videos into side-by-side (SBS) 3D videos. It utilizes a combination of image processing techniques and depth map predictions to generate separate views for each eye, creating a 3D effect when viewed with appropriate hardware. |
|[ColBERTv2: Indexing & Search Notebook.](https://colab.research.google.com/github/stanford-futuredata/ColBERT/blob/main/docs/intro2new.ipynb) |ColBERT is a cutting-edge generation and retrieval technique. To assist readers in getting up to speed and experimenting with the technique, the authors have included a notepad. |
|[intel-extension-for-transformers.](https://github.com/intel/intel-extension-for-transformers?utm_source=tldrai) |An Innovative Transformer-based Toolkit to Accelerate GenAI/LLM Everywhere |
|[aMUSEd: An Open MUSE Reproduction.](https://huggingface.co/papers/2401.01808) |We present aMUSEd, an open-source, lightweight masked image model (MIM) for text-to-image generation based on MUSE. With 10 percent of MUSE's parameters, aMUSEd is focused on fast image generation. |
|[RAGatouille.](https://github.com/bclavie/RAGatouille) | Easily use and train state-of-the-art retrieval methods in any RAG pipeline. Designed for modularity and ease of use, backed by research.|
|[ODTrack.](https://github.com/gxnu-zhonglab/odtrack) |ODTrack is a simple, flexible, and effective video-level tracking pipeline, which densely associates the contextual relationships of video frames in an online token propagation manner.  |
|[ARLib.](https://github.com/coderwzw/arlib) |An open-source framework for conducting data poisoning attacks on recommendation systems, designed to assist researchers and practitioners. |
|[Learning JAX as a PyTorch developer.](https://kidger.site/thoughts/torch2jax/) | Some ideas about the transition from Pytorch to Jax. This post explains nine key ideas that set Jax apart and make it effective; each is illustrated with a lovely piece of code.|
|[Mitigating Hallucination in LLMs.](https://arxiv.org/abs/2401.01313) | A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models|
|[If LLM Is the Wizard, Then Code Is the Wand.](https://arxiv.org/abs/2401.00812) |A Survey on How Code Empowers Large Language Models to Serve as Intelligent Agents |


## Perspectives
|Link|description|
|---|---|
|[How IBM Sees AI Changing the Game for Companies of All Sizes with IBM’s VP of Technology and Director of Startups.](https://www.saastr.com/how-ai-is-changing-the-game-for-companies-with-ibm/) |AI technology is revolutionizing a variety of sectors' business landscapes. In this article, IBM's Director of Startups Kylie Rutherford, and Vice President of Software and Technology Raj Datta discuss how artificial intelligence (AI) is transforming business for organizations of all kinds and provide several use examples for different products. |
|[LLMs and Programming in the first days of 2024.](http://antirez.com/news/140) | Large Language Models (LLMs) have greatly accelerated code creation and comprehension of intricate APIs or frameworks in 2023, making them indispensable for programmers. LLMs perform well at high-level Python coding and routine chores, but they are less effective at sophisticated system programming. They may also be used as a simplified form of documentation and as an effective method for increasing productivity.|
|[Surge in number of ‘extremely productive’ authors concerns scientists.](https://www.nature.com/articles/d41586-023-03865-y) |Some researchers publish a new paper every five days, on average. Data trackers suspect not all their manuscripts were produced through honest labor. |
|[Satellite images reveal untracked human activity on the oceans.](https://www.nature.com/articles/d41586-023-03983-7) | Machine learning and satellite imagery have been used to map industrial infrastructure at sea — from fishing vessels to wind turbines. The findings provide a more comprehensive picture of maritime activity than ever before.|
|[Revealing the ‘Clever Hans Effect’ in AI-Driven Drug Discovery.](https://bnnbreaking.com/tech/ai-ml/revealing-the-clever-hans-effect-in-ai-driven-drug-discovery/) |In a landmark study at the University of Bonn, a team led by Prof. Dr. Jürgen Bajorath has revealed a significant finding about the role of artificial intelligence (AI) in pharmaceutical research. |
|[What We Learned About AI and Education in 2023.](https://aisupremacy.substack.com/p/what-we-learned-about-ai-and-education) |From Disruption to Integration: AI Responsive Education in 2023 |
|[The AI trust crisis.](https://simonwillison.net/2023/Dec/14/ai-trust-crisis/) |Users worry that their data may be used to train OpenAI's models as a result of Dropbox's new AI features, even though Dropbox has denied this and has a policy requiring customer agreement for such usage. This circumstance draws attention to a larger crisis of confidence in AI and data privacy, highlighting the necessity of corporations communicating clearly and being open about how they use data. |
|[The official OpenAI prompt engineering guide.](https://platform.openai.com/docs/guides/prompt-engineering/) | a thorough, step-by-step manual that outlines methods and techniques for improving performance with big language models such as GPT-4.|

# ML news: Week 18 - 24 December

## Research
|Link|description|
|---|---|
|[Stabilizing Transformer Training by Preventing Attention Entropy Collapse.](https://github.com/apple/ml-sigma-reparam) |Despite their incredible skills, transformers may be challenging to train because to their numerous instabilities. When the entropy of an Attention matrix collapses is one of the primary problems. With a straightforward reparametrization, our work offers a means to avoid it. |
|[DiffusionLight: Light Probes for Free by Painting a Chrome Ball.](https://diffusionlight.github.io/?) | This effort overcomes the drawbacks of existing approaches that rely on HDR panorama datasets by introducing a unique method for predicting lighting in photos. The method uncovers a distinct link between chrome balls and diffusion noise by rendering chrome balls into conventional pictures using diffusion models.|
|[DriveMLM: Aligning Multi-Modal Large Language Models with Behavioral Planning States for Autonomous Driving.](https://arxiv.org/abs/2312.09245v1) |A new framework called DriveMLM makes advantage of massive language models to improve autonomous driving. This system performs better in simulations and interacts with current autonomous driving systems. It does this by fusing linguistic judgments with vehicle controls. |
|[Graph Neural Networks with Diverse Spectral Filtering.](https://arxiv.org/abs/2312.09041v1) |A novel technique known as DSF has been created by researchers to enhance spectral graph neural networks. The World Wide Web and other complicated networks can be handled more effectively by DSF by adding node-specific filter weights. |
|[Evaluating and Mitigating Discrimination in Language Model Decisions.](https://www.anthropic.com/index/evaluating-and-mitigating-discrimination-in-language-model-decisions) |A proactive approach to assessing language models' potential for discrimination is covered in this article. The process involves coming up with a broad range of possible prompts for different decision scenarios and variations in demographic data. The main tactic for reducing both positive and negative discrimination is cautious prompt engineering. |
|[Faster Diffusion: Rethinking the Role of UNet Encoder in Diffusion Models.](https://github.com/hutaihang/faster-diffusion) |A comparison of UNet encoders and decoders in diffusion models demonstrates the former's more stable behavior. Thanks to this realization, a novel encoder propagation strategy was developed, greatly accelerating jobs like text-to-image and text-to-video production. |
|[VideoPoet: A large language model for zero-shot video generation.](https://blog.research.google/2023/12/videopoet-large-language-model-for-zero.html) | VideoPoet, a large language model (LLM) that is capable of a wide variety of video generation tasks, including text-to-video, image-to-video, video stylization, video inpainting and outpainting, and video-to-audio. |
|[Unmasking Deepfake Faces from Videos Using An Explainable Cost-Sensitive Deep Learning Approach.](https://arxiv.org/abs/2312.10740v1) | a deep learning method for identifying deepfake faces in videos utilizing four pre-trained CNN models for high accuracy. [official code.](https://github.com/faysal-md/unmasking-deepfake-faces-from-videos-an-explainable-cost-sensitive-deep-learning-approach-ieee2023)|
|[Bi-directional Adapter for Multi-modal Tracking.](https://arxiv.org/abs/2312.10611v1) | This effort solves the drawbacks of single-modal object tracking by introducing a multi-modal visual cue tracking paradigm that dynamically leverages the advantages of several modalities, such as RGB and infrared. [official code.](https://github.com/sparktempest/bat)|
|[Tokenize Anything via Prompting.](https://github.com/baaivision/tokenize-anything) |We present Tokenize Anything via Prompting, a unified and promptable model capable of simultaneously segmenting, recognizing, and captioning arbitrary regions, with flexible visual prompts (point, box and sketch).  |
|[Gemini: A Family of Highly Capable Multimodal Models.](https://arxiv.org/abs/2312.11805) | Gemini Paper: This report introduces a new family of multimodal models, Gemini, that exhibit remarkable capabilities across image, audio, video, and text understanding. |
|[FontDiffuser: One-Shot Font Generation via Denoising Diffusion with Multi-Scale Content Aggregation and Style Contrastive Learning.](https://yeungchenwa.github.io/fontdiffuser-homepage) |Diffusion-based FontDiffuser is an automatic font production technique that works especially well with intricate characters and a wide range of style variants. It has a Style Contrastive Refinement module for style transfer and a Multi-scale Content Aggregation block for improved stroke preservation. |
|[Splatter Image: Ultra-Fast Single-View 3D Reconstruction.](https://szymanowiczs.github.io/splatter-image) |The Splatter Image is an ultra-fast method for single- and few-view 3D reconstruction. Training is done on 1 GPU, reconstruction is done at 38 FPS and rendering at 588 FPS. |
|[PowerInfer: Fast Large Language Model Serving with a Consumer-grade GPU.](https://arxiv.org/abs/2312.12456) |The hypothesis that models include cool neurons that are utilized significantly less frequently and hot neurons that are used for nearly all inputs is investigated in this research. It is possible to conserve memory without significantly reducing throughput by preloading the hot neurons to the GPU. There's a code library companion available. |
|[On Inference Stability for Diffusion Models.](https://arxiv.org/abs/2312.12431v1) |A 'sequence-aware' loss function has been created by researchers to enhance Denoising Probabilistic Models (DPMs) and solve the problem of timestep correlation in picture production. Better FID and Inception Scores demonstrate that this new method not only provides a tighter estimation of loss but also significantly improves picture quality on datasets such as CelebA and CIFAR10. |
|[CLIP-DINOiser: Teaching CLIP a few DINO tricks.](https://wysoczanska.github.io/CLIP_DINOiser/) |For better semantic segmentation without annotations, the novel CLIP-DINOiser approach combines self-supervised features with the zero-shot capabilities of the CLIP model. |
|[A Unified Framework for High-quality Text Synthesis in Arbitrary Images via Character-aware Diffusion Models.](https://udifftext.github.io/) | A novel technique called UDiffText improves the legibility of text in AI-generated graphics. Through the use of a sophisticated text encoder and extensive dataset fine-tuning, UDiffText enhances text correctness and dramatically lowers spelling errors.|

## News
|Link|description|
|---|---|
|[Snapchat+ subscribers can now create and send AI-generated images.](https://techcrunch.com/2023/12/12/snapchat-subscribers-can-now-create-and-send-ai-generated-images/) | Snapchat is releasing a few new AI powered features for Snapchat+ subscribers.|
|[Google brings Gemini Pro to Vertex AI.](https://techcrunch.com/2023/12/13/google-brings-gemini-pro-to-vertex-ai/) |After coming to Bard and the Pixel 8 Pro last week, Gemini, Google’s recently announced flagship GenAI model family, is launching for Google Cloud customers using Vertex AI. |
|[Competitive performance claims and industry-leading Inference performance on AMD Instinct MI300X.](https://community.amd.com/t5/instinct-accelerators/competitive-performance-claims-and-industry-leading-inference/ba-p/652304) |With ROCm 6, AMD's flagship AI accelerator, the MI300X, can now perform for inference tasks on par with NVIDIA. The community will benefit greatly from this as it gives burgeoning AI firms access to new chips. |
|[Agility is using large language models to communicate with its humanoid robots.](https://techcrunch.com/2023/12/14/agility-is-using-large-language-models-to-communicate-with-its-humanoid-robots/) |the company is showcasing some of that work in a short video shared through its social channels. |
|[Intel unveils new data center chip with focus on AI growth.](https://finance.yahoo.com/news/intel-unveils-new-data-center-chip-with-focus-on-ai-growth-150001734.html) |On Thursday, the company debuted its 5th Gen Intel Xeon processors during its AI Everywhere event |
|[ByteDance is secretly using OpenAI’s tech to build a competitor.](https://www.theverge.com/2023/12/15/24003151/bytedance-china-openai-microsoft-competitor-llm) | ‘They really just don’t want to get caught.’ The frenzied race to win in generative AI means that even the biggest players are cutting corners.|
|[Atlassian welcomes AI to the team.](https://www.atlassian.com/blog/announcements/atlassian-intelligence-ga) |AI capabilities are now generally available across Jira Software, Confluence, Jira Service Management, and more. |
|[Harvey raises $80M Series B.](https://www.harvey.ai/blog/series-b) | A new round of investment has been secured by Harvey AI, a legal service based on OpenAI technology, valuing the startup business at over $700 million. Using OpenAI, the business creates foundation models for applications related to law and legal practice.|
|[whiterabbitneo/WhiteRabbitNeo-13B.](https://huggingface.co/whiterabbitneo/WhiteRabbitNeo-13B) |The Matrix-related startup whiterabbitneo has produced a 13B parameter language model that has been trained for both offensive and defensive cyber security. It is qualified to respond to inquiries and offer details on computer security. |
|[Anthropic Updates Terms of Service.](https://www.anthropic.com/index/expanded-legal-protections-api-improvements) | We are introducing new, simplified Commercial Terms of Service with an expanded copyright indemnity, as well as an improved developer experience with our beta Messages API.|
|[Pilotless FedEx, Reliable Robotics Plane Completes Flight.](https://www.ttnews.com/articles/pilotless-fedex-plane) | Milestone for Autonomous Flight Could Lead to Regulatory Approval|
|[Microsoft Copilot gets a music creation feature via Suno integration.](https://techcrunch.com/2023/12/19/microsoft-copilot-gets-a-music-creation-feature-via-suno-integration/) |Microsoft Copilot, Microsoft’s AI-powered chatbot, can now compose songs thanks to an integration with GenAI music app Suno. |
|[Stability AI announces paid membership for commercial use of its models.](https://www.theverge.com/2023/12/19/24008149/stability-ai-paid-subscription-commercial-rights-safety) |The company said paid tiers will fund the future of its AI research. |
|[More than 10,000 research papers were retracted in 2023 — a new record.](https://www.nature.com/articles/d41586-023-03974-8) |The number of articles being retracted rose sharply this year. Integrity experts say that this is only the tip of the iceberg. |
|[Large language models direct automated chemistry laboratory.](https://www.nature.com/articles/d41586-023-03790-0) | Automation of chemistry research has focused on developing robots to execute jobs. Artificial-intelligence technology has now been used not only to control robots, but also to plan their tasks on the basis of simple human prompts. [research article.](https://www.nature.com/articles/s41586-023-06792-0)|
|[Introducing Text-to-CAD.](https://zoo.dev/blog/introducing-text-to-cad) |After changing their name, Zoo Dev (formerly Kitty Cad) unveiled a new text-to-cad feature. This robust platform creates 3D assets that can be printed or used as parts. |
|[Waymo finds that its driverless cars ‘significantly outperformed’ humans.](https://9to5google.com/2023/12/20/waymo-driverless-humans/) | New safety research from Waymo finds that its driverless cars “led to a significant reduction in the rates of police-reported and injury-causing crashes compared to human drivers.”|
|[Brush Your Text: Synthesize Any Scene Text on Images via Diffusion Model.](https://arxiv.org/abs/2312.12232) |A novel training-free framework called Diff-Text enables the creation of photo-realistic images with text in any language. Using sketched images as priors, it improves the multilingual capabilities of the Stable Diffusion model. |
|[Largest Dataset Powering AI Images Removed After Discovery of Child Sexual Abuse Material.](https://www.404media.co/laion-datasets-removed-stanford-csam-child-abuse/) | The model is a massive part of the AI-ecosystem, used by Stable Diffusion and other major generative AI products. The removal follows discoveries made by Stanford researchers, who found thousands of instances of suspected child sexual abuse material in the dataset.|
|[Rite Aid banned from using facial recognition software after falsely identifying shoplifters.](https://techcrunch.com/2023/12/20/rite-aid-facial-recognition/) |FTC says the company's 'reckless use' of AI humiliated customers |
|[AI startup Anthropic reportedly in talks to raise $750M on a $15B valuation.](https://enterprisetalk.com/quick-bytes/ai-startup-anthropic-reportedly-in-talks-to-raise-750m-on-a-15b-valuation/) | Anthropic PBC, an artificial intelligence startup backed by Amazon.com Inc. and Google LLC, is reportedly in talks to raise $750 million in new funding at a valuation of $15 billion|
|[Apple’s latest AI research could completely transform your iPhone.](https://venturebeat.com/ai/apples-latest-ai-research-could-completely-transform-your-iphone/) | two new papers introducing new techniques for 3D avatars and efficient language model inference. The advancements could enable more immersive visual experiences and allow complex AI systems to run on consumer devices such as the iPhone and iPad.|
|[OpenAI buffs safety team and gives board veto power on risky AI.](https://techcrunch.com/2023/12/18/openai-buffs-safety-team-and-gives-board-veto-power-on-risky-ai/) |A new safety advisory group has been established by OpenAI, and the board has been given veto power over all models. |

## Resources
|Link|description|
|---|---|
|[Introducing Ego-Exo4D: A foundational dataset for research on video learning and multimodal perception.](https://ai.meta.com/blog/ego-exo4d-video-learning-perception/) |  Ego-Exo4D, a foundational dataset and benchmark suite to support research on video learning and multimodal perception.|
|[Coffee.](https://github.com/Coframe/coffee) | Coffee, which was released last week, integrates AI into current codebases to speed up frontend development. The project primarily focuses on a first-class DX, drawing on insights the Coframe team has gained from producing more than 80% of their frontend using AI.|
|[DeepEval.](https://github.com/confident-ai/deepeval) | DeepEval is a simple-to-use, open-source evaluation framework for LLM applications. It is similar to Pytest but specialized for unit testing LLM applications. DeepEval evaluates performance based on metrics such as hallucination, answer relevancy, RAGAS, etc., using LLMs and various other NLP models locally on your machine.|
|[Understanding GPU Memory 1: Visualizing All Allocations over Time.](https://pytorch.org/blog/understanding-gpu-memory-1/) | Determining the reason behind memory leaks in Pytorch has proven to be one of the most difficult tasks for practitioners. Pytorch 2.1 has some incredible new features that provide insight into memory utilization. Classifying the utilization into well-known buckets (such as activations and gradients) is another application for it.|
|[Fine Tuning Mistral 7B on Magic the Gathering Drafts.](https://generallyintelligent.substack.com/p/fine-tuning-mistral-7b-on-magic-the) | Tips, examples, and thoughts from an exploration of the world of fine tuning|
|[MMLU prompt templates.](https://github.com/microsoft/promptbase/blob/main/src/promptbase/mmlu/prompt_templates.py) |The most effective prompting technique for MMLU at the moment is Microsoft's Medprompt+. The template, along with numerous other chain-of-thought style templates that are widely used in the evaluation community, was made available by Microsoft. |
|[Amphion.](https://github.com/open-mmlab/Amphion) | Amphion (/æmˈfaɪən/) is a toolkit for Audio, Music, and Speech Generation. Its purpose is to support reproducible research and help junior researchers and engineers get started in the field of audio, music, and speech generation research and development. Amphion offers a unique feature: visualizations of classic models or architectures. |
|[Big Vision.](https://github.com/google-research/big_vision) |This codebase is designed for training large-scale vision models using Cloud TPU VMs or GPU machines. It is based on Jax/Flax libraries, and uses tf.data and TensorFlow Datasets for scalable and reproducible input pipelines. |
|[Thoughts on Jaxtyping.](https://kidger.site/thoughts/jaxtyping/) |In machine learning, shape problems are difficult to debug and can go undetected until the model is attempted to run. Checking shapes as kinds can help you get over most of this obstacle and advance faster. |
|[Legaltech x AI: The Lightspeed View.](https://lsvp.com/legaltech-x-ai-the-lightspeed-view/) |Lightspeed's perspective on the legaltech industry's use of AI is obvious and intriguing when viewed from the angle that what's good for VCs is good for everyone. Time will tell if they are on the right track or not, but there are some intriguing observations. |
|[New Sequence Mixers.](https://hazyresearch.stanford.edu/blog/2023-12-11-zoology2-based) |The folks who brought us Mamba (and a ton of other models) have published a nice blog entry explaining simple sequence mixing topologies that provide some very significant speed increases over traditional Transformers. |
|[microagents.](https://github.com/aymenfurter/microagents) | Agents Capable of Self-Editing Their Prompts / Python Code|
|[LLMLingua.](https://github.com/microsoft/LLMLingua) |LLMLingua utilizes a compact, well-trained language model (e.g., GPT2-small, LLaMA-7B) to identify and remove non-essential tokens in prompts. This approach enables efficient inference with large language models (LLMs), achieving up to 20x compression with minimal performance loss. |
|[Distil-Whisper.](https://github.com/huggingface/distil-whisper) |Distil-Whisper is a distilled version of Whisper that is 6 times faster, 49% smaller, and performs within 1% word error rate (WER) on out-of-distribution evaluation sets |
|[M3DBench: Let's Instruct Large Models with Multi-modal 3D Prompts.](https://m3dbench.github.io/) |M3DBench introduces a comprehensive 3D instruction-following dataset that encompasses a variety of 3D vision-centric tasks, spanning fundamental abilities in real-world 3D environments. |
|[WhisperPlus: Advancing Speech-to-Text Processing.](https://github.com/kadirnar/whisper-plus) | Advanced speech-to-text processing|
|[tinyzero.](https://github.com/s-casci/tinyzero) | Easily train AlphaZero-like agents in any environment you want!|
|[MossFormer2: Combining Transformer and RNN-Free Recurrent Network for Enhanced Time-Domain Monaural Speech Separation.](https://github.com/alibabasglab/MossFormer2) | An improvement on the original MossFormer, the MossFormer2 model provides better monaural speech separation capabilities.|
|[llama-recipes.](https://github.com/facebookresearch/llama-recipes) |The 'llama-recipes' repository is a companion to the Llama 2 model. This repository aims to provide examples to quickly get started with fine-tuning for domain adaptation and how to run inference for the fine-tuned models. |
|[LLaVA-Interactive.](https://llava-vl.github.io/llava-interactive/) | LLaVA-Interactive is a large language-and-vision assistant demo, dedicated to demonstrating the possibilities of multimodal human-machine interaction: visual input, visual output, and visual interaction. It combines complementary skills from three models: visual chat of LLaVA, visual prompt for segmentation from SEEM, and visual prompt for image generation/editing from GLIGEN.|
|[Whisper Turbo.](https://github.com/FL33TW00D/whisper-turbo) | Whisper Turbo is a fast, cross-platform Whisper implementation, designed to run entirely client-side in your browser/electron app.|

## Perspectives
|Link|description|
|---|---|
|[The Where, When, and How of AI with Theory Ventures, Open AI, MotherDuck and Lamini.](https://www.saastr.com/the-where-when-and-how-of-ai-with-theory-ventures-open-ai-motherduck-and-lamini/) | Prominent inventors and venture capitalists discuss the latest developments in artificial intelligence, ranging from the use of LLMs to enterprise innovation. This is a helpful fast summary if the speed of "things you should know about AI" is a little overwhelming.|
|[The Competition is Coming for Nvidia.](https://www.bigtechnology.com/p/the-competition-is-coming-for-nvidia) |After a long, largely unimpeded run, NVIDIA’s challenge has finally arrived. |
|[From Einstein to AI: how 100 years have shaped science.](https://www.nature.com/articles/d41586-023-04021-2) | Looking back a century reveals how much the research landscape has changed — and how unclear the consequences of scientific innovation can be.|
|[ChatGPT and science: the AI system was a force in 2023 — for good and bad.](https://www.nature.com/articles/d41586-023-03930-6) | The poster child for generative AI software is a startling human mimic. It represents a potential new era in research, but brings risks.|
|[What was the Turing test actually about?.](https://www.nature.com/articles/d41586-023-04058-3) |It is important to develop metrics for the public scrutiny of today’s generative artificial intelligence. |
|[Should scientists delegate their writing to ChatGPT?.](https://www.nature.com/articles/d41586-023-04055-6) | Scientists should exercise caution when using generative artificial intelligence (AI) tools such as ChatGPT to write grant applications|
|[Mentor–trainee dialogue on proper use of AI tools.](https://www.nature.com/articles/d41586-023-04062-7) |The responsible use of artificial-intelligence (AI) tools in education and academia is important on a micro- as well as a macro scale |
|[My jaw hit the floor when I watched an AI master one of the world's toughest physical games in just six hours.](https://www.techradar.com/computing/artificial-intelligence/my-jaw-hit-the-floor-when-i-watched-an-ai-master-one-of-the-worlds-toughest-physical-games-in-just-six-hours) | An AI just mastered Labyrinth in six hours, and I am questioning my own existence.|
|[Meta’s CTO on how the generative AI craze has spurred the company to ‘change it up’.](https://www.semafor.com/article/12/20/2023/meta-cto-andrew-bosworth-on-the-generative-ai-craze) | Andrew Bosworth, Chief Technology Officer at Meta, discusses the company's future plans and the hype around artificial intelligence.|
|[End of YearPay Report 2023.](https://www.levels.fyi/2023/) |Levels.fyi's annual compensation report. View top-paying companies, cities, titles & other trends. |
|[Year One of Generative AI: Six Key Trends.](https://foundationcapital.com/year-one-of-generative-ai-six-key-trends) |In this post, drawing on countless founder meetings and pitch decks, we distill our first-hand learnings into six trends that have defined the generative AI space throughout 2023 and that are set to shape its trajectory in 2024. |
|[Marketplaces in the Age of AI.](https://a16z.com/marketplaces-in-the-age-of-ai/) |For the past 20 years, marketplaces have dominated company models. This is a summary from a16z discussing their predictions on how AI would affect this kind of business. Customizing the experience for both sides of the marketplace is the main concept. |


# ML news: Week 11 - 17 December

## Research
|Link|description|
|---|---|
|[RAVE: Randomized Noise Shuffling for Fast and Consistent Video Editing with Diffusion Models.](https://rave-video.github.io/) |RAVE is a technique for video editing that improves videos by utilizing pre-existing text-to-image diffusion models. With this method, it is possible to achieve excellent video edits without sacrificing the original composition and flow. |
|[Language-driven Scene Synthesis using Multi-conditional Diffusion Model.](https://github.com/andvg3/LSDM) |Textual cues give scene creation—which is influenced by things like human movement or room design—a new perspective. This repository presents a new method that effectively combines text, movement, and pre-existing objects: a multi-conditional diffusion model. |
|[Audiobox: Unified Audio Generation with Natural Language Prompts.](https://ai.meta.com/research/publications/audiobox-unified-audio-generation-with-natural-language-prompts/) |Meta has hinted at an AI model for audio foundations. The paper, along with more samples and powerful demos, have been made available. Producing controlled audio content with styles derived from the same model was the primary objective of the project. |
|[BioCLIP: A Vision Foundation Model for the Tree of Life.](https://imageomics.github.io/bioclip/) |A vision model with applications in biology in mind. On certain physiological tasks, it performs about 20% better than OpenAI's clip. There is also a training set of 10 million paired images and text. |
|[Diversifying Spatial-Temporal Perception for Video Domain Generalization.](https://arxiv.org/abs/2310.17942v1) |A novel model called the Spatial-Temporal Diversification Network (STDN) examines relationships over time as well as spatial elements within frames to identify a range of cues in movies. |
|[Train Once, Get a Family: State-Adaptive Balances for Offline-to-Online Reinforcement Learning.](https://shenzhi-wang.github.io/NIPS_FamO2O/) | FamO2O is a framework that researchers have developed to improve the performance of existing offline-to-online reinforcement learning algorithms by figuring out how to best balance limitations and improvement depending on the state.|
|[Promising or Elusive? Unsupervised Object Segmentation from Real-world Single Images.](https://vlar-group.github.io/UnsupObjSeg.html) |This study explores the challenge of utilizing unsupervised models to segment items in real-world photographs. |
|[Phi-2: The surprising power of small language models.](https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/) | Azure's Phi 2 is the latest in a line of small language models that were mostly trained on synthetic data. The performance of 13B parameter models is matched by the 2.7B parameter model. The difficult part of this task is identifying and addressing "test set rephrasing," although the model is very effective in any scenario.|
|[DiAD: A Diffusion-based Framework for Multi-class Anomaly Detection.](https://arxiv.org/abs/2312.06607v1) |DiAD uses diffusion models to its advantage in order to find abnormalities. To precisely identify and pinpoint abnormalities in multi-class environments, it integrates a pixel-space autoencoder, a Semantic-Guided (SG) network, and a feature-space extractor in a novel way. |
|[Learning Naturally Aggregated Appearance for Efficient 3D Editing.](https://felixcheng97.github.io/AGAP/) |A new technique called AGAP makes 3D editing easier. AGAP enables users to effortlessly update 3D scenes without having to re-optimize for each change by utilizing a 2D image known as a canonical image. |
|[Sherpa3D: Boosting High-Fidelity Text-to-3D Generation via Coarse 3D Prior.](https://liuff19.github.io/Sherpa3D/) | A novel framework called Sherpa3D enhances the production of 3D content via text prompts. By employing coarse 3D information to direct the creation process, it combines the advantages of 2D and 3D diffusion models. Thus, the constraints of current technologies are overcome and high-quality, diversified, and geometrically consistent 3D assets are produced.|
|[Rethinking Compression: Reduced Order Modelling of Latent Features in Large Language Models.](https://arxiv.org/abs/2312.07046v1) | This work presents a technique for reduced order modeling-based big language model compression that greatly minimizes memory and time requirements without requiring expensive hardware. |
|[Towards a Generalized Multimodal Foundation Model.](https://x-decoder-vl.github.io/) |With the help of FIND, AI models now have a flexible interface that improves their comprehension of datasets and visuals without changing the fundamental model. |
|[HyperRouter: Towards Efficient Training and Inference of Sparse Mixture of Experts via HyperNetwork.](https://github.com/giangdip2410/hyperrouter) |The HyperRouter technique dynamically modifies router characteristics to increase the effectiveness of training big language models. |
|[FunSearch: Making new discoveries in mathematical sciences using Large Language Models.](https://deepmind.google/discover/blog/funsearch-making-new-discoveries-in-mathematical-sciences-using-large-language-models/) | By searching for “functions” written in computer code, FunSearch made the first discoveries in open problems in mathematical sciences using LLMs. [scientific article.](https://www.nature.com/articles/s41586-023-06924-6)|
|[Weak to Strong Generalization.](https://openai.com/research/weak-to-strong-generalization) |An analog to weak people aligning super intelligent models, this new discovery from the OpenAI super alignment team (with code) implies that you may utilize much weaker supervisor models to guide or align a considerably more powerful model. To regain much of the alignment performance of GPT-4, they employed GPT-2. Among the key differences between this approach and RLHF-like approaches is that the former provides a tractable route for significant improvement. |
|[Chat-3D v2: Bridging 3D Scene and Large Language Models with Object Identifiers.](https://arxiv.org/abs/2312.08168v1) |Object identifiers are included in Large Language Models by a novel research technique aimed at enhancing comprehension and providing answers about 3D situations. This approach, which focuses on finding and connecting items in a scene, has demonstrated encouraging outcomes in terms of improving AI's comprehension of intricate spatial connections. |
|[SwitchHead: Accelerating Transformers with Mixture-of-Experts Attention.](https://arxiv.org/abs/2312.07987v2) |SwitchHead is a breakthrough in improving the effectiveness of AI models. Transformers' memory and processing requirements are decreased without sacrificing functionality. |
|[Beyond Human Data: Scaling Self-Training for Problem-Solving with Language Models.](https://arxiv.org/abs/2312.06585) |offers a method for self-training with feedback that can significantly lessen reliance on data created by humans; when model-generated data is used in conjunction with a reward function, LLM performance on problem-solving tasks is enhanced. |


## News
|Link|description|
|---|---|
|[French AI start-up Mistral secures €2bn valuation.](https://www.ft.com/content/ea29ddf8-91cb-45e8-86a0-f501ab7ad9bb) | Eight-month-old group set to close roughly €400mn funding round as early as Friday, in new deal lead by Andreessen Horowitz. Meanwhile, it unveils its platform with [new models, an embedding, and instruction-tuned models.](https://mistral.ai/news/la-plateforme/)|
|[Google unveils AlphaCode 2, powered by Gemini.](https://techcrunch.com/2023/12/06/deepmind-unveils-alphacode-2-powered-by-gemini/) | Alongside its Gemini generative AI model, Google this morning took the wraps off of AlphaCode 2, an improved version of the code-generating AlphaCode|
|[Introducing Stable LM Zephyr 3B.](https://stability.ai/news/stablelm-zephyr-3b-stability-llm) |Stable LM Zephyr 3B is a 3 billion parameter Large Language Model (LLM), 60% smaller than 7B models, allowing accurate, and responsive output on a variety of devices without requiring high-end hardware. |
|[Better, Cheaper, Faster LLM Alignment with KTO.](https://contextual.ai/better-cheaper-faster-llm-alignment-with-kto) |a method called Kahneman-Tversky Optimization (KTO) that makes it easier and cheaper than ever before to align LLMs on your data without compromising performance. |
|[Paving the way to efficient architectures: StripedHyena-7B.](https://www.together.ai/blog/stripedhyena-7b) |StripedHyena builds on the many lessons learned in the past year on designing efficient sequence modeling architectures: H3, Hyena, HyenaDNA, and Monarch Mixer. |
|[FTC looking into Microsoft's investment in OpenAI: Report.](https://finance.yahoo.com/video/ftc-looking-microsofts-investment-openai-222919020.html) |Following UK regulators' probe, the Federal Trade Commission (FTC) is inspecting Microsoft's (MSFT) relationship with and investment in artificial intelligence developer OpenAI, according to Bloomberg. |
|[Liquid AI, a new MIT spinoff, wants to build an entirely new type of AI.](https://techcrunch.com/2023/12/06/liquid-ai-a-new-mit-spinoff-wants-to-build-an-entirely-new-type-of-ai/) |An MIT spinoff co-founded by robotics luminary Daniela Rus aims to build general-purpose AI systems powered by a relatively new type of AI model called a liquid neural network. |
|[Microsoft and Labor Unions Form ‘Historic’ Alliance on AI.](https://finance.yahoo.com/news/microsoft-labor-unions-form-historic-142333100.html) |Microsoft Corp. is teaming up with labor unions to create “an open dialogue” on how artificial intelligence will impact workers. |
|[Europe reaches a deal on the world’s first comprehensive AI rules.](https://apnews.com/article/ai-act-europe-regulation-59466a4d8fd3597b04542ef25831322c) | European Union negotiators clinched a deal Friday on the world’s first comprehensive artificial intelligence rules, paving the way for legal oversight of AI technology that has promised to transform everyday life and spurred warnings of existential dangers to humanity.|
|[OpenAI leaders warned of abusive behavior before Sam Altman’s ouster.]() |Sam Altman was briefly fired by OpenAI after a group of top leaders expressed concerns to the board about his claimed psychological abuse, which included inciting conflict amongst staff and causing turmoil. There were also allegations of dishonesty in Altman's board discussions. Threats of widespread resignations and resounding staff support led to Altman's restoration; yet, the incident has raised doubts about the company's future course. |
|[MIT group releases white papers on governance of AI.](https://news.mit.edu/2023/mit-group-releases-white-papers-governance-ai-1211) | The series aims to help policymakers create better oversight of AI in society.|
|[Google weighs Gemini AI project to tell people their life story using phone data, photos.](https://www.cnbc.com/2023/12/08/google-weighing-project-ellmann-uses-gemini-ai-to-tell-life-stories.html) |“Project Ellmann” is an internal Google proposal to use artificial intelligence to help users get a “bird’s-eye view” of their life stories. The idea would be to use LLMs like Gemini to ingest search results, spot patterns in a user’s photos, create a chatbot and “answer previously impossible questions” about a person’s life. The team also demonstrated “Ellmann Chat,” with the description “Imagine opening ChatGPT but it already knows everything about your life.”|
|[a16z Open Source AI Grant recipients.](https://a16z.com/announcing-our-latest-open-source-ai-grants/) |This program is designed to support a thriving open-source ecosystem around modern AI. We provide grant funding (not an investment) to developers and small teams who are building critical pieces of the open-source AI stack.  |
|[Google debuts Imagen 2 with text and logo generation.](https://techcrunch.com/2023/12/13/google-debuts-imagen-2-with-text-and-logo-generation/) |Google’s making the second generation of Imagen, its AI model that can create and edit images given a text prompt, more widely available — at least to Google Cloud customers using Vertex AI who’ve been approved for access. |
|[First Impressions with Google’s Gemini.](https://blog.roboflow.com/first-impressions-with-google-gemini/) |The Roboflow team has analyzed Gemini across a range of standard prompts that we have used to evaluate other LMMs, including GPT-4 with Vision, LLaVA, and CogVLM. Our goal is to  better understand what Gemini can and cannot do well at the time of writing this piece. |
|[OpenAI inks deal with Axel Springer on licensing news for model training.](https://techcrunch.com/2023/12/13/openai-inks-deal-with-axel-springer-on-licensing-news-for-model-training/) | |
|[OpenAI's Superalignment Fast Grants.](https://openai.com/blog/superalignment-fast-grants) |We’re launching $10M in grants to support technical research towards the alignment and safety of superhuman AI systems, including weak-to-strong generalization, interpretability, scalable oversight, and more. |
|[A new old kind of R&D lab.](https://www.answer.ai/posts/2023-12-12-launch.html) | Respond AI is a new lab that seeks to find genuinely useful and productive applications for current models rather than creating new ones. Its goal is to do basic research to assist enterprises in enabling AI-enabled application cases.|
|[Samsung unveils its generative AI model Samsung Gauss.](https://www.zdnet.com/article/samsung-unveils-its-generative-ai-model-samsung-gauss/) |Samsung Gauss consists of language, code, and image models and will be applied to the company's various products in the future. |


## Resources
|Link|description|
|---|---|
|[Towards 100x Speedup: Full Stack Transformer Inference Optimization.](https://yaofu.notion.site/Towards-100x-Speedup-Full-Stack-Transformer-Inference-Optimization-43124c3688e14cffaf2f1d6cbdf26c6c) |Deployment optimizations are getting more and more popular as open models prove beneficial for various enterprise needs. But the terrain is uneven and complicated. This article provides a good in-depth analysis of numerous common methods for accelerating language model serving.|
|[Pearl - A Production-ready Reinforcement Learning AI Agent Library.](https://github.com/facebookresearch/Pearl) | Pearl is a new production-ready Reinforcement Learning AI agent library open-sourced by the Applied Reinforcement Learning team at Meta.|
|[Running Dolphin Locally with Ollama.](https://erichartford.com/running-dolphin-locally-with-ollama) |For llama cpp models, ollama functions similarly to a package management. Its characteristics for quality-of-life usability make modeling simple, even while using a CPU. The two fantastic models, Samantha and Dolphin, which are good unfiltered models helpful for conversational activities, are demonstrated in this example. |
|[LLM Visualization.](https://bbycroft.net/llm) |Welcome to the walkthrough of the GPT large language model! Here we'll explore the model nano-gpt, with a mere 85,000 parameters. |
|[giskard.](https://github.com/Giskard-AI/giskard) | The testing framework dedicated to ML models, from tabular to LLMs|
|[BricksLLM: AI Gateway For Putting LLM In Production.](https://github.com/bricks-cloud/BricksLLM) |BricksLLM is a cloud native AI gateway written in Go. Currently, it serves as a proxy to OpenAI. We let you create API keys that have rate limits, cost limits and TTLs.  |
|[KwaiAgents.](https://github.com/kwaikeg/kwaiagents) |KwaiAgents is a series of Agent-related works open-sourced by the KwaiKEG from Kuaishou Technology |
|[Now add a walrus: Prompt engineering in DALL-E 3.](https://simonwillison.net/2023/Oct/26/add-a-walrus/) |An experiment using DALL-E 3 that shows how various prompts produce a range of visuals and how additional prompts hone these images.|
|[HuggingFace gets AMD support.](https://github.com/huggingface/transformers/releases/tag/v4.36.0) |The new Mistral model, AMD compatibility, safetensors by default, and more are included in Transformers 4.36.0! |
|[AI Tamago.](https://github.com/ykhli/AI-tamago) |An 100% local, LLM-generated and driven virtual pet with thoughts, feelings and feedback. Revive your fond memories of Tamagotchi!|
|[Introducing gigaGPT: GPT-3 sized models in 565 lines of code.](https://www.cerebras.net/blog/introducing-gigagpt-gpt-3-sized-models-in-565-lines-of-code) |GigaGPT is Cerebras’ implementation of Andrei Karpathy’s nanoGPT – the simplest and most compact code base to train and fine-tune GPT models. |
|[Awesome CLIP in Medical Imaging.](https://github.com/zhaozh10/awesome-clip-in-medical-imaging) | This is a collection of awesome articles about CLIP in medical imaging|
|[Roadmap To Learn Generative AI In 2024.](https://github.com/krishnaik06/Roadmap-To-Learn-Generative-AI-In-2024) | A repository with links and videos |
|[Lookup Table meets Local Laplacian Filter: Pyramid Reconstruction Network for Tone Mapping.](https://github.com/fengzhang427/LLF-LUT) | LLF-LUT is an effective end-to-end framework for the HDR image tone mapping task performing global tone manipulation while preserving local edge details.|
|[Obsidian: Worlds smallest multi-modal LLM. First multi-modal model in size 3B.](https://huggingface.co/NousResearch/Obsidian-3B-V0.5) |Obsidian-3B-V0.5 is a multi-modal AI model that has vision! it's smarts are built on Capybara-3B-V1.9 based on StableLM-3B-4e1t. Capybara-3B-V1.9 achieves state-of-the-art performance when compared to model with similar size, even beats some 7B models. |
|[Mathematical Language Models: A Survey.](https://arxiv.org/abs/2312.07622) |a survey on LLMs' development on mathematical activities; includes papers and resources on LLM research on tasks including theorem proving and math word problem solving, as well as prompting approaches. |
|[A Survey of Large Language Models in Medicine: Principles, Applications, and Challenges.](https://arxiv.org/abs/2311.05112) |a thorough analysis of more than 300 papers on LLMs in medicine; provides a synopsis of the concepts, uses, and difficulties faced by LLMs in the field. |

## Perspectives
|Link|description|
|---|---|
|[Excuse me, but the industries AI is disrupting are not lucrative.](https://www.theintrinsicperspective.com/p/excuse-me-but-the-industries-ai-is) |Although the demo video for Google's Gemini AI model was remarkable, the model's real-time capabilities were questioned due to the use of pre-recorded material and edited responses, which resulted in a modest gain in Google's stock price. This caution is reflective of larger worries in the AI sector, as businesses set high standards but struggle to convert AI skills into meaningful economic gains. Current AI models are particularly good in domains that don't always generate large profits. |
|[Interoperable Authentication Protocol.](https://www.artifact.io/iap) |Considering how quickly model capabilities are developing, coordinating communication between language models and users is essential. In order to address this, the Interoperable Authorization Protocol (IAP) establishes a consent management system and secure, flexible communication routes. In order to match AI operations with a variety of human values and objectives, this open-source methodology promotes cooperation within the AI community. |
|[On Platform Shifts and AI.](https://caseyaccidental.com/on-platform-shifts-and-ai/) |While AI represents a technological shift, the discussion at the 2022 TCV Engage Summit focused on the fact that it requires a new distribution channel, which is critical for generating meaningful consumer prospects. Presently available AI breakthroughs are dependent on conventional channels of distribution, which benefits well-established businesses or creative start-ups; nevertheless, new channels of distribution may not materialize as expected. |
|[The AI revolution in chemistry is not that far away.](https://www.nature.com/articles/d41586-023-03948-w) |Although the artificial intelligence (AI) revolution in chemistry has yet to happen, it is not that far off. The key question is what we can do to get there faster. |
|[Can AI deliver advice that is judgement-free for science policy?](https://www.nature.com/articles/d41586-023-03949-9) | We acknowledge the potential of using artificial intelligence (AI) to inform science policy, but disagree with the suggestion that it can create judgement-free policy advice|
|[How to make data open? Stop overlooking librarians.](https://www.nature.com/articles/d41586-023-03935-1) |Digital archivists are already experts at tackling the complex challenges of making research data open and accessible. We can help to smooth the transition. |
|[Vertical AI.](https://greylock.com/greymatter/vertical-ai/) | The previous ten years of SaaS have been characterized by horizontal software, or software created to alleviate a user's pain regardless of the kind of user experiencing it. In contrast, vertical SaaS is intended for a specific user base, making it possible to customize the solution to meet their demands. According to a Greylock partner's prediction in this article, going future, software development will be guided by consumers' expectations for customized services.|
|[Why the AI Act was so hard to pass.](https://www.theverge.com/2023/12/13/23999849/eu-ai-act-artificial-intelligence-regulations-complicated-delays) |Over two years since it was first proposed, policymakers in Brussels were still debating core contents of the EU’s landmark AI regulations hours before reaching a deal. |
|[Google’s Gemini Marketing Trick.](https://www.bigtechnology.com/p/googles-gemini-marketing-trick) |The world saw a jaw-dropping demo of Gemini this week. It just wasn’t the real deal. |
|[Why Stability AI is launching a subscription fee.](https://sifted.eu/articles/stability-business-model) |Stability AI will charge commercial customers for the use of its most advanced models, pivoting away from being fully open source |
|[The real research behind the wild rumors about OpenAI’s Q* project.](https://www.understandingai.org/p/how-to-think-about-the-openai-q-rumors) | OpenAI hasn't said what Q* is but it has revealed plenty of clues.|
|[Two Titans on the Future of AI (with Reid Hoffman & Vinod Khosla).](https://www.newcomer.co/p/two-titans-on-the-future-of-ai-with) |A double header from Cerebral Valley. |


# ML news: Week 4 - 10 December

## Research
|Link|description|
|---|---|
|[Diffusion Models Without Attention.](https://arxiv.org/abs/2311.18257) | Modern diffusion models employ the attention mechanism in most cases, but not always. Recent advances in theory have accelerated the proliferation of interest in state spaces, leading to intriguing new applications. |
|[MoMask: Generative Masked Modeling of 3D Human Motions.](https://ericguo5513.github.io/momask/) | A new initiative by the authors of seminal work in this field combines innovative encoder techniques to provide fine-grained control over the production of the final animation.|
|[When StyleGAN Meets Stable Diffusion.](https://csxmli2016.github.io/projects/w-plus-adapter/) |Enhancing identity preservation in produced pictures, a novel technique uses the enlarged StyleGAN embedding space W+ for text-to-image diffusion models. |
|[MaXTron: Mask Transformer with Trajectory Attention for Video Panoptic Segmentation.](https://github.com/tacju/maxtron) | MaXTron is a simple yet effective unified meta-architecture for video segmentation, which enriches existing clip-level segmenters by introducing a within-clip tracking module and a cross-clip tracking module, thus achieving better temporally consistent segmentation results.|
|[Mamba: Linear-Time Sequence Modeling with Selective State Spaces.](https://arxiv.org/abs/2312.00752) | An additional article on state spaces that offers better performance and scalability. Here, they train a 3B parameter model, which beats out bigger 7B parameter Transformer models, by taking inspiration from the LSTM. [official code.](https://github.com/radarFudan/mamba)|
|[MotionEditor: Editing Video Motion via Content-Aware Diffusion.](https://arxiv.org/abs/2311.18830) |MotionEditor is a diffusion model that expertly strikes a balance between preserving the original material and manipulating motion in videos. With the introduction of a novel two-branch architecture with attention injection and a content-aware motion adaptor, modified movements may be seamlessly integrated while preserving the protagonist's look and the original background. [official code.](https://github.com/Francis-Rings/MotionEditor) |
|[Exploiting Diffusion Prior for Generalizable Pixel-Level Semantic Prediction.](https://shinying.github.io/dmp/) | Artificial intelligence-generated images now have more accurate semantic predictions because to a new technique called Diffusion Models as Prior (DMP). Even with minimal training data, this novel method outperforms existing approaches by shrewdly adapting pre-trained text-to-image models for a variety of tasks, such as semantic segmentation and 3D property estimation. [official code.](https://github.com/shinying/dmp)|
|[IMMA: Immunizing text-to-image Models against Malicious Adaptation.](https://zhengyjzoe.github.io/imma/) |A novel way to prevent malicious adaptations of text-to-image models to produce harmful content is provided by the new IMMA approach. [official code.](https://github.com/zhengyjzoe/IMMA)|
|[Language model self-teaching for domain adaptation.](https://morph.so/blog/self-teaching/) |You may either employ some retrieval strategies or fine-tune language models when attempting to apply them in areas that need knowledge of certain niches. Each has shortcomings. This innovative approach makes use of artificial data that is self-generated to improve knowledge throughout testing. In comparison to both fine-tuning and RAG, it demonstrates notable gains on typical adaption standards. |
|[DiffiT: Diffusion Vision Transformers for Image Generation.](https://github.com/nvlabs/diffit) |The Diffusion Vision Transformers (DiffiT) are a project that investigates the efficacy of vision transformers in diffusion-based generative learning. This model combines a new time-dependent self-attention module with a U-shaped encoder-decoder design. |
|[Zero123++: A Single Image to Consistent Multi-view Diffusion Base Model.](https://github.com/sudo-ai-3d/zero123plus) |This project introduces Zero123++, a model that applies diffusion concepts to produce consistent multi-view pictures from a single input image. Zero123++ tackles problems like as alignment and texture quality by using pretrained 2D models. |
|[Salient Object Detection in RGB-D Videos (RDVS dataset and DCTNet+ model).](https://github.com/kerenfu/rdvs) | The RDVS dataset, which contains a wide variety of RGB-D video sequences, and DCTNet+, a specialized network for RGB-D video object detection, which is outfitted with cutting-edge features for accurate prediction and enhanced performance over previous models, are the two main contributions revealed by this repository.|
|[Style Aligned Image Generation via Shared Attention.](https://style-aligned-gen.github.io/) |Amazing work by Google based on SDXL that distributes focus between generations to preserve unified looks. Importantly, this approach doesn't need to be adjusted. |
|[Describing Differences in Image Sets with Natural Language.](https://arxiv.org/abs/2312.02974) |This essay compares and contrasts two image collections using natural language. This is a brand-new, difficult challenge. The individual photos are captioned, rearranged, and summarized using a language model as part of the solution. [official code.](https://github.com/understanding-visual-datasets/visdiff)|
|[BenchLMM: Benchmarking Cross-style Visual Capability of Large Multimodal Models.](https://github.com/AIFEG/BenchLMM) | In this work, BenchLMM, a benchmark for testing the resilience of large multimodal models such as GPT-4V and LLaVA against different image styles, is presented.|
|[Let's Think Outside the Box !](https://zhongshsh.github.io/CLoT/) |This paper presents an approach to investigate Leap-of-Thought capabilities in multimodal LLMs using the Oogiri comedy generating game. This method forces LLMs to use non-sequential thinking, which is an essential ability for coming up with original and amusing answers to a variety of multimodal material. |
|[OneLLM: One Framework to Align All Modalities with Language.](https://onellm.csuhan.com/) | OneLLM employs a universal enocoder and a universal projection module to align multimodal inputs with LLM. It also utilizes modality tokens {modal} to switch between modalities.|
|[Kandinsky 3.0.](https://ai-forever.github.io/Kandinsky-3/) |We present Kandinsky 3.0, a large-scale text-to-image generation model based on latent diffusion, continuing the series of text-to-image Kandinsky models and reflecting our progress to achieve higher quality and realism of image generation. Compared to previous versions of Kandinsky 2.x, Kandinsky 3.0 leverages a two times larger UNet backbone, a ten times larger text encoder and remove diffusion mapping. [official code.](https://github.com/ai-forever/Kandinsky-3) |



## News
|Link|description|
|---|---|
|[OpenAI’s GPT store delayed to next year.](https://www.theverge.com/2023/12/1/23984497/openai-gpt-store-delayed-ai-gpt) | OpenAI’s GPT store will be delayed until next year, the company said in an email to people who signed up for its GPT Builder.|
|[Amazon's Q generative AI chatbot allegedly leaks location of AWS data centers - report.](https://www.datacenterdynamics.com/en/news/amazons-q-generative-ai-chatbot-leaks-location-of-aws-data-centers/) |Amazon's newly launched artificial intelligence chatbot Amazon Q is “experiencing severe hallucinations and leaking confidential data,” internal documents warn. |
|[Interview: Sam Altman on being fired and rehired by OpenAI.](https://www.theverge.com/2023/11/29/23982046/sam-altman-interview-openai-ceo-rehired) | “I totally get why people want an answer right now. But I also think it’s totally unreasonable to expect it.” In the meanwhile, [OpenAI Agreed to Buy $51 Million of AI Chips From a Startup Backed by CEO Sam Altman](https://www.wired.com/story/openai-buy-ai-chips-startup-sam-altman/) and other details on the story emerge: [New report illuminates why OpenAI board said Altman “was not consistently candid”.](https://arstechnica.com/ai/2023/12/openai-board-reportedly-felt-manipulated-by-ceo-altman)|
|[Report: Stability AI Positioning Itself for Acquisition.](https://www.pymnts.com/acquisitions/2023/report-stability-ai-positioning-itself-for-acquisition) |Stability AI, a British artificial intelligence (AI) startup, is reportedly considering selling the company amidst mounting pressure from investors over its financial position.  |
|[Report: Google delays Gemini launch from next week to January.](https://9to5google.com/2023/12/02/google-gemini-launch-delay/) |Google announced Gemini at I/O 2023 as its next-generation foundation model. According to a report today, Google was originally going to launch Gemini next week, but that has now been delayed until January. |
|[The GPT to rule them all: Training for one trillion parameter model backed by Intel and US government has just begun.](https://www.techradar.com/pro/the-gpt-to-rule-them-all-training-for-one-trillion-parameter-model-backed-by-intel-and-us-government-has-just-begun) | LLM playfully dubbed 'ScienceGPT' is being trained from data from the Aurora supercomputer|
|[Perplexity AI unveils ‘online’ LLMs that could dethrone Google Search.](https://venturebeat.com/ai/perplexity-ai-unveils-online-llms-that-could-dethrone-google-search/) |Confusing AI has the ability to overthrow Google with its blend of current knowledge, a conversational AI chatbot interface, and a web index. Versions of the open source models from Mistral and Meta that have been improved and enhanced have been made available by the firm. The models are meant to provide useful, accurate, and current information. These are the first-ever live LLM APIs with no knowledge cutoff, and they are based on online search data. |
|[AI Alliance Launches as an International Community for Safe and Open AI .](https://ai.meta.com/blog/ai-alliance) |More than 50 international organizations come together under the leadership of IBM and Meta to promote transparent, ethical AI development. Its main objectives are to advance hardware, establish AI standards, and advance AI knowledge and expertise. Major IT companies, academic organizations, and research centers are among the members. The Alliance places a strong emphasis on diversity, safety, and fair access to AI innovation. |
|[Elon Musk's AI firm xAI files to raise up to $1 billion in equity offering.](https://finance.yahoo.com/news/elon-musks-xai-files-raise-193558630.html) | lon Musk's artificial intelligence startup xAI has filed with the U.S. securities regulator to raise up to $1 billion in an equity offering, according to a filing on Tuesday.|
|[Google’s new AI experiment composes abstract musical clips inspired by instruments.](https://www.engadget.com/googles-new-ai-experiment-composes-abstract-musical-clips-inspired-by-instruments-203732054.html) | You may not hear the exact sound of the instrument you entered. [you can try here.](https://blog.google/outreach-initiatives/arts-culture/google-arts-culture-new-music-ai-experiment/)|
|[Solve Intelligence helps attorneys draft patents for IP analysis and generation.](https://techcrunch.com/2023/11/28/solve-intelligences-ai-solution-helps-attorneys-draft-patents-for-ip-analysis-and-generation/) | A platform that is AI-native and helps quickly create excellent patents is called Solve Intelligence. More than 25 IP firms worldwide have been employing them since their launch in July, and customers have reported 60–90% increases in efficiency. After completing Y Combinator, the startup just revealed the details of its $3 million seed financing.|
|[Airbnb has acquired GamePlanner.AI.](https://news.airbnb.com/airbnb-has-acquired-gameplanner-ai) |Airbnb has purchased GamePlanner, an AI startup.AI, a business headed by Siamak Hodjat, an AI specialist, and Adam Cheyer, a co-founder of Siri. The group's main goals will be to integrate their technologies with Airbnb's platform and expedite certain AI projects. GamePlanner and Airbnb.AI are dedicated to leveraging AI to improve human-computer interaction. |
|[Introducing Gemini: our largest and most capable AI model.](https://blog.google/technology/ai/google-gemini-ai/) | The field-wise network is a column-specific neural network so as to capture the information associated with the feature. The second component, on the other hand, is across-field-network to choose the specialized operations for the dataset. Finally, the last step n operation fusion network nonlinearly connects the chosen operations. In other words, it is an enhancement of DeepFM in which the network selects the best operations. Apparently, not all was good: [Google’s best Gemini demo was faked.](https://techcrunch.com/2023/12/07/googles-best-gemini-demo-was-faked)|
|[Meta's AI image generator is available as a standalone website.](https://www.engadget.com/metas-ai-image-generator-is-available-as-a-standalone-website-185953058.html) |The company is testing dozens of new AI features in Facebook, Instagram and WhatsApp. |
|[Microsoft’s Copilot is getting OpenAI’s latest models and a new code interpreter.](https://www.theverge.com/2023/12/5/23989052/microsoft-copilot-gpt-4-turbo-openai-models-code-interpreter-feature) |GPT-4 Turbo is on the way soon, alongside improvements to the DALL-E 3 model and deep search results for Bing. |
|[Elon Musk told OpenAI to move faster right before he left the company in 2018: NYT.](https://www.businessinsider.com/elon-musk-told-openai-to-move-faster-before-he-left-2023-12) | Elon Musk said OpenAI needed to be quicker with its work before departing from the company, per NYT.|
|[Purple Llama: Towards open trust and safety in the new world of generative AI.](https://ai.meta.com/blog/purple-llama-open-trust-safety-generative-ai/) |Aiming to provide fair and equitable conditions for creating responsible and safe generative AI experiences, Purple Llama is a new initiative that is releasing models, assessments, and tools under permissive licenses for both commercial and research use. The Llama Guard model for identifying and thwarting cyberattacks, CyberSecEval for evaluating AI system security, and tools for insecure code detection and cyberattack compliance testing are among the initial products. By democratizing access to necessary resources, this project enables developers to design safe and ethical AI experiences. |
|[X begins rolling out Grok, its ‘rebellious’ chatbot, to subscribers.](https://techcrunch.com/2023/12/07/x-begins-rolling-out-grok-its-rebellious-chatbot-to-subscribers/) |Grok, a ChatGPT competitor developed by xAI, Elon Musk’s AI startup, has officially launched on X, the site formerly known as Twitter. |
|[Enabling next-generation AI workloads: Announcing TPU v5p and AI Hypercomputer.](https://cloud.google.com/blog/products/ai-machine-learning/introducing-cloud-tpu-v5p-and-ai-hypercomputer) |Google unveiled Cloud TPU v5p, the company's most potent, adaptable, and scalable AI accelerator to yet. AI-powered products are trained and served using TPUs. Additionally, Google has revealed the AI Hypercomputer from Google Cloud, a supercomputer architecture that makes use of an integrated system of top-tier machine learning frameworks, open software, performance-optimized hardware, and adaptable consumption options. Systems-level co-design is used by AI Hypercomputer to increase productivity and efficiency in AI serving, tweaking, and training. |
|[Long context prompting for Claude 2.1.](https://www.anthropic.com/index/claude-2-1-prompting) | In reference, Anthropic's last release of Claude had 200k tokens. It only demonstrated 27% retrieval performance on certain common tasks, suggesting that it was afflicted by the "lost in the middle" issue that plagues language models in external evaluations. Retrieval performance rises to 98% when the prompt is modified to include the statement "Assistant: Here is the most relevant sentence in the context."|

## Resources
|Link|description|
|---|---|
|[weight-selection.](https://github.com/OscarXZQ/weight-selection) | We introduce weight selection, a method for initializing models by selecting a subset of weights from a pre-trained larger model. With no extra cost, it is effective for improving the accuracy of a smaller model and reducing its training time needed to reach a certain accuracy level.|
|[Nous-Hermes-2-Vision - Mistral 7B.](https://huggingface.co/NousResearch/Nous-Hermes-2-Vision-Alpha) |This vision model is a potent new open-source text and vision model that can operate on consumer hardware, and it is built on top of the best 7B language model with SigLIP integration. The incorporation of function calling is one of the neat ideas here. Due to a hallucination problem, the model remains in alpha. |
|[LLM As A Function.](https://blog.vjeux.com/2023/analysis/llm-as-a-function.html) | It's helpful to think about language models as functions with standard input and output when adding them to your code base. The author of React Native demonstrates a couple methods for doing that in this blog post, along with the advantages of modeling your models in this manner.|
|[aiconfig.](https://github.com/lastmile-ai/aiconfig) |AIConfig saves prompts, models and model parameters as source control friendly configs. This allows you to iterate on prompts and model parameters separately from your application code. |
|[Microsoft's Generative AI for Beginners.](https://microsoft.github.io/generative-ai-for-beginners/) |A 12 Lesson course teaching everything you need to know to start building Generative AI applications |
|[Unsloth.](https://github.com/unslothai/unsloth) | Fast and memory-efficient LLM tuning.|
|[Responsible Innovation Labs Launches First Pro-Innovation Responsible AI Protocol For Startups.](https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.rilabs.org%2Fnews%2Fresponsible-ai-protocol-launch) | A voluntary industry-driven approach for responsible AI has been introduced by nonprofit Responsible Innovation Labs (RIL), especially for startups and their investors. The protocol is intended to make sure startups incorporate ethical AI practices as they grow, and it has the backing of 35 top venture capital funds. This action is in line with the Biden Administration's ethical AI goal.|
|[mlx.](https://github.com/ml-explore/mlx) |Thanks to unified memory, Apple has discreetly introduced a new Array framework that runs faster on Mac devices. It offers some GPU support in addition to being straightforward and tidy. |
|[stable-fast.](https://github.com/chengzeyi/stable-fast) |An ultra lightweight inference performance optimization framework for HuggingFace Diffusers on NVIDIA GPUs. |
|[Introducing the OpenAI Switch Kit: Move from closed to open-source AI in minutes.](https://postgresml.org/blog/introducing-the-openai-switch-kit-move-from-closed-to-open-source-ai-in-minutes) | With just a few lines of code, you can make your project open source.|
|[Optimizing LLMs for Real-World Applications.](https://lsvp.com/optimizing-llms-for-real-world-applications/) |Lightspeed provides information from TitanML and Google regarding the specifics of enhancing LLMs through fine-tuning or prompting. |
|[Efficient SAM Example.](https://github.com/yformer/EfficientSAM/blob/main/EfficientSAM_example.ipynb) |This script provides example for how to get visualization result from EfficientSAM using ready-to-use torchscript |
|[CopilotKit.](https://github.com/CopilotKit/CopilotKit) |Integrate AI-powered Textareas and in-app chatbots into React web applications. |
|[Mamba-Chat.](https://github.com/havenhq/mamba-chat/tree/main) |Mamba-Chat is the first chat language model based on a state-space model architecture, not a transformer. The model is based on Albert Gu's and Tri Dao's work Mamba: Linear-Time Sequence Modeling with Selective State Spaces  |
|[mlx-llama.](https://huggingface.co/mlx-llama/Llama-2-7b-chat-mlx) | People have already enabled Llama 2 models to operate on the new framework, just one day after Apple published the MLX framework. [or if you prefer Mistral.](https://github.com/ml-explore/mlx-examples/tree/main/mistral)|
|[UIDraw.](https://github.com/jordansinger/UIDraw?) |Draw and build a website on your phone. |
|[SEO GPT by Writesonic.](https://seogpt.writesonic.com/) |Boost your website’s SEO instantly right inside ChatGPT. |


## Perspectives
|Link|description|
|---|---|
|[The future of AI in software development.](https://www.lennysnewsletter.com/p/the-future-of-ai-in-software-development) |Inbal Shani, the Chief Product Officer of GitHub, talks about the role AI plays in software development and makes the case that AI-driven code production will increase developer productivity rather than replace it. She delves into GitHub's Copilot's performance measures, philosophy, and innovation-promoting practices. The future of AI in the IT sector is clarified by this discussion. |
|[OpenAI & Grand Strategy.](https://www.notboring.co/p/openai-and-grand-strategy) | The importance of grand strategy in the IT industry is emphasized in this essay, which compares the lofty goals of contemporary tech executives to historical victories and exhorts them to behave and think like historical leaders in order to match capabilities with ambitions. It uses the recent happenings at OpenAI as an illustration of a grand strategy that works and challenges prospective leaders to develop plans that match their skills with their goals for meaningful, constructive change.|
|[AI and Trust.](https://www.schneier.com/blog/archives/2023/12/ai-and-trust.html) | In the discussion, the speaker emphasizes the differences between social and interpersonal trust and warns about the potential for profit-driven organizations to take advantage of our inclination to view AI as friends rather than as a service. In order to guarantee that AI continues to be a reliable and advantageous service for society, they urge for government intervention through transparency legislation and regulations targeted at the people who create AI. They also ask for the creation of public AI models.|
|[AI Doomers are worse than wrong - they're incompetent.](https://www.infinitescroll.us/p/ai-doomers-are-worse-than-wrong-theyre) | This essay attacks the OpenAI AI doomer movement for making calculated mistakes and unnecessarily speeding up AI development instead of protecting it.|
|[How AI Changes Workflows.](https://matt-rickard.com/how) |GitHub has acknowledged the impact of AI on developer workflows and is "re-founding" Copilot. With AI-assisted procedures like autocomplete code, it will boost productivity and might potentially completely reorganize operations. This change permits customized workflows, but it also necessitates striking a compromise between flexibility and the capacity to offer extensive client assistance. |
|[Teach Llamas to Talk: Recent Progress in Instruction Tuning.](https://gaotianyu.xyz/blog/2023/11/30/instruction-tuning/) |After instruction tweaking was implemented, the utility of language models significantly increased. Synthetic data pipelines are one of the numerous recent innovations that improve and streamline the process. |
|[Two Titans on the Future of AI (with Reid Hoffman & Vinod Khosla).](https://www.newcomer.co/p/two-titans-on-the-future-of-ai-with) | An excellent synopsis of Reid Hoffman and Vinod Khosla's 45+ minute lectures, in which they each delved into a range of subjects from AI to manifestos for "techno-optimists." Both titans have insightful opinions about the future and the best ways to manage the tech sector.|
|[Is AI leading to a reproducibility crisis in science?](https://www.nature.com/articles/d41586-023-03817-6) |Scientists worry that ill-informed use of artificial intelligence is driving a deluge of unreliable or useless research. |
|[Generative AI could revolutionize health care — but not if control is ceded to big tech.](https://www.nature.com/articles/d41586-023-03803-y) | Large language models such as that used by ChatGPT could soon become essential tools for diagnosing and treating patients. To protect people’s privacy and safety, medical professionals, not commercial interests, must drive their development and deployment.|
|[ChatGPT one year on: who is using it, how and why?.](https://www.nature.com/articles/d41586-023-03798-6) | In just a year, ChatGPT has permeated scientific research. Seven scientists reveal what they have learned about how the chatbot should — and shouldn’t — be used.|
|[ML system design: 300 case studies to learn from.](https://www.evidentlyai.com/ml-system-design) |How do companies like Netflix, Airbnb, and Doordash apply machine learning to improve their products and processes? We put together a database of 300 case studies from 80+ companies that share practical ML use cases and learnings from designing ML systems. |

# ML news: Week 27 November - 3 December

## Research
|Link|description|
|---|---|
|[SegVol: Universal and Interactive Volumetric Medical Image Segmentation.](https://arxiv.org/abs/2311.13385v1) |Clinical analysis has entered a new era with the release of SegVol, a universal model for medical picture segmentation. SegVol is highly proficient at segmenting a wide range of anatomical categories, having been trained on a large set of CT images. [official code.](https://github.com/baai-dcai/segvol)|
|[Visual In-Context Prompting.](https://arxiv.org/abs/2311.13601v1) | This novel strategy supports a variety of cues and environments, significantly improving performance in segmentation tasks and demonstrating outstanding outcomes in open-ended challenges. [official code.](https://github.com/ux-decoder/dinov)|
|[Starling-7B: Increasing LLM Helpfulness & Harmlessness with RLAIF.](https://starling.cs.berkeley.edu/) |Researchers at Berkeley used synthetic preference data to train a brand-new, cutting-edge 7B parameter model. This blog discusses the unique difficulties in training reward models (such as how an example's score might change depending on where it is in the list) and how they overcome them. Both the training reward model and the generated model are made public. |
|[Segmentation-Based Parametric Painting.](https://manuelladron.github.io/semantic_based_painting) | A novel method has been devised by researchers to convert pictures into paintings that emulate human characteristics and aesthetics.|
|[Rethinking Attention: Exploring Shallow Feed-Forward Neural Networks as an Alternative to Attention Layers in Transformers.](https://arxiv.org/abs/2311.10642) | A groundbreaking study explores the potential of shallow feed-forward networks to replace attention mechanisms in Transformer models. Shallow feed-forward networks can emulate the behavior of attention mechanisms effectively, with similar performances. This research opens new avenues in neural network design, potentially simplifying complex models.|
|[MEDITRON-70B: Scaling Medical Pretraining for Large Language Models.](https://huggingface.co/papers/2311.16079) |Large language models (LLMs) can potentially democratize access to medical knowledge.  In this work, we improve access to large-scale medical LLMs by releasing MEDITRON: a suite of open-source LLMs with 7B and 70B parameters adapted to the medical domain.  |
|[DiffSLVA: Harnessing Diffusion Models for Sign Language Video Anonymization.](https://arxiv.org/abs/2311.16060v1) |A novel technique for maintaining linguistic content in sign language films while maintaining anonymity is DiffSLVA. By eliminating the need for exact position prediction, this method, which makes use of pre-trained diffusion models and a dedicated module for face expressions, addresses earlier shortcomings. |
|[Efficient Dataset Distillation via Minimax Diffusion.](https://arxiv.org/abs/2311.15529v1) | Generative diffusion techniques have been used in a novel way to produce surrogate datasets that are much less computationally intensive and far more representative and varied.|
|[Enhancing Perceptual Quality in Video Super-Resolution through Temporally-Consistent Detail Synthesis using Diffusion Models.](https://arxiv.org/abs/2311.15908v1) | A new method for video super-resolution (VSR) called StableVSR uses a temporal conditioning module together with diffusion models to improve the quality of upscaled movies.|
|[Animatable Gaussians: Learning Pose-dependent Gaussian Maps
for High-fidelity Human Avatar Modeling.](https://animatable-gaussians.github.io/) | This research suggests "Animatable Gaussians," a cutting-edge method that blends 3D Gaussian splatting with 2D CNNs to produce more realistic and intricate human avatars from films.|
|[Illuminating protein space with a programmable generative model.](https://www.nature.com/articles/s41586-023-06728-8) |Evolution has produced a range of diverse proteins, and now a generative model called Chroma can expand that set by allowing the user to design new proteins and protein complexes with desired properties and functions. |
|[Bridging the Gap: A Unified Video Comprehension Framework for Moment Retrieval and Highlight Detection.](https://arxiv.org/abs/2311.16464v1) |UVCOM is a new framework that better handles the distinct requirements of Video Moment Retrieval (MR) and Highlight Detection (HD). |
|[DeepSeek-LLM.](https://github.com/deepseek-ai/deepseek-LLM) |The Deepseek coder model demonstrated remarkable code synthesis capability. Its current chat LLM, with 67B parameters, works noticeably better than Llama 2's 70B. |
|[llamafile.](https://github.com/mozilla-Ocho/llamafile) | llamafile lets you distribute and run LLMs with a single file. [Introducing llamafile.](https://hacks.mozilla.org/2023/11/introducing-llamafile/)|
|[Millions of new materials discovered with deep learning.](https://deepmind.google/discover/blog/millions-of-new-materials-discovered-with-deep-learning/) |AI tool GNoME finds 2.2 million new crystals, including 380,000 stable materials that could power future technologies |
|[Seamless: Multilingual Expressive and Streaming Speech Translation.](https://ai.meta.com/research/publications/seamless-multilingual-expressive-and-streaming-speech-translation/) |An innovative technique that transforms automated voice recognition is called Seamless. Conversations feel more natural thanks to this sophisticated model, which not only translates across 76 languages but also maintains the speaker's distinct prosody and voice style. |
|[Language-conditioned Detection Transformer.](https://arxiv.org/abs/2311.17902v1) | A novel open-vocabulary detection system called DECOLA is presented by researchers. It performs exceptionally well at recognizing things outside of its training dataset. [official code.](https://github.com/janghyuncho/decola)|
|[Diffusion-MU-Attack.](https://github.com/optml-group/diffusion-mu-attack) |This project proposes an evaluation system to assess the reliability of safety-driven unlearning techniques in diffusion models through the use of adversarial prompts. |
|[AI system self-organises to develop features of brains of complex organisms.](https://www.cam.ac.uk/research/news/ai-system-self-organises-to-develop-features-of-brains-of-complex-organisms) | Cambridge scientists have shown that placing physical constraints on an artificially-intelligent system – in much the same way that the human brain has to develop and operate within physical and biological constraints – allows it to develop features of the brains of complex organisms in order to solve tasks.|


## News
|Link|description|
|---|---|
|[Anthropic slashes AI pricing amid rising competition.](https://venturebeat.com/ai/anthropic-slashes-ai-pricing-amid-rising-competition/) | For tokens created after the most recent version of Claude was released, Anthropic added a pricing reduction. Both closed and open model pressure are the source of this. In addition, [the model now can digest up to 200k tokens, hallucinates half as often, and can search the web](https://www.theverge.com/2023/11/21/23971070/anthropic-claude-2-1-openai-ai-chatbot-update-beta-tools), [more info here.](https://www.anthropic.com/index/claude-2-1)|
|[Gen AI for the Genome: LLM Predicts Characteristics of COVID Variants.](https://blogs.nvidia.com/blog/generative-ai-covid-genome-sequences) |A new demo lets users explore visualizations of the genome-scale language model by Argonne National Laboratory, NVIDIA, and other collaborators. |
|[Codegen raises new cash to automate software engineering tasks.](https://techcrunch.com/2023/11/16/codegen-raises-new-capital-llm-automation-for-software-dev/) |Codegen has successfully raised a significant amount of money for some truly incredible automated software development technology. It links GitHub PRs for automated engineering to Jira boards. |
|[Kyutai is a French AI research lab with a $330 million budget that will make everything open source.](https://techcrunch.com/2023/11/17/kyutai-is-an-french-ai-research-lab-with-a-330-million-budget-that-will-make-everything-open-source/) |This new lab, called Kyutai, will be a privately funded nonprofit working on artificial general intelligence. It will work with PhD students, postdocs, and researchers on research papers and open-source projects.|
|[Amazon and Salesforce Expand Partnership to Add New AI Capabilities.](https://www.pymnts.com/partnerships/2023/amazon-and-salesforce-expand-partnership-to-add-new-ai-capabilities/) | Salesforce and AWS have extended their collaboration to facilitate customers' management of data on both platforms and their integration of generative AI technology into their workflows and apps.|
|[Tesla starts releasing to employees FSD v12 – a critical update to self-driving effort.]() |Tesla has started releasing to employees its FSD v12 update, which is apparently critical to Tesla’s achieving its self-driving goal. The biggest difference with the update is how vehicle controls will be taken over by neural nets rather than being hard-coded by engineers. |
|[ChatGPT with voice is now available to all free users.](https://twitter.com/openai/status/1727065166188274145) | Download the app on your phone and tap the headphones icon to start a conversation.|
|[Announcing the MLCommons AlgoPerf Training Algorithms Benchmark Competition.](https://mlcommons.org/2023/11/mlc-algoperf-training-algorithms-competition/) | A recent competition called AlgoPerf attempts to optimize for wall clock time. This implies that you can earn real money if you can develop a technique that outperforms current settings (faster than ADAM, for example). Some of the biggest AI companies in the world today support this fascinating task.|
|[Introducing SDXL Turbo: A Real-Time Text-to-Image Generation Model.](https://stability.ai/news/stability-ai-sdxl-turbo) |SDXL Turbo achieves state-of-the-art performance with a new distillation technology, enabling single-step image generation with unprecedented quality, reducing the required step count from 50 to just one. [code and weights.](https://huggingface.co/stabilityai/sdxl-turbo)|
|[OpenAI unlikely to offer board seat to Microsoft, other investors - source.](https://finance.yahoo.com/news/openai-not-expected-offer-board-220512455.html) | ChatGPT owner OpenAI is not expected to offer Microsoft and other investors including Khosla Ventures and Thrive Capital seats on its new board, a person familiar with the matter told Reuters on Tuesday. [OpenAI has a new initial board](https://openai.com/blog/sam-altman-returns-as-ceo-openai-has-a-new-initial-board). OpenAI seems to have returned to normality, however [Some OpenAI employees are still feeling uneasy and looking for other jobs despite Sam Altman's return, report says.](https://www.businessinsider.com/openai-employees-uneasy-looking-newjobs-despite-sam-altman-return-2023-11)|
|[Sports Illustrated Published Articles by Fake, AI-Generated Writers.](https://futurism.com/sports-illustrated-ai-generated-writers) |Articles created by fictitious AI authors have been covertly published by Sports Illustrated. |
|[Together AI raises $102M series A.](https://www.together.ai/blog/series-a) |This investment, led by Kleiner Perkins, will support the expansion of the training and inference solutions, which have had tremendous uptake since Together's June debut. |
|[Amazon Q.](https://aws.amazon.com/q/) | A generative model was trained by Amazon to help AWS platform users. Additionally, it will be used to general business support. The model is a proprietary mechanism that responds to inquiries from users on different facets of Amazon's backend infrastructure.|
|[Voltage Park launches massive new cloud for AI development.](https://blog.voltagepark.com/voltage-park-launches-massive-new-cloud-for-affordable-ai-development/) |With a 24k H100 mega cluster, Voltage Park is a new cloud service that powers processes for clients like Character AI. With less than $2 per hour for each GPU, it appears to have industry-leading price. |
|[These ex-Apple employees are bringing AI to the desktop.](https://www.theverge.com/2023/11/29/23981802/software-applications-inc-workflow-shortcuts-apple-employees-startup) |After selling Workflow to Apple in 2017, the co-founders are back with a new startup that wants to reimagine how desktop computers work using generative AI. |
|[Martian’s tool automatically switches between LLMs to reduce costs.](https://techcrunch.com/2023/11/15/martians-tool-automatically-switches-between-llms-to-reduce-costs/) | With $9 million in funding, AI experts Etan Ginsberg and Shriyash Upadhyay founded the startup Martian. Martian developed a "model router" tool that intelligently routes requests to the best appropriate model for the job, maximizing the utilization of huge language AI models like GPT-4 and reducing costs. According to the founders, this strategy encourages fundamental research as opposed to competitive research.|


## Resources
|Link|description|
|---|---|
|[ziplora-pytorch.](Low-rank learning matrices, or LoRAs, alter model behavior at a lower cost than traditional fine-tuning. This paper suggests a practical method for combining LoRAs while preserving their unique information.) | Low-rank learning matrices, or LoRAs, alter model behavior at a lower cost than traditional fine-tuning. This paper suggests a practical method for combining LoRAs while preserving their unique information. [original paper](https://ziplora.github.io/)|
|[DuckTrack: Accurate Computer Activity Tracking.](https://duckai.org/blog/ducktrack) | It can be a little difficult to extract image, audio, and keystroke data from your computer. This library's goal is to train digital agents by simplifying that procedure.|
|[direct-preference-optimization.](https://github.com/eric-mitchell/direct-preference-optimization) |Using extremely identical data, direct preference optimization is a reliable substitute for RLHF. An implementation of the approach can be studied in this repository to gain knowledge about it. |
|[Kandinsky Video — a new text-to-video generation model.](https://ai-forever.github.io/kandinsky-video/) |This paper presents a new two-stage latent diffusion text-to-video generation architecture based on the text-to-image diffusion model. [code.](https://github.com/ai-forever/KandinskyVideo) |
|[SD-T2I-360PanoImage.](https://github.com/archerfmy/sd-t2i-360panoimage) |A novel circular blending technique has been developed by researchers to solve the enduring problem of producing smooth 360-degree panoramic pictures. Their novel methods for creating panoramic panoramas from text and individual photos heavily rely on this methodology. |
|[insanely-fast-whisper.](https://github.com/Vaibhavs10/insanely-fast-whisper) |Transcribe 150 minutes (2.5 hours) of audio in less than 98 seconds. |
|[Agency: The Go Way to AI.](https://github.com/neurocult/agency?) |Library designed for developers eager to explore the potential of Large Language Models (LLMs) and other generative AI through a clean, effective, and Go-idiomatic approach. |
|[CoachLM.](https://github.com/lunyiliu/coachlm) |CoachLM presents a cutting-edge AI method for improving training datasets for LLMs. This approach dramatically increases the efficacy of instruction-following in LLMs by improving datasets in a novel way—by modifying rather than eliminating low-quality samples. |
|[multimodal-maestro.](https://github.com/roboflow/multimodal-maestro) |Effective prompting for Large Multimodal Models like GPT-4 Vision or LLaVA. |
|[Tanuki.](https://github.com/Tanuki/tanuki.py) |Easily build LLM-powered apps that get cheaper and faster over time. |
|[Accelerating Generative AI with PyTorch II: GPT, Fast.](https://pytorch.org/blog/accelerating-generative-ai-2/) | The PyTorch team describes in this blog post how to significantly accelerate language model inference using native Pytorch code. The article explains how to obtain more than 200 tokens from Llama 2 7B every second.|
|[Qwen-Audio.](https://qwen-audio.github.io/Qwen-Audio/) | An audio understanding model that is universal has been released by the Alibaba Cloud Group. It is capable of a variety of audio-related tasks, such as text question answering and music comprehension and speaker recognition.|
|[3D to Photo.](https://github.com/Dabble-Studio/3d-to-photo) | 3D to Photo is an open-source package by Dabble, that combines threeJS and Stable diffusion to build a virtual photo studio for product photography. Load a 3D model into the browser and virtual shoot it in any kind of scene you can imagine. The app currently uses Stable Diffusion 1.5-inpainting, hosted on Replicate.|
|[5 Ways To Leverage AI in Tech with Freshworks CIO Prasad Ramakrishnan.](https://www.saastr.com/5-ways-to-leverage-ai-in-tech-with-freshworks-cio-prasad-ramakrishnan/) | Prasad Ramakrishnan, CIO of Freshworks, goes over a few practical applications of AI for startups. This article outlines five ways that businesses may utilize AI to grow and address challenges, from improving user experience to onboarding and optimizing data platforms.|


## Perspectives
|Link|description|
|---|---|
|[The Q* hypothesis: Tree-of-thoughts reasoning, process reward models, and supercharging synthetic data.](https://www.interconnects.ai/p/q-star) |According to a recent leak, an internal breakthrough combining search and reinforcement learning was the reason behind the OpenAI leadership scandal. This article presents one notion that sheds light on what this new approach could be genuinely doing. |
|[Inside OpenAI, a rift between billionaires and altruistic researchers unravelled over the future of artificial intelligence.](https://www.abc.net.au/news/2023-11-26/openai-sam-altman-board-inside-the-chaotic-week/103149570) |a comprehensive overview of the OpenAI disaster. Generations to come will study this. This synopsis, which covers all of the intriguing facets and consequences, is essential reading for anyone who hasn't followed the full story. |
|[What is OpenAI, Really?.](https://newsletter.pragmaticengineer.com/p/what-is-openai?) | It’s been five incredibly turbulent days at the leading AI tech company, with the exit and then return of CEO Sam Altman. As we dig into what went wrong, an even bigger question looms: what is OpenAI?|
|[Why I Just Resigned From My Job In Generative AI.](https://www.musicbusinessworldwide.com/why-just-resigned-from-my-job-generative-ai/) | Stability AI's Audio team leader left because of differences in the company's position on using copyrighted material to train generative AI models. The proponent of generative AI feels that it is not fair use to train models on copyrighted material without permission, as this could put them in competition with original creations.|
|[Exploring the Growing Convergence Between Blockchain and AI.](https://pages.casperlabs.io/report/convergence-blockchain-ai) |This research, which surveyed more than 600 IT professionals worldwide, delves into the main causes of the increasing demand for AI, the most well-liked applications, and the main obstacles preventing its wider deployment. Interestingly, it refutes the idea that blockchain and artificial intelligence are incompatible technology. |
|[Reshaping the tree: rebuilding organizations for AI.](https://www.oneusefulthing.org/p/reshaping-the-tree-rebuilding-organizations) |By automating tasks and decision-making, the integration of AI in enterprises is altering conventional work processes and empowering teams to operate more productively. Organizations must adjust as AI develops quickly by promoting team experimentation with the technology, getting ready for new developments, and moving quickly to maintain their competitive edge. |
|[God Help Us, Let's Try To Understand AI Monosemanticity.](https://www.astralcodexten.com/p/god-help-us-lets-try-to-understand) | By replicating a larger AI within a smaller one, Anthropic researchers have devised a mechanism to comprehend the intricate workings of AI. What they have discovered is that AI neural networks are capable of encoding information in a sophisticated way, much like physics' superposition. Through the application of this method to a basic AI, they found that it could represent discrete concepts, such as "God," in discrete features. They further conjecture that the same methodology may yield deeper insights into artificial and biological neural systems, which could result in safer and more effective AI development.|
|[A Data-Driven Look at the Rise of AI.](https://www.newcomer.co/p/a-data-driven-look-at-the-rise-of?) |This article from the Cerebral Valley AI Summit examines the development of AI using data and is heavily illustrated with slides. We all hear it all the time, but there is a ton of evidence to support it. The development of developer interest and its eventual collapse are of particular importance. |
|[How Much Does it Cost to Use an LLM?.](https://tomtunguz.com/gm-saas/) | Different models cost different amounts. Also, the size of the context window is an important factor. But how much?|
|[The 10-Year “Overnight” Success Story of Casetext.](https://www.ycombinator.com/blog/the-10-year-overnight-success-story-of-casetext/) |When Casetext first launched in 2013, it was a crowdsourced legal library, similar to "Wikipedia meets reddit" for legal matters. A decade later, Casetext stands as one of the greatest AI achievements to date, able to compress weeks' worth of laborious legal work into hours or minutes. It was purchased for $650 million just a few months ago. Between those two points, what transpired? |
|[ChatGPT generates fake data set to support scientific hypothesis.](https://www.nature.com/articles/d41586-023-03635-w) |Researchers say that the model behind the chatbot fabricated a convincing bogus database, but a forensic examination shows it doesn’t pass for authentic. |
|[What the OpenAI drama means for AI progress — and safety.](https://www.nature.com/articles/d41586-023-03700-4) | A debacle at the company that built ChatGPT highlights concern that commercial forces are acting against the responsible development of artificial-intelligence systems.|
|[Adjust the format of papers to improve description by AI.](https://www.nature.com/articles/d41586-023-03739-3) |The chatbot ChatGPT and other tools based on large language models (LLMs) can make scientific research more efficient, but they can also introduce mistakes when they describe scientific work. I suggest that small changes to the format of scientific papers could improve the training of LLMs. |
|[AI under the microscope: the algorithms powering the search for cells.](https://www.nature.com/articles/d41586-023-03722-y) | Deep learning is driving the rapid evolution of algorithms that can automatically find and trace cells in a wide range of microscopy experiments.|
|[ChatGPT's training data can be exposed via a "divergence attack".](https://stackdiary.com/chatgpts-training-data-can-be-exposed-via-a-divergence-attack/) | Large language models, like ChatGPT, have been shown to be able to memorize and unintentionally disclose particular training data, raising privacy concerns—especially with bigger models.|
|[In The Age Of AI, Google Experiments With Bold Changes To Search.](https://www.bigtechnology.com/p/in-the-age-of-ai-google-experiments) | The excitement surrounding Q*, the purported AI breakthrough from OpenAI, illustrates the tech community's propensity to quickly change focus and conjecture about the next great development in AI, frequently with no information—a phenomenon known as "Shiny Object Syndrome."|
|[A global hit: AI translation tools help singers break down borders.](https://www.semafor.com/article/11/10/2023/ai-translation-tools-help-singers-break-down-borders) |While some producers view the cost as prohibitive, YouTube, Mr. Beast, and a South Korean label are among the companies using AI to dub video content into many languages. |
|[ChatGPT is winning the future — but what future is that?.](https://www.theverge.com/23981318/chatgpt-open-ai-launch-anniversary-future) | OpenAI didn’t mean to kickstart a generational shift in the technology industry. But it did. Now all we have to decide is where to go from here.|


# ML news: Week 20-26 November

## Research
|Link|description|
|---|---|
|[MILA: Memory-Based Instance-Level Adaptation for Cross-Domain Object Detection.](https://arxiv.org/abs/2309.01086) |Cross-domain object detection is challenging, and it involves aligning labeled source and unlabeled target domains. we propose a memory-based instance-level domain adaptation framework. Our method aligns a target instance with the most similar source instance of the same category retrieved from a memory storage. [official code.](https://github.com/hitachi-rd-cv/MILA)|
|[TopoMLP: An Simple yet Strong Pipeline for Driving Topology Reasoning.](https://arxiv.org/abs/2310.06753v1) |TopoMLP is a system that detects and analyzes traffic features and road centerlines to comprehend road scenes and identify drivable courses for self-driving automobiles. [official code.](https://github.com/wudongming97/topomlp)|
|[Fantastic Gains and Where to Find Them: On the Existence and Prospect of General Knowledge Transfer between Any Pretrained Model.](https://arxiv.org/abs/2310.17653) | In this study, several data optimization strategies that need less computational overhead to enable knowledge transfer across models are examined.|
|[StyleTTS 2: Towards Human-Level Text-to-Speech through Style Diffusion and Adversarial Training with Large Speech Language Models.](https://arxiv.org/abs/2306.07691) | StyleTTS 2 is a text-to-speech model that combines huge speech language models with adversarial training and style diffusion to produce human-level voice synthesis. [official code.](https://github.com/yl4579/StyleTTS2)|
|[Orca 2: Teaching Small Language Models How to Reason.](https://www.microsoft.com/en-us/research/blog/orca-2-teaching-small-language-models-how-to-reason/) | A few months ago, we introduced Orca, a 13-billion language model that demonstrated strong reasoning abilities by imitating the step-by-step reasoning traces of more capable LLMs.Orca 2 significantly surpasses models of similar size (including the original Orca model) and attains performance levels similar to or better than models 5-10 times larger, as assessed on complex tasks that test advanced reasoning abilities in zero-shot settings.|
|[Proving Test Set Contamination in Black Box Language Models.](https://arxiv.org/abs/2310.17623) | a thorough examination of the data that was utilized to train language models. Its findings imply that a large number of closed-source models most likely did not train on widely used benchmarks.|
|[Amazon Reportedly Training AI With Twice As Many Parameters As GPT-4 .](https://futurism.com/the-byte/amazon-training-ai-twice-parameters-gpt-4)  The model will have a whopping 2 trillion parameters, which are the variables that determine the output of a given model, making it one of the largest currently in development.| |


## News
|Link|description|
|---|---|
|[Discord is shutting down its AI chatbot Clyde.](https://www.theverge.com/2023/11/17/23965185/discord-is-shutting-down-its-ai-chatbot-clyde) | Discord users won’t be able to chat to Clyde from December 1st onwards.|
|[OpenAI has put ChatGPT Plus sign-ups on pause.](https://qz.com/openai-has-put-chatgpt-plus-sign-ups-on-pause-1851025002) |After announcing premium-tier users can build their own chatbots, CEO Sam Altman says its Plus subscription has exceeded capacity |
|[OpenAI Staff Threatens Exodus, Jeopardizing Company’s Future.](https://www.nytimes.com/2023/11/20/business/openai-staff-exodus-turmoil.html) | A board member who was part of Sam Altman’s ouster as chief executive joined a majority of the company’s staff in calling for the decision’s reversal.|
|[Sam Altman is still trying to return as OpenAI CEO.](https://www.theverge.com/2023/11/20/23969586/sam-altman-plotting-return-open-ai-microsoft) |Altman’s move to Microsoft isn’t a done deal, and Ilya Sutskever’s flip to supporting Altman means two board members need to change their minds. |
|[Salesforce looks to poach outbound OpenAI staff with "full cash" compensation offer.](https://www.itpro.com/technology/artificial-intelligence/salesforce-looks-to-poach-outbound-openai-staff-with-full-cash-compensation-offer) | OpenAI researchers leaving the firm in protest could be offered a lifeline at Salesforce|
|[Amazon’s offering free courses on generative AI.](https://www.theverge.com/2023/11/20/23969060/amazon-aws-generative-ai-ready-free-certification-courses) | From the company that brought you AWS certification comes a new ‘AI Ready’ education track to help train aspiring professionals on Amazon’s AI tech.|
|[Eye On AI: Bain Capital Ventures Launches BCV Labs In Search Of New AI Deals.](https://news.crunchbase.com/ai/bain-capital-launches-bcv-labs-startup-venture) | BCV Labs is a new AI incubator and technical community founded by Bain Capital Ventures that provides money, office space, events, GPU credits, fellowship program, and recruiting help.|
|[Microsoft rebrands its AI-powered Bing Chat as Copilot.](https://www.engadget.com/microsoft-rebrands-its-ai-powered-bing-chat-as-copilot-160027250.html) |The company has also announced more Copilot AI features for its 365 apps. |
|[Sam Altman to return as CEO of OpenAI.](https://www.theverge.com/2023/11/22/23967223/sam-altman-returns-ceo-open-ai) |After an attempted coup by OpenAI’s board that lasted five days, Altman is returning alongside co-founder Greg Brockman. |
|[Microsoft and Nvidia are making it easier to run AI models on Windows.](https://www.theverge.com/2023/11/15/23960471/microsoft-windows-ai-studio-nvidia-developers) |Microsoft’s new Windows AI Studio lets developers access and configure AI models, such as Microsoft’s Phi, Meta’s Llama 2, and Mistral. |
|[Break the Sequential Dependency of LLM Inference Using Lookahead Decoding.](https://lmsys.org/blog/2023-11-21-lookahead-decoding) |Automating autoregressive language model inference may be done in a variety of ways. One method that has generated excitement is the use of draft models. Although it may take longer, this needs two models. On the other hand, you may reduce the requirement for a draft model and accelerate creation linearly by producing related ngrams from the same model. |
|[OpenAI drops a big new ChatGPT feature with a joke about its CEO drama.](https://www.theverge.com/2023/11/21/23971489/openai-chatgpt-voice-feature-ceo-drama) | ChatGPT’s voice feature lets you ask it a question by saying it aloud — and now it’s available for free.|
|[Emmett Shear threatening to leave OpenAI if board can’t prove Sam Altman’s wrongdoing.](https://www.dexerto.com/tech/emmett-shear-threatening-to-leave-openai-if-board-cant-prove-sam-altmans-wrongdoing-2394706) | Former Twitch CEO Emmett Shear took a role at OpenAI following the ousting of Sam Altman, but is reportedly threatening to leave unless the board can show evidence of Altman’s wrongdoing.|
|[Artificial intelligence finds ways to develop new drugs.](https://ethz.ch/en/news-and-events/eth-news/news/2023/11/artificial-intelligence-finds-ways-to-develop-new-drugs.html) | A new AI model developed by chemists at ETH Zurich can not only predict where a pharmaceutically active molecule can be chemically modified, but also how best to do it. This makes it possible to identify new pharmaceutical ingredients more quickly and improve existing ones in a targeted manner.|
|[OpenAI researchers warned board of AI breakthrough ahead of CEO ouster, sources say.](https://www.reuters.com/technology/sam-altmans-ouster-openai-was-precipitated-by-letter-board-about-ai-breakthrough-2023-11-22/) |Ahead of OpenAI CEO Sam Altman’s four days in exile, several staff researchers wrote a letter to the board of directors warning of a powerful artificial intelligence discovery that they said could threaten humanity |


## Resources
|Link|description|
|---|---|
|[Neural-Cherche.](https://github.com/raphaelsty/neural-cherche) |Neural-Cherche is a library designed to fine-tune neural search models such as Splade, ColBERT, and SparseEmbed on a specific dataset. |
|[The Data Engineering Handbook.](https://github.com/DataEngineer-io/data-engineer-handbook) |This repo has all the resources you need to become an amazing data engineer. |
|[tensorli.](https://github.com/joennlae/tensorli) | Absolute minimalistic implementation of a GPT-like transformer using only numpy (<650 lines).|
|[THE RISE OF “WET” ARTIFICIAL INTELLIGENCE.](https://proto.life/2023/11/perspective-the-rise-of-wet-artificial-intelligence/) |Combining AI with traditional wet lab work creates a virtuous circle from lab to data and back to the lab. |
|[Video-LLaVA.](https://github.com/PKU-YuanGroup/Video-LLaVA) |Video-LLaVA exhibits remarkable interactive capabilities between images and videos, despite the absence of image-video pairs in the dataset. It achieves state-of-the-art performance in video summarization and captioning. |
|[make-real-starter.](https://github.com/tldraw/make-real-starter) |Recently, tldraw released a popular tool that lets people quickly design software using a paint-like interface. GPT-V is then used to write code for the design's online version. It produces reliable and functional code and operates remarkably well. It also accepts commands in plain language. |
|[AI Exploits.](https://github.com/protectai/ai-exploits) |A collection of real world AI/ML exploits for responsibly disclosed vulnerabilities |
|[Collaborative Word-based Pre-trained Item Representation for Transferable Recommendation.](https://github.com/ysh-1998/cowpirec) | The recently proposed CoWPiRec method enhances recommender systems using text-based item representations combined with collaborative filtering information. Using word graphs for item interactions, this novel approach has demonstrated better performance in a range of recommendation circumstances, including solving the cold-start issue.|
|[RustGPT.](https://github.com/bitswired/rustgpt) | A web ChatGPT clone entirely crafted using Rust and HTMX.|
|[Stable Video Diffusion Image-to-Video Model Card.](https://huggingface.co/stabilityai/stable-video-diffusion-img2vid) | Stable Video Diffusion (SVD) Image-to-Video is a diffusion model that takes in a still image as a conditioning frame, and generates a video from it.|
|[LangChain for Go.](https://github.com/tmc/langchaingo) | Building applications with LLMs through composability, with Go|
|[Reinforcement Learning for Generative AI: A Survey.](https://arxiv.org/pdf/2308.14328.pdf) |Comprehensive review across various application areas like NLP, computer vision, and more exciting and emerging domains. Insights into RL's flexibility in introducing new training approaches.Future directions for the evolution of generative AI.
|


## Perspectives
|Link|description|
|---|---|
|[OpenAI’s identity crisis and the battle for AI’s future.](https://www.exponentialview.co/p/openais-identity-crisis-and-the-battle) |Last weekend some news happened in OpenAI, this blog post is about discussing some open questions. |
|[A Data-Driven Look at the Rise of AI.](https://www.newcomer.co/p/a-data-driven-look-at-the-rise-of) |2023, The AI Revolution: Coatue's Sri Viswanath breaks down this year's developments in AI. |
|[AI: The Coming Revolution.](https://www.coatue.com/blog/perspective/ai-the-coming-revolution-2023) |Coatue highlight four points for the future: AI has potential to break through the hype and meaningfully improve our world. Open source is the heartbeat of AI, but not all open source is created equally. Builders and investors need to understand the new, AI-centric tech stack. The best of AI is yet to come|
|[OpenAI’s Misalignment and Microsoft’s Gain.](https://stratechery.com/2023/openais-misalignment-and-microsofts-gain/) |After co-founders Sam Altman and Greg Brockman resigned from OpenAI due to internal issues and the company's failing non-profit strategy, Microsoft acquired key staff and intellectual property from OpenAI, significantly changing the AI field. |
|[AGI's Impact on Tech, SaaS Valuations.](https://nextword.substack.com/p/agis-impact-on-tech-saas-valuations) | Thought experiments on how AGI affects SaaS companies of all shapes and sizes|
|[Oops! We Automated Bullshit.](https://www.cst.cam.ac.uk/blog/afb21/oops-we-automated-bullshit) |ChatGPT is a bullshit generator. To understand AI, we should think harder about bullshit |
|[Explaining the SDXL latent space.](https://huggingface.co/blog/TimothyAlexisVass/explaining-the-sdxl-latent-space) | Using a smaller latent space for diffusion was one of the advances of the original Stable Diffusion model. This indicates that the diffusion occurs on a compressed image representation rather than on pixels. This article explores many interpretations of that space for SDXL.|
|[Sudden Disturbances in Rapidly Moving Objects : The Implications of the OpenAI Fiasco.](https://tomtunguz.com/disturbing-rockets-in-flight) |The unexpected threat to OpenAI's dominating position in the developer ecosystem creates a chance for smaller businesses to step in and take advantage of a fresh opening. Microsoft will probably emerge victorious in the AI race, but it's possible that Anthropic and other model-layer businesses may capitalize on the disruption. |
|[AI should focus on equity in pandemic preparedness.](https://www.nature.com/articles/d41586-023-03608-z) | Over-reliance on AI could inadvertently prioritize certain viruses or populations, leading to inequities in vaccine and disease research.|
|[How AI is expanding art history.](https://www.nature.com/articles/d41586-023-03604-3) | From identifying disputed artworks to reconstructing lost masterpieces, artificial intelligence is enriching how we interpret our cultural heritage.|
|[How AI shapes the life sciences: an interview with Oliver Stegle.](https://www.embl.org/news/lab-matters/how-ai-shapes-the-life-sciences-an-interview-with-oliver-stegle/) |Oliver Stegle explains how AI-based tools have the potential to transform our ability to better understand the complexity of life and how these tools will shape the future of scientific exploration |


# ML news: Week 12-19 November

## Research
|Link|description|
|---|---|
|[3DStyle-Diffusion: Pursuing Fine-grained Text-driven 3D Stylization with 2D Diffusion Models. ](https://arxiv.org/abs/2311.05464v1) |In order to provide more control over appearance and geometry, this research integrates 2D diffusion models into the 3DStyle-Diffusion model, a revolutionary technique for comprehensive stylization of 3D meshes. It functions by first employing implicit MLP networks to parameterize the texture of a 3D mesh into reflectance and illumination. After that, a pre-trained 2D diffusion model is used to maintain geometric consistency and match the produced pictures with the text prompt. [official code. ](https://github.com/yanghb22-fdu/3dstyle-diffusion-official)|
|[Cross-modal Prompts: Adapting Large Pre-trained Models for Audio-Visual Downstream Task.](https://github.com/haoyi-duan/dg-sct) |Dual-Guided Spatial-Channel-Temporal (DG-SCT) attention mechanism to enhances pre-trained audio-visual models for multi-modal tasks. |
|[Generalized Biomolecular Modeling and Design with RoseTTAFold All-Atom](https://www.biorxiv.org/content/10.1101/2023.10.09.561603v1) | RoseTTAFold All-Atom (RFAA), a deep network addressing the limitations of current protein structure modeling tools by accurately representing complete biological assemblies, including covalent modifications and interactions with small molecules. RFAA demonstrates comparable accuracy to AlphaFold2 in protein structure prediction, excels in flexible small molecule docking, and predicts covalent modifications and assemblies involving nucleic acids and small molecules. Additionally, the authors present RFdiffusion All-Atom (RFdiffusionAA), a fine-tuned model for generating binding pockets around small and non-protein molecules, showcasing experimental validation with proteins binding to therapeutic, enzymatic, and optically active molecules.|
|[FinGPT: Large Generative Models for a Small Language](https://arxiv.org/abs/2311.05640) | This study tackles the challenges of creating large language models (LLMs) for Finnish, a language spoken by less than 0.1% of the world population.|
|[Watermarking Vision-Language Pre-trained Models for Multi-modal Embedding as a Service](https://arxiv.org/abs/2311.05863v1) | VLPMarker, a secure and robust backdoor-based embedding watermarking method for vision-language pre-trained models (VLPs), which effectively injects triggers into VLPs without interfering with model parameters, providing high-quality copyright verification and minimal impact on performance, while also enhancing resilience against various attacks through a collaborative copyright verification strategy based on both backdoor triggers and embedding distribution.|
|[Visualizing the Diversity of Representations Learned by Bayesian Neural Networks.](https://openreview.net/pdf?id=ZSxvyWrX6k) |ExplainableAI methods and their applications to Bayesian Neural Networks |
|[MonoDiffusion: Self-Supervised Monocular Depth Estimation Using Diffusion Model](https://arxiv.org/abs/2311.07198v1) |In this work, a novel framework for self-supervised monocular depth estimation called MonoDiffusion is presented. It takes a fresh approach to the problem by treating iterative denoising. Instead of employing real depth ground-truth for training, it makes use of a faux ground-truth diffusion process led by a teacher model that has already been taught. [official code.](https://github.com/ShuweiShao/MonoDiffusion)|
|[Knowledgeable Preference Alignment for LLMs in Domain-specific Question Answering](https://arxiv.org/abs/2311.06503) | The paper discusses the deployment challenges of large language models (LLMs) in real-world scenarios, particularly in domain-specific question answering (QA) with the integration of domain knowledge graphs. The authors introduce KnowPAT, a novel pipeline that employs style and knowledge preference sets, coupled with a new alignment objective, to improve LLMs for practical use in domain-specific QA, as evidenced by superior performance in experiments against 15 baseline methods. [official code.](https://github.com/zjukg/knowpat)|
|[DeepMind AI accurately forecasts weather — on a desktop computer](https://www.nature.com/articles/d41586-023-03552-y) |The machine-learning model takes less than a minute to predict future weather worldwide more precisely than other approaches. [original article](https://www.science.org/doi/10.1126/science.adi2336) |
|[Role play with large language models. ](https://www.nature.com/articles/s41586-023-06647-8) | Casting dialogue-agent behaviour in terms of role play allows us to draw on familiar folk psychological terms, without ascribing human characteristics to language models that they in fact lack. |
|[Fine-tuning Language Models for Factuality. ](https://arxiv.org/abs/2311.08401) |ChatGPT's widespread acceptance was made possible by a breakthrough in model optimization based on preferences. By using comparable technologies, model accuracy and factual accuracy can be increased, leading to a 50% reduction in medical recall errors. |
|[Ultra-Efficient On-Device Object Detection on AI-Integrated Smart Glasses with TinyissimoYOLO. ](https://arxiv.org/abs/2311.01057) |This group trained an ultra-small YOLO computer vision model and developed new RISC-V hardware specifically for vision, allowing for real-time object identification at very low latency and low power consumption. |
|[SentAlign: Accurate and Scalable Sentence Alignment. ](https://arxiv.org/abs/2311.08982v1) |an accurate sentence alignment tool designed to handle very large parallel document pairs. It can efficiently handle tens of thousands of sentences. [official code.](https://github.com/steinst/sentalign)|
|[Large Language Models are Temporal and Causal Reasoners for Video Question Answering. ]() | LLMs make errors in VQA when they focus too much on the language and ignore the video content, this article aims to solve this [official code.](https://github.com/mlvlab/Flipped-VQA)|


## News
|Link|description|
|---|---|
|[Google in talks to invest ‘hundreds of millions’ into AI startup Character.AI. ](https://www.calcalistech.com/ctechnews/article/h1vdzfaqt) | Character.AI's chatbots, with various roles and tones to choose from, have appealed to users ages 18 to 24, who contributed about 60% of its website traffic.|
|[Introducing AI to FigJam.](https://www.figma.com/blog/introducing-ai-to-figjam/) | FigJam, Figma's digital whiteboard application, now incorporates AI support to help streamline and improve design interactions. |
|[LLaVA-Plus: Large Language and Vision Assistants that Plug and Learn to Use Skills. ](https://llava-vl.github.io/llava-plus/) |An open-source approach that integrates language and vision is called LLaVa. The updated version gives the instruction-tuned model access to tools for creating and altering images, among other things. |
|[ai-town-rwkv-proxy. ](https://github.com/recursal/ai-town-rwkv-proxy) | Hundreds of agents in AI Town, an incredible experiment, go about their everyday lives as prompt states in language models. Compared to typical Transformers, the RWKV model is a linear language model that uses less resources. This repository runs AI Town on your local computer using this less expensive model.|
|[Nvidia is launching a new must-have AI chip — as customers still scramble for its last one.](https://www.theverge.com/2023/11/13/23958823/nvidia-h200-ai-gpu-announced-specs-release-date) |The new class-leading H200 has more memory capacity and bandwidth, speeding up its work with generative AI and LLMs. |
|[OpenAI reveals new details about its AI development roadmap and fundraising plans](https://siliconangle.com/2023/11/13/openai-reveals-new-details-ai-development-roadmap-fundraising-plans/) | OpenAI LP is working on GPT-5 and plans to raise more capital from Microsoft Corp. to support its development efforts, Chief Executive Officer Sam Altman has disclosed in a new interview.|
|[Xbox partners with Inworld AI to build generative AI tools for game development](https://inworld.ai/blog/xbox-partners-with-inworld-ai-to-build-generative-ai-tools-for-game-development) | Xbox and Inworld AI are working together to build AI-driven technologies that will enhance game developers' narratives and character creation features. As part of the collaboration, an AI character runtime engine and an AI design copilot will be created to help game creators create immersive gaming experiences. They believe these technologies will accelerate game creation, improve immersion, and encourage boundless innovation.|
|[New techniques efficiently accelerate sparse tensors for massive AI models](https://news.mit.edu/2023/new-techniques-efficiently-accelerate-sparse-tensors-1030) | Complimentary approaches — “HighLight” and “Tailors and Swiftiles” — could boost the performance of demanding machine-learning tasks.|
|[OpenAI’s six-member board will decide ‘when we’ve attained AGI’](https://venturebeat.com/ai/openais-six-member-board-will-decide-when-weve-attained-agi/) |According to OpenAI, the six members of its nonprofit board of directors will determine when the company has “attained AGI”  |
|[Giant AI Platform Introduces ‘Bounties’ for Deepfakes of Real People. ](https://www.404media.co/giant-ai-platform-introduces-bounties-for-nonconsensual-images-of-real-people/) | Users of the contentious "bounties" function of Civitai, an AI model sharing site, may now commission and profit from the production of AI-generated photographs.|
|[You.com launches new APIs to connect LLMs to the web.](https://techcrunch.com/2023/11/14/you-com-launches-new-apis-to-connect-llms-to-the-web/) | When OpenAI connected ChatGPT to the internet, it supercharged the AI chatbot’s capabilities. Now, the search engine You.com wants to do the same for every large language model (LLM) out there.|
|[Microsoft and OpenAI partnership unveils new AI opportunities. ](https://www.microsoft.com/en-us/microsoft-cloud/blog/2023/11/07/come-build-with-us-microsoft-and-openai-partnership-unveils-new-ai-opportunities/) |Microsoft said at OpenAI's DevDay that it will launch the new GPT-4 Turbo on Azure OpenAI Service before year's end, offering more control and cost savings. Businesses' AI skills will be enhanced by OpenAI's Custom Models initiative, which will easily interact with Microsoft's ecosystem. |
|[Nous-Capybara-34B V1.9. ](https://huggingface.co/NousResearch/Nous-Capybara-34B) |This is trained on the Yi-34B model with 200K context length, for 3 epochs on the Capybara dataset (multi-turn data with more than 1000 tokens per conversation)|
|[AI writes summaries of preprints in bioRxiv trial. ](https://www.nature.com/articles/d41586-023-03545-x) | Large language model creates synopses of papers aimed at various reading levels to help scientists sift through the literature.|
|[Catch me if you can! How to beat GPT-4 with a 13B model. ](https://lmsys.org/blog/2023-11-14-llm-decontaminator/) |Announcing Llama-rephraser: 13B models reaching GPT-4 performance in major benchmark. What's the trick behind it? Well, rephrasing the test set is all you need!  |
|[IBM debuts $500 million enterprise AI venture fund](https://www.axios.com/2023/11/07/ibm-enterprise-ai-venture-fund) |IBM is dedicating $500 million to invest in generative AI startups focused on business customers.|
|[Microsoft is finally making custom chips — and they’re all about AI. ](https://www.theverge.com/2023/11/15/23960345/microsoft-cpu-gpu-ai-chips-azure-maia-cobalt-specifications-cloud-infrastructure) |The Azure Maia 100 and Cobalt 100 chips are the first two custom silicon chips designed by Microsoft for its cloud infrastructure |
|[Google's AI-powered search feature goes global with a 120-country expansion](https://www.engadget.com/googles-ai-powered-search-feature-goes-global-with-a-120-country-expansion-180028037.html) |The SGE update includes additional language support for Spanish, Portuguese, Korean and Indonesian. |
|[Universe 2023: Copilot transforms GitHub into the AI-powered developer platform. ](https://github.blog/2023-11-08-universe-2023-copilot-transforms-github-into-the-ai-powered-developer-platform/) | GitHub is announcing general availability of GitHub Copilot Chat and previews of the new GitHub Copilot Enterprise offering, new AI-powered security features, and the GitHub Copilot Partner Program.|
|[Deepmind’s animation gallery](https://www.pexels.com/@googledeepmind/gallery/) |A variety of animations and artwork have been made available by Google's deepmind research department to help people comprehend various AI systems. The animations are visually stunning but also a little strange. |
|[Deep mind announce music generation model. ](https://deepmind.google/discover/blog/transforming-the-future-of-music-creation/) |Today, in partnership with YouTube, we’re announcing Google DeepMind’s Lyria, our most advanced AI music generation model to date. Any content published by our Lyria model will be watermarked with SynthID. |
|[META introduces Emu Video and Emu Edit, our latest generative AI research milestones. ](https://ai.meta.com/blog/emu-text-to-video-generation-image-editing-research/) | A generative model frequently produces an output image that isn't exactly what you were hoping for. It is really difficult to alter that image using the same model, though. Meta made a crucial discovery: editing capabilities can arise when all generations are treated as instructions. This is a really good improvement, especially when combined with the model architecture's newfound simplicity.|
|[Microsoft launches a deepfakes creator at Ignite 2023 event. ](https://techcrunch.com/2023/11/15/microsoft-launches-a-deepfakes-creator/) |One of the more unexpected products to launch out of the Microsoft Ignite 2023 event is a tool that can create a photorealistic avatar of a person and animate that avatar saying things that the person didn’t necessarily say. |
|[YouTube will show labels on videos that use AI](https://9to5google.com/2023/11/14/youtube-ai-labels-videos-shorts/) |YouTube is now requiring creators to mark videos that are made using AI, and the platform will show labels to viewers. |
|[Sam Altman fired as CEO of OpenAI. ](https://www.theverge.com/2023/11/17/23965982/openai-ceo-sam-altman-fired) |In a sudden move, Altman is leaving after the company’s board determined that he ‘was not consistently candid in his communications.’ President and co-founder Greg Brockman has also quit. [apparently, they asked him to come back](https://www.theverge.com/2023/11/18/23967199/breaking-openai-board-in-discussions-with-sam-altman-to-return-as-ceo) [but he is now hired by Microsoft.](https://www.theverge.com/2023/11/20/23968829/microsoft-hires-sam-altman-greg-brockman-employees-openai)|


## Resources
|Link|description|
|---|---|
|[The Alignment Handbook. ](https://github.com/huggingface/alignment-handbook) | The HuggingFace's Alignment Handbook aims to fill that gap by providing the community with a series of robust training recipes that span the whole pipeline.|
|[versatile_audio_super_resolution. ](https://github.com/haoheliu/versatile_audio_super_resolution) |Pass your audio in, AudioSR will make it high fidelity! |
|[tarsier. ](https://github.com/reworkd/tarsier) |Vision utilities for web interaction agents. A number of teams are working on creating agents that can interact with web items through vision thanks to the development of potent new vision models. A standard toolset is introduced by Tarsier (e.g., element tagging). Any vision system will work to help you navigate the website and take action. It also has browsing facilities for language models without eyesight. |
|[Extra-fast Bark for generating long texts. ](https://colab.research.google.com/github/ylacombe/explanatory_notebooks/blob/main/extra_fast_bark_for_long_generation.ipynb) |In this notebook, we'll show you how to generate very long texts very quickly using Bark, Flash Attention 2 and batching.|
|[OpenGPTs.](https://github.com/langchain-ai/opengpts) | This is an open source effort to create a similar experience to OpenAI's GPTs. It builds upon LangChain, LangServe and LangSmith. |
|[Tamil-Llama: A Family of LLaMA-based LLMs focused on Tamil Language](https://github.com/abhinand5/tamil-llama.) | This repository contains the code and models for "Tamil-Llama", a project focused on enhancing the performance of language models for the Tamil language.|
|[GPT4V-AD-Exploration. ](https://github.com/pjlab-adg/gpt4v-ad-exploration) | In our report, we explore the revolutionary GPT-4V, a visionary in the field of autonomous driving.|
|[BestGPTs. ](https://github.com/AgentOps-AI/BestGPTs) |Top ranked OpenAI GPTs |
|[Hallucination Leaderboard. ](https://github.com/vectara/hallucination-leaderboard) | This evaluates how often an LLM introduces hallucinations when summarizing a document.  |
|[draw-a-ui](https://github.com/SawyerHood/draw-a-ui) |This is an app that uses tldraw and the gpt-4-vision api to generate html based on a wireframe you draw. |
|[AMBER: An Automated Multi-dimensional Benchmark for Multi-modal Hallucination Evaluation. ](https://github.com/junyangwang0410/amber) | a new benchmark designed to assess and reduce hallucinations in Multi-modal Large Language Models (MLLMs)|
|[https://github.com/jxnl/instructor](https://github.com/jxnl/instructor) | Structured extraction in Python, powered by OpenAI's function calling api, designed for simplicity, transparency, and control.|
|[GPU-Accelerated LLM on a $100 Orange Pi. ](https://blog.mlc.ai/2023/08/09/GPU-Accelerated-LLM-on-Orange-Pi) | This post shows GPU-accelerated LLM running smoothly on an embedded device at a reasonable speed. Additionally, we are able to run a Llama-2 13b model at 1.5 tok/sec on a 16GB version of the Orange Pi 5+ under $150. |
|[LLM Sherpa. ](https://github.com/nlmatics/llmsherpa) |LLM Sherpa provides strategic APIs to accelerate large language model (LLM) use cases. |
|[The Developer's Guide to Production-Grade LLM Apps](https://buildingaistuff.com/p/the-developers-guide-to-production) |dvanced Techniques for Maximizing LLM Performance |
|[Accelerating Generative AI with PyTorch: Segment Anything, Fast](https://pytorch.org/blog/accelerating-generative-ai/) | This blog shows how to get META SAM 8x faster, just using PyTorch features: quantization, nested tensors and Triton |
|[ai-exploits](https://github.com/protectai/ai-exploits) |This repository, ai-exploits, is a collection of exploits and scanning templates for responsibly disclosed vulnerabilities affecting machine learning tools. |
|[Music ControlNet](https://musiccontrolnet.github.io/web/) |ControlNet represented an innovative approach to providing image synthetics models with fine-grained control. There is now a model for music generation that is fairly similar and allows you to manage several aspects such as pitch and pronunciation. |
|[GPT-4 Turbo Note Taker](https://tactiq.io/ai-tools/gpt4-note-taker) | Fast and simple, Tactiq’s AI Note Taker with GPT-4 Turbo lets you turn your meetings into actionable notes - so that you're always taking the right action and getting more out of your meetings.|
|[Chroma. ](https://github.com/generatebio/chroma) |Chroma is a generative model for designing proteins programmatically. |
|[A Survey on Language Models for Code. ](https://arxiv.org/abs/2311.07989v1) |gives a summary of LLMs for code, covering 500 relevant works, more than 30 assessment tasks, and more than 50 models. |


## Perspectives
|Link|description|
|---|---|
|[Adversarial Attacks on LLMs. ](https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm) | This blog post discusses the many new assaults that language model systems are facing. It has good details regarding several attack types as well as some successful mitigations that teams have discovered.|
|[AI and Open Source in 2023. ](https://magazine.sebastianraschka.com/p/ai-and-open-source-in-2023) |A comprehensive review of the major developments in the AI research, industry, and open-source space that happened in 2023. |
|[How investors see your start up?](https://medium.com/angularventures/thin-and-ephemeral-vs-big-and-weak-vs-small-and-strong-53bb4b9d2bc8) |A general partner at Angular Ventures divides the application concepts we are seeing into three major categories in an attempt to make sense of all the nascent AI firms. This exclusively examines application-layer businesses; it ignores model-layer companies. |
|[retool's state of AI 2023.](https://retool.com/reports/state-of-ai-2023) | Retool surveyed 1,500 tech workers |
|[Language models can use steganography to hide their reasoning, study finds.](https://venturebeat.com/ai/language-models-can-use-steganography-to-hide-their-reasoning-study-finds/) |large language models (LLMs) can master “encoded reasoning,” a form of steganography. This intriguing phenomenon allows LLMs to subtly embed intermediate reasoning steps within their generated text in a way that is undecipherable to human readers.  |
|[Why teachers should explore ChatGPT’s potential — despite the risks. ](https://www.nature.com/articles/d41586-023-03505-5) |Many students now use AI chatbots to help with their assignments. Educators need to study how to include these tools in teaching and learning — and minimize pitfalls. |
|[The future is quantum: universities look to train engineers for an emerging industry. ](https://www.nature.com/articles/d41586-023-03511-7) | With quantum technologies heading for the mainstream, undergraduate courses are preparing the workforce of the future.|
|[The Future of Music: How Generative AI Is Transforming the Music Industry. ](https://a16z.com/the-future-of-music-how-generative-ai-is-transforming-the-music-industry/) |AI-generated music has the potential to become our primary source of music in the future and influence our listening preferences. This might mark the beginning of music's "Midjourney moment." |
|[AI Doomers Are Finally Getting Some Long Overdue Blowback. ](https://www.bigtechnology.com/p/ai-doomers-are-finally-getting-some) | Now, those who predicted AI will bring about our collective extinction must reconsider their claims. The "AI doom" really mainly benefited the large players, and there are plenty of chances for the open source AI movements.|
|[There's a model for democratizing AI. ](https://www.programmablemutter.com/p/theres-a-model-for-making-ai-democratic) |The request for recommendations made by OpenAI on integrating democratic procedures in AI decision-making comes out as constrictive and prefers to handle delicate political matters without accepting accountability, which could limit the application and efficacy of democracy in AI governance. |
|[Copilot is an Incumbent Business Model](https://matt-rickard.com/copilot-is-an-incumbent-business-model) | Though its ultimate disruptive potential rests in redesigning workflows, a challenge that might open substantially larger market opportunities, the Copilot AI business model improves current workflows for efficiency without generating new markets or upending lower ends.|



# ML news: Week 6-12 November

## Research
|Link|description|
|---|---|
|[RT-Sketch: Goal-Conditioned Imitation Learning from Hand-Drawn Sketches. ](https://rt-sketch.github.io/) | Hand-drawn sketches as a modality for goal specification in visual imitation learning. You sketch the robot execute, in other words, you can communicate with the robot with a sketch. [here is the official article.](https://rt-sketch.github.io/assets/rt_sketch.pdf) |
|[Cheating Depth: Enhancing 3D Surface Anomaly Detection via Depth Simulation](https://arxiv.org/abs/2311.01117v1) | RGB-based surface anomaly detection methods have advanced significantly. However, certain surface anomalies remain practically invisible in RGB alone, necessitating the incorporation of 3D information. This new approach 3D data with RGB outperforms traditional methods for surface anomaly detection. [official code](https://github.com/vitjanz/3dsr). |
|[Gaussian Mixture Solvers for Diffusion Models. ](https://arxiv.org/abs/2311.00941v1) | Recently, diffusion models have achieved great success in generative tasks. Gaussian mixture solvers improve the model both in speed and quality [official code](https://github.com/Guohanzhong/GMS).|
|[PixArt-α: Fast Training of Diffusion Transformer for Photorealistic Text-to-Image Synthesis. ](https://huggingface.co/papers/2310.00426) |This paper introduces PIXART-alpha, a Transformer-based T2I diffusion model whose image generation quality is competitive with state-of-the-art image generators. The model uses three elements:  T5 text encodings, cross attention, and a diffusion transformer|
|[Language Models are Super Mario: Absorbing Abilities from Homologous Models as a Free Lunch. ](https://arxiv.org/abs/2311.03099) |In this paper, we uncover that Language Models (LMs), either encoder- or decoder-based, can obtain new capabilities by assimilating the parameters of homologous models without retraining or GPUs. [official code](https://github.com/yule-buaa/mergelm). |
|[An Efficient Self-Supervised Cross-View Training For Sentence Embedding](https://arxiv.org/abs/2311.03228v1) |Cross-View Training (SCT) allows efficient sentence embedding with small language models [official code](https://github.com/mrpeerat/sct).|
|[A Systematic Review of Deep Graph Neural Networks: Challenges, Classification, Architectures, Applications & Potential Utility in Bioinformatics](https://arxiv.org/abs/2311.02127) |Apart from presenting all existing GNN models, mathematical analysis and comparison of the variants of all types of GNN have been highlighted in this survey. Graph neural networks are investigated for their potential real-world applications in various fields, focusing on Bioinformatics. |
|[How AI could lead to a better understanding of the brain](https://www.nature.com/articles/d41586-023-03426-3) |Early machine-learning systems were inspired by neural networks — now AI might allow neuroscientists to get to grips with the brain’s unique complexities. |
|[How AI can help to save endangered species](https://www.nature.com/articles/d41586-023-03328-4) |Scientists are using artificial intelligence to fight biodiversity loss by analysing vast amounts of data, monitoring ecosystems and spotting trends over time.|
|[Pretraining Data Mixtures Enable Narrow Model Selection Capabilities in Transformer Models](https://arxiv.org/abs/2311.00871) | An article from Google providing experimental evidence that the transformer (and therefore LLMs) cannot generalize beyond the training data. This is an indication that the transformer will be not the architecture leading us to artificial general intelligence (AGI)|
|[RobustMat: Neural Diffusion for Street Landmark Patch Matching under Challenging Environments](https://arxiv.org/abs/2311.03904v1) |For autonomous vehicles (AVs), visual perception techniques based on sensors like cameras play crucial roles in information acquisition and processing. In various computer perception tasks for AVs, it may be helpful to match landmark patches taken by an onboard camera with other landmark patches captured at a different time or saved in a street scene image database. The authors using spatial information and neural differential equation have created an approach to imrpove landmark matching. [official code](https://github.com/ai-it-avs/robustmat)  |
|[I2VGen-XL: High-Quality Image-to-Video Synthesis via Cascaded Diffusion Models. ](https://i2vgen-xl.github.io/) | Video synthesis has recently made remarkable strides benefiting from the rapid development of diffusion models. However, it still encounters challenges in terms of semantic accuracy, clarity and spatio-temporal continuity. This new approach is composed of two steps:  preserve the static image's content and refine details and resolution.|
|[Rethinking Benchmark and Contamination for Language Models with Rephrased Samples. ](https://arxiv.org/abs/2311.04850v1) | We know that better data improves the LLM training, here a better way to clean your data. The authors have published they decontaminator tool [here. ](https://github.com/lm-sys/llm-decontaminator)|
|[Hallucination in LLMs. ](https://arxiv.org/abs/2311.05232) | We begin with an innovative taxonomy of LLM hallucinations, then delve into the factors contributing to hallucinations. Subsequently, we present a comprehensive overview of hallucination detection methods and benchmarks|
|[Simplifying Transformer Blocks. ](https://arxiv.org/abs/2311.01906) |Combining signal propagation theory and empirical observations, we motivate modifications that allow many block components to be removed with no loss of training speed, including skip connections, projection or value parameters, sequential sub-blocks, and normalization layers. [official code](https://github.com/bobby-he/simplified_transformers) |
|[LLaVA-Med: Large Language and Vision Assistant for BioMedicine](https://arxiv.org/abs/2306.00890)|LLaVA-Med was initialized with the general-domain LLaVA and then continuously trained in a curriculum learning fashion (first biomedical concept alignment then full-blown instruction-tuning). We evaluated LLaVA-Med on standard visual conversation and question answering tasks. [official repository](https://github.com/microsoft/LLaVA-Med)|

## News
|Link|description|
|---|---|
|[Google Research scholar program. ](https://research.google/outreach/research-scholar-program/) |The Research Scholar Program aims to support early-career professors who are pursuing research in fields relevant to Google. |
|[OpenAI DevDay Buzz Includes Alleged Leak Of New ChatGPT Prototype. ](https://www.searchenginejournal.com/openai-devday-buzz-includes-alleged-leak-of-new-chatgpt-prototype/500122/) |"highlights: OpenAI could introduce major updates for developers, making it cheaper and faster to build AI-based applications. A rumored "Team" plan for ChatGPT could offer unlimited high-speed GPT-4, advanced data analysis, and more." |
|[Google is extending its Vulnerability Rewards Program (VRP) to include generative AI. ](https://blog.google/technology/safety-security/google-ai-security-expansion/) | Today, we’re expanding our VRP to reward attack scenarios specific to generative AI. As part of expanding VRP for AI, we’re taking a fresh look at how bugs should be categorized and reported. |
|[Paper Digest: NeurIPS 2023 Highlights. ](https://www.paperdigest.org/2023/10/nips-2023-highlights/) |Paper digest has analyzed more than 500/3500 papers. Interesting, but many articles are already been published for a while|
|[HelixNet. ](https://huggingface.co/migtissera/HelixNet) |HelixNet is a Deep Learning architecture consisting of 3 x Mistral-7B LLMs. It has an actor, a critic, and a regenerator. The authors also used AI synthetic data. This approach showed impressive results. The model is available on HuggingFace |
|[ChatGPT Plus members can upload and analyze files in the latest beta. ](https://www.theverge.com/2023/10/29/23937497/chatgpt-plus-new-beta-all-tools-update-pdf-data-analysis) |ChatGPT Plus members can also use modes like Browse with Bing without manually switching, letting the chatbot decide when to use them. |
|[OpenAI Dev day recap. ](https://openai.com/blog/new-models-and-developer-products-announced-at-devday) | A recap by OpenAI:New GPT-4 Turbo model that is more capable, cheaper and supports a 128K context window, New Assistants API that makes it easier for developers to build their own assistive AI apps. New multimodal capabilities in the platform, including vision, image creation (DALL·E 3), and text-to-speech (TTS)  |
|[xAI  PromptIDE](https://x.ai/prompt-ide/) |Integrated development environment for prompt engineering and interpretability research, released by xAI |
|[ChatGPT continues to be one of the fastest-growing services ever ](https://www.theverge.com/2023/11/6/23948386/chatgpt-active-user-count-openai-developer-conference) | In less than a year, it’s hit 100 million weekly users, and over 2 million developers are currently building on the company’s API, including the majority of Fortune 500 companies. |
|[Xbox partners with Inworld AI to build AI tools for game development. ](https://venturebeat.com/games/xbox-partners-with-inworld-ai-to-build-ai-tools-for-game-development/) |Microsoft’s Xbox and Inworld AI have partnered to create AI-powered game development tools for narrative and character creation. |
|[Nvidia Is Piloting a Generative AI for Its Engineers. ](https://spectrum.ieee.org/ai-for-engineering) |ChipNeMo summarizes bug reports, gives advice, and writes design-tool scripts |
|[YouTube to test generative AI features. ](https://techcrunch.com/2023/11/06/youtube-to-test-generative-ai-features-including-a-comments-summarizer-and-conversational-tool/) | Users may test out a new conversational tool that utilizes artificial intelligence (AI) to respond to inquiries about YouTube content and provide suggestions, as well as a new feature that summarizes subjects in video comments, as part of the premium package offered to pay subscribers. |
|[Google Announces Expansion of AI Partnership with Anthropic. ](https://finance.yahoo.com/news/google-announces-expansion-ai-partnership-170000867.html) | Partnership includes important new collaborations on AI safety standards, committing to the highest standards of AI security, and use of TPU v5e accelerators for AI inference |
|[Cohere Introduced Embed v3](https://txt.cohere.com/introducing-embed-v3/) |Embed v3 offers state-of-the-art performance per trusted MTEB and BEIR benchmarks. it is multilingual (100+ languages), works well with noisy data, retrieval-augmentation generation (RAG) systems, searches in a language or cross-language searches |
|[Microsoft has over a million paying Github Copilot users](https://www.zdnet.com/article/microsoft-has-over-a-million-paying-github-copilot-users-ceo-nadella/) |"We have over 1 million paid copilot users in more than 37,000 organizations that subscribe to copilot for business," said Nadella, "with significant traction outside the United States." |
|[Meta's audiocraft can also generate stereo music](https://github.com/facebookresearch/audiocraft) |Audiocraft is a library for audio processing and generation with deep learning. It features the state-of-the-art EnCodec audio compressor / tokenizer, along with MusicGen, a simple and controllable music generation LM with textual and melodic conditioning. |
|[Hugging Face has a two-person team developing ChatGPT-like AI models](https://techcrunch.com/2023/11/08/hugging-face-has-a-two-person-team-developing-chatgpt-like-ai-models) | Hugging Face's H4 team is focused on developing open-source ChatGPT |
|[Samsung is joining the AI arms race, too](https://www.theverge.com/2023/11/8/23953198/samsung-galaxy-ai-live-translate-call) | Samsung’s live translate feature, which the company is calling “AI Live Translate Call,” will be built into the company’s native phone app. Samsung says “audio and text translations will appear in real-time as you speak” and that the translations will happen on device.|
|[Introducing Adept Experiments](https://www.adept.ai/blog/experiments) | Adept is building AI agent and now they are opening the access to test them|
|[Introducing GPTs](https://openai.com/blog/introducing-gpts) |You can now create custom versions of ChatGPT that combine instructions, extra knowledge, and any combination of skills. Highlight: Starting today, you can create GPTs and share them publicly. Later this month, we’re launching the GPT Store, featuring creations by verified builders. Once in the store, GPTs become searchable and may climb the leaderboards. We will also spotlight the most useful and delightful GPTs we come across in categories like productivity, education, and “just for fun”. In the coming months, you’ll also be able to earn money based on how many people are using your GPT. |
|[Google Cloud demonstrates the world’s largest distributed training job for large language models across 50000+ TPU v5e chips](https://cloud.google.com/blog/products/compute/the-worlds-largest-distributed-llm-training-job-on-tpu-v5e) | Google Cloud TPU Multislice Training was built from the ground up to address the challenges of distributed ML training in orchestration, compilation, and end-to-end optimization. We demonstrated the benefits of Cloud TPU Multislice Training with what we believe is the largest publicly disclosed LLM distributed training job in the world (in terms of number of chips used for training) on a compute cluster of 50,944 Cloud TPU v5e chips on the JAX ML framework, utilizing both BF16 and INT8 quantized training.|
|[OpenAI Data Partnerships. ](https://openai.com/blog/data-partnerships) |We’re interested in large-scale datasets that reflect human society and that are not already easily accessible online to the public today. We can work with any modality, including text, images, audio, or video. We’re particularly looking for data that expresses human intention (e.g. long-form writing or conversations rather than disconnected snippets), across any language, topic, and format.  |



## Resources
|Link|description|
|---|---|
|[DeepSpeed-FastGen: High-throughput Text Generation for LLMs via MII and DeepSpeed-Inference. ](https://github.com/microsoft/DeepSpeed/tree/master/blogs/deepspeed-fastgen) | new software for competing with vLLM and text-generation interfaces for the fast serving of language models.|
|[qdrant. ](https://github.com/qdrant/qdrant) |Qdrant (read: quadrant) is a vector similarity search engine and vector database. It provides a production-ready service with a convenient API to store, search, and manage points—vectors with an additional payload Qdrant is tailored to extended filtering support. |
|[Video2Music](https://github.com/amaai-lab/video2music) | Video2Music: Suitable Music Generation from Videos using an Affective Multimodal Transformer model. [official article.](https://arxiv.org/abs/2311.00968)|
|[Hacking Google Bard - From Prompt Injection to Data Exfiltration. ](https://embracethered.com/blog/posts/2023/google-bard-data-exfiltration/) | Great post that explain what are the novel risk with generative AI plugins|
|[RedPajama-Data-v2. ](https://together.ai/blog/redpajama-data-v2?utm_source=tldrai) | a new version of the RedPajama dataset, with 30 trillion filtered and deduplicated tokens (100+ trillions raw) from 84 CommonCrawl dumps covering 5 languages, along with 40+ pre-computed data quality annotations that can be used for further filtering and weighting. A dataset bigger than the one used for GPT-4 and already preprocessed|
|[LLM4Rec. ](https://github.com/yaochenzhu/llm4rec) |The proposed CLLM4Rec is the first recommender system that tightly combines the ID-based paradigm and LLM-based paradigm and leverages the advantages of both worlds. |
|[consistencydecoder. ](https://github.com/openai/consistencydecoder) |OpenAI has released an Improved decoding for stable diffusion vaes. Consistency decoder  has reached the SOTA and it is nice they released also for stable diffusion |
|[TopicGPT. ](https://github.com/chtmp223/topicgpt) |we introduce TopicGPT, a prompt-based framework that uses large language models (LLMs) to uncover latent topics within a provided text collection. TopicGPT produces topics that align better with human categorizations compared to competing methods. [official article](https://arxiv.org/abs/2311.01449). |
|[FACTOR. ](https://github.com/talreiss/factor) | an effective tool to detect deep fakes even without training. FACTOR leverages the discrepancy between false facts and their imperfect synthesis within deepfakes. By quantifying the similarity using the truth score, computed via cosine similarity, FACTOR effectively distinguishes between real and fake media, enabling robust detection of zero-day deepfake attacks. |
|[CogVLM. ](https://github.com/THUDM/CogVLM) |CogVLM is a powerful open-source visual language model (VLM). CogVLM-17B has 10 billion vision parameters and 7 billion language parameters. |
|[langroid](https://github.com/langroid/langroid) |Langroid is an intuitive, lightweight, extensible and principled Python framework to easily build LLM-powered applications. You set up Agents, equip them with optional components (LLM, vector-store and methods), assign them tasks, and have them collaboratively solve a problem by exchanging messages.  |
|[OVIR-3D. ](https://github.com/shiyoung77/ovir-3d) | D object retrieval from text prompts using 2D image fusion. his work provides a straightforward yet effective solution for open-vocabulary 3D instance retrieval, which returns a ranked set of 3D instance segments given a 3D point cloud reconstructed from an RGB-D video and a language query.|
|[JaSPICE: Automatic Evaluation Metric Using Predicate-Argument Structures for Image Captioning Models. ](https://arxiv.org/abs/2311.04192) | an automatic evaluation metric called JaSPICE, which evaluates Japanese captions based on scene graphs. There is a gap between performance of models for english captioning and other languages, this clever approach promises to reduce the gap|
|[awesome-openai-vision-api-experiments. ](https://github.com/roboflow/awesome-openai-vision-api-experiments) |A set of examples showing how to use the OpenAI vision API to run inference on images, video files and webcam streams.|
|[punica. ](https://github.com/punica-ai/punica) |Low rank adapation (LoRA) is a parameter efficient way to add new knowledge to a pretrained LLM. Although the pretrained LLM takes 100s of GB storage, a LoRA finetuned model only adds 1% storage and memory overhead. Punica enables running multiple LoRA finetuned models at the cost of running one. |
|[LongQLoRA. ](https://github.com/yangjianxin1/longqlora) | LongQLoRA is a memory-efficient and effective method to extend context length of Large Language Models with less training GPUs. On a single 32GB V100 GPU, LongQLoRA can extend the context length of LLaMA2 7B and 13B from 4096 to 8192 and even to 12k.|
|[Lidar-Annotation-is-All-You-Need. ](https://github.com/evocargo/lidar-annotation-is-all-you-need) |a smarter method for self-driving cars to recognize roads by using lidar technology.  |
|[LM4VisualEncoding. ](https://github.com/ziqipang/lm4visualencoding) |pretrained transformers from LLMs, despite being trained solely on textual data, are surprisingly strong encoders for purely visual tasks in the absence of language. Our exploration shows the potential of LLMs as general-purpose encoders for visual data, as opposed to the previous usages of either pure encoders for text embeddings or decoders for tokenized outputs. [official article.](https://arxiv.org/abs/2310.12973) |
|[vimGPT. ](https://github.com/ishan0102/vimGPT) | Browse the web with GPT-4V and Vimium. Vimium is a Chrome extension that lets you navigate the web with only your keyboard. You  could use Vimium to give the model a way to interact with the web. |
|[Announcing a New Way to Create AI Employees](https://www.lindy.ai/blog/announcing-a-new-way-to-create-ai-employees) | the first platform letting you build a team of AI employees working together to perform any task. The idea is to build an agent that you can call and ask to perform a task|


## Perspectives
|Link|description|
|---|---|
|[Data Pipeline Attacks. ](https://www.securerobotics.ai/blog/ai-data-pipeline-attacks) |An excerpt from Secure Intelligent Machines. In the future attacks will be focused on poisoning data or other components of the data pipeline. This blog post describes this issue and potential mitigation issues |
|[Could Cruise be the Theranos of AI? And is there a dark secret at the core of the entire driverless car industry? ](https://garymarcus.substack.com/p/could-cruise-be-the-theranos-of-ai) | Cruise is a driverless car company bought by General Motors. However, it seems that remote human interventions is needed in many cases|
|[Will generative AI transform business? ](https://www.ft.com/content/647fdf88-d757-45e4-a640-9654673b7ece) |Industries expect demand for quality control and human oversight of AI-generated content to grow |
|[A minor ChatGPT update is a warning to founders: Big Tech can blow up your startup at any time. ](https://www.businessinsider.com/openai-chatgpt-pdfs-ai-startups-wrappers-2023-10) | Wrapping chatGPT as a core business is not a great idea.  chatGPT can now interact with PDF and let you ask questions which is blowing the business of small start-ups. It's a bleak reminder that swift rule changes by Big Tech firms can wreak havoc on smaller players.|
|[Pixel Perfect: How AI Unlocks Creativity. ](https://www.digitalnative.tech/p/pixel-perfect-how-ai-unlocks-creativity) | AI, and creators are gaining momentum. Using the right tactics can increase it  |
|[Almost an Agent: What GPTs can do. ](https://www.oneusefulthing.org/p/almost-an-agent-what-gpts-can-do) | GPT is almost an agent, but what actually an agent can do? For instance, write a scientific article by itself|
|[Are language models good at making predictions?] (https://www.lesswrong.com/posts/CkhJAxHeyFCg2EcET/are-language-models-good-at-making-predictions?) |It seems so. The article suggests GPT-4 really is better at making predictions for politics than for science or technology, even once the hardness of the questions are accounted for. |
|[OpenAI Is A Lot More Vulnerable Than You Think. ](https://www.bigtechnology.com/p/openai-is-a-lot-more-vulnerable-than) |All the press, money, and awards in the world won’t prevent OpenAI from the cold reality of competition. |
|[ChatGPT use shows that the grant-application system is broken. ](https://www.nature.com/articles/d41586-023-03238-5) |The fact that artificial intelligence can do much of the work makes a mockery of the process. It’s time to make it easier for scientists to ask for research funding. |
|[The world’s week on AI safety: powerful computing efforts launched to boost research. ](https://www.nature.com/articles/d41586-023-03472-x) | UK and US governments establish efforts to democratize access to supercomputers that will aid studies on AI systems.|
|[Is AI the Next Crypto? Insights from 2M HN comments. ](https://openpipe.ai/blog/hn-ai-crypto) |Both crypto and AI have been heavily debated on Hacker News, with discussions going back years. By looking at trends in HN commenter opinions we might find interesting similarities and differences. |
|[AI companies have all kinds of arguments against paying for copyrighted content. ](https://www.theverge.com/2023/11/4/23946353/generative-ai-copyright-training-data-openai-microsoft-google-meta-stabilityai) |The biggest companies in AI aren’t interested in paying to use copyrighted material as training data. |
|[AI could cause ‘catastrophic’ financial crisis, says Yuval Noah Harari](https://www.theguardian.com/technology/2023/nov/09/yuval-noah-harari-artificial-intelligence-ai-cause-financial-crisis) |Historian and Sapiens author says sophistication of technology makes it difficult to forecast its dangers |
|[Nvidia Envy: understanding the GPU gold rush. ](https://blog.johnluttig.com/p/nvidia-envy-understanding-the-gpu) |In 2023, thousands of companies and countries begged Nvidia to purchase more GPUs. Can the exponential demand endure? |
|[AI is about to completely change how you use computers. ](https://www.gatesnotes.com/AI-agents) | Bill Gates in his blog (yes, he has a blog) discuss how AI will revolutionize software interaction  |
|[Self Supervised Learning Market Size Thrives with AI Systems That Discover Patterns and Insights Independently](https://www.abnnewswire.net/press/en/121697/Self-Supervised-Learning-Market-Size-Thrives-with-AI-Systems-That-Discover-Patterns-and-Insights-Independently-121697.html) | Self Supervised Learning market growth surges due to AI's ability to autonomously learn from unlabelled data, enhancing efficiency and innovation|
|[Yoko Taro Foresees the End of Video Games as We Know Them](https://www.wired.com/story/yoko-taro-interview/) | Yoko Taro says the rise of AI will give birth to a new era of video games in which the line between developer and player is blurred into nonexistence. |
|[How Generative AI Will Transform Knowledge Work](https://hbr.org/2023/11/how-generative-ai-will-transform-knowledge-work)|
Generative AI can be a boon for knowledge work, but only if you use it in the right way. New generative AI-enabled tools are rapidly emerging to assist and transform knowledge work in industries ranging from education and finance to law and medicine.|

# ML news 30 October  -  5 November:

## Research
|Link|description|
|---|---|
|[An Emulator for Fine-Tuning Large Language Models using Small Language Models](https://arxiv.org/abs/2310.12962) |What would happen if we combined the knowledge learned by a large model during pre-training with the knowledge learned by a small model during fine-tuning (or vice versa)? Our experiments with EFT show that scaling up fine-tuning tends to improve helpfulness while scaling up pre-training tends to improve factuality.  |
|[Nearest Neighbor Guidance for Out-of-Distribution Detection](https://arxiv.org/abs/2309.14888v1) |Detecting out-of-distribution (OOD) or unfamiliar data samples is crucial for machine learning models deployed in open-world environments. NNguide can help the model in this setting, especially in identifying unknown data. [Code for the benchmark](https://github.com/jingkang50/openood),[Code for the method](https://github.com/roomo7time/nnguide) |
|[Towards Monosemanticity: Decomposing Language Models With Dictionary Learning](https://transformer-circuits.pub/2023/monosemantic-features/index.html) | Using a sparse autoencoder, we extract a large number of interpretable features from a one-layer transformer.|
|[AlphaFold update](https://www.isomorphiclabs.com/articles/a-glimpse-of-the-next-generation-of-alphafold?utm_source=tldrai) |AlphaFold’s update by Isomorphic (a spin-off from Google). A more powerful model that expand coverage beyond proteins. Other related information:  [Comment by DeepMind](https://deepmind.google/discover/blog/a-glimpse-of-the-next-generation-of-alphafold/), [official article](https://storage.googleapis.com/deepmind-media/DeepMind.com/Blog/a-glimpse-of-the-next-generation-of-alphafold/alphafold_latest_oct2023.pdf)|
|[Mask Propagation for Efficient Video Semantic Segmentation](https://arxiv.org/abs/2310.18954v1) |a method for segmenting video content that reduces computational load by focusing on key frames and then predicting masks |
|[Multimodal ChatGPT for Medical Applications: an Experimental Study of GPT-4V](https://arxiv.org/abs/2310.19061v1) | how well GPT-4 with Vision (GPT-4V) answers questions related to medical images? This study analyzes exactly this [offcial code](https://github.com/zhilingyan/gpt4v-medical-report) |
|[Learning From Mistakes Makes LLM Better Reasoner](https://arxiv.org/abs/2310.20689v1) |Consider a human student who failed to solve a math problem, he will learn from what mistake he has made and how to correct it. Mimicking this error-driven learning process, LeMa fine-tunes LLMs on mistake-correction data pairs generated by GPT-4. [Analysis of the article](https://levelup.gitconnected.com/lema-for-an-llm-learning-math-is-making-mistakes-f758f63eaafe) |
|[AI ‘breakthrough’: neural net has human-like ability to generalize languageAI ‘breakthrough’: neural net has human-like ability to generalize language](https://www.nature.com/articles/d41586-023-03272-3) | Systematic generalization is demonstrated by people’s ability to effortlessly use newly acquired words in new settings. [official article](https://www.nature.com/articles/s41586-023-06668-3)|
|[Battle of the Backbones: A Large-Scale Comparison of Pretrained Models across Computer Vision Tasks](https://arxiv.org/pdf/2310.19909.pdf) | This article benchmarks different pre-trained models on different computer vision tasks [official code](https://github.com/hsouri/Battle-of-the-Backbones)|
|[The Foundation Model Transparency Index](https://arxiv.org/abs/2310.12941) |Stanford measured how transparent companies are true their Large Language Models (LLMs) and other foundation models. The results? there is a lot to improve. [deep dive](https://pub.towardsai.net/how-transparent-are-large-language-models-71dbb128a61c) |
|[SoulChat: Improving LLMs' Empathy, Listening, and Comfort Abilities through Fine-tuning with Multi-turn Empathy Conversations](https://arxiv.org/abs/2311.00273v1) | Researchers developed a new method to improve empathy capabilities of large language models. This is can be very important for psychological counseling or medical application   [official code](https://github.com/scutcyr/soulchat) |
|[Towards Foundation Models for Knowledge Graph Reasoning](https://github.com/DeepGraphLearning/ULTRA) | A foundation model for knowledge graphs which was actually missing[blog post from the authors](https://towardsdatascience.com/ultra-foundation-models-for-knowledge-graph-reasoning-9f8f4a0d7f09)|


## News
|Link|description|
|---|---|
|[Google commits to invest $2 billion in OpenAI competitor Anthropic](https://www.cnbc.com/2023/10/27/google-commits-to-invest-2-billion-in-openai-competitor-anthropic.html) | Google  agreed to invest up to $2 billion in Anthropic, the artificial intelligence startup founded by ex-OpenAI executives, CNBC has confirmed.|
|[Amazon rolls out AI-powered image generation]() |Amazon Ads has introduced an AI-powered image generation feature in beta. Without technical skills, brands can now create more engaging ads |
|[Multi-modal prompt injection image attacks against GPT-4V](https://simonwillison.net/2023/Oct/14/multi-modal-prompt-injection/) | Multi-modal prompt injection image attacks against GPT-4V. GPT4-V is the new mode of GPT-4 that allows you to upload images as part of your conversations. It’s absolutely brilliant. It also provides a whole new set of vectors for prompt injection attacks.|
|[Biden releases AI executive order directing agencies to develop safety guidelines](https://www.theverge.com/2023/10/30/23914507/biden-ai-executive-order-regulation-standards) |The executive order builds on non-binding agreements the White House made with AI companies. |
|[A group behind Stable Diffusion wants to open source emotion-detecting AI](https://techcrunch.com/2023/10/27/a-group-behind-stable-diffusion-wants-to-open-source-emotion-detecting-ai/) | The group wants to open source the Empathic project. This in order to improve AI-human interaction|
|[Kuo: Apple Could Spend $4.75 Billion on AI Servers in 2024](https://www.macrumors.com/2023/10/23/apple-ai-server-spending-2024/) |Apple is expected to spend several billion on hardware to support its artificial intelligence development in 2024. Tim Cook has commented that they are spending quite a bit of money on AI (more details [here](https://www.macrumors.com/2023/11/02/tim-cook-generative-ai-comments/)) |
|[Artists Lose First Round of Copyright Infringement Case Against AI Art Generators](https://www.hollywoodreporter.com/business/business-news/artists-copyright-infringement-case-ai-art-generators-1235632929/) | While a federal judge advanced an infringement claim against Stability AI, he dismissed the rest of the lawsuit.|
|[Hackers Are Weaponizing AI to Improve a Favorite Attack](https://themessenger.com/tech/hackers-artificial-intelligence-phishing-scams-attacks) |Phishing attacks are already devastatingly successful. What happens when artificial intelligence makes them even harder to spot? |
|[Chinese tech giant Alibaba launches upgraded AI model to challenge Microsoft, Amazon](https://www.cnbc.com/2023/10/31/alibaba-launches-upgraded-ai-model-to-challenge-microsoft-amazon.html) |Alibaba on Tuesday launched the latest version of its artificial intelligence model (Tongyi Qianwen 2.0, its latest large language model), as the Chinese technology giant looks to compete with U.S. rivals like Amazon and Microsoft. |
|[Microsoft pushes the boundaries of small AI models with big breakthrough](https://www.semafor.com/article/11/01/2023/microsoft-pushes-the-boundaries-of-small-ai-models) |Microsoft researchers shared that the model, Phi 1.5, is now “multimodal,” meaning it can view and interpret images. Phi 1.5 is open source.|
|[New techniques efficiently accelerate sparse tensors for massive AI models](https://www.eurekalert.org/news-releases/1006490) |Researchers from MIT and NVIDIA have developed two techniques that accelerate the processing of sparse tensors, a type of data structure that’s used for high-performance computing tasks. The complementary techniques could result in significant improvements to the performance and energy-efficiency of systems like the massive machine-learning models that drive generative artificial intelligence. |
|[Stability AI’s latest tool uses AI to generate 3D models](https://techcrunch.com/2023/11/02/stability-ais-latest-tool-uses-ai-to-generate-3d-models/) |Stability AI, the startup behind the text-to-image AI model Stable Diffusion, thinks 3D model creation tools could be the next big thing in generative AI. |
|[UK invests $273 million in AI supercomputer as it seeks to compete with U.S., China](https://www.cnbc.com/2023/11/01/uk-to-invest-273-million-in-turing-ai-supercomputer.html) |The U.K. government said Wednesday that it will invest £225 million, or $273 million, into an AI supercomputer, highlighting the country’s ambition to lead in the technology as it races to catch up to the U.S. and China. |
|[The Beatles Just Released Their Final Song With The Help Of AI](https://futurism.com/the-byte/beatles-final-song-ai) | More than 50 years after their breakup, The Beatles have released their final song — and used AI to bring John Lennon's voice back to life.|


## Resources
|Link|description|
|---|---|
|[Audioflare](https://github.com/seanoliver/audioflare) | An all-in-one AI audio playground using Cloudflare AI Workers to transcribe, analyze, summarize, and translate any audio file.|
|[JudgeLM: Fine-tuned Large Language Models are Scalable Judges](https://github.com/baaivision/judgelm) | JudgeLM is an open platform for training, serving, and evaluating scalable large language model|
|[Deep learning in Rust](https://burn.dev/book/) | Rust is a popular language and Burn is a framework to use ML in Rust. Now, you have a free book to learn burn in rust. |
|[LLM Collection](https://www.promptingguide.ai/models/collection) | a collection and summary of notable and foundational LLMs|
|[Leveraging Embeddings and Clustering Techniques in Computer Vision](https://blog.roboflow.com/embeddings-clustering-computer-vision-clip-umap/) | How to use CLIP to cluster images|
|[Training LLMs at Scale with AMD MI250 GPUs](https://www.databricks.com/blog/training-llms-scale-amd-mi250-gpus) | Everyone uses NVIDIA, this post discuss how to train a LLM with AMD GPU |
|[ICTC: Image Clustering Conditioned on Text Criteria](https://github.com/sehyunkwon/ictc) |New methodology for performing image clustering based on user-specified criteria in the form of text  [paper](https://arxiv.org/abs/2310.18297)|
|[Insanely Fast Whisper](https://github.com/Vaibhavs10/insanely-fast-whisper) |Transcribe 300 minutes (5 hours) of audio in less than 10 minutes - with OpenAI's Whisper Large v2.  |
|[magentic](https://github.com/jackmpcollins/magentic) | Easily integrate Large Language Models into your Python code. Simply use the @prompt decorator to create functions that return structured output from the LLM. Mix LLM queries and function calling with regular Python code to create complex logic.|
|[PUCA: Patch-Unshuffle and Channel Attention for Enhanced Self-Supervised Image Denoising](https://github.com/HyemiEsme/PUCA) |  a new self-supervised denoising approach with incredible performances |
|[LangChain Templates](https://github.com/langchain-ai/langchain/tree/master/templates) |LangChain Templates are the easiest and fastest way to build a production-ready LLM application. These templates serve as a set of reference architectures for a wide variety of popular LLM use cases. |
|[how-to guide for LLaMA](https://ai.meta.com/llama/get-started/) | META has released a guide on how to get started with LLaMA |
|[Fine-tuning Mistral on your own data](https://github.com/brevdev/notebooks/blob/main/mistral-finetune-own-data.ipynb) | In this notebook and tutorial, we will fine-tune the Mistral 7B model with just 1 dollar|
|[Amazon release Mistral 7B with longer context window](https://huggingface.co/amazon/MistralLite) | Amazon has used RoPE to extend the model context length to 32K. However, there is already a Mistral version with 128K (by Nous using the Yarn method) which you can find [here](https://huggingface.co/NousResearch/Yarn-Mistral-7b-128k)|
|[Tiger toolkit ](https://github.com/tigerlab-ai/tiger) | open-source resource for developers to create AI models and language applications tailored to their specific needs.|
|[parameter-efficient-MOE](https://github.com/for-ai/parameter-efficient-moe) | Cohere has released the code base for training efficient mixture of experts (MOE)|
|[ChatGPT-Powered Hierarchical Comparisons for Image Classification](https://arxiv.org/abs/2311.00206v1) |Conventional image classification approaches typically evaluate their performance on the same set of categories as their training data. However, this evaluation paradigm fails to capture the challenges in real-world scenarios, where classes in the test set are not overlapped with the training set. For this reason here a simple method using ChatGPT to create hierarchical classes [official code](https://github.com/zhiyuan-r/chatgpt-powered-hierarchical-comparisons-for-image-classification)|
|[talk-llama](https://github.com/ggerganov/whisper.cpp/tree/master/examples/talk-llama) | Talk with an LLaMA AI in your terminal|
|[What's In My Big Data?](https://arxiv.org/abs/2310.20707) |WIMBD platform analyzes content in text corpora, revealing duplicates, low-quality content, PII, toxicity, and benchmark contamination. [code will be release here](https://github.com/allenai/wimbd) |


## Perspectives
|Link|description|
|---|---|
|[Thanks to AI, the future of programming may involve YELLING IN ALL CAPS](https://arstechnica.com/information-technology/2023/10/thanks-to-ai-the-future-of-programming-may-involve-yelling-in-all-caps) |Politeness and emphasis play a surprising role in AI-model communications. Some OpenAI internal prompts are leaked, showing that using caps-lock for important words and adding please is a surprisingly efficient technique|
|[Is AI alignment on track? Is it progressing... too fast?](https://guzey.com/ai/alignment-on-track/) | We do not have concrete benchmarks about alignment, this is feeding a narrative of fear and doom. but it is true? Without serious study, we cannot know, this blog post discusses it in detail  |
|[The White House Is Preparing for an AI-Dominated Future](https://www.theatlantic.com/technology/archive/2023/10/biden-white-house-ai-executive-order/675837/) |The Atlantic perspective on the new bill: "President Biden’s big swing on AI is as impressive and confusing as the technology itself." |
|[The Half-Life of the AI Stack](https://matt-rickard.com/the-half-life-of-the-ai-stack) |The infrastructure layer in AI is rapidly changing |
|[Ilya Sutskever, OpenAI’s chief scientist, on his hopes and fears for the future of AI](https://www.technologyreview.com/2023/10/26/1082398/exclusive-ilya-sutskever-openais-chief-scientist-on-his-hopes-and-fears-for-the-future-of-ai) | Interviewer to one of the most famous AI researcher |
|[How Amazon and Berkshire got too big](https://every.to/napkin-math/death-of-a-flywheel) | a perspective about threats the business growth |
|[Seismic Waves of Gen Z Behavior](https://www.digitalnative.tech/p/seismic-waves-of-gen-z-behavior) | A perspective on how generation z is changing the industries and the market. |
|[Andrew NG warns big tech mount on AI fear to stop competition](https://www.businessinsider.com/andrew-ng-google-brain-big-tech-ai-risks-2023-10) |A leading AI expert and Google Brain cofounder said Big Tech companies were stoking fears about the technology's risks to shut down competition. Yann LeCun is also discussing the same [here](https://www.businessinsider.com/sam-altman-and-demis-hassabis-just-want-to-control-ai-2023-10) |
|[Biden’s AI Order May Have Wide Impact For Startups](https://news.crunchbase.com/ai/biden-ai-executive-order-startups-impact/) | The new order can have a deep impact for start-up|
|[What AI means for your product strategy](https://www.lennysnewsletter.com/p/what-ai-means-for-your-product-strategy) | 1 hour podcast about how AI will impact product strategy|
|[4 Ways AI Is Changing Marketing](https://www.forbes.com/sites/kimberlywhitler/2023/10/29/4-ways-ai-is-changing-marketing/) | How can AI be harnessed to drive more effective and efficient marketing? Forbes is discussing this|
|[Sifting Through the Noise](https://maried.substack.com/p/sifting-through-the-noise) | We are in the ago of information overload and soon we can be flooded from AI generated content, how we survive? |


# ML news: Week 23-29 October

## Research
|Link|description|
|---|---|
|[Geographical erasure in language generation](https://www.amazon.science/publications/geographical-erasure-in-language-generation) | LLMs encode a vast amount of knowledge but it is not representative of all countries, Amazon shows how to mitigate this unbalance|
|[Entangled Preferences: The History and Risks of Reinforcement Learning and Human Feedback](https://arxiv.org/abs/2310.13595) | A deep dive in the history of  RLHF, potential issues and suggestions for new lines of research|
|[AgentTuning: Enabling Generalized Agent Abilities for LLMs](https://huggingface.co/papers/2310.12823) | Open-source models are inferior as AI agents when you need them as efficient controllers for complex tasks. This paper  highlights how to create efficient agent LLaMA-2  [models](https://huggingface.co/THUDM/agentlm-70b)|
|[The Foundation Model Transparency Index](https://hai.stanford.edu/news/introducing-foundation-model-transparency-index?utm_source=tldrai) | Stanford's new index rates the transparency of 10 foundation model companies and finds them lacking. The new index analyses 100 parameters, showing there is room for improvements|
|[BotChat: Evaluating LLMs' Capabilities of Having Multi-Turn Dialogues](https://arxiv.org/abs/2310.13650v1) | evaluation of the ability of large language models (LLMs) to engage in human-like multi-turn conversations. |
|[SALMONN: Towards Generic Hearing Abilities for Large Language Models](https://arxiv.org/abs/2310.13289v1) | SALMONN understands text and audio at the same time, can be used for speech recognition and speech translation. [official code](https://github.com/bytedance/salmonn)|
|[FreeNoise: Tuning-Free Longer Video Diffusion via Noise Rescheduling](http://haonanqiu.com/projects/FreeNoise.html?utm_source=tldrai) | While you can generate easily an image with diffusion creating a video is much more complex (consistency), this work allows generations up to 512 frames long [paper](https://arxiv.org/abs/2310.15169), [code](https://github.com/arthur-qiu/LongerCrafter)|
|[PDFTriage: Question Answering over Long, Structured Documents](https://arxiv.org/abs/2309.08872) | Finding information from pdfs (web pages or other multi-page structured documents) is more difficult than for regular text. Therefore researchers at Adobe Research have developed a model that is able to consider both the text and the structure of the document|
|[VidChapters-7M: Video Chapters at Scale](https://antoyang.github.io/vidchapters.html) |Segmenting long videos into chapters enables users to quickly navigate to the information of their interest. Here the authors collected VidChapters-7M, a dataset of 817K user-chaptered videos including 7M chapters in total. |
|[RLMRec: Representation Learning with Large Language Models for Recommendation](https://arxiv.org/abs/2310.15950) | In this article the authors enhanced a recommendation system with an LLM, resulting in better recommendations. [code here](https://github.com/hkuds/rlmrec)|
|[CommonCanvas: An Open Diffusion Model Trained with Creative-Commons Images](https://arxiv.org/abs/2310.16825) | We assemble a dataset of Creative-Commons-licensed (CC) images, which we use to train a set of open diffusion models that are qualitatively competitive with Stable Diffusion 2 (SD2). [official code](https://github.com/mosaicml/diffusion)|
|[LLM-FP4: 4-Bit Floating-Point Quantized Transformers](https://arxiv.org/abs/2310.16836v1) | We propose LLM-FP4 for quantizing both weights and activations in large language models (LLMs) down to 4-bit floating-point values, in a post-training manner. Existing post-training quantization (PTQ) solutions are primarily integer-based and struggle with bit widths below 8 bits.[official code](https://github.com/nbasyl/llm-fp4)|
|[Deja Vu: Contextual Sparsity for Efficient LLMs at Inference Time](https://arxiv.org/abs/2310.17157) |For a specific input, only a small fraction of attention heads and MLP neurons are needed, while the rest can be "silenced" without changing the output. Deja Vu to speed up inference for large language models. exploiting "contextual sparsity" (finding small subsets of model parameters that are sufficient to compute the same output for a given input.).  This is unlike prior pruning methods that permanently remove parameters.  [official code](https://github.com/FMInference/DejaVu/tree/master) |
|[ConvNets Match Vision Transformers at Scale](https://arxiv.org/abs/2310.16764) | Many researchers believe that ConvNets perform well on small or moderately sized datasets, but are not competitive with Vision Transformers when given access to datasets on the web-scale. The authors invested the same computer budget on a CNN to make a fair comparison with the vision transformers and they matched the performance [deep dive](https://medium.com/gitconnected/have-convolutional-networks-become-obsolete-245969f6b9d9)|
|[Llemma: An Open Language Model For Mathematics](https://arxiv.org/abs/2310.10631) |a large language model for mathematics, the authors show how using a small model in continuous pretraining you can beat bigger models on Math and STEM. [deep dive](https://levelup.gitconnected.com/llemma-a-model-speaking-math-c8c07e1c001c) |
|[Zephyr: Direct Distillation of LM Alignment](https://arxiv.org/abs/2310.16944) | a 7B parameter model with competitive performance to ChatGPT on AlpacaEval|

## News
|Link|description|
|---|---|
|[New Nvidia AI agent, powered by GPT-4, can train robots](https://venturebeat.com/ai/new-nvidia-ai-agent-powered-by-gpt-4-can-train-robots/) | Eureka, a new AI agent (powered by GPT-4) can teach complex skills to robots|
|[‘Mind-blowing’ IBM chip speeds up AI](https://www.nature.com/articles/d41586-023-03267-0) | IBM has developed a brain-inspired computer chip that could supercharge artificial intelligence (AI) by working faster with much less power  |
|[“Math is hard” — if you are an LLM – and why that matters](https://garymarcus.substack.com/p/math-is-hard-if-you-are-an-llm-and) | LLM success on math is still limited, especially if you just rely on a LLM|
|[Apple Rumored to Follow ChatGPT With Generative AI Features on iPhone as Soon as iOS 18](https://www.macrumors.com/2023/10/19/apple-generative-ai-late-2024-jeff-pu/) |Apple plans to start implementing generative AI technology on the iPhone and iPad in late 2024 at the earliest according to analysts |
|[Reddit can survive without search](https://www.theverge.com/2023/10/20/23925504/reddit-deny-force-log-in-see-posts-ai-companies-deals) | Reddit and other companies may stop crawlers (and be not find anymore on google search) if they do not find an agreement in generative AI|
|[This new data poisoning tool lets artists fight back against generative AI](https://www.technologyreview.com/2023/10/23/1082189/data-poisoning-artists-fight-generative-ai) |A new tool lets artists add invisible changes to the pixels in their art before they upload it online so that if it’s scraped into an AI training set, it can cause the resulting model to break in chaotic and unpredictable ways.  |
|[AI risk must be treated as seriously as climate crisis, says Google DeepMind chief](https://www.theguardian.com/technology/2023/oct/24/ai-risk-climate-crisis-google-deepmind-chief-demis-hassabis-regulation) | Demis Hassabis calls for greater regulation to quell existential fears over tech with above-human levels of intelligence|
|[Claude accessibility is expanded to 95 countries](https://twitter.com/AnthropicAI/status/1714025126516432996) | |
|[IBM Presents NorthPole](https://research.ibm.com/blog/northpole-ibm-ai-chip) | a new chip much faster for AI and much more energy efficient|
|[Perplexity raises new funding at $500 million valuation](https://techstartups.com/2023/10/24/ai-search-startup-perplexitys-valuation-climbs-to-500-million-after-new-funding-round-led-by-ivp/) | Perplexity is developing an AI-powered search engine competing with the likes of OpenAI’s ChatGPT and Google’s Bard. According to recent reports, Perplexity has been generating annual recurring revenue of $3 million as of this month.|
|[AI rapidly diagnoses brain tumours during surgery](https://www.nature.com/articles/d41586-023-03072-9) |A machine-learning method to assess DNA can accurately classify brain tumours in real time. This rapid analysis might help surgeons to identify the tumour type when operating and to adjust their surgical strategy accordingly. |
|[AI executive order on October 30](https://www.engadget.com/the-white-house-will-reportedly-reveal-a-sweeping-ai-executive-order-on-october-30-200558649.html) |The Biden Administration is reportedly set to unveil a broad executive order on artificial intelligence next week. |
|[Lenovo and NVIDIA Announce Hybrid AI Solutions to Help Enterprises Quickly Adopt GenAI](https://nvidianews.nvidia.com/news/lenovo-nvidia-hybrid-ai) |New End-to-End Solutions Include Accelerated Systems, AI Software and Expert Services to Build and Deploy Domain-Specific AI Models with Ease |

## Resources
|Link|description|
|---|---|
|[caption-usampling](https://github.com/sayakpaul/caption-upsampling) | DALL-3 power is derived from better data quality, this library can allow you to upsample your dataset |
|[SolidGPT](https://github.com/AI-Citizen/SolidGPT) | Chat everything with your code repository, ask repository-level code questions, and discuss your requirements. AI Scan and learning your code repository, provide you code repository level answer|
|[GoLLIE 34B](https://huggingface.co/HiTZ/GoLLIE-34B) | zero-shot Information Extraction model for extracting information from unstructured data (CSV, JSON, and so on)|
|[Arithmo-Mistral-7B](https://huggingface.co/akjindal53244/Arithmo-Mistral-7B) | Mistral 7B fine-tuned on math|
|[GraphMaker](https://github.com/Graph-COM/GraphMaker) |a diffusion model capable of generating highly realisitc large attributed graphs. [original article](https://github.com/Graph-COM/GraphMaker) |
|[Meta’s Habitat 3.0 simulates real-world environments for intelligent AI robot training](https://siliconangle.com/2023/10/20/metas-habitat-3-0-simulates-real-world-environments-intelligent-ai-robot-training/) |Researchers from Meta Platforms Inc.’s Fundamental Artificial Intelligence Research team said today they’re releasing a more advanced version of the AI simulation environment Habitat, which is used to teach robots how to interact with the physical world. |
|[SAM-Med3D](https://github.com/uni-medical/sam-med3d) |the most comprehensive study to modify SAM for 3D medical images. Curated the most extensive volumetric medical dataset to date for training, boasting 131K 3D masks and 247 categories. [paper](https://arxiv.org/abs/2310.15161)|
|[deepsparse](https://github.com/neuralmagic/deepsparse) | DeepSparse is a CPU inference runtime that takes advantage of sparsity to accelerate neural network inference. |
|[ExecuTorch](https://pytorch.org/blog/pytorch-edge/) |PyTorch Edge: Enabling On-Device Inference Across Mobile and Edge Devices with ExecuTorch |
|[Spelltest: AI-to-AI Testing for LLM Based Applications](https://github.com/artas728/spelltest) | Today's AI-driven applications largely depend on Large Language Models (LLMs) like GPT-4 to deliver innovative solutions. However, ensuring that they provide relevant and accurate responses in every situation is a challenge. Spelltest addresses this by simulating LLM responses using synthetic user personas and an evaluation technique to evaluate these responses automatically(but still requires human supervision).|
|[polyfire-js](https://github.com/polyfire-ai/polyfire-js) |An all-in-one managed backend for AI apps. Build AI apps from the frontend, very fast |
|[ToRA: A Tool-Integrated Reasoning Agent](https://github.com/microsoft/ToRA) |ToRA is a series of Tool-integrated Reasoning Agents designed to solve challenging mathematical reasoning problems by interacting with tools, e.g., computation libraries and symbolic solvers. ToRA series seamlessly integrate natural language reasoning with the utilization of external tools, thereby amalgamating the analytical prowess of language and the computational efficiency of external tools. |
|[Adala](https://github.com/HumanSignal/adala/) |Adala offers a robust framework for implementing agents specialized in data processing, with an emphasis on diverse data labeling tasks. |

## Perspectives
|Link|description|
|---|---|
|[Emotional labor and its consequences](https://seths.blog/2023/10/emotional-labor-and-its-consequences/) | Emotional labor is what differentiate us from AI |
|[The Techno-Optimist Manifesto](https://a16z.com/the-techno-optimist-manifesto) | A blog post that has ignited a strong debate in Silicon Valley about positive impact of technology|
|[Peak Data](https://eastwind.substack.com/p/peak-data) | a blog post discussing what will happen if the internet is filled only with AI-generated data, this will lead probably to collapse of AI model trained on these data|
|[Five Areas of AI Opportunity According to Snowflake’s Ahmad Khan](https://lsvp.com/five-areas-of-ai-opportunity-according-to-snowflakes-ahmad-khan/) |Lightspeed recently hosted the latest in its Generative AI series in Los Angeles, a fireside chat with Ahmad Khan, Head of AI/ML Strategy at Snowflake |
|[An AI revolution is brewing in medicine. What will it look like?](https://www.nature.com/articles/d41586-023-03302-0) |Emerging generalist models could overcome some limitations of first-generation machine-learning tools for clinical use. |
|[The Convergence of Data & Software Engineering in the Age of AI](https://tomtunguz.com/data-engineering/) | This convergence signals how far data teams have evolved into core engineering teams. Machine learning’s demand for data has accelerated this movement because AI needs data to function.|
|[Managing AI Risks in an Era of Rapid Progress](https://managing-ai-risks.com/managing_ai_risks.pdf) | Soem of the biggest names in the field (Hinton, Bengio and so on) discuss the potential threats of AI and how to manage them |
