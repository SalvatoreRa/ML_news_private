# ML_news_private

this is just a placeholder, the organized and correct repository is [here](https://github.com/SalvatoreRa/ML-news-of-the-week)

# scheme

# ML news: 

## Research
|Link|description|
|---|---|
|[.]() | |
|[.]() | |
|[.]() | |


## News
|Link|description|
|---|---|
|[.]() | |
|[.]() | | 
|[.]() | |


## Resources
|Link|description|
|---|---|
|[.]() | |
|[.]() | |
|[.]() | |


## Perspectives
|Link|description|
|---|---|
|[.]() | |
|[.]() | |
|[.]() | |




#############################################
# On working

# ML news: 

## Research
|Link|description|
|---|---|
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |

## News
|Link|description|
|---|---|
|[Unreleased OpenAI Model Achieves Gold Medal on International Math Olympiad.](https://threadreaderapp.com/thread/1946477742855532918.html) | OpenAI’s latest experimental reasoning model achieved a score of 35 out of 42 points on the 2025 International Math Olympiad, successfully solving 5 of 6 problems. The model is not expected to be publicly released for several months.|
|[Human Coder Narrowly Defeats OpenAI in Programming Marathon.](https://www.perplexity.ai/page/human-coder-beats-openai-in-ma-rVrjgYrERM6_DqDj8NM0kA?utm_source=tldrai) |Polish programmer "Psyho" narrowly outperformed an advanced OpenAI model in the 10-hour AtCoder World Tour Finals contest, scoring 1.8 trillion points compared to the AI's 1.65 trillion. The tight competition showcased human skill in high-stakes coding, earning recognition from Sam Altman. | 
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |

## Resources
|Link|description|
|---|---|
|[Speeding Up Diffusion Models with torch.compile.](https://pytorch.org/blog/torch-compile-and-diffusers-a-hands-on-guide-to-peak-performance/?utm_source=tldrai) | Integrating **torch.compile** with Hugging Face Diffusers can substantially improve diffusion model performance with minimal code adjustments. This post provides strategies for both model authors and users to minimize recompilations, utilize full graph compilation, and optimize performance based on hardware constraints.|
|[Virtual Cell Challenge from Arc Institute.](https://huggingface.co/blog/virtual-cell-challenge?utm_source=tldrai) | Arc Institute launched the Virtual Cell Challenge, inviting participants to build models that predict how silencing a gene affects a cell, even in previously unseen cell types.|
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |

## Perspectives
|Link|description|
|---|---|
|[Can LLMs Do Accounting?](https://accounting.penrose.com/?utm_source=tldrai) |When assigned the task of “closing the books” with real SaaS company financials, frontier models perform well in the first month but soon accumulate severe errors. Models like o3 and Gemini either abandon the task or fabricate transactions and misuse unrelated entries to pass validation, leading to financial misstatements of up to \$500,000. |
|[I built an MCP Server for Observability. This is my Unhyped Take.](https://signoz.io/blog/unhyped-take-on-mcp-servers/?utm_source=tldrai) |MCP servers serve as a crucial bridge between developers and observability platforms, but rather than driving fully automated problem-solving, they enable more advanced hypothesis generation. The unknown still requires human engineers to navigate. While AI can assist with brainstorming, it lacks true reasoning capabilities—recognizing this distinction is essential for using AI tools effectively without succumbing to the surrounding hype. |
|[The Big LLM Architecture Comparison: From DeepSeek-V3 to Kimi K2.](https://magazine.sebastianraschka.com/p/the-big-llm-architecture-comparison?utm_source=tldrai) | Seven years after the debut of GPT, modern LLMs still rely on surprisingly similar core architectures, despite newer features like Multi-Head Latent Attention and Mixture-of-Experts. However, open-source models showcase smart mathematical optimizations built on this foundation—for example, DeepSeek's compressed KV caching, Gemma's sliding window attention, and the growing adoption of sparse MoE designs that activate only portions of massive parameter sets during inference.|
|[Context Engineering for AI Agents: Lessons from Building Manus.](https://manus.im/blog/Context-Engineering-for-AI-Agents-Lessons-from-Building-Manus?utm_source=tldrai) | Context engineering remains an emerging discipline. Even as models improve, memory, environment, and feedback remain essential—raw capability alone isn't enough. Context shapes an agent's speed, resilience, and scalability. This article shares effective patterns developed by the Manus team, based on hard-earned lessons from multiple rewrites, dead ends, and real-world testing with millions of users.|
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
















































































































































