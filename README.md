# ML_news_private

this is just a placeholder, the organized and correct repository is [here](https://github.com/SalvatoreRa/ML-news-of-the-week)

# scheme

# ML news: 

## Research
|Link|description|
|---|---|
|[.]() | |
|[.]() | |
|[.]() | |


## News
|Link|description|
|---|---|
|[.]() | |
|[.]() | | 
|[.]() | |


## Resources
|Link|description|
|---|---|
|[.]() | |
|[.]() | |
|[.]() | |


## Perspectives
|Link|description|
|---|---|
|[.]() | |
|[.]() | |
|[.]() | |



#############################################
# On working

## Research
|Link|description|
|---|---|
|[Baba is Eval.](https://fi-le.net/baba/) | *Baba is You* is a puzzle game that challenges players to manipulate rules to solve levels, requiring a high level of abstract reasoning. This study examines how large language models perform in the game. Currently, Claude 4 struggles with it, suggesting that a model focused on reasoning might be more suitable. The next phase of the study may involve evaluating such models.|
|[CoRT (Chain of Recursive Thoughts).](https://github.com/PhialsBasement/Chain-of-Recursive-Thoughts) | CoRT boosts AI performance by enabling models to self-evaluate and iteratively generate alternative responses to find the best one. When tested with Mistral 3.1 24B, it led to notable gains in programming tasks. This approach refines outputs through repeated generation and selection, resulting in more accurate and effective responses.|
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |

## News
|Link|description|
|---|---|
|[Grok 4 benchmarks leak with 45% score on Humanity Last Exam.](https://www.testingcatalog.com/grok-4-benchmarks-leak-with-45-score-on-humanity-last-exam/) | Leaked benchmarks suggest Grok 4 will be a cutting-edge model. Mentions of it have appeared in the xAI console. If the benchmarks are accurate, Grok 4 might surpass top models such as Gemini 2.5 Pro, o3 Pro, and Claude 4 Opus. xAI is under pressure to launch Grok 4 soon, as OpenAI, Google, and Anthropic are reportedly getting ready to unveil new models.|
|[Character AI's Real-Time Video Generation.](https://blog.character.ai/character-ais-real-time-video-breakthrough/) | Character.AI's TalkingMachines is a real-time, audio-driven video generation model that creates FaceTime-style animations from a single image and voice input.|
|[Sakana AI’s TreeQuest: Deploy multi-model teams that outperform individual LLMs by 30](https://venturebeat.com/ai/sakana-ais-treequest-deploy-multi-model-teams-that-outperform-individual-llms-by-30/) | Japanese AI lab Sakana AI has introduced a new technique that allows multiple large language models (LLMs) to cooperate on a single task, effectively creating a “dream team” of AI agents. The method, called Multi-LLM AB-MCTS, enables models to perform trial-and-error and combine their unique strengths to solve problems that are too complex for any individual model.|
|[Google faces EU antitrust complaint over AI Overviews.](https://techcrunch.com/2025/07/05/google-faces-eu-antitrust-complaint-over-ai-overviews/i) |A group known as the Independent Publishers Alliance has filed an antitrust complaint with the European Commission over Google’s AI Overviews, according to Reuters. The complaint accuses Google of “misusing web content for Google’s AI Overviews in Google Search, which have caused, and continue to cause, significant harm to publishers, including news publishers in the form of traffic, readership and revenue loss.”| 
|[Elon Musk confirms xAI is buying an overseas power plant and shipping the whole thing to the U.S. to power its new data center — 1 million AI GPUs and up to 2 Gigawatts of power under one roof, equivalent to powering 1.9 million homes.](https://www.tomshardware.com/tech-industry/artificial-intelligence/elon-musk-xai-power-plant-overseas-to-power-1-million-gpus) | xAI's next data centers are expected to house millions of AI chips.|
|[A new, 200% faster DeepSeek R1-0528 variant appears from German lab TNG Technology Consulting GmbH.](https://venturebeat.com/ai/holy-smokes-a-new-200-faster-deepseek-r1-0528-variant-appears-from-german-lab-tng-technology-consulting-gmbh/) |It’s been a little more than a month since Chinese AI startup DeepSeek, an offshoot of Hong Kong-based High-Flyer Capital Management, released the latest version of its hit open source model DeepSeek, R1-0528. Like its predecessor, DeepSeek-R1 — which rocked the AI and global business communities with how cheaply it was trained and how well it performed on reasoning tasks, all available to developers and enterprises for free — R1-0528 is already being adapted and remixed by other AI labs and developers, thanks in large part to its permissive Apache 2.0 license. |
|[NFDG: The $1.1B VC Fund That 4X'd in Two Years—Then Got Acquired by Meta .](https://www.saastr.com/the-1-1b-vc-fund-that-4xd-in-two-years-then-got-acquired-by-meta/) | This post looks at NFDG's portfolio, advisory board, performance, success factors, and more.|
|[Nvidia's deal to buy Canadian AI startup CentML could top US$400M.](https://thelogic.co/news/exclusive/nvidias-deal-centml-us400m/) | CentML makes software that operates between users' AI models and the chips powering them, making the systems run better.|
|[Grok 4 spotted ahead of launch with special coding features.](https://www.bleepingcomputer.com/news/artificial-intelligence/grok-4-spotted-ahead-of-launch-with-special-coding-features/) | Elon Musk-funded xAI is skipping Grok 3.5 and releasing Grok 4 after Independence Day in the United States, and it could be the best model from the company.|
|[Researchers seek to influence peer review with hidden AI prompts.](https://techcrunch.com/2025/07/06/researchers-seek-to-influence-peer-review-with-hidden-ai-prompts/) | Academics may be leaning on a novel strategy to influence peer review of their research papers — adding hidden prompts designed to coax AI tools to deliver positive feedback. Nikkei Asia reports that when examining English-language preprint papers available on the website arXiv, it found 17 papers that included some form of hidden AI prompt. The paper’s authors were affiliated with 14 academic institutions in eight countries, including Japan’s Waseda University and South Korea’s KAIST, as well as Columbia University and the University of Washington in the United States.|
|[Apple appeals against ‘unprecedented’ €500m EU fine over app store.](https://www.theguardian.com/technology/2025/jul/07/apple-appeals-eu-fine-app-store) | iPhone maker accuses European Commission of going ‘far beyond what the law requires’ in ruling|
|[Tesla shares dive as investors fear new Elon Musk political party will damage brand.](https://www.theguardian.com/technology/2025/jul/07/tesla-shares-dive-as-investors-fear-new-elon-musk-political-party-will-damage-brand) |Fall of 7.5% in early trading wipes $76bn off firm’s value as market frets CEO’s foray into politics will distract from role |
|[Trump to start TikTok sale talks with China, he says, with deal ‘pretty much’ reached.](https://www.theguardian.com/technology/2025/jul/05/trump-to-start-tiktok-sale-talks-with-china-he-says-with-deal-pretty-much-reached) | President also says he may visit Xi Jinping or Chinese leader could come to US after Trump last month extended app sale deadline for third time|
|[‘The vehicle suddenly accelerated with our baby in it’: the terrifying truth about why Tesla’s cars keep crashing.](https://www.theguardian.com/technology/2025/jul/05/the-vehicle-suddenly-accelerated-with-our-baby-in-it-the-terrifying-truth-about-why-teslas-cars-keep-crashing) |Elon Musk is obsessive about the design of his supercars, right down to the disappearing door handles. But a series of shocking incidents – from drivers trapped in burning vehicles to dramatic stops on the highway – have led to questions about the safety of the brand. Why won’t Tesla give any answers? |
|[Minister demands overhaul of UK’s leading AI institute.](https://www.theguardian.com/technology/2025/jul/04/minister-demands-overhaul-of-uks-leading-ai-institute-alan-turing) |Peter Kyle calls for new leadership at Alan Turing Institute and greater focus on defence and national security |
|[Elon Musk’s xAI gets permit for methane gas generators.](https://www.theguardian.com/us-news/2025/jul/03/elon-musk-xai-pollution-memphis) |NAACP plans to sue over massive Memphis datacenter near Black residents, who have long dealt with pollution |
|[Grok 4 release livestream.](https://threadreaderapp.com/thread/1942325820170907915.html) |xAI will hold a livestream for the Grok 4 release on Wednesday at 8 PM PT. |
|[Apple Loses Top AI Models Executive to Meta’s Hiring Spree.](https://www.bloomberg.com/news/articles/2025-07-07/apple-loses-its-top-ai-models-executive-to-meta-s-hiring-spree?accessToken=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzb3VyY2UiOiJTdWJzY3JpYmVyR2lmdGVkQXJ0aWNsZSIsImlhdCI6MTc1MTk1MTEzOCwiZXhwIjoxNzUyNTU1OTM4LCJhcnRpY2xlSWQiOiJTWjFQNE1EV1JHRzAwMCIsImJjb25uZWN0SWQiOiJFQTExNDNDNTM4NEE0RUY5QTg5RjJEN0IxMTg2MzcwOSJ9.0oqigRfyg_3QJ4_r6OvsL7Db9uRTGc0lHzzYUJ60Hb4) | Ruoming Pang, Apple's head of AI models, is leaving to join Meta's new superintelligence team. Meta is aggressively recruiting top AI talent with multi-million-dollar packages and recently reorganized its AI efforts under Meta Superintelligence Labs, led by Alexandr Wang.|
|[ChatGPT Experiments with ‘Study Together' Mode.](https://www.reddit.com/r/ChatGPT/comments/1lswn88/new_study_together_option_in_chatgpt/) |A few users have noticed a new, experimental ChatGPT feature dubbed “Study Together.” Instead of providing direct answers, it prompts users with questions to foster a more interactive learning experience. Details are still scarce, and OpenAI hasn't made an official announcement yet. |
|[Replit Dynamic Intelligence for Replit Agent.](https://blog.replit.com/dynamic-intelligence) |Replit has launched Dynamic Intelligence for its Agent, introducing three key features: Extended Thinking, High Power Model, and Web Search. These upgrades enhance the Agent’s context awareness, iterative reasoning, and autonomous task execution. Users can enable or disable each feature per request, tailoring the Agent’s problem-solving abilities to fit specific needs more effectively. |
|[China’s AI unity fractures as Huawei faces model theft allegations from the Alibaba camp.](https://www.computerworld.com/article/4018098/chinas-ai-unity-fractures-as-huawei-faces-model-theft-allegations-from-the-alibaba-camp.html) | A public feud over model originality threatens China’s collaborative AI front, with Huawei denying whistleblower claims of cloning Alibaba’s Qwen model amid rising global scrutiny.|
|[CoreWeave to acquire Core Scientific in $9 billion all-stock deal.](https://www.cnbc.com/2025/07/07/coreweave-to-acquire-core-scientific-in-9-billion-all-stock-deal.html) |The AI cloud infrastructure provider will buy the data center operator to eliminate $10 billion in future lease obligations and gain ownership of 1.3 gigawatts of compute capacity. |
|[Mirage, an AI-native game engine for real-time world generation.](https://blog.dynamicslab.ai/) | The first generative game engine lets players modify environments through natural language during gameplay, launching with GTA-style and racing demos that run entirely on AI-generated content at 16 FPS.|
|[Cursor Apologizes for Unclear Pricing Changes .](https://cursor.com/blog/june-2025-pricing) |Cursor's parent company, Anysphere, issued an apology after rolling out pricing changes to its Pro plan without sufficient clarity, prompting backlash from its user base. |
|[Replit Collaborates with Microsoft to bring Vibe Coding to Enterprise Customers.](https://replit.com/news/microsoft-partnership) | Replit and Microsoft have partnered to deliver natural-language-based enterprise app development, integrating with Azure services to let business users create and deploy production-ready software without coding experience.|
|[Mistral is reportedly in talks to raise $1B.](https://techcrunch.com/2025/07/08/mistral-is-reportedly-in-talks-to-raise-1b/) |French AI startup Mistral is in talks to raise up to $1 billion in equity from investors, including Abu Dhabi’s MGX fund, reports Bloomberg, citing people familiar with the matter. |
|[Gemini Nano in Chrome 137: notes for AI Engineers.](https://www.swyx.io/gemini-nano) |Gemini Nano is nearing release for all Chrome users, and this post offers a rewritten, developer-focused guide based on Google’s official documentation. The highlight is the Prompt API—an open-ended, highly flexible interface that will be of greatest interest to developers. The post walks through setup, key considerations, and common pitfalls to help you get started effectively. |
|[These Tesla, X, and xAI engineers were just poached by OpenAI .](https://www.teslarati.com/tesla-xai-executives-poached-openai/) |OpenAI has reportedly hired top engineering talent from companies like Tesla, xAI, X, and Meta. Notable hires include David Lau, Tesla’s VP of Software Engineering; Uday Ruddarraju, head of infrastructure engineering at X and xAI; Mike Dalton, another xAI infrastructure engineer; and Angela Fan, an AI researcher from Meta. This article explores their backgrounds, areas of expertise, and what their addition might signal for OpenAI’s future direction. |
|[OpenAI tightens the screws on security to keep away prying eyes.](https://techcrunch.com/2025/07/07/openai-tightens-the-screws-on-security-to-keep-away-prying-eyes/) | OpenAI has reportedly overhauled its security operations to protect against corporate espionage. According to the Financial Times, the company accelerated an existing security clampdown after Chinese startup DeepSeek released a competing model in January, with OpenAI alleging that DeepSeek improperly copied its models using “distillation” techniques.|
|[Microsoft, OpenAI and Anthropic are investing millions to train teachers how to use AI.](https://amp.cnn.com/cnn/2025/07/08/tech/ai-teacher-training-academy-microsoft-openai-anthropic) |A group of leading tech companies is teaming up with two teachers’ unions to train 400,000 kindergarten through 12th grade teachers in artificial intelligence over the next five years. |
|[LangChain is about to become a unicorn, sources say.](https://techcrunch.com/2025/07/08/langchain-is-about-to-become-a-unicorn-sources-say/) |LangChain, an AI infrastructure startup providing tools to build and monitor LLM-powered applications, is raising a new round of funding at an approximate $1 billion valuation led by IVP, according to three sources with knowledge of the deal.  |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |

## Resources
|Link|description|
|---|---|
|[Adding Memory to Gemini 2.5 Chatbots.](https://www.philschmid.de/gemini-with-memory) |A tutorial on using the Gemini API alongside the open-source mem0 tool to equip Gemini 2.5 chatbots with long-term memory. This setup helps bots remember previous interactions, tailor their replies, and avoid repeating information, leading to more contextually aware conversations. |
|[agent-squad.](https://github.com/awslabs/agent-squad) |A framework for building collaborative multi-agent AI systems that can plan, delegate, and work together to solve complex tasks. |
|[Economics of Claude 3 Opus Inference.](https://x.com/tessera_antra/status/1941563920587817203) |Anthropic has announced it will deprecate API access to Claude 3 Opus, citing a legitimate operational challenge. This article explores the economics behind running models at reduced scale and considers alternative solutions that could benefit both Anthropic and independent researchers. Maintaining inference access to Claude 3 Opus involves more complexity than is immediately apparent. |
|[Microjax: JAX in two classes and six functions.](https://github.com/joelburget/microjax) |Microjax is a tiny autograd engine with a Jax-like API. It was inspired by Andrej Karpathy's Micrograd, a PyTorch-like library with about 150 lines of code. JAX uses a more functional style, which some developers prefer. |
|[BitNet.](https://github.com/microsoft/BitNet) |An inference framework for Microsoft's BitNet b1.58, a 1.58-bit (ternary) large language model designed for efficient and lossless CPU inference using optimized low-bit kernels. |
|[Google Explores AI in Mental Health Treatment.](https://blog.google/technology/health/new-mental-health-ai-tools-research-treatment/) | Google announced two mental health AI initiatives: a practical guide to responsibly deploying AI in mental health care, and a multi-year research partnership with DeepMind and Wellcome Trust to study AI-driven diagnosis and treatment of anxiety, depression, and psychosis.|
|[The OLMo 2 model family.](https://allenai.org/olmo) | OLMo 2 is a fully open family of language models, with OLMo 2 32B as its most advanced version—marking the first fully open model to outperform GPT-3.5 Turbo and GPT-4o mini on key benchmark suites. The 7B and 13B variants hold their own against leading open-weight models from Meta and Mistral on English academic tasks. Even the smallest model, OLMo 2 1B, outperforms peers like Gemma 3 1B and Llama 3.2 1B.|
|[SmolLM3 Released by Hugging Face.](https://huggingface.co/blog/smollm3) | Hugging Face's SmolLM3 is a fully open 3B-parameter language model that supports six languages, strong reasoning capabilities, and long-context processing. It targets high performance in the small model segment.|
|[Mem0.](https://github.com/mem0ai/mem0) | An open-source memory layer for AI agents that enables long-term, personalized interactions by efficiently storing and retrieving user context across sessions, reducing token costs and improving response accuracy.|
|[NotebookLlaMa.](https://github.com/run-llama/notebookllama) | A fully open-source, LlamaCloud-backed alternative to NotebookLM, this project uses LlamaCloud for document processing, OpenAI for content generation, and ElevenLabs for voice synthesis.|
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |

## Perspectives
|Link|description|
|---|---|
|[The American DeepSeek Project.](https://www.interconnects.ai/p/the-american-deepseek-project) |Meta's recent AI struggles have left a gap in the open-source AI landscape, now mostly occupied by Chinese models. If this trend persists, the AI field could divide into two camps: high-performing but costly closed-source models from the U.S., and affordable, widespread, yet possibly insecure models from China. The U.S. likely has a narrow window—around two years—to reverse this by investing \$100–500 million in an open-source model that rivals the best proprietary ones. |
|[What can agents actually do?](https://lethain.com/what-can-agents-do/) |While there's plenty of hype around AI, much of the discussion is so abstract it becomes unhelpful. This post aims to clearly explain how AI agents function, using a few real-world examples. AI agents can significantly enhance software quality and system design—but if the underlying systems are flawed, agents can actually make things worse. |
|[Why I don't think AGI is right around the corner.](https://www.dwarkesh.com/p/timelines-june-2025) |Getting LLMs to perform consistent, humanlike work is difficult because they’re missing key capabilities. One major issue is their inability to improve over time—without continual learning, they stay fixed at their initial skill level. There's also no effective way to give them nuanced, human-style feedback. Tweaking system prompts falls far short of the kind of learning humans go through. Unlike people, LLMs can’t build context over time, reflect on their mistakes, or gradually refine their performance through practice. |
|[A Review of Alpha School, the private school with 2-hour days and AI teachers.](https://www.astralcodexten.com/p/your-review-alpha-school) |A year-long investigation by a parent revealed that the \$40,000 Austin school operates with 3.5-hour school days, a 5:1 student-teacher ratio, and strong incentive systems—contrary to its marketing as an AI-driven, teacher-free model. While students progress through material 2.6 times faster using personalized learning tools, parents argue the real benefit isn't acceleration, but time: the model could give children around nine extra years outside the classroom to explore their own interests. |
|[The ‘ChatGPT Moment’ in Robotics and beyond.](https://paritoshmohan.substack.com/p/the-chatgpt-moment-in-robotics-and) | Just three years ago, reliable robotic object manipulation demanded large engineering teams. Today, a college student can fine-tune an open-source vision-language-action model over a weekend and achieve results that once took months. This article explores what a "ChatGPT moment" for robotics might look like, surveys the current landscape, highlights emerging technologies, and predicts likely leaders. While the presence of robots in daily life may initially feel surreal, they'll soon become as essential and commonplace as AI assistants are today.|
|[Automating oral argument.](https://adamunikowsky.substack.com/p/automating-oral-argument) | A Harvard Law graduate and former Supreme Court advocate tested Claude 4 Opus by feeding it his case briefs and having it respond to the same questions posed by the Justices. The AI delivered what he described as an “outstanding oral argument,” offering coherent answers and insightful points he hadn’t considered. He concluded that AI lawyers may soon surpass even the best human advocates in oral argument performance.|
|[People Are Using AI Chatbots to Guide Their Psychedelic Trips.](https://www.wired.com/story/people-are-using-ai-chatbots-to-guide-their-psychedelic-trips/) |In the few states where it’s legal, in-person psychedelic therapy often costs thousands per session and involves long wait times. As a more accessible alternative, some users are turning to AI tripsitters. Companies like Mindbloom are also starting to integrate AI into their ketamine treatment programs. However, experts remain skeptical, arguing that AI lacks the emotional attunement necessary for safe and effective psychedelic experiences. |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |

#############################################
#############################################
#############################################
#############################################
#############################################
#############################################
#############################################
#############################################
#############################################
#############################################
#############################################
#############################################
#############################################
#############################################
#############################################
#############################################
#############################################
#############################################

# ML news: 

## Research
|Link|description|
|---|---|
|[Self-Adapting Language Models.](https://arxiv.org/abs/2506.10943) |A new training method allows LLMs to generate “self-edits” that result in lasting weight updates via supervised fine-tuning. Despite using a smaller model, this approach outperformed GPT-4.1, though it faced issues like catastrophic forgetting and consumed 15 times more tokens than typical inference. The technique offers a potential solution to the data bottleneck and personalization limits by letting models improve themselves through self-generated training data, reducing reliance on human-written text. |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |

## News
|Link|description|
|---|---|
|[New Insights for Scaling Laws in Autonomous Driving.](https://waymo.com/blog/2025/06/scaling-laws-in-autonomous-driving) | Waymo’s research confirms that, much like in language modeling, scaling up data and compute leads to better performance in autonomous vehicles. This insight reinforces the idea that larger, higher-quality datasets and models can directly improve driving systems. It also paves the way for more adaptive training approaches in robotic planning tasks, with significant implications for the future of autonomous mobility.|
|[Google tests Audio Overviews for Search queries.](https://techcrunch.com/2025/06/13/google-tests-audio-overviews-for-search-queries/) | Google Search is experimenting with Audio Overviews for certain Search queries, the company announced on Friday. The feature was first introduced to NotebookLM, Google’s AI-based note-taking and research assistant.| 
|[Institutional Books 1.0.](https://huggingface.co/datasets/institutional/institutional-books-1.0) |Harvard Library and Google Books released 242 billion tokens from almost 1 million public domain books as a high-quality training dataset. |
|[The cracks in the OpenAI-Microsoft relationship are reportedly widening.](https://techcrunch.com/2025/06/16/the-cracks-in-the-openai-microsoft-relationship-are-reportedly-widening/) |OpenAI and Microsoft may be reaching an inflection point in their relationship, according to a report from The Wall Street Journal. The report, citing anonymous sources, says OpenAI executives have considered publicly accusing Microsoft of anticompetitive behavior throughout their partnership. OpenAI executives also mulled whether to seek a federal regulatory review of their contract with Microsoft. |
|[OpenAI wins $200 million U.S. defense contract.](https://www.cnbc.com/2025/06/16/openai-wins-200-million-us-defense-contract.html) |OpenAI has been awarded a $200 million contract to provide the U.S. Defense Department with artificial intelligence tools. The department announced the one-year contract on Monday, months after OpenAI said it would collaborate with defense technology startup Anduril to deploy advanced AI systems for “national security missions.” |
|[🇵 🇷 🇴 🇲 🇵 🇹 🇸 are an API primitive now](https://threadreaderapp.com/thread/1934717086783426698.html) |Prompts are now treated as a first-class API primitive on OpenAI’s platform. Developers can centrally manage, version, and optimize prompts across tools like the Playground, API, Evals, and Stored Completions. Prompts can also be preconfigured with specific models, tools, and messages. This update is designed to streamline prompt refinement and reuse, making development more efficient. |
|[Character AI's Writing Evaluation Framework.](https://blog.character.ai/evaluating-our-models-using-principles-of-compelling-writing/) |Character AI outlined a new framework that scores conversational storytelling by combining creative writing heuristics with objective metrics to judge pacing, engagement, and fun. |
|[TikTok Launches AI-Generated Product Models and Reviewers.](https://www.theverge.com/news/684572/tiktok-ai-advertising-videos-try-on-product-placement) | TikTok's Symphony platform will now generate videos of virtual avatars modeling products and trying on clothes, potentially replacing human influencers.|
|[AstraZeneca signs AI research deal with China's CSPC for chronic diseases.](https://www.reuters.com/business/healthcare-pharmaceuticals/astrazeneca-agrees-research-deal-worth-up-522-billion-with-cspc-2025-06-13/) AstraZeneca will pay $110 million upfront for CSPC to use AI-driven research to discover small molecule therapies, including an oral treatment for immunological diseases.| |
|[Cursor's $200 Ultra Plan.](https://cursor.com/en/blog/new-tier?utm_source=tldrai) |Anysphere has introduced a fixed‑price Ultra tier that offers far higher compute than Pro, made possible by long‑term deals with major model vendors. |
|[Gemini 2.5: Updates to our family of thinking models.](https://developers.googleblog.com/en/gemini-2-5-thinking-model-updates/?utm_source=tldrai) |Google released Gemini 2.5 Pro and Flash to general availability, debuted Flash‑Lite in preview, and introduced controllable “thinking” budgets that improve reasoning accuracy while giving developers flexibility. |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |

## Resources
|Link|description|
|---|---|
|[Low-Bit Quantization with ParetoQ.](https://pytorch.org/blog/paretoq-scaling-laws-in-extremely-low-bit-llm-quantization) | ParetoQ is a new training algorithm that unifies binary, ternary, and 2-to-4 bit quantization, achieving state-of-the-art results across all levels.|
|[The AI Eval Flywheel: Scorers, Datasets, Production Usage, & Rapid Iteration.](https://pejmanjohn.com/ai-eval-flywheel) |At the 2025 AI Engineer World's Fair, there was striking alignment in how evaluation frameworks were approached. Most centered on structuring inputs and evaluating outputs, then iterating based on real production usage. The goal is to create fast, low-friction eval flywheels to improve user experience through rapid feedback loops. A key concept is the use of 'playgrounds'—interactive environments where engineers can tweak features and immediately test them against datasets and evaluation metrics. |
|[How Anthropic Built Their Deep Research System.](https://www.anthropic.com/engineering/built-multi-agent-research-system) |In this engineering blog post, Anthropic shares insights into prompt design, tool coordination, and production reliability when building multi-agent systems. Their architecture follows an orchestrator-worker model, where a lead agent spawns specialized sub-agents that search in parallel—significantly outperforming a single-agent Opus setup. Token usage emerged as the primary driver of performance, accounting for 80% of the variance. While multi-agent systems use roughly 15 times more tokens than standard chats, they enable far more sophisticated research workflows. |
|[Google's Veo for Live-Action Videos.](https://blog.google/technology/google-deepmind/ancestra-behind-the-scenes/) |Google DeepMind teamed up with filmmakers to create *ANCESTRA*, a hybrid film combining live-action footage with Veo-generated video. The project leveraged new Veo capabilities that allow for personalized, motion-matched generative content, resulting in visually seamless integration between real and AI-generated scenes. |
|[Featherless AI on Hugging Face Inference Providers.](https://huggingface.co/blog/inference-providers-featherless) |Featherless AI is now available as an inference provider on Hugging Face. It offers serverless access to a wide variety of models from Meta, Qwen, DeepSeek, and others. |
|[Automated Issue Resolution Data Pipelines.](https://github.com/deepsoftwareanalytics/swe-factory) |SWE-Factory provides automated training and evaluation pipelines for GitHub issue resolution tasks. It is powered by LLM-based multi-agent systems. |
|[An Introduction to Google's Approach to AI Agent Security.](https://simonwillison.net/2025/Jun/15/ai-agent-security/) | A recent paper from Google describes key risks involved in deploying AI agents and the company's framework for securing them.|
|[Nanonets OCR Small.](https://nanonets.com/research/nanonets-ocr-s/) |Nanonets-OCR-s is a cutting-edge image-to-markdown OCR model that surpasses basic text extraction by intelligently converting documents into structured, semantically tagged markdown. It understands both document layout and content context, producing output that's optimized for further processing by large language models. The model can handle LaTeX equations, generate image descriptions, detect and separate signatures, extract watermarks, process checkboxes, and accurately extract complex tables. |
|[CoRT: Code-integrated Reasoning within Thinking.](https://github.com/chengpengli1003/cort) |CoRT post‑trains large reasoning models with hint engineering so they can delegate calculations to external code interpreters. |
|[TreeRL for On‑Policy LLM Training.](https://arxiv.org/abs/2506.11902) | TreeRL uses on‑policy tree search and intermediate supervision to train LLMs without a separate reward model, delivering stronger math and code reasoning than ChainRL.|
|[Groq on Hugging Face Inference Providers.](https://huggingface.co/blog/inference-providers-groq) |Groq's low‑latency hardware is now a selectable inference provider on the Hub and SDKs, adding fast serverless access to models like Llama 4 and Qwen 32B. |
|[Models.dev.](https://models.dev/) |This site contains an open-source database of AI models that lists AI model specifications, pricing, and capabilities. |
|[Understanding and Coding the KV Cache in LLMs.](https://magazine.sebastianraschka.com/p/coding-the-kv-cache-in-llms?utm_source=tldrai) |Key-value (KV) caches help speed up LLM inference by storing intermediate attention results, preventing redundant computation. For example, when generating a sentence like "Time flies fast" token by token, the model would typically recalculate attention for "Time" and "flies" at each step—but caching these values yields up to 5x speedups. This tutorial walks through enhancing a 124M-parameter GPT model, starting with simple cache buffers and position tracking, and advancing to production-grade optimizations like pre-allocated memory and sliding windows to tackle the linear memory growth that limits long-sequence performance. |
|[OpenAI's Practical Guide to Building Agent.](https://cdn.openai.com/business-guides-and-resources/a-practical-guide-to-building-agents.pdf?utm_source=tldrai) | This guide recommends beginning with single-agent systems before scaling to multi-agent setups, favoring manager patterns where one agent coordinates others through tool calls or decentralized handoffs for peer-to-peer delegation. Key takeaways include using layered guardrails—like LLM-based classifiers, regex filters, and moderation APIs—designing tools that can handle messy, long-horizon tasks, and incorporating human-in-the-loop mechanisms that activate when failures occur or actions carry significant risk.|
|[Real-Time Action Chunking with Large Models.](https://www.physicalintelligence.company/research/real_time_chunking?utm_source=tldrai) |Unlike chatbots or image generators, robots must function in real time—any lag between input and output directly impacts performance. While vision-language-action (VLA) models show strong generalization in open-world tasks, they often suffer from slow execution. This article introduces an algorithm called real-time chunking, which allows VLA models to run continuously and responsively without interruptions. The method works with any diffusion- or flow-based VLA model and requires no changes during training. |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |

## Perspectives
|Link|description|
|---|---|
|[AMD's AI Future is Rack Scale 'Helios'.](https://morethanmoore.substack.com/p/amds-ai-future-is-rack-scale-helios) |AMD's MI400 will rival Nvidia's Blackwell chips with rack-scale architecture that enables thousands of GPUs to function as unified systems. The company claims 40% better tokens/$ compared to NVIDIA. Its roadmap includes a path to 20x rack-scale energy efficiency by 2030. |
|[Google, Scale AI's largest customer, plans split after Meta deal, sources say.](https://www.reuters.com/business/google-scale-ais-largest-customer-plans-split-after-meta-deal-sources-say-2025-06-13/) |Meta’s \$14 billion acquisition of a 49% stake in Scale AI has triggered major fallout across the AI industry. Concerned about exposing sensitive data to a competitor, Google pulled a planned \$200 million contract for human-labeled training data. Microsoft, xAI, and OpenAI are also distancing themselves from Scale for similar reasons. This shift is benefiting competitors like Labelbox, which anticipates “hundreds of millions” in new revenue as AI labs seek neutral providers or bring data operations in-house. |
|[Have LLMs Finally Mastered Geolocation?](https://www.bellingcat.com/resources/how-tos/2025/06/06/have-llms-finally-mastered-geolocation/) | Open-source intelligence researchers evaluated 20 AI models on 500 geolocation tasks using unpublished travel photos to prevent reliance on memorized data. OpenAI’s latest models outperformed Google Lens by analyzing architectural features, vegetation, and partial text cues, while models like Claude typically only identified the correct continent. Despite their strengths, all models still produced hallucinations, and surprisingly, "deep research" modes often performed worse than standard settings.|
|[The Claude Bliss Attractor.](https://www.astralcodexten.com/p/the-claude-bliss-attractor) |Claude, when talking to copies of itself, will eventually turn the conversation into a discussion on spiritual bliss, Buddhism, and the nature of consciousness. |
|[Coding Agents Have Crossed a Chasm.](https://blog.singleton.io/posts/2025-06-14-coding-agents-cross-a-chasm/) | Advanced AI coding tools are transforming how developers work—shifting the focus from writing code to designing solutions and crafting clear problem descriptions. One developer found that providing Claude with ASCII diagrams of OAuth flows or full DOM trees from Chrome DevTools reduced debugging time from 45 minutes to just 10. But while AI can greatly boost efficiency, it also magnifies both expertise and misunderstanding—helping you implement flawed architecture faster if your foundations aren’t solid.|
|[Some thoughts on human-AI relationships.](https://reservoirsamples.substack.com/p/some-thoughts-on-human-ai-relationships) |OpenAI’s head of model behavior and policy has shared how the company is addressing the growing emotional bonds users form with ChatGPT. While the question of AI consciousness remains unresolved, OpenAI aims to prevent users from mistakenly viewing models as sentient. The goal is to design a model that feels warm and approachable—without suggesting it has thoughts, feelings, or an inner life. |
|[AI Use at Work Has Nearly Doubled in Two Years.](https://www.gallup.com/workplace/691643/work-nearly-doubled-two-years.aspx) | A Gallup survey found that 40% percent of U.S. employees now use AI at work, with white-collar workers driving adoption. Technology workers lead with 50% frequent AI use while production and frontline workers remain stuck at 9%.|
|[Sam Altman's Take on Meta's $100M Offers.](https://www.youtube.com/watch?v=mZUG0pr5hBo) | In a podcast, the OpenAI CEO confirmed Meta dangled nine‑figure packages to lure researchers to its superintelligence team but said virtually none defected, taking the opportunity to jab at Meta's recruiting push.|
|[How Not to Lose Your Job to AI.](https://80000hours.org/agi/guide/skills-ai-makes-valuable/?utm_source=tldrai) |This career guide highlights skills that grow more valuable as automation advances—such as AI deployment, leadership, and government relations. It encourages knowledge workers to bypass traditional entry-level roles, recommending side projects and startup positions instead, as AI disrupts and flattens established corporate hierarchies. |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |














































































































































