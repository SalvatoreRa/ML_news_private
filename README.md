# ML_news_private

this is just a placeholder, the organized and correct repository is [here](https://github.com/SalvatoreRa/ML-news-of-the-week)

# scheme

# ML news: 

## Research
|Link|description|
|---|---|
|[.]() | |
|[.]() | |
|[.]() | |

## News
|Link|description|
|---|---|
|[.]() | |
|[.]() | |
|[.]() | |


## Resources
|Link|description|
|---|---|
|[.]() | |
|[.]() | |
|[.]() | |

## Perspectives
|Link|description|
|---|---|
|[.]() | |
|[.]() | |
|[.]() | |

#############################################
# On working 

# ML news: 

## Research
|Link|description|
|---|---|
|[Genie 2: A large-scale foundation world model.](https://deepmind.google/discover/blog/genie-2-a-large-scale-foundation-world-model/) |A foundation world model generates playable 3D environments from single prompt images, offering endless training scenarios for AI agents with features like physics simulation, character animation, and object interactions. Genie 2, trained on video data using a combination of autoencoder and transformer, creates virtual worlds capable of real-time interactivity. A faster, lower-quality version is also available for immediate play. |
|[Reverse Thinking Makes LLMs Stronger Reasoners.](https://arxiv.org/abs/2411.19865) |Training LLMs in "reverse thinking" improves performance in commonsense, math, and logical reasoning tasks, reportedly surpassing standard fine-tuning methods trained on ten times more forward reasoning data. |
|[Towards Adaptive Mechanism Activation in Language Agent.](https://arxiv.org/abs/2412.00722) | A new framework enables language agents to automatically determine when to use various mechanisms (ReAct, CoT, Reflection, etc.) for task completion, improving on methods that rely on fixed or predefined strategies. The framework adaptively selects the appropriate mechanism based on the task's characteristics. Experimental results show substantial improvements in downstream tasks, such as mathematical reasoning and knowledge-intensive reasoning.|
|[Auto-RAG: Autonomous Retrieval-Augmented Generation for Large Language Models.](https://arxiv.org/abs/2411.19443) |Auto-RAG is an autonomous iterative retrieval model that achieves outstanding performance across various datasets. It is a fine-tuned LLM that utilizes the decision-making abilities of an LLM to engage in multiturn dialogues with the retriever, systematically planning retrievals and refining queries to gather relevant information. This process continues until adequate external knowledge is obtained. The authors also demonstrate that the model can adjust the number of iterations based on question difficulty without requiring human intervention. |
|[https://www.microsoft.com/en-us/research/uploads/prod/2024/12/HCAI_Agents.pdf.](https://www.microsoft.com/en-us/research/uploads/prod/2024/12/HCAI_Agents.pdf) |This work provides a detailed analysis of the main challenges in human-agent communication, emphasizing how humans and AI agents can build common ground and mutual understanding. It identifies 12 core challenges grouped into three categories: conveying information from agents to users, enabling users to communicate with agents, and overarching communication issues that impact all interactions. |
|[RARE: Retrieval-Augmented Reasoning Enhancement for Large Language Models.](https://arxiv.org/abs/2412.02830) |This work extends the rStar reasoning framework to improve the reasoning accuracy and factual reliability of LLMs. It integrates a Monte Carlo Tree Search (MCTS) framework with retrieval-augmented reasoning to generate multiple candidate reasoning trajectories. A retrieval-augmented factuality scorer then evaluates these trajectories for factual accuracy, selecting the one with the highest score as the final answer. In medical reasoning tasks, RARE (powered by Llama 3.1) outperforms larger models like GPT-4. On commonsense reasoning tasks, it surpasses Claude-3.5 Sonnet and GPT-4o-mini, achieving results comparable to GPT-4o. |
|[DataLab: A Unified Platform for LLM-Powered Business Intelligence.](https://arxiv.org/abs/2412.02205) |A unified business intelligence platform powered by LLM-based agents combines task planning, reasoning, and computational notebooks to optimize the entire BI workflow. The system achieves state-of-the-art performance on research benchmarks and significantly enhances accuracy and efficiency when applied to real enterprise data from Tencent. It delivers up to a 58.58% improvement in accuracy and a 61.65% reduction in token cost for enterprise-specific BI tasks. |
|[Procedural Knowledge in Pretraining Drives Reasoning in Large Language Models.](https://arxiv.org/abs/2411.12580) | This study examines which documents in pretraining data influence model outputs, aiming to better understand the generalization strategies LLMs use for reasoning tasks. It finds that during reasoning, influential documents often contain procedural knowledge, such as examples of solving problems using formulae or code.|
|[Is ImageNet worth 1 video? Learning strong image encoders from 1 long unlabelled video.](https://arxiv.org/abs/2310.08584) | By training an image encoder unsupervised on a single long walking video, this study illustrates how innovative model adjustments can lead to highly powerful representations.|
|[FlashAttention on a Napkin: A Diagrammatic Approach to Deep Learning IO-Awareness.](https://arxiv.org/abs/2412.03317) |FlashAttention is a highly efficient software implementation of attention, designed to be hardware-aware and minimize unnecessary I/O. However, its complexity can make it difficult to grasp. This paper seeks to demystify and simplify the algorithm through diagrams and explanations. |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |

## News
|Link|description|
|---|---|
|[Facebook UK cut 700 staff and reduced tax bill last year, accounts show.](https://www.theguardian.com/business/2024/dec/08/facebook-cuts-uk-staff-reduces-tax-bill-accounts) | 10% of Facebook’s UK workforce was axed while revenue fell slightly but pre-tax profits rose despite advertising slowdown|
|[US appeals court upholds law forcing sale or ban of TikTok.](https://www.theguardian.com/technology/2024/dec/06/tiktok-sale-ban-us) |Decision is latest twist in a years-long battle between the social media company and the US government |
|[Google CEO: AI development is finally slowing down—‘the low-hanging fruit is gone’.](https://www.cnbc.com/2024/12/08/google-ceo-sundar-pichai-ai-development-is-finally-slowing-down.html) | Generative artificial intelligence probably won’t change your life in 2025 — at least, not more than it already has, according to Google CEO Sundar Pichai.|
|[Nobel recipient Geoffrey Hinton wishes he thought of AI safety sooner.](https://www.ctvnews.ca/sci-tech/nobel-recipient-geoffrey-hinton-wishes-he-thought-of-ai-safety-sooner-1.7137867) | Geoffrey Hinton says he doesn’t regret the work he did that laid the foundations of artificial intelligence, but wishes he thought of safety sooner.|
|[Landlords Are Using AI to Raise Rents—and Cities Are Starting to Push Back.](https://gizmodo.com/landlords-are-using-ai-to-raise-rents-and-cities-are-starting-to-push-back-2000535519) |If you’ve hunted for apartments recently and felt like all the rents were equally high, you’re not crazy: Many landlords now use a single company’s software — which uses an algorithm based on proprietary lease information — to help set rent prices. |
|[xAI's Image Generator.](https://kingy.ai/news/grok-2-aurora-a-new-image-generator-for-the-masses/) | xAI's Aurora is an advanced image generation model integrated into Grok 2.|
|[OpenAI's Reinforcement Fine-Tuning Research Program.](https://openai.com/form/rft-research-program/) |We’re expanding our Reinforcement Fine-Tuning Research Program to enable developers and machine learning engineers to create expert models fine-tuned to excel at specific sets of complex, domain-specific tasks. |
|[OpenAI’s 12 days of ‘ship-mas’: all the new announcements.](https://www.theverge.com/24314146/openai-12-days-ship-mas-chatgpt-sora-o1-update) | OpenAI’s 12 days of “ship-mas” have officially begun, with the company set to reveal some new features, products, and demos during all 12 days starting December 5th, just a few days shy of the second anniversary of ChatGPT’s explosive launch in 2022.|
|[AWS brings prompt routing and caching to its Bedrock LLM service.](https://techcrunch.com/2024/12/04/aws-brings-prompt-routing-and-caching-to-its-bedrock-llm-service/) |  At its re:Invent conference in Las Vegas, AWS on Wednesday announced both of these features for its Bedrock LLM hosting service.|
|[OpenAI may launch Sora, its text-to-video model, very soon.](https://www.engadget.com/ai/openai-may-launch-sora-its-text-to-video-model-very-soon-171434280.html) |OpenAI is set to launch new AI features, including a text-to-video tool called Sora and a reasoning model, during a 12-day livestream event. Sora has drawn criticism over data provenance, raising concerns about the possible use of YouTube content without authorization. Meanwhile, Google is working on its own text-to-video tool, Veo, which is currently in private review. |
|[Google’s new generative AI video model is now available.](https://www.theverge.com/2024/12/4/24312938/google-veo-generative-ai-video-model-available-preview) | Google's Veo, a generative AI video model, is now accessible to businesses through Vertex AI, enabling the creation of high-quality 1080p videos from text or images. It incorporates safeguards and DeepMind's SynthID digital watermark to tackle issues related to copyright and misinformation. Additionally, Google has expanded access to Imagen 3 for text-to-image generation on Google Cloud, introducing new features for brand customization.|
|[Elon Musk's xAI to Expand Colossus Supercomputer, Boosting Memphis as Emerging AI Hub.](https://hoodline.com/2024/12/elon-musk-s-xai-to-expand-colossus-supercomputer-boosting-memphis-as-emerging-ai-hub/) |xAI is enhancing its Colossus supercomputer facility in Memphis by adding one million GPUs to boost its AI capabilities. This expansion positions Memphis as a potential global AI innovation hub, drawing interest from major companies like Nvidia and Dell. The Greater Memphis Chamber is backing this growth and has formed a dedicated team to accelerate xAI's expansion. |
|[OpenAI and Anduril Partner on Defense AI Applications.](https://www.maginative.com/article/openai-and-anduril-partner-on-defense-ai-applications/) | OpenAI has collaborated with Anduril Industries to create AI-driven solutions for military use, with an emphasis on counter-drone defense systems.|
|[Meta quietly leans on rival GPT-4 despite Zuckerberg’s bold Llama claims.](https://www.infoworld.com/article/3617048/meta-quietly-leans-on-rival-gpt-4-despite-zuckerbergs-bold-llama-claims.html) |Even as Meta touts its Llama model, the company is incorporating OpenAI’s GPT-4 to enhance internal tools and philanthropic ventures. |
|[Google unveils ‘mindboggling’ quantum computing chip.](https://www.theguardian.com/technology/2024/dec/09/google-unveils-mindboggling-quantum-computing-chip) |Chip takes minutes to complete tasks that would otherwise take 10,000,000,000,000,000,000,000,000 years |
|[WaveForms $40M seed round.](https://www.waveforms.ai/about) |WaveForms is a pioneering audio AI company aiming to crack the Turing test for audio intelligence. Founded by Alexis Conneau, the mind behind ChatGPT's Advanced Voice Mode, WaveForms has secured $40M in seed funding at a $200M valuation. The company's mission is to push the boundaries of audio AI, enabling hyper-realistic voice interactions and redefining the future of auditory machine intelligence. |
|[Sora is here.](https://openai.com/index/sora-is-here/) | OpenAI's video generation model has launched and is available to Pro subscribers.|
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |

## Resources
|Link|description|
|---|---|
|[Align3R: Aligned Monocular Depth Estimation for Dynamic Videos.](https://igl-hkust.github.io/Align3R.github.io/) |A refined alignment technique offering consistent depth estimation in videos, based on Dust3r, and excelling in 3D estimation performance. |
|[ClearVoice.](https://github.com/modelscope/ClearerVoice-Studio/tree/main/clearvoice) | Unified platform for audio separation, speech understanding, and speech enhancement.|
|[DocOwl.](https://github.com/X-PLUG/mPLUG-DocOwl) | OCR-free document understanding with multimodal LLMs. It has strong chart understanding, table extraction, and more.|
|[TRELLIS.](https://github.com/Microsoft/TRELLIS) | Microsoft's 3D image and text generation models are currently the most advanced in the field, excelling in handling 3D occlusions.|
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |

## Perspectives
|Link|description|
|---|---|
|[Publishers are selling papers to train AIs — and making millions of dollars.](https://www.nature.com/articles/d41586-024-04018-5) |Generative-AI models require massive amounts of data — scholarly publishers are licensing their content to train them. |
|[Is doom scrolling really rotting our brains? The evidence is getting harder to ignore.](https://www.theguardian.com/commentisfree/2024/dec/09/brain-rot-word-of-the-year-reality-internet-cognitive-function) | ‘Brain rot’ is the Oxford word of the year – a fitting choice, given the startling impact the internet is having on our grey matter|
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |
|[.]() | |

# ML news: Week 2 - 8 December

## Research
|Link|description|
|---|---|
|[Large language models surpass human experts in predicting neuroscience results.](https://www.nature.com/articles/s41562-024-02046-9) | Researchers have introduced BrainBench, a tool designed to evaluate large language models' (LLMs) ability to predict outcomes in neuroscience experiments. By fine-tuning an LLM on neuroscience literature, they developed BrainGPT, which achieved an 86% accuracy rate in forecasting study results, surpassing human experts who averaged 63%.  Notably, when BrainGPT expressed high confidence in its predictions, its accuracy increased, indicating a strong correlation between confidence levels and correctness.|
|[Foundational Generative Audio Transformer Opus 1.](https://d1qx31qr3h6wln.cloudfront.net/publications/FUGATTO.pdf) | NVIDIA has introduced a generative AI sound model capable of creating and transforming music, voices, and sounds through text and audio inputs. Trained on 2.5 billion parameters, the model can produce unique audio outputs, such as trumpets barking or saxophones meowing.|
|[o1 Replication Journey - Part 2.](https://arxiv.org/abs/2411.16489) | The study demonstrates that combining simple distillation from o1's API with supervised fine-tuning significantly enhances performance on complex mathematical reasoning tasks. A base model fine-tuned on just tens of thousands of o1-distilled long-thought chains outperforms o1-preview on the American Invitational Mathematics Examination (AIME).|
|[Beyond Examples: High-level Automated Reasoning Paradigm in In-Context Learning via MCTS.](https://arxiv.org/abs/2411.18478) |Enhances in-context learning with high-level automated reasoning, achieving state-of-the-art accuracy (79.6%) on the MATH benchmark using Qwen2.5-7B-Instruct, outperforming GPT-4o (76.6%) and Claude 3.5 (71.1%). Instead of relying on manually crafted high-quality demonstrations, it emphasizes abstract thinking patterns. The approach introduces five atomic reasoning actions to form chain-structured patterns and employs Monte Carlo Tree Search to explore reasoning paths and create thought cards that guide inference. |
|[Generative Agent Simulations of 1,000 People.](https://arxiv.org/abs/2411.10109) | Presents a novel agent architecture leveraging LLMs to simulate real individuals' behaviors, achieving 85% accuracy in replicating human responses on the General Social Survey and reducing demographic biases compared to traditional methods.|
|[Measuring Bullshit in the Language Games played by ChatGPT.](https://arxiv.org/abs/2411.15129) | Suggests that LLM-based chatbots engage in the "language game of bullshit." By instructing ChatGPT to produce scientific articles on topics it lacks knowledge or expertise in, the authors created a reference set illustrating how this "bullshit" manifests.|
|[Study: 94% Of AI-Generated College Writing Is Undetected By Teachers.](https://www.forbes.com/sites/dereknewton/2024/11/30/study-94-of-ai-generated-college-writing-is-undetected-by-teachers/) | Increasingly, homework and exam writing are being done by generative AI instead of students, turned in and passed off as authentic work for grades, credit, and degrees. |
|[Mapping the ionosphere with the power of Android.](https://research.google/blog/mapping-the-ionosphere-with-the-power-of-android/) | Google researchers successfully mapped the Ionosphere using GPS fluctuations combined with innovative algorithms. This approach, which is typically costly and time-intensive, offers potential benefits for various climate solutions.|
|[DeMo: Decoupled Momentum Optimization.](https://arxiv.org/abs/2411.19870) |2.5x faster and requiring 100x less communication, this new optimizer, developed by the original Adam author, delivers significant performance gains for language model training, surpassing existing optimization methods. |
|[Diffusion Meets Flow Matching: Two Sides of the Same Coin.](https://diffusionflow.github.io/) |This post explores the literature and demonstrates that, mathematically, flow matching and diffusion models are equivalent. However, flow matching appears to scale more effectively in practice. |
|[Genie 2: A large-scale foundation world model.](https://deepmind.google/discover/blog/genie-2-a-large-scale-foundation-world-model/) |Genie 2 is a large-scale latent diffusion model designed for world generation. It accepts character control as input, operates without a classifier, and produces stunning outputs with consistent control over time. |
|[Virtual lab powered by ‘AI scientists’ super-charges biomedical research.](https://www.nature.com/articles/d41586-024-01684-3) |Could human–AI collaborations be the future of interdisciplinary studies? |

## News
|Link|description|
|---|---|
|[Googling Is for Old People. That’s a Problem for Google.](https://www.wsj.com/tech/googling-is-for-old-people-thats-a-problem-for-google-5188a6ed?st=GrEFVZ&reflink=desktopwebshare_permalink) |And it’s not just demographics that are weighing on the search giant. Its core business is under siege from pressures that threaten to dismantle its ecosystem of search dominance and digital advertising. |
|[TSMC bets big on 2nm by 2025 – but can it deliver?](https://www.theregister.com/2024/11/29/tsmc_2nm_mass_production/) |Ambition meets reality as geopolitical, technical, and logistical challenges loom |
|[The AI Effect: Amazon Sees Nearly 1 Billion Cyber Threats a Day.](https://www.wsj.com/articles/the-ai-effect-amazon-sees-nearly-1-billion-cyber-threats-a-day-15434edd) |The technology has spawned a surge in hacking attempts, says cyber chief CJ Moses, while Amazon is also using it to powerfully amp up its threat-analysis capability |
|[Meet 'Chameleon' – an AI model that can protect you from facial recognition thanks to a sophisticated digital mask.](https://www.livescience.com/technology/artificial-intelligence/meet-chameleon-an-ai-model-that-can-protect-you-from-facial-recognition-thanks-to-a-sophisticated-digital-mask) | A new AI model can mask a personal image without destroying its quality, which will help to protect your privacy.|
|[Elon Musk targets OpenAI’s for-profit transition in a new filing.](https://www.theverge.com/2024/11/30/24309697/elon-musk-openai-lawsuit-for-profit-transition-preliminary-injunction) |Musk’s attorneys say if OpenAI goes for-profit, it could ‘lack sufficient funds’ for damages if Musk wins his lawsuit. |
|[Perplexity mulls getting into hardware.](https://techcrunch.com/2024/11/26/perplexity-mulls-getting-into-hardware/) |Perplexity's CEO aims to create an affordable AI device, priced under $50, for voice-to-voice interactions. This reflects a growing interest among AI startups in developing hardware for novel interaction methods, though past challenges in AI hardware development pose risks. Backed by significant funding, Perplexity seeks to overcome obstacles encountered by others, such as Humane's Ai Pin. |
|[Inflection AI CEO says it’s done trying to make next-generation AI models.](https://techcrunch.com/2024/11/26/inflection-ceo-says-its-done-competing-to-make-next-generation-ai-models/) |Inflection AI has transitioned from creating advanced AI models to offering AI tools tailored for enterprise customers, utilizing existing AI models. To enhance its capabilities, it has acquired three AI startups and is open to licensing models from previous competitors. CEO Sean White emphasizes the company's shift toward practical applications, prioritizing on-premise AI solutions to ensure enterprise data security over frontier model innovation. |
|[PlayAI's $21M Funding and The Release of a New Multi-Turn Speech Model.](https://blog.play.ai/blog/21m-funding) | PlayAI secured $21 million to enhance voice-first AI interfaces and models, launching Play Dialog, an advanced multi-turn speech model.|
|[Anthropic says Claude AI can match your unique writing style.](https://www.theverge.com/2024/11/26/24306575/anthropic-claude-ai-custom-style-presets) | Three style presets are available alongside the ability to create personalized styles for the chatbot to mimic.|
|[Intel CEO Pat Gelsinger retires amid chipmaker’s struggles.](https://www.theguardian.com/technology/2024/dec/02/intel-ceo-pat-gelsinger) | David Zinsner and Michelle Johnson Holthaus named interim co-CEOs of company fighting to keep up with rivals|
|[ChatGPT turns two: how the AI chatbot has changed scientists’ lives.](https://www.nature.com/articles/d41586-024-03940-y) | How many researchers are using the AI tool? Nature gathers data and talks to members of the academic community.|
|[Ads might be coming to ChatGPT — despite Sam Altman not being a fan.](https://techcrunch.com/2024/12/02/ads-might-be-coming-to-chatgpt-despite-sam-altman-not-being-a-fan/) | OpenAI is exploring advertising as a potential business model to fund its expensive AI tool development. While there are no active plans for ads, the option remains under consideration. CEO Sam Altman views ads as a last resort and has expressed unease about merging ads with AI.|
|[OpenAI targets 1bn users in next phase of growth.](https://www.ft.com/content/e91cb018-873c-4388-84c0-46e9f82146b4) |OpenAI plans to attract 1 billion users by introducing new AI agents, enhancing AI infrastructure, and integrating ChatGPT with Apple devices. The company is heavily investing in AI development to stay competitive against rivals like Google and Microsoft, while navigating political challenges to promote US leadership in AI over China's growing influence. |
|[AI company Mistral is latest European startup to eye expansion in Silicon Valley.](https://www.semafor.com/article/11/27/2024/ai-company-mistral-is-latest-european-startup-to-eye-expansion-in-silicon-valley) | Mistral AI, a leading European AI startup known for its open-weight large language models, is expanding into the U.S. by establishing an office in Palo Alto, California. This move aims to attract top AI talent and enhance its U.S. sales operations. One of Mistral's co-founders, Guillaume Lample, is considering relocating from Paris to support this expansion|
|[OpenAI gets new $1.5 billion investment from SoftBank, allowing employees to sell shares in a tender offer.](https://www.cnbc.com/2024/11/26/openai-gets-1point5-billion-investment-from-softbank-in-tender-offer.html) |OpenAI is allowing employees to sell about $1.5 billion worth of shares in a new tender offer to SoftBank, CNBC has learned. SoftBank’s latest investment adds to OpenAI’s recent $6.6 billion funding round at a $157 billion valuation. The deal was spurred by SoftBank billionaire founder and CEO Masayoshi Son, who was persistent in asking for a larger stake in the company, a person familiar with the matter said.|
|[ChatGPT’s refusal to acknowledge ‘David Mayer’ down to glitch, says OpenAI.](https://www.theguardian.com/technology/2024/dec/03/chatgpts-refusal-to-acknowledge-david-mayer-down-to-glitch-says-openai) | Name was mistakenly flagged and prevented from appearing in responses, says chatbot’s developer|
|[Smartphones should carry health warning, Spanish government told.](https://www.theguardian.com/technology/2024/dec/03/smartphones-should-carry-health-warning-spanish-government-told) |Report by committee of experts also calls for doctors to ask about screen time during checkups |
|[Meta says it has taken down about 20 covert influence operations in 2024.](https://www.theguardian.com/technology/2024/dec/03/meta-says-it-has-taken-down-about-20-covert-influence-operations-in-2024) | Firm names Russia as top source of such activity but says it is ‘striking’ how little AI was used to try to trick voters|
|[Why Silicon Valley panicked over Australia’s under-16 social media ban.](https://www.theguardian.com/technology/2024/dec/02/australia-social-media-children-ban) |Australia’s children account for a tiny portion of users but tech companies worry about the law setting a precedent |
|[Chip war ramps up with new US semiconductor restrictions on China.](https://www.theguardian.com/us-news/2024/dec/03/joe-biden-china-microchip-export-restrictions-law-changes) | Biden administration broadens limits on Chinese access to advanced microchip technology, with Donald Trump expected to go even further|
|[Eleven Labs Conversational AI.](https://elevenlabs.io/conversational-ai) | Eleven Labs has introduced a new conversational AI service designed as a comprehensive solution for creating conversational agents. It employs multiple LLMs on the backend and integrates smoothly with a diverse range of specialized voices.|
|[Claude 3.5 Haiku on AWS Trainium2 and model distillation in Amazon Bedrock.](https://www.anthropic.com/news/trainium2-and-distillation) | Claude models are being tailored for AWS's advanced Trainium2 AI chips, allowing for faster and more efficient performance. Claude 3.5 Haiku is now accessible on AWS Trainium2 and supports model distillation in Amazon Bedrock.|
|[AI Music Is More Realistic Than Ever: Meet Suno's New Model.](https://www.rollingstone.com/music/music-features/ai-music-generator-new-model-suno-1235172581/) |Suno has become the fifth most-used generative AI service with its realistic AI music model V4, despite facing a copyright lawsuit. The model improves user experience by focusing on human preferences, offering enhanced sound quality and advanced composition skills. Suno aims to advance AI-human music collaboration while addressing copyright concerns with the recording industry. |
|[Bluesky’s open API means anyone can scrape your data for AI training.](https://techcrunch.com/2024/11/27/blueskys-open-api-means-anyone-can-scrape-your-data-for-ai-training/) |Bluesky might not be training AI systems on user content as other social networks are doing, but there’s little stopping third parties from doing so. |
|[Google launches the London AI Campus.](https://blog.google/around-the-globe/google-europe/united-kingdom/google-launches-ai-campus-london/) | The AI Campus is a pilot program aimed at fostering and diversifying the next generation of local AI talent.|
|[OpenAI 12 days of Shipmas.](https://threadreaderapp.com/thread/1864335461268754712.html) |OpenAI will be having 12 live streams over the next 12 days to ship new product and model features. |
|[Meta's Nuclear Energy Plans.](https://sustainability.atmeta.com/blog/2024/12/03/accelerating-the-next-wave-of-nuclear-to-power-ai-innovation/) |Meta revealed plans to partner with nuclear energy developers through a new request for proposals, aiming to add 1-4 gigawatts of nuclear capacity in the U.S. to bolster its AI innovation and sustainability initiatives. |
|[AWS Reinvent Top Announcements.](https://aws.amazon.com/it/blogs/aws/top-announcements-of-aws-reinvent-2024/) |At AWS re:Invent 2024, AWS announced enhancements to its Bedrock LLM service, including the introduction of prompt routing and caching features. |
|[Certain names make ChatGPT grind to a halt, and we know why.](https://arstechnica.com/information-technology/2024/12/certain-names-make-chatgpt-grind-to-a-halt-and-we-know-why/) |OpenAI's ChatGPT uses hard-coded filters to prevent generating false statements about certain individuals, causing disruptions in conversations when those names are mentioned. This measure, introduced after incidents like defamation lawsuits against OpenAI, restricts outputs related to sensitive names. However, these filters limit ChatGPT's functionality and make it susceptible to adversarial attacks. |
|[World Labs’ AI can generate interactive 3D scenes from a single photo.](https://techcrunch.com/2024/12/02/world-labs-ai-can-generate-interactive-3d-scenes-from-a-single-photo/) |World Labs, the startup founded by AI pioneer Fei-Fei Li, has unveiled its first project: an AI system that can generate video game-like, 3D scenes from a single image. |
|[bias found in AI system used to detect UK benefits fraud.](https://www.theguardian.com/society/2024/dec/06/revealed-bias-found-in-ai-system-used-to-detect-uk-benefits) |Age, disability, marital status and nationality influence decisions to investigate claims, prompting fears of ‘hurt first, fix later’ approach |
|[How AI monitoring is cutting stillbirths and neonatal deaths in a clinic in Malawi.](https://www.theguardian.com/global-development/2024/dec/06/how-ai-monitoring-is-cutting-stillbirths-and-neonatal-deaths-in-a-clinic-in-malawi) |The only hospital in the country using foetal safety software has seen baby fatalities drop by 82% in three years |
|[Windows 11 loses customers amid the world's most popular OS gaining traction.](https://www.tweaktown.com/news/101966/windows-11-loses-customers-amid-the-worlds-most-popular-os-gaining-traction/index.html) | Despite Microsoft's push to move Windows 10 users to Windows 11, Redmond's latest operating system is losing marketshare to its predecessor.|
|[Stop using generative AI as a search engine.](https://www.theverge.com/2024/12/5/24313222/chatgpt-pardon-biden-bush-esquire) |A fake presidential pardon explains why you can’t trust robots with the news. |
|[Soon, the tech behind ChatGPT may help drone operators decide which enemies to kill.](https://arstechnica.com/ai/2024/12/openai-and-anduril-team-up-to-build-ai-powered-drone-defense-systems/) |OpenAI and Palmer Luckey's weapons company sign agreement to explore lethal drone defense for military use. |
|[Google Says AI Weather Model Masters 15-day Forecast.](https://www.barrons.com/news/google-says-ai-weather-model-masters-15-day-forecast-cdc5793d) |A new artificial intelligence-based weather model can deliver 15-day forecasts with unrivaled accuracy and speed, a Google lab said, with potentially life-saving applications as climate change ramps up. |
|[Perplexity Expanding It's Publisher's Program.](https://www.perplexity.ai/hub/blog/perplexity-expands-publisher-program-with-15-new-media-partners) |Perplexity has expanded its Publishers' Program by partnering with over a dozen international news organizations, providing tools, revenue sharing, and support to enhance collaboration with global media. |
|[DeepMind’s Genie 2 can generate interactive worlds that look like video games.](https://techcrunch.com/2024/12/04/deepminds-genie-2-can-generate-interactive-worlds-that-look-like-video-games/) |DeepMind, Google’s AI research org, has unveiled a model that can generate an “endless” variety of playable 3D worlds. Called Genie 2, the model — the successor to DeepMind’s Genie, which was released earlier this year — can generate an interactive, real-time scene from a single image and text description (e.g. “A cute humanoid robot in the woods”). |
|[Key leaders behind Google’s viral NotebookLM are leaving to create their own startup.](https://techcrunch.com/2024/12/04/key-leaders-behind-googles-viral-notebooklm-are-leaving-to-create-their-own-startup/) |Three core members of Google NotebookLM have departed to launch a new stealth AI startup. The venture intends to use cutting-edge AI models to develop consumer-oriented, user-focused AI products. It is still in its early stages, with no defined focus or disclosed funding. |
|[Bezos says he is ‘very optimistic’ about Trump’s plan to roll back regulations.](https://www.theguardian.com/technology/2024/dec/05/jeff-bezos-trump-regulations-tech) | Amazon billionaire known for previously frosty relations with president-elect signals willingness to collaborate|


## Resources
|Link|description|
|---|---|
|[Large Language Model-Brained GUI Agents: A Survey.](https://arxiv.org/abs/2411.18279) | Provides an overview of LLM-powered GUI Agents, covering their techniques and applications.|
|[A Survey on LLM-as-a-Judge.](https://arxiv.org/abs/2411.15594) |Offers an in-depth survey of the LLM-as-a-Judge paradigm, with a detailed exploration of strategies for developing reliable LLM-as-a-Judge systems. |
|[TÜLU 3: Pushing Frontiers in Open Language Model Post-Training.](https://arxiv.org/abs/2411.15124) | Introduces a suite of fully open state-of-the-art post-trained models, along with their accompanying data, code, and training methodologies, providing a detailed guide to contemporary post-training techniques.|
|[INTELLECT-1 Release: The First Globally Trained 10B Parameter Model.](https://www.primeintellect.ai/blog/intellect-1-release) | INTELLECT-1 is a 10B parameter model trained on 1 trillion tokens using globally distributed hardware. Its benchmarks are solid, and achieving an MFU of over 30% is remarkable considering the distributed training setup. If these results are validated, it represents a significant advancement in decentralized large model training.|
|[From Open Vocabulary to Open World: Teaching Vision Language Models to Detect Novel Objects.](https://arxiv.org/abs/2411.18207v1) |This framework advances object detection into open-world settings by enabling AI to recognize and learn from previously unseen objects. |
|[HUPE: Heuristic Underwater Perceptual Enhancement with Semantic Collaborative Learning.](https://arxiv.org/abs/2411.18296v1) |HUPE is an AI-driven technique that enhances underwater image clarity while maintaining essential details for tasks such as object detection. |
|[LTNtorch: PyTorch Implementation of Logic Tensor Networks.](https://arxiv.org/abs/2409.16045v1) | Logic Tensor Networks (LTN) combine deep learning with logical reasoning, enabling neural models to learn by optimizing a knowledge base constructed from logical formulas.|
|[Programming Every Example: Lifting Pre-training Data Quality Like Experts at Scale.](https://gair-nlp.github.io/ProX/homepage.html) |ProX is a framework that approaches data refinement as a programming task, enabling models to perform detailed operations on individual examples at scale. It enhances pre-training corpus quality by utilizing small language models to generate programs. |
|[MMDuet.](https://huggingface.co/wangyueqian/MMDuet) |MMDuet introduces a unique "video-text duet" interaction format for VideoLLMs, enabling AI to deliver real-time responses as videos play. This method simulates a dialogue where users and AI can exchange messages during video playback. |
|[Converting GPT to Llama.](https://github.com/rasbt/LLMs-from-scratch/tree/main/ch05/07_gpt_to_llama) | This repository contains code for converting a GPT implementation to Meta AI's Llama.|
|[DeMo training run.](https://distro.nousresearch.com/) | Nous is training a 15B distributed model using the DeMo optimizer. All of the training can be followed live at this link.|
|[Fine-Tune Models with LoRA-SB.](https://github.com/raghavsinghal10/lora-sb) |LoRA-SB is a new method that brings full fine-tuning performance to low-rank adapters for large language models. |
|[Making AI Datasets More Diverse.](https://github.com/vila-lab/delt) |Researchers proposed a new approach, Diversity-driven EarlyLate Training (DELT), to enhance dataset distillation for large-scale tasks. |
|[Google’s plan to keep AI out of search trial remedies isn’t going very well.](https://arstechnica.com/tech-policy/2024/11/google-drags-ai-rivals-into-search-trial-as-judge-entertains-ai-remedies/) | US District Judge Amit Mehta indicates that AI could be pivotal in shaping remedies after the government's win in the Google search monopoly trial, potentially impacting Google's AI products. The DOJ has proposed measures to prevent Google from leveraging AI to maintain market dominance, including limits on exclusive agreements and AI investments. Microsoft opposes Google's requests for confidential AI deal details, citing irrelevance, while OpenAI may face pressure to disclose data in this context.|
|[Using uv with PyTorch.](https://docs.astral.sh/uv/guides/integration/pytorch/) |Documentation on how to use the new package manager UV to install PyTorch. |
|[Amazon Launches Nova.](https://aws.amazon.com/it/blogs/aws/introducing-amazon-nova-frontier-intelligence-and-industry-leading-price-performance/) | Amazon Nova unveils a series of multimodal models tailored for tasks such as document analysis, visual comprehension, and creative content generation. Prioritizing customization and efficiency, Nova models address various enterprise needs and excel in handling text, image, and video inputs.|
|[Restructuring Vector Quantization with the Rotation Trick.](https://arxiv.org/abs/2410.06424) |Vector Quantization uses the Straight Through Gradient estimator for gradient estimation, though its direction can occasionally be inaccurate. This paper proposes using rotation to correct the gradients and enhance codebook utilization. |
|[Layout Generation with Diffusion GANs.](https://arxiv.org/abs/2412.00381v1) | DogLayout is a hybrid model integrating GANs with diffusion processes to address challenges in layout generation.|
|[Hunyuan Video Model.](https://github.com/Tencent/HunyuanVideo) |Tencent's state-of-the-art open video model stands out for its realistic motion and dual training as both a video and image generation model. This dual approach enhances the aesthetic quality of its output, making it comparable to image generation models like Flux. |
|[Scene Text Recognition.](https://github.com/YesianRohn/TextSSR) |TextSSR is a framework leveraging diffusion-based techniques to produce precise and realistic synthetic text images for scene text recognition. |
|[T2Vid: Efficient Video Fine-tuning Scheme for MLLMs.](https://github.com/xjtupanda/t2vid) |T2Vid is a novel approach aimed at enhancing video comprehension in Multimodal Large Language Models (MLLMs). It creates video-like samples to diversify training instructions. |
|[aisuite.](https://github.com/andrewyng/aisuite) | aisuite offers a unified interface for seamless interaction with multiple LLM providers, enabling developers to test and compare outputs without modifying their code.|
|[Motion Prompting: Controlling Video Generation with Motion Trajectories.](https://motion-prompting.github.io/) |Motion Prompting is a technique for training video generation models using novel input types, including text, the first image frame, and a pixel tracking field. This enables innovative control during inference, allowing for new pixel fields (e.g., indicating an object moving in a different direction) to generate corresponding videos. While highly compelling, the method is not open source. |
|[Remote Sensing Temporal Vision-Language Models: A Comprehensive Survey.](https://github.com/chen-yang-liu/awesome-rs-temporal-vlm) |This repository provides an extensive survey on the use of Vision-Language Models (VLMs) in remote sensing. |
|[ImplicitPRM.](https://github.com/lifan-yuan/ImplicitPRM) |Process reward models (PRMs) provide detailed feedback by assessing reasoning step-by-step, unlike outcome reward models (ORMs), which evaluate complete responses. However, training PRMs demands detailed intermediate annotations, making it challenging. This paper demonstrates that an implicit PRM can be obtained at no extra cost by training an ORM on response-level labels, utilizing log-likelihood ratios between policy and reference models, thereby enabling optimization without specific loss objectives. |
|[Unsloth - Dynamic 4-bit Quantization.](https://unsloth.ai/blog/dynamic-4bit) | The Unsloth team seeks to compress a 20GB language model into 5GB while maintaining accuracy. Although various algorithms attempt this, challenges arise with outliers and compressibility. Llama, known for its difficulty in quantization, is addressed by selectively avoiding the quantization of specific parameters, significantly enhancing overall accuracy.|
|[AccDiffusion v2: Tackling Repetitive Image Generation.](https://github.com/lzhxmu/accdiffusion_v2) |AccDiffusion v2 enhances diffusion models for generating high-resolution images without requiring additional training, resolving issues such as object repetition and local distortions. |
|[Optimizing AI Inference at Character.AI.](https://research.character.ai/optimizing-ai-inference-at-character-ai-part-deux/) | Character AI features a robust inference pipeline. This post explores their implementation of int8 quantization and flash attention 3, offering valuable insights for those interested in scaling large language models.|
|[Flow.](https://github.com/lmnr-ai/flow) |Flow is a lightweight engine for creating flexible AI workflows using dynamic task scheduling and concurrent execution. |
|[OpenAI o1 System Card.](https://openai.com/index/openai-o1-system-card/) | This report details the safety measures undertaken before releasing OpenAI o1 and o1-mini, including external red teaming and frontier risk assessments aligned with OpenAI's Preparedness Framework.|
|[PaliGemma 2: A Family of Versatile VLMs for Transfer.](https://arxiv.org/abs/2412.03555) |Paligemma 2 is among the top Vision-Language Models (VLMs) available today, utilizing SigLIP and Gemma technologies. |
|[ASANet: Asymmetric Semantic Aligning Network for RGB and SAR image land cover classification.](https://arxiv.org/abs/2412.02044v1) |The Asymmetric Semantic Aligning Network (ASANet) improves land cover classification using both SAR and RGB images. |
|[AIM: Adaptive Inference of Multi-Modal LLMs via Token Merging and Pruning.](https://arxiv.org/abs/2412.03248v1) | Researchers have created a training-free method to enhance the efficiency of multi-modal language models (LLMs) with minimal performance loss. Their technique reduces computational demands by up to sevenfold through strategic merging and pruning of visual data tokens.|
|[Google DeepMind GraphCast and GenCast.](https://github.com/google-deepmind/graphcast) |DeepMind has open-sourced its GraphCast algorithm, which significantly outperforms and accelerates localized weather predictions for up to 36 hours, operating in a fraction of the time required by other methods. |
|[Anagram-MTL.](https://github.com/pixtella/anagram-mtl) | visual anagram generation - images that change appearance when flipped or rotated -using diffusion models|
|[ScoreLiDAR.](https://github.com/happyw1nd/scorelidar) |ScoreLiDAR is a new method that speeds up 3D LiDAR scene completion for autonomous vehicles. |
|[New Fish Audio Model.](https://threadreaderapp.com/thread/1864370933496205728.html) | Fish Audio 1.5 is currently ranked #2 on the Text-to-Speech Leaderboards, just behind ElevenLabs. It supports voice cloning and runs quickly, though the output quality can be inconsistent.|
|[Deepthought-8B.](https://huggingface.co/ruliad/deepthought-8b-llama-v0.01-alpha) |Deepthought-8B is a small and capable reasoning model built on LLaMA-3.1 8B, designed to make AI reasoning more transparent and controllable. Despite its relatively small size, it achieves sophisticated reasoning capabilities that rival much larger models. |
|[LLM-Brained GUI Agents.](https://vyokky.github.io/LLM-Brained-GUI-Agents-Survey/) |A Collection of Research Papers and Projects in: Large Language Model-Brained GUI Agents: A Survey. |

## Perspectives
|Link|description|
|---|---|
|[AI expert Marietje Schaake: ‘The way we think about technology is shaped by the tech companies themselves’.](https://www.theguardian.com/technology/2024/nov/30/marietje-schaake-tech-coup-save-democracy-silicon-valley) | The Dutch policy director and former MEP on the unprecedented reach of big tech, the need for confident governments, and why the election of Trump changes everything|
|[If AI can provide a better diagnosis than a doctor, what’s the prognosis for medics?](https://www.theguardian.com/commentisfree/2024/nov/30/if-ai-can-provide-a-better-diagnosis-than-a-doctor-whats-the-prognosis-for-medics) | Studies in which ChatGPT outperformed scientists and GPs raise troubling questions for the future of professional work|
|[Building LLMs is probably not going be a brilliant business.](https://calpaterson.com/porter.html) | LLM developers, including OpenAI, face major hurdles due to the industry's structure, particularly NVIDIA's dominance as a critical chip supplier and the intense price sensitivity and competition among buyers. While many AI companies secure significant funding, they often face profitability challenges, reminiscent of past tech firms like Netscape. Nonetheless, the technology is likely to continue progressing. AI businesses may find success by focusing on leveraging existing models instead of creating new ones.|
|[Rox: How to Manufacture Path Dependence in Applied AI.](https://www.notboring.co/p/rox) |like Salesforce by leveraging AI to manage unstructured data and integrate seamlessly with data warehouses. Its strategy focuses on enhancing the productivity of top sales performers through AI-powered agents, while ensuring customer data security for future AI developments. This approach has attracted significant investor confidence, with Rox securing $50 million in funding from Sequoia Capital, GV, and General Catalyst across its seed and Series A rounds.  |
|[How close is AI to human-level intelligence?](https://www.nature.com/articles/d41586-024-03905-1) |Large language models such as OpenAI’s o1 have electrified the debate over achieving artificial general intelligence, or AGI. But they are unlikely to reach this milestone on their own. |
|[The race is on to make AI agents do your online shopping for you.](https://techcrunch.com/2024/12/02/the-race-is-on-to-make-ai-agents-do-your-online-shopping-for-you/) |Tech companies are creating AI shopping agents to automate online purchases, which could transform the retail industry. Perplexity's model faces operational hurdles, while OpenAI, Google, and Amazon are also working on AI purchasing tools. These advancements aim to simplify shopping but raise concerns about privacy, retailer dynamics, and the future of online shopping. |
|[Salesforce CEO Marc Benioff Has Thoughts on AI Agents, Automation, And The Future of Your Job.](https://www.bigtechnology.com/p/salesforce-ceo-marc-benioff-has-thoughts) |Salesforce CEO Marc Benioff foresees companies using AI agents to manage customer service and sales by utilizing their existing data and policies, with Salesforce serving as a central enabler of this change. He contends that AI-driven automation will boost productivity rather than replace jobs, enabling businesses to grow and operate more efficiently without adding human labor. Benioff emphasizes this transition as a pivotal moment in business evolution, offering a competitive advantage and transforming traditional workflows. |
|[Reward Hacking in Reinforcement Learning.](https://lilianweng.github.io/posts/2024-11-28-reward-hacking/) | Lilian Weng has published an insightful blog post on the issue of Reward Hacking in language model alignment, a key challenge hindering the deployment of models in production environments.|
|[Create JSONL dataset from API chat logs.](https://github.com/cognitivecomputations/chat-logger) |A straightforward utility that enables the creation of a JSONL dataset from messages exchanged between the user and the API. |
|[The ChatGPT secret: is that text message from your friend, your lover – or a robot?](https://www.theguardian.com/technology/2024/dec/03/the-chatgpt-secret-is-that-text-message-from-your-friend-your-lover-or-a-robot) | People are turning to chatbots to solve all their life problems, and they like its answers. But are they on a very slippery slope?|
|[A System of Agents brings Service-as-Software to life.](https://foundationcapital.com/system-of-agents/) |AI is evolving software from a tool into autonomous agents capable of performing tasks traditionally handled by humans, representing a projected $4.6 trillion market opportunity. Advancements like LLMs and agents empower AI systems to handle unstructured data, make decisions, and operate independently in sectors such as sales and healthcare. The future of AI envisions Systems of Agents working collaboratively and learning from one another, akin to a highly skilled team delivering seamless services. |
|[Over ½ of Long Posts on LinkedIn are Likely AI-Generated Since ChatGPT Launched.](https://originality.ai/blog/ai-content-published-linkedin) | Since the launch of ChatGPT, LinkedIn has experienced a 189% increase in AI-generated content, with more than half of long-form posts now probably AI-created.|
|[AI’s computing gap: academics lack access to powerful chips needed for research.](https://www.nature.com/articles/d41586-024-03792-6) | Survey highlights disparity between academic and industry scientists’ access to computing power needed to train machine-learning models.|
|['Brutal’ math test stumps AI but not human experts.](https://www.science.org/content/article/brutal-math-test-stumps-ai-not-human-experts) |Benchmark shows humans can still top machines—but for how much longer? |
|[Finetuning LLM Judges for Evaluation.](https://cameronrwolfe.substack.com/p/finetuned-judge) |Evaluating LLMs is challenging due to their complex, open-ended outputs. While traditional human evaluation provides detailed insights, it is inefficient. Therefore, scalable assessments using automatic metrics and model-based approaches like LLM-as-a-Judge are essential. Innovations such as fine-tuned judges (e.g., Prometheus) and synthetic data generation are improving evaluation precision and adaptability across various tasks and domains. |
|[The Gen AI Bridge to the Future.](https://stratechery.com/2024/the-gen-ai-bridge-to-the-future/) |Generative AI is set to revolutionize wearable technology by creating on-demand UI interfaces that adapt to user needs and context. |
|[Sam Altman Says Artificial General Intelligence Is on the Horizon.](https://www.nytimes.com/video/business/100000009858580/sam-altman-openai-dealbook.html) |Speaking at The New York Times DealBook Summit, Sam Altman, the chief executive of OpenAI, said that the arrival of artificial general intelligence would “matter much less” to the average person than currently thought. |

# ML news: Week 25 November - 1 December

## Research
|Link|description|
|---|---|
|[Learning high-accuracy error decoding for quantum processors.](https://www.nature.com/articles/s41586-024-08148-8) | A new AI-driven decoder has established a state-of-the-art benchmark for detecting errors in quantum computers. Leveraging transformer architecture, AlphaQubit achieved a 6% reduction in errors compared to tensor network methods and a 30% reduction compared to correlated matching on the Sycamore data. It also demonstrated promising performance in simulations with larger systems of up to 241 qubits. While this marks substantial progress in quantum error correction, the system requires speed enhancements to enable real-time error correction for practical quantum computing applications.|
|[The Dawn of GUI Agent: A Preliminary Case Study with Claude 3.5 Computer Use.](https://arxiv.org/abs/2411.10323) |This work examines Claude 3.5's computer use capabilities across various domains and software, offering a ready-to-use agent framework for deploying API-based GUI automation models. Claude 3.5 showcases an exceptional ability to perform end-to-end tasks, translating language inputs into desktop actions seamlessly. |
|[Adding Error Bars to Evals: A Statistical Approach to Language Model Evaluations.](https://arxiv.org/abs/2411.00640) | The paper proposes five statistical recommendations for improving the evaluation of performance differences in LLMs. These include using the Central Limit Theorem to estimate theoretical averages over all possible questions rather than relying on observed averages, clustering standard errors when questions are related instead of treating them as independent, reducing variance within questions through resampling or next-token probabilities, analyzing paired differences between models by leveraging shared questions across evaluations, and conducting power analysis to determine sufficient sample sizes for identifying meaningful differences. The authors suggest that these approaches will help researchers better identify whether performance differences reflect genuine capability gaps or are merely due to chance, resulting in more accurate and reliable model evaluations.|
|[Marco-o1: Towards Open Reasoning Models for Open-Ended Solutions.](https://arxiv.org/abs/2411.14405) | Marco-o1 is a reasoning model designed for open-ended solutions, leveraging Chain-of-Thought (CoT) fine-tuning, Monte Carlo Tree Search (MCTS), reflection mechanisms, and advanced reasoning strategies. It achieves accuracy gains of +6.17% on the MGSM (English) dataset and +5.60% on the MGSM (Chinese) dataset.|
|[Cut Your Losses in Large-Vocabulary Language Models.](https://arxiv.org/abs/2411.09009) | The paper introduces Cut Cross-Entropy (CCE), a method designed to drastically reduce memory usage in LLM training by optimizing the computation of cross-entropy loss. Traditional cross-entropy layers can consume up to 90% of memory in some models by storing logits for the entire vocabulary. CCE addresses this by calculating logits only for the correct token and dynamically evaluating the log-sum-exp over all logits using flash memory. This approach reduces the memory footprint of Gemma 2 from 24GB to just 1MB. By leveraging the sparsity in softmax calculations, it skips elements that have minimal impact on gradients. The authors demonstrate that CCE achieves this substantial memory reduction without affecting training speed or convergence, allowing for larger batch sizes and potentially more efficient scaling of LLM training.|
|[AIGS: Generating Science from AI-Powered Automated Falsification.](https://arxiv.org/abs/2411.11910v1) | The study presents a multi-agent system for automated scientific discovery, focusing on falsification through automated ablation studies. Tested on three machine learning tasks—data engineering, self-instruct alignment, and language modeling—the system successfully generated meaningful scientific insights. However, its performance remains inferior to that of experienced human researchers.|
|[Does Prompt Formatting Have Any Impact on LLM Performance?](https://arxiv.org/abs/2411.10541) |The study investigates how different prompt formats (plain text, Markdown, JSON, and YAML) influence GPT model performance across various tasks. It finds that GPT-3.5-turbo's performance can vary by up to 40% depending on the format, whereas larger models like GPT-4 are more resilient to such changes. There is no universally optimal format across models or tasks; for example, GPT-3.5-turbo performed better with JSON, while GPT-4 favored Markdown. Models within the same family exhibited similar format preferences, but these preferences did not translate well to different model families. The findings highlight the significant impact of prompt formatting on model performance, emphasizing the importance of considering format choice during prompt engineering, model evaluation, and application development. |
|[Juna.ai wants to use AI agents to make factories more energy-efficient.](https://techcrunch.com/2024/11/18/juna-ai-wants-to-use-ai-agents-to-make-factories-more-energy-efficient/) | AI agents are all the rage, a trend driven by the generative AI and large language model (LLM) boom these past few years. Getting people to agree on what exactly AI agents are is a challenge, but most contend they are software programs that can be assigned tasks and given decisions to make — with varying degrees of autonomy.|
|[Why ‘open’ AI systems are actually closed, and why this matters.](https://www.nature.com/articles/s41586-024-08141-1) | This paper examines ‘open’ artificial intelligence (AI). Claims about ‘open’ AI often lack precision|
|[Qwen's first reasoning inspired model QwQ.](https://qwenlm.github.io/blog/qwq-32b-preview/) | Qwen has introduced a 32B parameter reasoning model that rivals OpenAI's o1 series in performance. The model demonstrates scalability when generating extended reasoning traces and is particularly proficient in mathematics and coding. It is now available for use.|
|[Pathways on the Image Manifold: Image Editing via Video Generation.](https://arxiv.org/abs/2411.16819) | In the early days of image synthesis, exploring the latent space was an effective method for creating diverse images. This concept has now extended to video, enabling sequential edits to a single image while preserving semantic consistency.|
|[Low-Bit Quantization Favors Undertrained LLMs.](https://arxiv.org/abs/2411.17691) | Models trained for shorter durations on fewer tokens show less performance degradation when quantized after training. This aligns with findings from other research, suggesting that extended training allows models to utilize higher precision to compress increasingly complex information.|


## News
|Link|description|
|---|---|
|[Don’t know what to buy your loved ones for Christmas? Just ask ChatGPT.](https://www.theguardian.com/technology/2024/nov/24/dont-know-what-to-buy-your-loved-ones-for-christmas-just-ask-chatgpt) |Santa has a new little helper. But can an AI-powered shopping assistant really master the subtle art of gift giving? |
|[Anthropic x AWS trainium collaboration.](https://www.anthropic.com/news/anthropic-amazon-trainium) |Anthropic is collaborating with AWS to enhance trainium inference and tooling capabilities as part of a recent investment initiative.|
|[Will Sam Altman always win the OpenAI board fight in an AI agent simulation?](https://venturebeat.com/games/can-sam-altman-win-the-openai-board-fight-in-an-ai-agent-simulation/) | Fable, a company specializing in games and AI simulations, used its AI decision-making framework SIM-1 to simulate the OpenAI board dispute involving Sam Altman. The simulation, which incorporated multi-agent competition and GPT-4o, suggested Altman’s return as CEO in only 4 out of 20 scenarios. This research highlights AI's ability to model complex decision-making scenarios.|
|[Anthropic Announces Model Context Protocol.](https://www.anthropic.com/news/model-context-protocol) |The Model Context Protocol (MCP) is an open standard that enables AI systems to connect directly to data sources, such as business tools and content repositories. It streamlines data access by replacing fragmented, custom integrations with a universal protocol, enhancing scalability and efficiency. |
|[OpenAI Shares Insights on Red Teaming for Safer AI.](https://openai.com/index/advancing-red-teaming-with-people-and-ai/) | OpenAI has enhanced its red teaming initiatives by publishing two papers: one outlining the involvement of external experts in red teaming, and another presenting a novel approach to automated testing.|
|[Nvidia’s CEO defends his moat as AI labs change how they improve their AI models.](https://techcrunch.com/2024/11/20/nvidias-ceo-defends-his-moat-as-ai-labs-change-how-they-improve-their-ai-models/) | "Test-time scaling" is gaining significance with the advancement of AI models, and Nvidia is prepared for this transition. This approach, which boosts AI inference by increasing computational power, introduces competitive pressure as startups create faster AI inference chips. While there are concerns about diminishing returns, Nvidia is determined to capitalize on its strong platform advantage for pretraining and expects substantial growth in AI inference.|
|[Anthropic Introduces Custom Styles for Personalized Responses.](https://www.anthropic.com/news/styles) |Anthropic now offers custom styles, enabling users to adapt the AI's responses to suit their communication preferences and workflows. |
|[OpenAI’s Sora video generator appears to have leaked.](https://techcrunch.com/2024/11/26/artists-appears-to-have-leaked-access-to-openais-sora/) |A group leaked access to OpenAI's unreleased video generator, Sora, in protest against perceived unfair practices and "art washing." They launched a frontend on Hugging Face that enabled users to generate videos, but OpenAI reportedly took it down within hours. OpenAI states that Sora remains in a research preview phase. |
|[Now Hear This: World’s Most Flexible Sound Machine Debuts.](https://blogs.nvidia.com/blog/fugatto-gen-ai-sound-model/) |A team of generative AI researchers created a Swiss Army knife for sound, one that allows users to control the audio output simply using text. While some AI models can compose a song or modify a voice, none have the dexterity of the new offering. |
|[OLMo 2: The best fully open language model to date.](https://allenai.org/blog/olmo2) | Building on its commitment to fully open-source training, Allen AI has introduced a new generation of language models that are entirely transparent and rival or exceed the performance of the best open-weight models available.|
|[Amazon to invest another $4 billion in Anthropic, OpenAI’s biggest rival.](https://www.cnbc.com/2024/11/22/amazon-to-invest-another-4-billion-in-anthropic-openais-biggest-rival.html) |Amazon revealed a $4 billion investment in Anthropic, raising its total commitment to $8 billion and solidifying AWS as Anthropic's main cloud and training partner. |
|[OpenAI is funding research into ‘AI morality’.](https://techcrunch.com/2024/11/22/openai-is-funding-research-into-ai-morality/) | OpenAI is funding academic research into algorithms that can predict humans’ moral judgements.|
|[Quantum computing: physics–AI collaboration quashes quantum errors.](https://www.nature.com/articles/d41586-024-03557-1) |A neural network has learnt to correct the errors that arise during quantum computation, outperforming algorithms that were designed by humans. The strategy sets out a promising path towards practical quantum computers. |
|[OpenAI moves to trademark its o1 ‘reasoning’ models.](https://techcrunch.com/2024/11/27/openai-moves-to-trademark-its-reasoning-models/) | OpenAI has filed a trademark application for its latest AI model, o1, as the firm moves to shield its IP.|
|[ElevenLabs’ new feature is a NotebookLM competitor for creating GenAI podcasts.](https://techcrunch.com/2024/11/27/elevenlabs-new-feature-is-a-notebooklm-competitor-for-creating-genai-podcasts/) | Voice AI startup ElevenLabs on Wednesday introduced a feature that lets you upload different types of content to create a multispeaker podcast for you, similar to Google’s NotebookLM.|
|[Cradle raises $73M Series B to Put AI-Powered Protein Engineering in Every Lab.](https://www.cradle.bio/blog/series-b) |Cradle has solved a critical challenge in optimizing protein shapes. It is now expanding its team and efforts to land this technology in the hands of practitioners everywhere. |
|[Teach mode, Rabbit's tool for automating R1 tasks, is now available to all users.](https://www.engadget.com/ai/teach-mode-rabbits-tool-for-automating-r1-tasks-is-now-available-to-all-users-170036677.html) |Rabbit R1 has launched a teach mode feature that enables users to train its AI to automate tasks across various websites. This enhancement aims to boost functionality and productivity by supporting intricate multi-platform interactions, potentially providing a superior experience compared to dedicated apps. Rabbit plans to establish a marketplace for user-created automations and seeks widespread adoption, despite possible platform challenges. |
|[Use robots instead of hiring low-paid migrants, says shadow home secretary.](https://www.theguardian.com/uk-news/2024/nov/28/use-robots-instead-of-hiring-low-paid-migrants-says-shadow-home-secretary) |Tory MP Chris Philp calls for more investment in technology to reduce UK’s net migration figures |
|[Tesla owners turn against Musk: ‘I’m embarrassed driving this car around’.](https://www.theguardian.com/technology/2024/nov/29/tesla-owners-elon-musk) | The electric car brand was once a liberal favourite – but the CEO’s embrace of Trump has led to an angry backlash|
|[Alibaba releases an ‘open’ challenger to OpenAI’s o1 reasoning model.](https://oodaloop.com/briefs/technology/alibaba-releases-an-open-challenger-to-openais-o1-reasoning-model/) | Alibaba has released QwQ-32B-Preview, an ‘open' challenger to OpenAI's o1 reasoning model.|
|[Ai2 releases new language models competitive with Meta’s Llama.](https://techcrunch.com/2024/11/26/ai2-releases-new-language-models-competitive-with-metas-llama/) |Ai2 has launched OLMo 2, an open-source language model series featuring 7- and 13-billion-parameter models. Built using publicly available training data and code, OLMo 2 aims to advance open-source AI innovation. Ai2 asserts that these models surpass comparable open models, such as Meta's Llama 3.1. The models are licensed under Apache 2.0, allowing for commercial use. |
|[xAI could soon have its own app.](https://www.theverge.com/2024/11/27/24307571/xai-consumer-app-planned-report) |Elon Musk’s xAI is reportedly about to take its next step to compete with OpenAI. |


## Resources
|Link|description|
|---|---|
|[An Empirical Study on LLM-based Agents for Automated Bug Fixing.](https://arxiv.org/abs/2411.10213) |The study evaluates seven top LLM-based bug fixing systems on the SWE-bench Lite benchmark, identifying MarsCode Agent by ByteDance as the best performer with a 39.33% success rate. It highlights that line-level fault localization accuracy is more crucial than file-level accuracy for error localization, and bug reproduction capabilities play a significant role in fixing success. Notably, 24 out of 168 resolved issues required reproduction techniques, though these sometimes misled LLMs when issue descriptions were already clear. The study concludes that improving LLM reasoning abilities and refining agent workflows are essential for advancing automated bug fixing. |
|[FinRobot: AI Agent for Equity Research and Valuation with Large Language Models.](https://arxiv.org/abs/2411.08804) |The framework introduces an AI agent system for equity research that utilizes multi-agent Chain-of-Thought (CoT) prompting to integrate data analysis with human-like reasoning, producing professional investment reports comparable to those from major brokerages. It employs three specialized agents: the Data-CoT Agent, which aggregates diverse data sources for comprehensive financial integration; the Concept-CoT Agent, which mimics an analyst's reasoning to derive actionable insights; and the Thesis-CoT Agent, which synthesizes these insights into a cohesive investment thesis and report. |
|[Bi-Mamba: Towards Accurate 1-Bit State Space Models.](https://arxiv.org/abs/2411.11843) | The scalable 1-bit Mamba architecture is designed to optimize LLM efficiency across multiple model sizes (780M, 1.3B, and 2.7B). Bi-Mamba delivers performance comparable to full-precision formats like FP16 and BF16, while drastically reducing memory usage. It also achieves higher accuracy than post-training binarization Mamba baselines.|
|[Ai2 OpenScholar: Scientific literature synthesis with retrieval-augmented language models.](https://allenai.org/blog/openscholar) | Ai2 has introduced OpenScholar, a retrieval-augmented language model designed to search for relevant academic papers and provide answers based on those sources, streamlining the process for scientists to locate and synthesize information.|
|[Detecting Human Artifacts from Text-to-Image Models.](https://arxiv.org/abs/2411.13842v1) | This study addresses the issue of distorted human figures in text-to-image models by presenting the Human Artifact Dataset (HAD), a comprehensive dataset containing more than 37,000 annotated images.|
|[UnifiedCrawl: Aggregated Common Crawl for Affordable Adaptation of LLMs on Low-Resource Languages.](https://arxiv.org/abs/2411.14343v1) | UnifiedCrawl is a method that efficiently gathers extensive text data for low-resource languages from the Common Crawl corpus, utilizing minimal computational resources. This approach filters and extracts relevant data, resulting in monolingual datasets significantly larger than previously available sources.|
|[A New Image-to-Video Model.](https://arxiv.org/abs/2411.13975v1) |Researchers have created image-to-video diffusion models capable of generating realistic motion transformations from static images, overcoming the constraints of traditional approaches such as affine transformations. |
|[AIMv2: New Vision Models.](https://github.com/apple/ml-aim) | The AIMv2 vision model family employs a multimodal autoregressive training approach, delivering remarkable performance across various tasks.|
|[A New Attention Mechanism for Training LLMs.](https://github.com/haonan3/anchorcontext) |AnchorAttention: Improved attention for LLMs long-context training |
|[Combining Convolutions and Self-Attentions for Efficient Vision Models.](https://github.com/rayleizhu/glmix) |GLMix is a novel approach that combines convolutions and multi-head self-attentions (MHSAs) at varying granularity levels for vision tasks. Convolutions capture fine-grained local details, while MHSAs focus on coarse-grained semantic slots to provide global context. |
|[Echo Mimic v2.](https://antgroup.github.io/ai/echomimic_v2) |Open weights system to animate partial human bodies with a reference image and audio input. It uses pose specific VAEs to combine the information from various channels and a reference image to animate.|
|[LTX-Video.](https://github.com/Lightricks/LTX-Video) |LTX-Video is the first DiT-based video generation model that can generate high-quality videos in real-time. It can generate 24 FPS videos at 768x512 resolution, faster than it takes to watch them. The model is trained on a large-scale dataset of diverse videos and can generate high-resolution videos with realistic and diverse content. |
|[Documind.](https://github.com/DocumindHQ/documind) | Documind utilizes AI to extract structured data from PDFs by converting them into images and leveraging OpenAI's API.|
|[Coalescence: making LLM inference 5x faster.](https://blog.dottxt.co/coalescence.html) | "Coalescence" is a framework that accelerates LLM inference by up to 5x when producing structured outputs like JSON. It achieves this by transforming structured formats into finite state machines and eliminating redundant paths that result in the same output, reducing the need for unnecessary LLM calls. Although this approach greatly enhances speed, it is crucial to preserve output quality by ensuring that optimization does not exclude more likely sequences.|
|[WildLMa: Long Horizon Loco-Manipulation in the Wild.](https://arxiv.org/abs/2411.15131) | WildLMa is a framework designed to enable quadruped robots to perform advanced manipulation tasks in real-world settings. It integrates three core components: a whole-body controller for teleoperation via VR, a skill library learned through imitation learning (WildLMa-Skill), and a language model-based planner (WildLMa-Planner) that organizes these skills for long-term tasks. The researchers showcase its application in tasks such as cleaning trash from hallways and rearranging bookshelf items. The framework proves effective across various environments and object setups.|
|[MMGenBench: Evaluating the Limits of LMMs from the Text-to-Image Generation Perspective.](https://mmgenbench.alsoai.com/) | MMGenBench is a novel evaluation framework for large multimodal models, emphasizing their capacity to generate and interpret images. In this process, models produce descriptions from input images, which are subsequently used to generate new images for comparison.|
|[Moondream Python Client Library.](https://github.com/vikhyat/moondream/tree/main/clients/python) | Moondream's Python client library provides tools for image analysis and querying, featuring CPU-optimized inference. However, it is not yet suitable for GPU or Mac M1/M2/M3 users. The library can be installed using pip, and model weights are available for download in various formats, including int8, fp16, and int4. |
|[Sana: Efficient High-Resolution Image Synthesis with Linear Diffusion Transformer.](https://github.com/NVlabs/Sana) |Sana is a highly efficient image generation model capable of producing high-quality 1024x1024 images in under a second on a laptop GPU. Its innovations include a 32x image compression autoencoder (DC-AE), linear attention replacing traditional attention in DiT, a decoder-only LLM for text encoding, and improved training and sampling techniques. The 0.6B parameter model rivals or surpasses much larger models like Flux-12B, despite being 20x smaller and 100x faster. Requiring only 9GB of VRAM for inference, Sana-0.6B is accessible on consumer hardware. The repository provides code for training, inference, and evaluation, offering both 0.6B and 1.6B model variants. |
|[Flow Models.](https://drscotthawley.github.io/blog/posts/FlowModels.html) |A great introduction to flow based modeling, which is a theoretical improvement over diffusion. |
|[Building an AI-Powered Game.](https://www.deeplearning.ai/short-courses/building-an-ai-powered-game/) | This is a course by Andrew Ng, Latitude, and Together AI on how to make an AI powered game.|
|[Sharper Infrared Images.](https://github.com/hey-it-s-me/corple) | This project improves image super-resolution for infrared images, addressing issues where traditional methods distort spectral fidelity.|
|[Mochi 1 LoRA Fine-tuner.](https://github.com/genmoai/mochi/blob/main/demos/fine_tuner/README.md) |Mochi 1, a top open-source video model, supports LoRA fine-tuning and operates on a single GPU. The repository demonstrates various applications, such as creating custom effects and ensuring character consistency. |
|[OneDiffusion.](https://github.com/lehduong/onediffusion) |OneDiffusion is a versatile large-scale diffusion model capable of handling various tasks, including text-to-image generation, image editing, and reverse processes such as depth estimation and segmentation. |
|[customized-flash-attention.](https://github.com/xiayuqing0622/customized-flash-attention) | New flash attention fork that can have ragged Q/V matrix sizes.|
|[Novel View Synthesis.](https://ewrfcas.github.io/MVGenMaster/) |MVGenMaster is a multi-view diffusion model that enhances Novel View Synthesis tasks by incorporating 3D priors. |
|[FlowMol: Mixed Continuous and Categorical Flow Matching for 3D De Novo Molecule Generation.](https://github.com/dunni3/flowmol) |This work benchmarks discrete flow matching methods for generating novel 3D molecular structures, critical for chemical discovery. |
|[From Generation to Judgment: Opportunities and Challenges of LLM-as-a-judge.](https://llm-as-a-judge.github.io/) | This project investigates the growing "LLM-as-a-judge" approach, where large language models are utilized for scoring, ranking, and selection tasks in diverse AI and NLP applications.|
|[aisuite.](https://github.com/andrewyng/aisuite) |An easy way to work with a variety of API based models in a single packaged environment. |
|[UK government failing to list use of AI on mandatory register.](https://www.theguardian.com/technology/2024/nov/28/uk-government-failing-to-list-use-of-ai-on-mandatory-register) | Technology secretary admits Whitehall departments are not being transparent over way they use AI and algorithms|
|[Reddit overtakes X in popularity of social media platforms in UK.](https://www.theguardian.com/technology/2024/nov/28/reddit-overtakes-x-in-popularity-of-social-media-platforms-in-uk) | Discussion platform takes fifth place in rankings and is the fastest growing large social media platform in the UK|
|[Star Attention: Efficient LLM Inference over Long Sequences.](https://arxiv.org/abs/2411.17116v1) | Star Attention introduces a block-sparse method to accelerate Transformer-based large language models (LLMs) during long-sequence inference.|
|[SketchAgent.](https://github.com/yael-vinker/SketchAgent) | SketchAgent utilizes a multimodal LLM to enable language-guided, step-by-step sketch generation using an intuitive sketching language. It can create diverse sketches, interact with humans for collaborative sketching, and edit content through chat.|
|[DROID-Splat.](https://github.com/chenhoy/droid-splat) |A deep learning-based dense visual SLAM framework capable of real-time global pose optimization and 3D reconstruction. |
|[P2DFlow.](https://github.com/bleach366/p2dflow) | P2DFlow is a protein ensemble generative model with SE(3) flow matching based on ESMFold, the ensembles generated by P2DFlow could aid in understanding protein functions across various scenarios.|
|[ThunderMittens For Your ThunderKittens.](https://hazyresearch.stanford.edu/blog/2024-11-28-tk-mlx) |Hazy Research has played a significant role in optimizing hardware utilization for AI workloads. They have expanded their impressive ThunderKittens Kernel writing framework to support Apple Silicon. |
|[DiffusionDrive: Truncated Diffusion Model for End-to-End Autonomous Driving.](https://arxiv.org/abs/2411.15139) | Diffusion models for End-to-End driving of autonomous vehicles which can operate at 45 FPS on a 4090 chip.|
|[PassionSR: Post-Training Quantization with Adaptive Scale in One-Step Diffusion based Image Super-Resolution.](https://arxiv.org/abs/2411.17106v1) |PassionSR introduces an approach that makes diffusion-based image super-resolution (SR) models more hardware-friendly. |
|[Training Open Instruction-Following Language Models.](https://github.com/allenai/open-instruct) |This repo serves as an open effort on instruction-tuning popular pretrained language models on publicly available datasets.  |
|[Grounding-IQA: Multimodal Language Grounding Model for Image Quality Assessment.](https://zhengchen1999.github.io/Grounding-IQA-Web/) | Grounding-IQA is an innovative method for image quality assessment (IQA) that combines location-specific grounding with multimodal descriptions.|
|[Steel Browser API for AI Agents.](https://github.com/steel-dev/steel-browser) |The open-source browser API built for AI agents. Steel provides a REST API to control headless browsers with session management, proxy support, and anti-detection features. Perfect for web automation, scraping, and building AI agents that can interact with the web. |
|[PixMo dataset.](https://huggingface.co/collections/allenai/pixmo-674746ea613028006285687b) | Allen AI has released several datasets that were used to train its visual language models.|
|[StableAnimator: High-Quality Identity-Preserving Human Image Animation.](https://francis-rings.github.io/StableAnimator/) |StableAnimator introduces a breakthrough in human image animation by ensuring identity consistency in generated videos. |


## Perspectives
|Link|description|
|---|---|
|[Jeff Jarvis: ‘Elon Musk’s investment in Twitter seemed insane, but it gave him this power’.](https://www.theguardian.com/technology/2024/nov/23/jeff-jarvis-elon-musks-investment-in-twitter-seemed-insane-but-it-gave-him-this-power) | The US media pundit on the dangers of overregulation online, why he’s more frightened of the tech bros than AI itself, and how to reclaim the web by getting rid of the geeks|
|[Passwords are giving way to better security methods – until those are hacked too, that is.](https://www.theguardian.com/business/2024/nov/24/small-business-data-security-methods) | It’s a war that will never end. But for small-business owners, it’s all about managing risk while reaping rewards|
|[Gwern Branwen - How an Anonymous Researcher Predicted AI's Trajectory.](https://www.dwarkeshpatel.com/p/gwern-branwen) |In this post, Gwern Branwen, an early advocate of LLM scaling, explores AI advancements and their influence on the path to AGI. He highlights the significance of scaling and computational power over traditional algorithmic innovations. Branwen reflects on the interplay between human intelligence and AI, as well as the societal implications of upcoming technologies like weight-loss drugs on behavior. Additionally, he offers thoughts on his writing process and the transformative effects of AI on creative endeavors |
|[The Bitter Religion: AI’s Holy War Over Scaling Laws.](https://www.generalist.com/briefing/the-bitter-religion) | The AI community is currently divided over the emphasis on scaling computation as the primary driver of AI performance, a concept often referred to as "The Bitter Lesson." Proponents, including leaders at OpenAI, believe that achieving artificial general intelligence (AGI) is possible in the near future through continued scaling of computational resources. However, others argue that alternative scientific advancements are necessary, as scaling laws may not be sustainable in the long term. This debate significantly influences investment and development strategies within AI and related fields. |
|[Why LLMs Within Software Development May Be a Dead End.](https://thenewstack.io/why-llms-within-software-development-may-be-a-dead-end/) |LLMs in software development face challenges due to their lack of decomposability and explainability. |
|[How the far right is weaponising AI-generated content in Europ.](https://www.theguardian.com/technology/2024/nov/26/far-right-weaponising-ai-generated-content-europe) | Experts say fake images raising fears around issues such as immigration have proliferated since EU elections|
|[‘What many of us feel’: why ‘enshittification’ is Macquarie Dictionary’s word of the year.](https://www.theguardian.com/science/2024/nov/26/enshittification-macquarie-dictionary-word-of-the-year-explained) |The committee’s honourable mentions went to ‘right to disconnect’ and ‘rawdogging’ |
|[Valuing Humans in the Age of Superintelligence: HumaneRank.](https://roadtoartificia.com/p/valuing-humans-in-the-age-of-superintelligence-humanerank) |AI's ability to exceed human intellectual output could result in economic displacement. The proposed Humanerank system addresses this by allowing individuals to allocate endorsements that represent societal value, influencing resource distribution. This approach preserves market dynamics and personal freedom while offering a new way to value human contributions in an AI-driven world. |
|[Something weird is happening with LLMs and chess.](https://dynomight.substack.com/p/chess) | This article examines how various LLMs perform in playing chess. Most models falter after a few moves, except for GPT-3.5-turbo-instruct, which excels. This indicates that instruction tuning might impair chess capabilities or that GPT-3.5-turbo-instruct was trained on more chess-related data. Additionally, tokenizer handling issues could be affecting model performance.|
|[Amazon, Google and Meta are ‘pillaging culture, data and creativity’ to train AI, Australian inquiry finds.](https://www.theguardian.com/technology/2024/nov/27/amazon-google-and-meta-are-pillaging-culture-data-and-creativity-to-train-ai-australian-inquiry-finds) | Among the report’s 13 recommendations is the call for the introduction of standalone AI legislation and protections for creative workers|
|[When we become cogs.](https://www.strangeloopcanon.com/p/when-we-become-cogs) |AI enhances material scientists' efficiency, driving a 44% rise in material discoveries but reducing work satisfaction by 44% due to fewer opportunities for idea generation. Similarly, GitHub Copilot boosts productivity for less experienced developers, shifting their focus from project management to coding. While AI helps bridge skill gaps, it risks alienation by automating creative tasks, mirroring the effects of automation in other industries. |
|[AI Alone Isn't Ready for Chip Design.](https://spectrum.ieee.org/chip-design-ai) |Hybrid methods blending classical search techniques with machine learning are proving effective in addressing the challenges of chip design, especially in floorplanning. While AI alone faces difficulties with multi-constraint scenarios, incorporating AI to guide search-based algorithms, such as simulated annealing, improves both efficiency and performance. This synergy accelerates the design process and facilitates the development of more intricate chip solutions. |
|[In the big data era, prioritize statistical significance in study design.](https://www.nature.com/articles/d41586-024-03843-y) |Analysis of neuroimaging studies shows that close attention to experimental design can increase the statistical robustness of research results. |
|[AI could pose pandemic-scale biosecurity risks. Here’s how to make it safer.](https://www.nature.com/articles/d41586-024-03815-2) |AI-enabled research might cause immense harm if it is used to design pathogens with worrying new properties. To prevent this, we need better collaboration between governments, AI developers and experts in biosafety and biosecurity. |
|[Don’t let watermarks stigmatize AI-generated research content.](https://www.nature.com/articles/d41586-024-03869-2) | Given the increasing integration of LLMs into research processes, identifying their contributions transparently is ever more urgent. But watermarking risks fostering a reductive and binary view of content as either ‘pure’ or ‘tainted’ depending on whether it is human- or LLM-generated.|
|[It's Surprisingly Easy to Jailbreak LLM-Driven Robots.](https://spectrum.ieee.org/jailbreak-llm) |RoboPAIR is an algorithm capable of bypassing safety guardrails in robots powered by LLMs, effectively jailbreaks these systems. Tests demonstrated a 100% success rate in compromising platforms like the Go2 self-driving simulator and robot dogs. This highlights critical security vulnerabilities, underscoring the urgent need for stronger defenses against LLM-based robot hacking. |
|[A new AI scaling law shell game?](https://garymarcus.substack.com/p/a-new-ai-scaling-law-shell-game) | Recent changes in AI scaling laws have exposed limits in predictability and effectiveness, with newer models falling short of previous expectations. Microsoft CEO Satya Nadella emphasizes "inference time compute" as a key area to address, though issues of cost and reliability remain. Advancing beyond scaling is essential, and LLMs should be integrated into a more comprehensive AI strategy.|


# ML news: ML news: Week 18 - 24 November

## Research
|Link|description|
|---|---|
|[Artificial Intelligence, Scientific Discovery, and Product Innovation.](https://aidantr.github.io/files/AI_innovation.pdf) |indicates that leading scientists use their expertise to focus on the most promising AI-generated suggestions, while others often expend considerable resources on false positives; shows that adopting AI technology for materials discovery boosts productivity, resulting in 44% more materials discovered, a 39% increase in patent filings, and 17% greater product innovation; notes that these improvements come with drawbacks, as 82% of scientists experienced lower job satisfaction, citing reduced creativity and underutilization of their skills. |
|[Scaling Laws for Precision.](https://arxiv.org/abs/2411.04330) | presents "precision-aware" scaling laws that forecast how both training and inference precision impact LLM performance; key insights include: 1) post-training quantization becomes increasingly detrimental as models are trained on larger datasets, to the point where more pretraining may harm performance, 2) training with lower precision necessitates a larger model size to sustain performance levels, and 3) when optimizing model size, data, and precision together, the ideal training precision is around 7-8 bits, independent of compute availability; further notes that with a fixed model size, the optimal precision for compute increases roughly logarithmically with data size; the authors confirm their predictions on models up to 1.7B parameters trained on up to 26B tokens, demonstrating that both very high (16-bit) and very low (under 4-bit) training precisions may be inefficient.|
|[Sequence modeling and design from molecular to genome scale with Evo.](https://www.science.org/doi/10.1126/science.ado9336) |a 7B parameter AI model built to comprehend and generate DNA sequences across various biological scales; trained on 2.7 million prokaryotic and phage genomes, it can handle sequences up to 131 kilobases long while preserving single-nucleotide precision, allowing it to capture both molecular interactions and genome-wide patterns; Evo outperforms in predicting and generating functional DNA, RNA, and protein sequences, achieving the first experimentally validated AI-generated CRISPR-Cas complexes and transposable systems. |
|[The Surprising Effectiveness of Test-Time Training for Abstract Reasoning.](https://ekinakyurek.github.io/papers/ttt.pdf) | examines test-time training (TTT), where model parameters are temporarily updated during inference, to enhance an LLM's abstract reasoning on the ARC benchmark; highlights three essential components: initial fine-tuning on related tasks, using auxiliary task formats and augmentations, and per-instance training; TTT yields substantial performance gains, with accuracy improvements of up to 6x over base fine-tuned models; applying TTT to an 8B LLM results in 53% accuracy on ARC's public validation set, a nearly 25% increase over the previous state-of-the-art for neural approaches; combining their method with program generation techniques achieves a new public validation accuracy of 61.9%, on par with average human performance; the results indicate that explicit symbolic search is not the sole route to better abstract reasoning in LLMs, and that test-time training on few-shot examples can be highly effective.|
|[Toward Optimal Search and Retrieval for RAG.](https://arxiv.org/abs/2411.07396) | investigates the impact of retrieval on performance in RAG pipelines for QA tasks; performs experiments using BGE-base and ColBERT retrievers with LLaMA and Mistral, showing that incorporating more gold (relevant) documents enhances QA accuracy; observes that using approximate nearest neighbor search with lower recall has minimal performance impact while potentially boosting speed and memory efficiency; notes that introducing noisy or irrelevant documents consistently harms performance, refuting prior research claims; concludes that optimizing the retrieval of gold documents is essential for RAG effectiveness and that lower search accuracy can be a practical strategy.|
|[Rapid Response: Mitigating LLM Jailbreaks with a Few Examples.](https://arxiv.org/abs/2411.07494) |presents a novel approach for defending LLMs against jailbreak attacks, emphasizing the rapid adaptation of defenses upon detecting new attacks rather than striving for perfect initial adversarial robustness; using a new benchmark, the top-performing method—fine-tuning an input classifier—reduced attack success rates by over 240x for known attack types and 15x for new variations after observing just one example of each attack strategy; shows that swiftly responding to emerging jailbreaks can be an effective alternative to traditional static defenses. |
|[Solving the Travelling Salesman Problem.](https://arxiv.org/abs/2411.09238v1) |This study highlights the often underestimated value of the "heatmap + Monte Carlo Tree Search (MCTS)" method, demonstrating that well-tuned, straightforward heatmaps can surpass more sophisticated models. |
|[Graph-based AI model maps the future of innovation.](https://news.mit.edu/2024/graph-based-ai-model-maps-future-innovation-1112) | MIT researchers created an AI model that employs generative knowledge extraction and graph reasoning to detect intricate patterns across varied domains such as biology and music. The model efficiently generates knowledge maps from scientific literature, uncovering connections and proposing novel materials inspired by art. This method boosts interdisciplinary research by uncovering hidden insights and fostering innovative concepts for material design.|
|[Teaching Video Models to Understand Time Like a Story.](https://arxiv.org/abs/2411.10332v1) | This paper presents NumPro, an innovative approach designed to assist Video Large Language Models in managing Video Temporal Grounding tasks.|
|[Generative World Explorer.](https://generative-world-explorer.github.io/) |The Generative World Explorer (Genex) is a system capable of simulating exploration in 3D spaces through generation and leveraging those simulations to enhance planning. It employs an ST-VAE and a diffusion pass for its imagination process, leading to better planning outcomes. |
|[Search, Verify and Feedback: Towards Next Generation Post-training Paradigm of Foundation Models via Verifier Engineering.](https://arxiv.org/abs/2411.11504) |The Generative World Explorer (Genex) is a system capable of simulating exploration in 3D spaces through generation and leveraging those simulations to enhance planning. It employs an ST-VAE and a diffusion pass for its imagination process, leading to better planning outcomes. |
|[OneNet: A Channel-Wise 1D Convolutional U-Net.](https://arxiv.org/abs/2411.09838v1) |OneNet is a 1D convolutional encoder optimized for efficient image segmentation, making it well-suited for edge devices. |
|[AI’s math problem: FrontierMath benchmark shows how far technology still has to go.](https://venturebeat.com/ai/ais-math-problem-frontiermath-benchmark-shows-how-far-technology-still-has-to-go/) |Artificial intelligence systems may be good at generating text, recognizing images, and even solving basic math problems—but when it comes to advanced mathematical reasoning, they are hitting a wall. A groundbreaking new benchmark, FrontierMath, is exposing just how far today’s AI is from mastering the complexities of higher mathematics. |
|[Enhancing Reasoning Capabilities of LLMs via Principled Synthetic Logic Corpus.](https://arxiv.org/abs/2411.12498v1) |Researchers have proposed Additional Logic Training to enhance reasoning in LLMs, focusing on teaching them to manage complex deductions involving varied rules and distractions. |
|[Solving Cold Starts in Adaptive Testing.](https://arxiv.org/abs/2411.12182v1) | The "cold start" issue in adaptive testing arises when initial questions fail to align with examinees' abilities. Researchers have addressed this with the Diffusion Cognitive States Transfer Framework (DCSR), which employs diffusion models to utilize prior learning data across different domains.|
|[samurai.](https://github.com/yangchris11/samurai) | Tracking a consistent object over an extended period is a challenging task. This work enhances SAM 2 by integrating motion-aware memory banks, ensuring consistency over time and through occlusions. It stands out as one of the most effective visual tracking systems developed so far.|
|[Compress and Reconstruct Images.](https://github.com/guaishou74851/pcnet) |PCNet is a new compact network for image-compressed sensing. It reduces sampling costs while delivering high-quality reconstructions. |
|[LMM-driven Semantic Image-Text Coding for Ultra Low-bitrate Learned Image Compression.](https://arxiv.org/abs/2411.13033v1) |Large multi-modal models can generate captions and compress images simultaneously within a single system |

## News
|Link|description|
|---|---|
|[Hi-tech recreation of Richard III’s voice has a Yorkshire accent.](https://www.theguardian.com/uk-news/2024/nov/17/technology-used-to-recreate-richard-iiis-voice-with-yorkshire-accent) |A digital avatar of the king’s head, complete with ‘meticulously researched’ voice, is on display in York |
|[OpenAI’s tumultuous early years revealed in emails from Musk, Altman, and others.](https://techcrunch.com/2024/11/15/openais-tumultuous-early-years-revealed-in-emails-from-musk-altman-and-others/) | Elon Musk's lawsuit against OpenAI has unveiled emails from the startup's early days, exposing internal conflicts.|
|[Spotify’s Plans For AI Generated Music, Podcasts, and Recommendations, According To Its Co-President, CTO, and CPO Gustav Söderström.](https://www.bigtechnology.com/p/spotifys-plans-for-ai-generated-music) | Spotify's Gustav Söderström talks about AI music, Notebook LM podcasts, and the nuance of building better discovery using LLMs.|
|[AI cloning of celebrity voices outpacing the law, experts warn.](https://www.theguardian.com/technology/2024/nov/19/ai-cloning-of-celebrity-voices-outpacing-the-law-experts-warn) | David Attenborough among famous people whose voices have been exploited by fraudsters|
|[John Oliver on potential US TikTok ban: ‘May not be necessary, but it isn’t sufficient’.](https://www.theguardian.com/tv-and-radio/2024/nov/18/john-oliver-last-week-tonight-tiktok-ban) | Last Week Tonight host looks into looming US ban over privacy concerns and fear of its Chinese parent company|
|[Shop like a Pro: Perplexity’s new AI-powered shopping assistant.](https://www.perplexity.ai/hub/blog/shop-like-a-pro) | Perplexity has introduced a shopping feature for Pro users in the U.S., enabling them to research and purchase products directly within the platform. This feature includes a "Buy with Pro" button that allows users to order items using saved billing and shipping information, with free shipping on all purchases. |
|[Ben Affleck Shares Candid Take on the Positive Use of AI in Hollywood, but Doesn't See It Threatening Creativity.](https://movieweb.com/ben-affleck-ai-role-in-hollywood/) |During an interview, Ben Affleck reassured Hollywood actors and writers, stating that AI currently poses minimal risk to their jobs because of its existing limitations. |
|[The Dawn of GUI Agent: A Preliminary Case Study with Claude 3.5 Computer Use.](https://arxiv.org/abs/2411.10323) |This work seeks to systematically evaluate the capabilities of new autonomous computer use agents, revealing that Claude is particularly strong at handling traditional linear tasks. |
|[Llama 3.1 405B now runs at 969 tokens/s on Cerebras Inference.](https://cerebras.ai/blog/llama-405b-inference) |Cerebras has developed a 405-billion-parameter Llama 3.1 model, the largest in its class, capable of processing nearly 1,000 tokens per second. This performance is approximately 12 times faster than comparable systems and 18 times faster than some closed-model API providers. The model is expected to be accessible via API at the beginning of next year. |
|[Nous Research Forge.](https://nousresearch.com/introducing-the-forge-reasoning-api-beta-and-nous-chat-an-evolution-in-llm-inference/) |The Forge Reasoning API enhances popular language models by integrating a code interpreter and advanced reasoning capabilities, leading to improved performance. |
|[US justice department plans to push Google to sell off Chrome browser.](https://www.theguardian.com/technology/2024/nov/19/us-doj-sell-chrome-browser-ai-android) |Authorities seek to dismantle monopoly on search market and also want action related to AI and Android |
|[Meta pushes AI bid for UK public sector forward with technology aimed at NHS.](https://www.theguardian.com/technology/2024/nov/19/meta-hackathon-devises-ways-to-use-ai-system-in-uk-public-services) | Tech giant awards funding to project to shorten waits in A&E, after ‘hackathon’ on using Llama system in Britain|
|[Meta hires Salesforce's CEO of AI, Clara Shih.](https://www.axios.com/2024/11/19/meta-new-ai-tools-businesses) | Meta is creating a new product unit to develop AI tools for the 200 million businesses that use its apps.|
|[Rox's Public Beta and $50M Raise.](https://docs.rox.com/development/about-rox/founder-note/make-the-best-better) |Rox, an AI-powered sales productivity platform, boosts enterprise sales reps' performance by over 30% through AI analyst teams that handle tasks like planning and engagement. It integrates effortlessly with existing systems, eliminating the inefficiencies of traditional CRMs, and is already used by leading companies. Rox recently secured $50M in funding, led by Sequoia and other prominent investors, to expand its market presence. |
|[Genies launches Parties for brands and creators to launch their own ‘AI Roblox’.](https://venturebeat.com/games/genies-launches-parties-for-brands-and-creators-to-launch-their-own-ai-roblox/) | Genies, a culture-focused avatar technology company, has launched Parties after developing its foundational technology stack since the last fundraise.|
|[Generative AI taught a robot dog to scramble around a new environment.](https://www.technologyreview.com/2024/11/12/1106811/generative-ai-taught-a-robot-dog-to-scramble-around-a-new-environment) |Teaching robots to navigate new environments is tough. You can train them on physical, real-world data taken from recordings made by humans, but that’s scarce and expensive to collect. Digital simulations are a rapid, scalable way to teach them to do new things, but the robots often fail when they’re pulled out of virtual worlds and asked to do the same tasks in the real one.  |
|[Breakthrough robot nails surgery like a human doctor after watching videos.](https://interestingengineering.com/innovation/robot-nails-surgery-lik-human-doctor) | The model can quickly train robots for diverse surgeries, from basic tasks to full procedures, advancing robotic medical capabilities.|
|[DeepL launches DeepL Voice, real-time, text-based translations from voices and videos.](https://techcrunch.com/2024/11/13/deepl-launches-deepl-voice-real-time-text-based-translations-from-voices-and-videos/) | DeepL has made a name for itself with online text translation it claims is more nuanced and precise than services from the likes of Google — a pitch that has catapulted the German startup to a valuation of $2 billion and more than 100,000 paying customers. Users will now be able to use DeepL Voice to listen to someone speaking in one language and automatically translate it to another, in real time.|
|[Google releases standalone Gemini app for iPhone.](https://www.macworld.com/article/2521235/google-releases-standalone-gemini-app-for-iphone.html) | You've always been able to access this in the Google app, but now there's another way.|
|[ChatGPT can now read some of your Mac’s desktop apps.](https://techcrunch.com/2024/11/14/chatgpt-can-now-read-some-of-your-macs-desktop-apps/) |On Thursday, the startup announced the ChatGPT desktop app for macOS can now read code in a handful of developer-focused coding apps, such as VS Code, Xcode, TextEdit, Terminal, and iTerm2. |
|[Google must sell Chrome to end search monopoly, justice department argues in court filing.](https://www.theguardian.com/technology/2024/nov/21/google-sell-chrome-us-court-filing-demand-competition-laws) |Justice department urges court to force Google to share data with rivals as part of wide-ranging changes to end online giant’s monopoly on web searching |
|[Nvidia earnings: AI chip leader shows no signs of stopping mammoth growth.](https://www.theguardian.com/technology/2024/nov/20/nvidia-earnings-ai-chipmaker) |World’s most valuable company delights investors as it reports $35bn of revenue in quarterly results |
|[DeepSeek r1 reasoning model.](https://threadreaderapp.com/thread/1859200141355536422.html) | DeepSeek has replicated o1 with its r1 Deep Think model, a highly powerful system that the company plans to make fully open-source. The model was trained using reinforcement learning with reasoning traces.|
|[Introducing AI Backgrounds, HD Video Calls, Noise Suppression and More for Messenger Calling.](https://about.fb.com/news/2024/11/introducing-ai-backgrounds-noise-suppression-and-more-messenger-calling/) |Meta has announced new updates for its Messenger app, including HD video calling, noise suppression, and AI-generated backgrounds. HD video calling will be enabled by default on Wi-Fi, but can also be activated using a cell data plan through call settings.  |
|[A.I. Chatbots Defeated Doctors at Diagnosing Illness.](https://www.nytimes.com/2024/11/17/health/chatgpt-ai-doctors-diagnosis.html?unlocked_article_code=1.a04.Pypn.jAqrCrVkp6Z3&smid=url-share) |A small study found ChatGPT outdid human physicians when assessing medical case histories, even when those doctors were using a chatbot. |
|[AlphaQubit tackles one of quantum computing’s biggest challenges.](https://blog.google/technology/google-deepmind/alphaqubit-quantum-error-correction/) |Deepmind and Google Quantum have trained a model that can identify errors in quantum computations and correct them as needed. |
|[Superhuman vision lets robots see through walls, smoke with new LiDAR-like eyes.](https://interestingengineering.com/innovation/superhuman-vision-lets-robots-see-through-walls-smoke) | PanoRadar, developed by researchers at the University of Pennsylvania, is an AI-driven system that transforms radio waves into 3D views, offering robots LiDAR-like vision at a reduced cost. By leveraging AI to process radio wave reflections, it overcomes challenges faced by traditional sensors in conditions like smoke, fog, and glass. The team plans to integrate PanoRadar with existing sensing technologies to enhance multi-modal perception in robotics.|
|[Google DeepMind has a new way to look inside an AI's “mind”.](https://www.technologyreview.com/2024/11/14/1106871/google-deepmind-has-a-new-way-to-look-inside-an-ais-mind/) |DeepMind has introduced Gemma Scope, a tool designed to enhance the understanding of AI models' internal mechanisms and decision-making processes. By employing sparse autoencoders, Gemma Scope dissects and analyzes data layers, aiding in the identification of biases or errors, such as incorrect numerical interpretations. This advancement in model transparency aims to improve AI control and alignment, thereby reducing deployment risks. |
|[AI model identifies overlooked brain tumors in just 10 seconds.](https://newatlas.com/brain/fastglioma-ai-identifies-brain-tumors/) | FastGlioma is an AI model that rapidly detects residual brain tumor tissues during surgery with high accuracy.|
|[It's Surprisingly Easy to Jailbreak LLM-Driven Robots.](https://spectrum.ieee.org/jailbreak-llm) | Researchers induced bots to ignore their safeguards without exception|
|[Nvidia to fuel humanoid robots with ‘Jetson Thor’.](https://iottechnews.com/news/nvidia-fuel-humanoid-robots-jetson-thor/) |Nvidia plans to launch its “Jetson Thor” computing platform in the first half of 2025, providing the processing power needed to bring sophisticated humanoid robots to life. |
|[Introducing FLUX.1 Tools.](https://blackforestlabs.ai/flux-1-tools/) |FLUX.1 Tools is a collection of models designed to enhance control and steerability in the FLUX.1 text-to-image model. It includes utilities and model checkpoints that enable features like inpainting, outpainting, and certain controlnets. These tools are ideal for users looking to expand their creative capabilities using one of the leading models available. |
|[Elon Musk Asked People to Upload Their Health Data. X Users Obliged.](https://www.nytimes.com/2024/11/18/well/x-grok-health-privacy.html?unlocked_article_code=1.a04.k65h.c7aN7-TAu-PB&smid=url-share) |Users are uploading medical images to X's AI chatbot Grok for diagnostic purposes, a practice endorsed by Elon Musk despite concerns about accuracy and privacy. Unlike regulated medical platforms, Grok lacks HIPAA compliance, raising ethical questions about data security. While AI shows promise in healthcare, experts warn of risks related to inaccurate diagnoses and privacy violations. |
|[ElevenLabs now offers ability to build conversational AI agents.](https://techcrunch.com/2024/11/18/elevenlabs-now-offers-ability-to-build-conversational-ai-agents/) | ElevenLabs, a startup that provides AI voice cloning and a text-to-speech API, launched the ability to build conversational AI bots on Monday.|
|[New OpenAI emails reveal a long history of mistrust.](https://www.transformernews.ai/p/openai-emails-altman-trust) | Greg Brockman and Ilya Sutskever had questions about Sam Altman's intentions as early as 2017|
|[Musk’s amended lawsuit against OpenAI names Microsoft as defendant.](https://techcrunch.com/2024/11/14/musks-amended-lawsuit-against-openai-names-microsoft-as-defendant/) |Elon Musk’s lawsuit against OpenAI accusing the company of abandoning its nonprofit mission was withdrawn in July, only to be revived in August. Now, in an amended complaint, the suit names new defendants, including Microsoft, LinkedIn co-founder Reid Hoffman, and former OpenAI board member and Microsoft VP Dee Templeton. |

## Resources
|Link|description|
|---|---|
|[OpenCoder: The Open Cookbook for Top-Tier Code Large Language Models.](https://arxiv.org/abs/2411.04905) | introduces OpenCoder, a completely open-source LLM tailored for code generation and comprehension; the authors highlight key elements for creating top-performing code LLMs: (1) rigorous data cleaning using code-specific heuristic rules for deduplication, (2) effective recall of related text corpus for code context, and (3) high-quality synthetic data utilized in both annealing and supervised fine-tuning phases; OpenCoder outperforms previous open models at the 6B+ parameter level and provides not only the model weights but also the full training pipeline, datasets, and protocols to support reproducible research.|
|[A Taxonomy of AgentOps for Enabling Observability of Foundation Model based Agents.](https://arxiv.org/abs/2411.05285v1) |examines AgentOps platforms and tools, emphasizing the necessity of robust observability and traceability features to maintain reliability in foundation model-based autonomous agent systems throughout their development and production lifecycle. |
|[Mixture-of-Transformers: A Sparse and Scalable Architecture for Multi-Modal Foundation Models.](https://arxiv.org/abs/2411.04996) | presents Mixture-of-Transformers (MoT), a novel sparse multi-modal transformer architecture that achieves performance comparable to traditional models while using nearly half the computational resources for text and image tasks; MoT matches the performance of a dense baseline while utilizing only 55.8% of the FLOPs.|
|[HtmlRAG: HTML is Better Than Plain Text for Modeling Retrieved Knowledge in RAG Systems.](https://arxiv.org/abs/2411.02959v1) | introduces a novel approach that uses HTML instead of plain text for constructing RAG systems; the core insight is that preserving HTML structure retains richer semantic and structural information compared to plain text conversion, which often loses critical formatting like headings, tables, and semantic tags; to handle the challenge of long HTML documents exceeding LLM context windows, the authors design a two-step pruning method: first, cleaning unnecessary HTML elements to cut length by 94%, and then applying a block-tree-based pruning approach that integrates embedding-based and generative pruning to retain essential content; experiments on six QA datasets show that HtmlRAG surpasses existing plain-text methods, confirming the benefits of maintaining HTML structure in RAG systems.|
|[LLaMA-Mesh: Unifying 3D Mesh Generation with Language Models.](https://research.nvidia.com/labs/toronto-ai/LLaMA-Mesh/) | NVIDIA has developed LLaMA-Mesh, a method that fine-tunes the LLaMA language model to generate 3D meshes from text prompts. By training LLaMA on a curated dataset of 3D dialogues, LLaMA-Mesh enables the model to represent and generate 3D mesh data in plain text format, integrating 3D mesh generation with language understanding.|
|[Your Fixed Watermark is Fragile: Towards Semantic-Aware Watermark for EaaS Copyright Protection.](https://arxiv.org/abs/2411.09359v1) |Researchers have introduced the Semantic Perturbation Attack (SPA) to exploit vulnerabilities in current watermarking schemes for Embedding-as-a-Service (EaaS) systems. Traditional watermarking methods often inject fixed signals into embeddings, regardless of the input's semantics, making them susceptible to adaptive attacks. SPA leverages semantic perturbations to identify and bypass these static watermark signals, effectively compromising watermark verification. |
|[Don’t Look Twice: Faster Video Transformers with Run-Length Tokenization.](https://github.com/rccchoudhury/rlt) | By adaptively caching video tokens that remain unchanged across frames, you can significantly accelerate run time without sacrificing performance or requiring extra training.|
|[Region-Aware Text-to-Image Generation via Hard Binding and Soft Refinement.](https://github.com/NJU-PCALab/RAG-Diffusion) |An improved technique for generating images with improved control based on chosen regions. |
|[Accurate Image Matching.](https://github.com/fb82/miho) |MOP+MiHo+NCC is a non-deep, modular method for improving image matches using a combination of three techniques. Multiple Overlapping Planes (MOP) clusters inlier matches and uses RANSAC to remove outliers. Middle Homography (MiHo) minimizes distortion during planar reprojection. Normalized Cross Correlation (NCC) adjusts keypoint positions post-transformation. |
|[The Beginner's Guide to Visual Prompt Injections.](https://www.lakera.ai/blog/visual-prompt-injections) |Visual prompt injections present security threats to LLMs like GPT-4V by embedding harmful instructions within images, potentially causing unintended model behavior. These vulnerabilities can manipulate outputs, for instance, by causing the model to overlook certain individuals in images or misrepresent described contexts. With the increasing adoption of generative AI, companies must implement strong security measures to address these risks. |
|[PyGen: Turning Your Ideas into Python Package.](https://github.com/GitsSaikat/Pygen) | PyGen simplifies the process of turning your ideas into software, making coding more accessible and enjoyable. Leveraging advanced language models, PyGen acts like a tech-savvy assistant, transforming abstract concepts into complete Python tools, including testing and documentation. |
|[UltraVox Audio Language Models.](https://huggingface.co/collections/reach-vb/ultravox-audio-language-model-release-67373b602af0a52b2a88ae71) |A suite of open weight models that can take text and audio as input modalities. |
|[https://arxiv.org/abs/2410.17758.](https://mistral.ai/news/pixtral-large/) | Pixtral Large is a 124B open-weight multimodal model built upon Mistral Large 2. As the second model in this multimodal series, it showcases advanced image comprehension, capable of interpreting documents, charts, and natural images, while retaining the top-tier text understanding of Mistral Large 2.|
|[LLaVA-o1: Let Vision Language Models Reason Step-by-Step.](https://arxiv.org/abs/2411.10440) |Although this isn't an exact replication of the training process used for o1, it remains a robust VLM trained on reasoning traces. |
|[CLIP for Semantic Segmentation.](https://github.com/YuHengsss/Trident) |Although CLIP has excelled in open-vocabulary tasks, it faces challenges in semantic segmentation due to noisy features and limited resolution. Trident tackles the resolution problem with a training-free framework, integrating CLIP and DINO features from sub-images and employing SAM's encoder for global feature aggregation. |
|[Confidence-aware Denoised Fine-tuning of Off-the-shelf Models for Certified Robustness.](https://github.com/suhyeok24/ft-cadis) |This work focuses on improving the certified robustness of smoothed classifiers by fine-tuning off-the-shelf models |
|[ReCapture: Generative Video Camera Controls for User-Provided Videos using Masked Video Fine-Tuning.](https://generative-video-camera-controls.github.io/) | This paper from Google demonstrates a method for altering the camera viewpoint of an existing video.|
|[Evaluating-Constitutions.](https://github.com/saskia-rr/Evaluating-Constitutions) | Code to assist in evaluating constitutions based on human feedback.|
|[StableV2V: Stablizing Shape Consistency in Video-to-Video Editing.](https://alonzoleeeooo.github.io/StableV2V) | StableV2V is a novel video editing framework that maintains shape consistency across frames, even when user prompts require significant transformations. This method ensures smooth and precise modifications throughout the video, preserving structural integrity|
|[CCExpert: Advancing MLLM Capability in Remote Sensing Change Captioning with Difference-Aware Integration and a Foundational Dataset.](https://github.com/meize0729/ccexpert) |CCExpert is an AI model developed to describe changes in images using natural language. It can identify what has changed, where the change occurred, and how it happened. |
|[SAM Decoding: Speculative Decoding via Suffix Automaton.](https://arxiv.org/abs/2411.10666v1) | SAM-Decoding offers a faster method for text generation in LLMs by utilizing a suffix automaton to create drafts efficiently and accurately.|
|[That Chip Has Sailed: A Critique of Unfounded Skepticism Around AI for Chip Design.](https://arxiv.org/abs/2411.10053) |DeepMind has issued a robust defense of its AlphaChip project, which has faced criticism from some academic circles despite widespread industry adoption. In a recent paper titled "That Chip Has Sailed: A Critique of Unfounded Skepticism Around AI for Chip Design," DeepMind addresses these critiques, emphasizing AlphaChip's significant contributions to chip design. The paper highlights AlphaChip's role in creating superhuman chip layouts for Google's Tensor Processing Units (TPUs) and its influence on hardware used globally. |
|[PoM: Efficient Image and Video Generation with the Polynomial Mixer.](https://arxiv.org/abs/2411.12663v1) |Polynomial Mixer offers a faster and more memory-efficient alternative to Multi-Head Attention (MHA) in diffusion models used for image and video generation. |
|[Cross-View Geo-Localization.](https://github.com/gaoshuang98/cvcities) | Researchers have created a framework to address the challenges of cross-view geo-localization, including variations in viewpoints and large-scale global contexts.|
|[A statistical approach to model evaluations.](https://www.anthropic.com/research/statistical-approach-to-model-evals) | When two models are evaluated on a benchmark, declaring one as superior to the other often lacks strong confidence. This research from Anthropic introduces robust statistical methods to reliably determine when one model genuinely outperforms the other.|
|[Software is a team sport.](https://github.blog/news-insights/company-news/software-is-a-team-sport-building-the-future-of-software-development-together/) | GitHub Copilot, utilized by over 2.8 million developers, enhances the development experience with AI-powered features such as code completion, debugging, and secure code reviews. Developers can select AI models from providers like OpenAI and Google within Visual Studio Code. Integration with Azure and tools like GitHub Actions streamlines cloud deployments and continuous integration/continuous deployment (CI/CD) processes. |
|[Prompt Injecting Your Way To Shell: OpenAI's Containerized ChatGPT Environment.](https://0din.ai/blog/prompt-injecting-your-way-to-shell-openai-s-containerized-chatgpt-environment) |This article examines the interactive features of OpenAI's Debian-based sandbox environment for ChatGPT, revealing surprising details about its structure. Users can run Python scripts, manage files, and possibly expose core instructions through prompt engineering. These capabilities have sparked debates around transparency and privacy. While designed as intentional features, OpenAI does not consider them security vulnerabilities unless they result in breaches of the sandbox environment. |


## Perspectives
|Link|description|
|---|---|
|[AI could cause ‘social ruptures’ between people who disagree on its sentience.](https://www.theguardian.com/technology/2024/nov/17/ai-could-cause-social-ruptures-between-people-who-disagree-on-its-sentience) |AI could cause ‘social ruptures’ between people who disagree on its sentience |
|[Is this (finally) the end for X? Delicate Musk-Trump relationship and growing rivals spell trouble for platform.](https://www.theguardian.com/technology/2024/nov/17/bluesky-musk-trump-x-twitter-authoritarian-world) | The former Twitter could fade away, or help shape a dark future hosting voices of a new authoritarian world|
|[‘Have your bot speak to my bot’: can AI productivity apps turbocharge my life?](https://www.theguardian.com/technology/2024/nov/17/have-your-bot-speak-to-my-bot-can-ai-productivity-apps-turbocharge-my-life) |I tried out organisational software to help streamline my work and build a ‘second brain’. I never knew there were so many different ways to take notes… |
|[Is “AI welfare” the new frontier in ethics?](https://arstechnica.com/ai/2024/11/anthropic-hires-its-first-ai-welfare-researcher) | A few months ago, Anthropic quietly hired its first dedicated "AI welfare" researcher, Kyle Fish, to explore whether future AI models might deserve moral consideration and protection, reports AI newsletter Transformer. While sentience in AI models is an extremely controversial and contentious topic, the hire could signal a shift toward AI companies examining ethical questions about the consciousness and rights of AI systems.|
|[What if AI doesn’t just keep getting better forever?](https://arstechnica.com/ai/2024/11/what-if-ai-doesnt-just-keep-getting-better-forever/) |Recent reports suggest that traditional large language model (LLM) training is encountering diminishing returns, with newer models like OpenAI's Orion showing only modest improvements over predecessors. Experts are concerned about the scarcity of high-quality textual data for LLM training, leading to a shift towards synthetic data and specialized AI models. Future advancements may prioritize enhancing reasoning capabilities and developing task-specific models over general scaling. |
|[AI Makes Tech Debt More Expensive.](https://www.gauge.sh/blog/ai-makes-tech-debt-more-expensive) |AI amplifies the cost of tech debt by widening the velocity gap between low-debt and high-debt codebases. |
|[Where's My Robot Butler?](https://spectrum.ieee.org/ai-robots) | Advancements in AI and robotics are speeding up the creation of humanoid robots like Atlas, Optimus, and Neo, designed to handle domestic tasks similar to Rosie from "The Jetsons." However, developing cost-effective, safe, and efficient actuators remains a challenge. AI models play a vital role in training these robots for autonomous, complex tasks. Although there has been notable progress, these robots are currently better suited for industrial applications and may only become practical for home use with major breakthroughs.|
|[Google's head of research on whether 'learn to code' is still good advice in the age of AI.](https://www.businessinsider.com/google-research-head-career-advice-learn-to-code-2024-11) |Even though AI can manage some coding tasks, having a fundamental understanding of coding remains essential and opens up new opportunities in various fields, such as healthcare and education. |
|[Why are we using LLMs as calculators?](https://vickiboykis.com/2024/11/09/why-are-we-using-llms-as-calculators/) |Researchers are experimenting with LLMs' ability to solve math problems to assess their reasoning capabilities. |
|[GPTs Are Maxed Out.](https://www.thealgorithmicbridge.com/p/gpts-are-maxed-out) | OpenAI's next-generation model, internally called Orion, is said to fall short of expectations set by Sam Altman, hinting at a possible limit to the scalability of AI model improvements.|
|[Can Google Scholar survive the AI revolution?](https://www.nature.com/articles/d41586-024-03746-y) |The largest scholarly search engine is celebrating its 20th birthday, but AI-driven competitors offer advantages. |
|[Computational technologies of the Human Cell Atlas.](https://www.nature.com/articles/d41586-024-03762-y) |As the international effort reaches a ‘critical mass’ of achievements, Nature highlights seven tools that are poised to enable the next set of discoveries. |
|[Can a fluffy robot really replace a cat or dog? My weird, emotional week with an AI pet.](https://www.theguardian.com/technology/2024/nov/20/fluffy-robot-weird-emotional-week-ai-pet-moflin) |Casio says Moflin can develop its own personality and build a rapport with its owner – and it doesn’t need food, exercise or a litter tray. But is it essentially comforting or alienating? |
|[The Evolution of the Creator.](https://www.digitalnative.tech/p/the-evolution-of-the-creator) |Generative AI is transforming the creator economy by reducing production barriers, allowing creators to produce high-quality content effortlessly. Innovations like digital clones are reshaping content distribution and engagement, unlocking new monetization opportunities by scaling interactions and fan transactions. With AI revolutionizing creation, distribution, and monetization, the creator economy is poised to give rise to a new generation of major tech companies. |
|[‘A place of joy’: why scientists are joining the rush to Bluesky.](https://www.nature.com/articles/d41586-024-03784-6) | Researchers say the social-media platform — an alternative to X — offers more control over the content they see and the people they engage with.|
|[Tülu 3: The next era in open post-training.](https://www.interconnects.ai/p/tulu-3) |An open-source, cutting-edge post-training framework offering open data, training code, model weights, and scientific insights. It may be the most comprehensive resource for understanding modern post-training techniques for large language models. |
|[We can all be AI engineers – and we can do it with open source models.](https://blog.helix.ml/p/we-can-all-be-ai-engineers) |The barriers to AI engineering are quickly lowering as improved tools and standardized workflows streamline complex processes. Creating AI applications now involves applying basic engineering skills to utilize models, prompts, integrations, testing, and deployment. Open-source models ensure data privacy, while existing DevOps tools support the development and management of AI applications. |
|[‘An AI Fukushima is inevitable’: scientists discuss technology’s immense potential and dangers.](https://www.theguardian.com/science/2024/nov/22/an-ai-fukushima-is-inevitable-scientists-discuss-technologys-immense-potential-and-dangers) |Experts are optimistic about energy and drug production breakthroughs but also fear its potential misuse |


# ML news: Week 11 - 17 November

## Research
|Link|description|
|---|---|
|[Project Sid: Many-agent simulations toward AI civilization.](https://arxiv.org/abs/2411.00114) | This work illustrates the behavior and evolution of societies composed of 10-1000+ AI agents. It introduces PIANO, an architecture that allows agents to interact with both humans and other agents in real-time. The study reveals that agents can autonomously adopt specialized roles, follow and modify collective rules, and participate in cultural and religious transmissions.|
|[Mixtures of In-Context Learners.](https://arxiv.org/abs/2411.02830) |utilizes subsets of demonstrations to train experts through in-context learning; a trainable weighting function is then employed to merge the next-token predictions from these experts based on the training set. This method is compatible with black-box LLMs, as it does not require access to their internal parameters. Key advantages include: 1) being competitive with standard ICL while offering much greater efficiency in terms of data, memory, and computation, and 2) demonstrating robustness to noisy demonstrations and label imbalance. |
|[Attacking Vision-Language Computer Agents via Pop-ups.](https://arxiv.org/abs/2411.02391) | demonstrates that incorporating adversarial pop-ups into current agent testing environments results in an attack success rate of 86%, reducing the agents' task success rate by 47%. It also notes that simple defense methods, like instructing the agent to ignore pop-ups, prove ineffective.|
|[Multi-expert Prompting Improves Reliability, Safety, and Usefulness of Large Language Models.](https://arxiv.org/abs/2411.00492) |enhances LLM responses by simulating multiple experts and combining their outputs; it directs an LLM to complete input instructions by simulating several experts and choosing the best response from both individual and aggregated perspectives. This approach sets a new state-of-the-art on TruthfulQA-Generation with ChatGPT, surpassing the previous record of 87.97%. Additionally, it improves performance in terms of factuality and usefulness while reducing toxicity and hurtfulness. |
|[Number Cookbook: Number Understanding of Language Models and How to Improve It.](https://arxiv.org/abs/2411.03766) |offers a thorough analysis of the numerical understanding and processing ability (NUPA) of LLMs; reveals that while naive finetuning significantly boosts NUPA on many tasks, it doesn’t work for all. It also finds that methods specifically developed to improve NUPA are ineffective when finetuning pretrained models. The study examines the application of chain-of-thought techniques to NUPA and notes that these methods encounter scalability issues, limiting their practical use. |
|[WebRL: Training LLM Web Agents via Self-Evolving Online Curriculum Reinforcement Learning.](https://arxiv.org/abs/2411.02337) | introduces a self-evolving online curriculum RL framework aimed at closing the performance gap between open and proprietary LLM-based web agents. It boosts the success rate of Llama-3.1-8B from 4.8% to 42.4% and GLM4-9B from 6.1% to 43%, with the open models significantly outperforming GPT-4-Turbo (17.6%) and GPT-4o (13.9%). The framework addresses the limited availability of web agent training tasks using a robust outcome-supervised reward model for task success evaluation. An adaptive RL strategy manages distribution drift in online learning, ensuring steady performance improvements.|
|[Adapting While Learning: Grounding LLMs for Scientific Problems with Intelligent Tool Usage Adaptation.](https://arxiv.org/abs/2411.00412) |introduces a two-stage fine-tuning method where LLMs first learn from tool-generated solutions and then are trained to decide when to solve problems independently versus using tools. Evaluations on benchmarks in math, climate science, and epidemiology demonstrate significant gains, with a 28% increase in accuracy and a 14% improvement in tool usage precision over top models like GPT-4 and Claude-3.5. This approach enables the LLM to flexibly handle scientific problems of varying complexity. |
|[Google's Flood Forecasting AI to Reach 700 Million People.](https://blog.google/technology/ai/expanding-flood-forecasting-coverage-helping-partners/) | Google is expanding riverine flood forecasting coverage to over 100 countries and 700 million people, and enabling partners and researchers to better understand flood forecasting through more data and the development of a new API|
|[Mixture-of-Transformers: A Sparse and Scalable Architecture for Multi-Modal Foundation Models.](https://arxiv.org/abs/2411.04996) |The Mixture-of-Transformers (MoT) architecture features a sparse multi-modal transformer that separates parameters based on modality (text, images, and speech), allowing for efficient processing while preserving performance. In various evaluations, such as Chameleon 7B and Transfusion settings, MoT matches or outperforms dense baselines, utilizing significantly fewer resources—only 37.2% of the FLOPs for speech processing and 47.2% of the wall-clock time for image generation. |
|[Exploring the Alignment Landscape: LLMs and Geometric Deep Models in Protein Representation.](https://arxiv.org/abs/2411.05316v1) | This study investigates methods to enhance alignment between LLMs and protein-focused geometric deep models, aiming to improve cross-modal understanding.|
|[Can LLMs Follow Threads Through Near-Million-Scale Haystacks?](https://needle-threading.github.io/) | Large Language Models (LLMs) with extended context windows support a wider range of applications. Recent research on 17 top LLMs shows that although many can manage multiple information threads simultaneously, their practical context limits are often shorter than the stated maximum. While several models demonstrate "thread-safety" by handling concurrent threads without a drop in performance, accuracy typically decreases as the context window approaches its upper limit.|
|[Compressing Mesh Data for 3D Generation.](https://whaohan.github.io/bpt/) | By reducing the mesh sequence length by about 75%, a mesh compression method known as Blocked and Patchified Tokenization (BPT) effectively produces meshes with more than 8k faces.|
|[Successor Feature Matching.](https://github.com/arnavkj1995/sfm) |A new non-adversarial method for inverse reinforcement learning that avoids reward function learning is called Successor Feature Matching. |
|[Oasis: A Universe in a Transformer.](https://oasis-model.github.io/) | A 500M parameter foundation model without a game engine powers Oasis, a fully AI-generated, real-time open-world video game model. It is tailored for Etched's Sohu ASIC to achieve great frame rate efficiencies and uses quick transformer inference to generate gameplay. Despite showing great promise, issues like long-context consistency and domain generalization still exist.|
|[OpenAI to present plans for U.S. AI strategy and an alliance to compete with China.](https://www.cnbc.com/2024/11/13/openai-to-present-plans-for-us-ai-strategy-and-an-alliance-to-compete-with-china.html) | OpenAI's AI infrastructure blueprint suggests establishing AI economic zones and collaborating with the U.S. Navy on nuclear energy to promote AI-driven economic growth and innovation. The proposal features a North American AI alliance and initiatives modeled after the National Interstate and Defense Highways Act to address infrastructure demands. It stresses the importance of investing in U.S. data centers and energy projects to stay competitive with China.|
|[Introducing Athene-V2: Advancing Beyond the Limits of Scaling with Targeted Post-training.](https://nexusflow.ai/blogs/athene-v2) | Athene V2 consists of models built upon Qwen 2.5 72B, optimized for agentic and chat-based workflows, and outperform GPT-4o on several key benchmarks.|

## News
|Link|description|
|---|---|
|[Modal buys Tidbyt.](https://modal.com/blog/tidbyt-is-joining-modal) |The elastic scaling GPU company made its first acquisition by purchasing Tidbyt, a hardware firm based in NYC, to gain the in-house expertise of its team specializing in infrastructure and containerization. |
|[OpenAI reportedly developing new strategies to deal with AI improvement slowdown.](https://techcrunch.com/2024/11/09/openai-reportedly-developing-new-strategies-to-deal-with-ai-improvement-slowdown/) |OpenAI's forthcoming model, codenamed "Orion," reportedly exhibits only modest improvements over its predecessors, indicating a potential deceleration in AI advancement. To address this, OpenAI has established a foundations team dedicated to enhancing models through alternative approaches, including synthetic data training and post-training adjustments, in response to the diminishing availability of new data. |
|[Near plans to build world’s largest 1.4T parameter open-source AI model.](https://cointelegraph.com/news/near-plans-to-create-world-s-largest-1-4-t-parameter-open-source-ai-model) | Near Protocol has announced plans to develop a 1.4 trillion-parameter open-source AI model, aiming to surpass existing models like Meta's Llama. This initiative reflects Near Protocol's commitment to advancing AI capabilities and contributing to the open-source community.|
|[Samsung debuts AI-powered ‘Next-generation Bixby,’ but you can’t use it yet.](https://9to5google.com/2024/11/06/samsung-next-generation-bixby-china/) |Samsung has launched a "next-generation Bixby" with enhanced AI capabilities on the Galaxy W25 and W25 Flip in China. |
|[Even Microsoft Notepad is getting AI text editing now.](https://www.theverge.com/2024/11/6/24289707/microsoft-notepad-ai-text-editing-rewrite) |Along with adding AI to a text editor that launched in 1983, Microsoft will let Windows Insiders test generative fill-and-erase tools in Paint, too. |
|[Ofcom warns tech firms after chatbots imitate Brianna Ghey and Molly Russell.](https://www.theguardian.com/technology/2024/nov/09/ofcom-warns-tech-firms-after-chatbots-imitate-brianna-ghey-and-molly-russell) | After ‘distressing incidents’, watchdog says content from user-made bots would be covered by UK Online Safety Act|
|[AI protein-prediction tool AlphaFold3 is now open source.](https://www.nature.com/articles/d41586-024-03708-4) |The code underlying the Nobel-prize-winning tool for modelling protein structures can now be downloaded by academics. |
|[Qwen 2.5 Coder 32B Instruct is here.](https://qwenlm.github.io/blog/qwen2.5-coder-family) |The Qwen 2.5 Coder series consists of language models tailored for coding tasks. The latest 32B parameter model outperforms GPT-4o and is compact enough for local use by many. It also matches Claude Sonnet 3.5 on several benchmarks. |
|[X is testing a free version of AI chatbot Grok.](https://techcrunch.com/2024/11/10/x-is-testing-a-free-version-of-ai-chatbot-grok/) |Social network X has so far limited its AI chatbot Grok (built by Elon Musk’s other company xAI) to its premium, paying users. However, the platform is seemingly preparing to open up the chatbot to free users. |
|[Octoverse: AI leads Python to top language as the number of global developers surges.](https://github.blog/news-insights/octoverse/octoverse-2024/) | In this year’s Octoverse report, we study how public and open source activity on GitHub shows how AI is expanding as the global developer community surges in size.|
|[Google accidentally leaked a preview of its Jarvis AI that can take over computers.](https://www.engadget.com/ai/google-accidentally-leaked-a-preview-of-its-jarvis-ai-that-can-take-over-computers-203125686.html) |Google's new AI prototype, Jarvis, briefly appeared on the Chrome Web Store. |
|[AI-powered parenting is here and a16z is ready to back it.](https://techcrunch.com/2024/11/07/ai-powered-parenting-is-here-and-a16z-is-ready-to-back-it/) | Andreessen Horowitz partner Justine Moore introduced a new investment thesis for the firm on X on Thursday, endorsing “a new wave of ‘parenting co-pilots’ built with LLMs and agents.” She pointed to companies like Cradlewise, makers of an AI-powered baby monitor to detect a baby’s sleep pattern and rock the crib, and Nanit, which uses AI to process crib footage to tell if a baby is breathing. |
|[French news titles sue X over allegedly running their content without payment.](https://www.theguardian.com/world/2024/nov/12/french-news-titles-sue-x-over-allegedly-running-their-content-without-payment) | Social media site accused of violating law that requires platforms to pay media when republishing articles|
|[Musk’s influence on Trump could lead to tougher AI standards, says scientist.](https://www.theguardian.com/technology/2024/nov/12/elon-musk-donald-trump-ai-artificial-general-intelligence) |Tycoon might help president-elect realise race for artificial general intelligence is a ‘suicide race’, says Max Tegmark |
|[Bluesky adds 700,000 new members as users flee X after the US election.](https://www.theguardian.com/technology/2024/nov/12/us-election-bluesky-users-flee-x-twitter-trump-musk) | Social media platform has become a ‘refuge’ from the far-right activism on X, experts say, after Elon Musk teamed up with Donald Trump|
|[Baidu announces its own pair of AI smart glasses.](https://www.engadget.com/ai/baidu-announces-its-own-pair-of-ai-smart-glasses-143044805.html) |Baidu, which is often called China's answer to Google, has launched its own pair of AI-powered smart glasses at its annual World Conference event in Shanghai. |
|[OpenAI co-founder Greg Brockman returns after three months of leave.](https://www.cnbc.com/2024/11/12/openai-co-founder-greg-brockman-returns-after-three-months-of-leave.html) | In the midst of major management departures and controversy over OpenAI's transition to a for-profit business model, co-founder Greg Brockman has returned to the company as president after taking a sabbatical. In its most recent fundraising round, OpenAI was valued at $157 billion. Due to the departure of executives like Lilian Weng, Bob McGrew, and Mira Murati, the company is experiencing internal issues.|
|[European Google rivals partner on search engine infrastructure to counter Big Tech.](https://www.cnbc.com/2024/11/12/ecosia-qwant-partner-on-search-engine-tech-to-counter-googles-power.html) |To improve AI skills and lessen dependency on U.S. Big Tech, Ecosia and Qwant are collaborating to create a European search index. Using a "privacy-first" strategy, the project seeks to promote AI developments by developing a new search infrastructure. Since generative AI is becoming more and more prevalent in search, alternative search providers are better positioned to compete as a result of the rising API expenses. |
|[Robotic exoskeleton adapts to changes in leg movements in real time.](https://www.nature.com/articles/d41586-024-03546-4) |Wearable robots that assist leg movements could transform the lives of people with reduced mobility — but only if the devices can adapt in real time to support a vast range of human activities. Machine learning provides a way forward. |
|[OpenAI’s take on AI agents could come in January.](https://techcrunch.com/2024/11/13/openais-take-on-ai-agents-could-come-in-january/) | OpenAI is reportedly preparing to launch "Operator," an AI agent tool, as early as January. Bloomberg states that Operator may be able to execute tasks directly on a user's computer. It will initially be accessible as a research preview through OpenAI's developer API.|
|[Google's AI Initiative to Boost MENA Economy by $320 Billion.](https://blog.google/around-the-globe/google-middle-east/ai-opportunity-initiative-middle-east-north-africa/) |Google.org has launched the AI Opportunity Initiative, its largest AI investment in the Middle East and North Africa (MENA) region, aiming to develop essential AI skills, fund research, and expand AI access. This initiative is projected to contribute $320 billion to MENA's economy by 2030 |
|[Two Trillion Token Common Corpus.](https://huggingface.co/blog/Pclanglais/two-trillion-tokens-open) | the release of Common Corpus (part of the AI Alliance Open Trusted Data Initiative)—the largest fully open multilingual dataset for training LLMs, containing over 2 trillion tokens of permissibly licensed content with provenance information (2,003,039,184,047 tokens).|
|[Lume raises $4.2M Seed Round led by General Catalyst.](https://lume.ai/blog/lume-raises-4-2m-seed-round-led-by-general-catalyst) | Lume automates data mapping with AI, streamlining mapping, cleaning, and validation of data.|
|[Amazon launches under-$20 online storefront to compete with Temu.](https://www.theguardian.com/technology/2024/nov/13/amazon-haul-low-cost-storefront-temu-shein) | Company says Amazon Haul will mostly feature products under $10, which it plans to ship from China warehouse|
|[Francois Chollet leaves Google.](https://developers.googleblog.com/en/farewell-and-thank-you-for-the-continued-partnership-francois-chollet/) |The founder of Keras and Arc eval, among other contributions, has departed from Google. He will continue to support the Jax and Keras communities while exploring new opportunities. |
|[OpenAI launches ChatGPT desktop integrations, rivaling Copilot.](https://venturebeat.com/ai/openai-launches-chatgpt-desktop-integrations-rivaling-copilot/) | When OpenAI released desktop app versions of ChatGPT, it was clear the goal was to get more users to bring ChatGPT into their daily workflows. Now, new updates to Mac OS and Windows PC versions encourage users to stay in the ChatGPT apps for most of their tasks. |
|[Supermaven joins Cursor.](https://supermaven.com/blog/cursor-announcement) |The team behind the code editing plugin is joining Cursor to further enhance the user experience. |
|[Google’s AI ‘learning companion’ takes chatbot answers a step further.](https://www.theverge.com/2024/11/11/24293891/google-learn-about-ai-search-educational) |Google’s Learn About AI tool has more educational, textbook-style responses to guide you through new topics. |

## Resources
|Link|description|
|---|---|
|[FrontierMath.](https://epochai.org/frontiermath) |Epoch AI has introduced FrontierMath, a benchmark comprising expert-level mathematics problems to assess AI's mathematical reasoning capabilities. Notably, leading AI models have solved less than 2% of these problems, highlighting the benchmark's difficulty and the current limitations of AI in advanced mathematical reasoning. |
|[BitNet a4.8: 4-bit Activations for 1-bit LLMs.](https://arxiv.org/abs/2411.04965) | A major challenge with 1.58bit LLMs has been the absence of hardware acceleration support. This research introduces 4.8bit activations to leverage the INT4/FP4 kernels available in new hardware, achieving this with no added runtime cost.|
|[LLM2CLIP.](https://microsoft.github.io/LLM2CLIP/) | LLM2CLIP combines CLIP's visual and textual alignment with the advanced language understanding of LLMs.|
|[Torch Compatible Muon Optimizer.](https://github.com/KellerJordan/Muon) | Muon is the optimizer that set the training record for GPT-2. It is a momentum-adapted method similar to SGD. This repository provides an implementation that can be easily used as a replacement for AdamW.|
|[Mochi video model with optimized inference.](https://github.com/xdit-project/mochi-xdit) |Mochi 1, an open-source text-to-video model, initially required eight H100 GPUs for operation. Thanks to community efforts, it can now run on a single 48GB L40 GPU without compromising quality. |
|[A trainable PyTorch reproduction of AlphaFold 3.](https://github.com/bytedance/Protenix) | Protenix is a functional and trainable reproduction of AlphaFold 3, DeepMind's protein folding project, developed by ByteDance's 'AI for Science' team. This open-source initiative aims to advance protein structure prediction by providing a customizable platform for researchers.|
|[LlamaPReview.](https://github.com/marketplace/llamapreview) | LlamaPReview is an AI assistant for GitHub that provides easy one-click installation and automatically reviews pull requests with context-aware analysis. It supports various programming languages and integrates seamlessly with GitHub Actions, delivering insightful feedback directly on PRs. Offered for free, it improves code quality by detecting issues and recommending optimizations.|
|[SmolLM2.](https://simonwillison.net/2024/Nov/2/smollm2/) | Hugging Face's SmolLM2 is a compact family of language models, ranging from 135M to 1.7B parameters, trained on 11 trillion tokens. These models are designed to run efficiently on-device and support various tasks. The weights are released under the Apache 2 license, and quantized versions, such as the 1.7GB and 138MB models, offer flexibility to meet different computational requirements.|
|[AI for Real-time Fusion Plasma Behavior Prediction and Manipulation.](https://control.princeton.edu/machine-learning-for-rt-profile-control-in-tokamaks/) |A novel multimodal machine learning approach improves super-resolution data, enabling better analysis of complex fusion plasma phenomena like Edge Localized Modes (ELM), and supports the stabilization of future fusion reactors. |
|[A Comprehensive Survey of Small Language Models in the Era of Large Language Models.](https://arxiv.org/abs/2411.03350) | a review of small language models (SLMs), covering topics such as definitions, applications, improvements, reliability, and related concerns.|
|[Magentic-One: A Generalist Multi-Agent System for Solving Complex Tasks.](https://www.microsoft.com/en-us/research/publication/magentic-one-a-generalist-multi-agent-system-for-solving-complex-tasks/) | A new generalist multi-agent system capable of managing complex web and file-based tasks, featuring an Orchestrator agent that coordinates four specialized agents: WebSurfer for browser tasks, FileSurfer for file management, Coder for programming, and ComputerTerminal for console operations. Magentic-One performs competitively on various benchmarks, such as GAIA, AssistantBench, and WebArena, without needing any changes to its core architecture.|
|[Personalization of Large Language Models: A Survey.](https://arxiv.org/abs/2411.00027) |offers a comprehensive framework for understanding personalized LLMs, introducing taxonomies for various personalization aspects and consolidating existing research in personalized text generation and downstream applications. |
|[StdGEN: Semantic-Decomposed 3D Character Generation from Single Images.](https://stdgen.github.io/) | StdGen is a novel approach for generating 3D characters from a single image. It breaks down the process into distinct components, such as hair and jackets, enhancing the overall quality of the output.|
|[alphafold3.](https://github.com/google-deepmind/alphafold3) | DeepMind has open-sourced the code and weights of AlphaFold 3 for academic research, marking a significant advancement in protein structure prediction. This release is expected to accelerate AI applications in scientific research, particularly in molecular biology and drug discovery.|
|[Online-LoRA.](https://github.com/christina200/online-lora-official) |Online-LoRA is a framework developed to mitigate catastrophic forgetting in online continual learning (OCL) by enabling real-time fine-tuning of pre-trained Vision Transformers (ViTs) without the use of rehearsal buffers. |
|[DeepArUco++: Improved detection of square fiducial markers in challenging lighting conditions.](https://arxiv.org/abs/2411.05552v1) |DeepArUco++ presents a deep learning-based method for enhancing fiducial marker detection, especially in difficult lighting conditions where traditional techniques typically struggle. |
|[Hermes 3.](https://nousresearch.com/hermes3/) | Hermes 3, fine-tuned from Llama 3.1, excels in both reasoning and creativity, showcasing outstanding performance across models with 8B, 70B, and 405B parameters. It introduces new possibilities in AI alignment and artificial consciousness.|
|[ENAT: Rethinking Spatial-temporal Interactions in Token-based Image Synthesis.](https://arxiv.org/abs/2411.06959v1) |To improve the speed and quality of token-based picture production, EfficientNAT is an improved non-autoregressive Transformer model. |
|[UniGAD: Unifying Multi-level Graph Anomaly Detection.](https://arxiv.org/abs/2411.06427v1) |A novel framework for graph anomaly detection (GAD), UniGAD simultaneously detects anomalies in nodes, edges, and complete graphs. |
|[Object and Attribute Matching in Images with Token Merging.](https://github.com/hutaihang/tome) | Token Merging tackles a prevalent problem in text-to-image models: semantic binding, or the inability to associate things with their particular properties.|
|[DataChain.](https://github.com/iterative/datachain) |Without abstracting AI models, DataChain is a Pythonic data-frame toolkit for AI that enables effective processing and dataset structuring of unstructured data. It facilitates the creation of metadata, filtering, and vector search by integrating with AI tools like PyTorch, TensorFlow, and LLM APIs. Additionally, the library has built-in vectorized operations on Python object fields, out-of-memory computation, and parallelization. |
|[browser-use.](https://github.com/gregpr07/browser-use) |Through a streamlined UI, this open-source web automation application enables LLMs to communicate with websites. It is compatible with models such as Claude 3.5 Sonnet and GPT-4o. XPath extraction, customisable actions, and multi-tab management are important features. Data extraction and smooth web navigation are made possible by the program. Message length is one of its drawbacks, as it impacts task repetition and LLM speed. Robustness and cost reduction will be the main goals of further development. |
|[CUDA Programming Course – High-Performance Computing with GPUs.](https://www.youtube.com/watch?v=86FAWCzIe_4&ab_channel=freeCodeCamp.org) |A great course from freeCodeCamp on CUDA programming from start to finish. |
|[Masked Token Modeling for Zero-Shot Anything-to-Drums Conversion.](https://oreillyp.github.io/tria/) |Zero-shot drum style transfer for any input rhythm presents an exciting music application for artists. This is achieved using a masked token modeling objective, which is particularly effective for audio. |
|[HiCoM: Hierarchical Coherent Motion for Streamable Dynamic Scene with 3D Gaussian Splatting.](https://arxiv.org/abs/2411.07541v1) |HiCoM is a cutting-edge framework designed to enhance real-time 3D reconstruction from multi-view streaming videos. It effectively addresses key challenges in storage, training speed, and rendering quality, making it a significant advancement in the field. |
|[Janus.](https://github.com/deepseek-ai/Janus) |Janus, DeepSeek's multimodal model, has a new version incorporating rectified flows, similar to Meta Movie Gen, for image generation and understanding. The results are highly impressive. |
|[Link Conversation with Reference Materials.](https://github.com/rosewang2008/posr) |Problem-Oriented Segmentation & Retrieval (POSR) is a method that breaks conversations into meaningful segments and connects each segment to relevant reference materials, like worksheets or meeting notes. |
|[MureObjectStitch: Multi-reference Image Composition.](https://arxiv.org/abs/2411.07462v1) |Researchers have presented an improved fine-tuning method for generative image composition, which seamlessly merges a specified foreground object with a new background to generate realistic images. |
|[StoryTeller.](https://github.com/hyc2026/StoryTeller) | StoryTeller is a system created to generate coherent descriptions for long videos, tackling issues like plot consistency and character tracking throughout different scenes.|
|[SAMPart3D: Segment Any Part in 3D Objects.](https://yhyang-myron.github.io/SAMPart3D-website/) | SAMPart3D, developed by the University of Hong Kong, is a robust method for segmenting 3D objects into semantically meaningful components.|
|[Convolutional Differentiable Logic Gate Networks.](https://arxiv.org/abs/2411.04732) | 
Researchers have developed a method to train image recognition networks that are 29 times smaller and more efficient than traditional convolutional neural networks (CNNs) by making logic gates differentiable. They have also provided efficient CUDA kernels in their paper release|
|[Physics Informed Distillation for Diffusion Models.](https://arxiv.org/abs/2411.08378v1) |Physics Informed Distillation (PID) is a method that employs a student model to simplify and accelerate diffusion models by framing them as solutions to differential equations. |
|[MinerU: high-quality data extraction tool.](https://github.com/opendatalab/MinerU) | MinerU is a robust tool built on StructTable-InternVL2-1B, enabling the extraction of information from PDFs into various machine-readable formats.|
|[Isotonic regression.](https://josephsalmon.eu/blog/isotonic/) |A powerful technique for fitting a monotonic function to data. It can be differentiated really well for a number of applications outside of curve fitting. |
|[Text-to-SQL Query.](https://github.com/XGenerationLab/XiYan-SQL) |XiYan-SQL is an innovative framework aimed at enhancing both the accuracy and diversity of SQL queries produced from natural language input. |
|[X-Portrait 2: Highly Expressive Portrait Animation.](https://byteaigc.github.io/X-Portrait2/) | ByteDance's AI group has unveiled X-Portrait 2, an advanced portrait animation technology that transforms static images into highly expressive, realistic videos. Building upon its predecessor, X-Portrait, this new model excels in capturing subtle facial expressions and complex movements, such as pouting, tongue-out gestures, cheek-puffing, and frowning. It achieves high fidelity in emotion preservation, ensuring the generated videos maintain the subject's identity and emotional nuances.|
|[MVSplat360: Feed-Forward 360 Scene Synthesis from Sparse Views.](https://donydchen.github.io/mvsplat360/) |The MVSplat360 model offers a new way to create realistic 360° views of real-world scenes, even from just a few sparse images. |
|[Improved Multi-Task Brain Tumour Segmentation with Synthetic Data Augmentation.](https://arxiv.org/abs/2411.04632v1) | This paper presents the leading approach for brain tumor segmentation in the BraTS challenge, demonstrating how synthetic data can improve AI models for medical imaging applications.|

## Perspectives
|Link|description|
|---|---|
|[Embeddings are underrated.](https://technicalwriting.dev/data/embeddings.html) | Machine learning embeddings can revolutionize technical writing by enabling mathematical comparisons of any text, enhancing features like recommendation systems through semantic similarities. By positioning text in a multi-dimensional space, they reveal intuitive semantic relationships, which are valuable for tasks such as finding related content. Documentation site owners who provide embeddings for their content could inspire innovative applications from their communities.|
|[The images of Spain’s floods weren’t created by AI. The trouble is, people think they were.](https://www.theguardian.com/commentisfree/2024/nov/09/the-images-of-spains-floods-werent-created-by-ai-the-trouble-is-people-think-they-were) |The rapid growth of ‘AI slop’ – content created by artificial tools – is starting to warp our perception of what is, or could be, real |
|[What Trump’s election win could mean for AI, climate and health.](https://www.nature.com/articles/d41586-024-03667-w) |Donald Trump made numerous promises during his presidential campaign that could affect scientists and science policy. Will they be implemented once he is president? |
|[The case for targeted regulation.](https://www.anthropic.com/news/the-case-for-targeted-regulation) | Advancements in AI are significantly enhancing capabilities in mathematics, coding, and science, presenting both opportunities and risks. Effective regulation is crucial to prevent misuse in areas such as cybersecurity and chemical, biological, radiological, and nuclear (CBRN) threats. Anthropic's Responsible Scaling Policy emphasizes transparency and advocates for a balanced legislative approach that ensures safety while fostering innovation. |
|[AI-powered parenting is here and a16z is ready to back it .](https://techcrunch.com/2024/11/07/ai-powered-parenting-is-here-and-a16z-is-ready-to-back-it/) | Andreessen Horowitz partner Justine Moore introduced a new investment thesis for the firm on X on Thursday, endorsing “a new wave of ‘parenting co-pilots’ built with LLMs and agents.” She pointed to companies like Cradlewise, makers of an AI-powered baby monitor to detect a baby’s sleep pattern and rock the crib, and Nanit, which uses AI to process crib footage to tell if a baby is breathing. |
|[Speculation on Test Time Compute.](https://www.youtube.com/watch?v=6PEJ96k1kiw&ab_channel=SashaRush%F0%9F%A4%97) | This video discusses O1 models, their capacity for replication, and their potential utility for a range of future tasks.|
|[Can AI review the scientific literature — and figure out what it all means?](https://www.nature.com/articles/d41586-024-03676-9) |Artificial intelligence could help speedily summarize research. But it comes with risks. |
|[Why we are all lab rats in the digital world.](https://www.nature.com/articles/d41586-024-03674-x) |Researchers need to establish robust ethical protocols for online experiments. |
|[Don’t blame search engines for sending users to unreliable sites.](https://www.nature.com/articles/d41586-024-03574-0) |Analysis of billions of pages of results from searches using the Bing algorithm suggests that reliable sites appear in search results 19 to 45 times more often than do sites with low-quality content. |
|[AI-generated images threaten science — here’s how researchers hope to spot them.](https://www.nature.com/articles/d41586-024-03542-8) | Generative-AI technologies can create convincing scientific data with ease — publishers and integrity specialists fear a torrent of faked science.|
|[The quest to build bionic limbs that feel like the real thing.](https://www.nature.com/articles/d41586-024-03675-w) | Through brain implants, neural interfaces and skin grafts, researchers are starting to restore sensation for paralysed or amputated limbs.|
|[How AI is reshaping science and society.](https://www.nature.com/articles/d41586-024-03679-6) | Artificial-intelligence tools such as ChatGPT might soon become fully autonomous by learning to perceive and interact with their environment.|
|[‘It gets more and more confused’: can AI replace translators?](https://www.theguardian.com/books/2024/nov/11/it-gets-more-and-more-confused-can-ai-replace-translators) |A Dutch publisher has announced that it will use AI to translate some of its books – but those in the industry are worried about the consequences if this becomes the norm |
|[StackBlitz achieves $4M ARR in 4 weeks for their AI web development platform with Claude.](https://www.anthropic.com/customers/stackblitz) |StackBlitz developed an online developer tool that integrates closely with Claude 3.5 Sonnet. This post details how the company achieved $4 million in annual recurring revenue within a few months. |
|[Why the deep learning boom caught almost everyone by surprise.](https://www.understandingai.org/p/why-the-deep-learning-boom-caught) |Fei-Fei Li's development of the extensive ImageNet dataset played a crucial role in the revival of neural networks. It supplied the training data essential for landmark models such as AlexNet. Using GPUs and Geoffrey Hinton's backpropagation method, AlexNet showcased the potential of deep learning on large datasets, igniting the current AI revolution. This key event highlighted the significance of integrating neural networks, big data, and GPU computing to drive AI advancements. |
|[Just Have AI Build an App for That.](https://davidgomes.com/just-have-ai-build-an-app-for-that/) | AI agents are increasingly being used to quickly create functional apps for tasks like resizing SVGs.|
|[AI isn’t about unleashing our imaginations, it’s about outsourcing them. The real purpose is profit.](https://www.theguardian.com/technology/2024/nov/16/ai-isnt-about-unleashing-our-imaginations-its-about-outsourcing-them-the-real-purpose-is-profit) |Artificial intelligence doesn’t just incrementally erode the rights of authors and other creators. These technologies are designed to replace creative workers altogether |
|[Companies building AI-powered tech are using your posts. Here’s how to opt out.](https://www.theguardian.com/technology/2024/nov/15/x-ai-gmail-meta-privacy-settings) | ven if you haven’t knowingly opted in, companies are still scraping your personal information to train their systems|


















































































